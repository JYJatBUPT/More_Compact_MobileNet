{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1D卷积  ---等效于CNN做文本分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://op4a94iq8.bkt.clouddn.com/18-7-13/49813055.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: torch.Size([5, 2, 10])\n",
      "output size: torch.Size([5, 3, 4])\n",
      "filter size: torch.Size([3, 2, 4])\n",
      "<built-in method type of Parameter object at 0x7f3134527798>\n"
     ]
    }
   ],
   "source": [
    "# --------------------------- 1D 卷积 实例 ---------------------------------\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "m = nn.Conv1d(2, 3, 4, stride=2,padding=0,groups=1,dilation=1)\n",
    "\n",
    "input = torch.randn(5, 2, 10)\n",
    "print(\"input size:\",input.shape)\n",
    "\n",
    "output = m(input)\n",
    "print(\"output size:\",output.shape)\n",
    "\n",
    "print(\"filter size:\",m.weight.shape)\n",
    "print(m.weight.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: torch.Size([1, 512, 14, 14])\n",
      "<built-in method type of Tensor object at 0x7f30d1ec9af8>\n",
      "output size: torch.Size([1, 512, 1, 1])\n",
      "avg size: torch.Size([1, 1, 512])\n",
      "out_1 size: torch.Size([1, 1024, 512])\n",
      "filter size: torch.Size([1024, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# pool of non-square window\n",
    "input = torch.randn(1, 512, 14, 14) # batch_size=1\n",
    "print(\"input size:\",input.shape)\n",
    "print(input.type)\n",
    "\n",
    "m = nn.AvgPool2d(14)\n",
    "\n",
    "output = m(input)\n",
    "print(\"output size:\",output.shape)\n",
    "\n",
    "avg=output.view(output.shape[0],1,output.shape[1])\n",
    "print(\"avg size:\",avg.shape)\n",
    "\n",
    "one_conv_filter = nn.Conv1d(1, 1024, 3, stride=1,padding=1,groups=1,dilation=1)\n",
    "\n",
    "out_1 = one_conv_filter(avg)\n",
    "print(\"out_1 size:\",out_1.shape)\n",
    "print(\"filter size:\",one_conv_filter.weight.shape)\n",
    "\n",
    "\n",
    "# --------------------- 加权融合 -----------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y size: torch.Size([2, 3, 1, 1])\n",
      "X size: torch.Size([3, 2, 2])\n",
      "torch.Size([2, 3, 2, 2])\n",
      "tensor([[[  0.2000,   0.2000],\n",
      "         [  0.2000,   0.2000]],\n",
      "\n",
      "        [[  0.8000,   0.8000],\n",
      "         [  0.8000,   0.8000]],\n",
      "\n",
      "        [[ 30.0000,  30.0000],\n",
      "         [ 30.0000,  30.0000]]])\n",
      "torch.Size([2, 2, 2])\n",
      "tensor([[[ 10.5000,  10.5000],\n",
      "         [ 10.5000,  10.5000]],\n",
      "\n",
      "        [[ 31.0000,  31.0000],\n",
      "         [ 31.0000,  31.0000]]])\n"
     ]
    }
   ],
   "source": [
    "# 不考虑batchsize时实现了1x1卷积\n",
    "y=torch.Tensor(\n",
    "    [\n",
    "       [[[0.1]],[[0.7]],[[3]],],\n",
    "       [[[0.2]],[[0.4]],[[10]],]\n",
    "    ])\n",
    "\n",
    "print(\"Y size:\",y.shape)\n",
    "\n",
    "x=torch.Tensor(\n",
    "    [\n",
    "        [[1,1,],[1,1,],],\n",
    "        \n",
    "        [[2,2,],[2,2,],],\n",
    "        \n",
    "        [[3,3,],[3,3,],],\n",
    "    ])\n",
    "\n",
    "print(\"X size:\",x.shape)\n",
    "\n",
    "out=x*y\n",
    "print(out.shape)\n",
    "print(out[1]) \n",
    "\n",
    "# ----------------- 聚合 ----------\n",
    "res=out.sum(dim=1)\n",
    "print(res.shape)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 改造版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 32  缩放5次到 1x1@1024 \n",
    "# From https://github.com/kuangliu/pytorch-cifar \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def Attention(X):\n",
    "    # [bs,in_Channel,in_H,in_W]\n",
    "    m = nn.AvgPool2d(X.shape[-1])  #最好在初始化层定义好\n",
    "    # [bs,in_Channel,1,1]\n",
    "    out=m(X)\n",
    "    out=out.view(out.shape[0],1,output.shape[1])\n",
    "    \n",
    "    one_conv_filter = nn.Conv1d(1, out_channel, 3, stride=1,padding=1,groups=1,dilation=1)\n",
    "\n",
    "    out = one_conv_filter(out)\n",
    "    \n",
    "    \n",
    "\n",
    "class Block(nn.Module):\n",
    "    '''Depthwise conv + Pointwise conv'''\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        \n",
    "        # 分组卷积数=输入通道数\n",
    "        self.conv1 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=in_planes, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        \n",
    "        \n",
    "        self.conv2 = \n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        \n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        \n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    # (128,2) means conv planes=128, conv stride=2, by default conv stride=1\n",
    "    cfg = [64, (128,2), 128, (256,2), 256, (512,2), 512, 512, 512, 512, 512, (1024,2), 1024]\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layers = self._make_layers(in_planes=32) # 自动化构建层\n",
    "        self.linear = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        layers = []\n",
    "        for x in self.cfg:\n",
    "            out_planes = x if isinstance(x, int) else x[0]\n",
    "            stride = 1 if isinstance(x, int) else x[1]\n",
    "            layers.append(Block(in_planes, out_planes, stride))\n",
    "            in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 原来版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 32  缩放5次到 1x1@1024 \n",
    "# From https://github.com/kuangliu/pytorch-cifar \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    '''Depthwise conv + Pointwise conv'''\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        \n",
    "        # 分组卷积数=输入通道数\n",
    "        self.conv1 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=in_planes, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        \n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        return out\n",
    "\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    # (128,2) means conv planes=128, conv stride=2, by default conv stride=1\n",
    "    cfg = [64, (128,2), 128, (256,2), 256, (512,2), 512, 512, 512, 512, 512, (1024,2), 1024]\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layers = self._make_layers(in_planes=32) # 自动化构建层\n",
    "        self.linear = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        layers = []\n",
    "        for x in self.cfg:\n",
    "            out_planes = x if isinstance(x, int) else x[0]\n",
    "            stride = 1 if isinstance(x, int) else x[1]\n",
    "            layers.append(Block(in_planes, out_planes, stride))\n",
    "            in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
