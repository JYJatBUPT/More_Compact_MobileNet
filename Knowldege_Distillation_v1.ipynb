{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1,\n",
    "                          stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------- 在面试之前把这段代码背下来 ------------------------------------------------\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes: # 利用1x1卷积对齐高和宽 对齐输出通道数\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1,\n",
    "                          stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = ResNet50()\n",
    "    print(net)\n",
    "    y = net(torch.randn(4, 3, 32, 32))\n",
    "    print(y.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 32  缩放5次到 1x1@1024 \n",
    "# From https://github.com/kuangliu/pytorch-cifar \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    '''Depthwise conv + Pointwise conv'''\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        \n",
    "        # 分组卷积数=输入通道数\n",
    "        self.conv1 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=in_planes, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        return out\n",
    "\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    # (128,2) means conv planes=128, conv stride=2, by default conv stride=1\n",
    "    # cfg = [64, (128,2), 128, (256,2), 256, (512,2), 512, 512, 512, 512, 512, (1024,2), 1024]\n",
    "    # cfg = [64, (128,2), 128, (256,2), 256, (512,2), 512, 512, 512, 512, 512, (1024,2), (1024,1)]\n",
    "    #cfg = [48, (96,2), 96, (192,2), 192, (384,2), 384, 384, 384, 384, 384, (768,2), (1024,1)]\n",
    "    cfg = [64, (128,2), 128, 256, 256, (512,2), 512, 512, 512, 512, 512,1024,1024]\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layers = self._make_layers(in_planes=32) # 自动化构建层\n",
    "        self.linear = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        layers = []\n",
    "        for x in self.cfg:\n",
    "            if isinstance(x, int):\n",
    "                out_planes = x\n",
    "                stride = 1 \n",
    "                layers.append(Block(in_planes, out_planes, stride))\n",
    "            elif isinstance(x, tuple):\n",
    "                out_planes = x[0]\n",
    "                stride = x[1]\n",
    "                layers.append(Block(in_planes, out_planes, stride))\n",
    "            # AC层通过list存放设置参数\n",
    "            elif isinstance(x, list):\n",
    "                out_planes= x[0]\n",
    "                stride = x[1] if len(x)==2 else 1\n",
    "                layers.append(Block_Attention(in_planes, out_planes, stride))   \n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            in_planes = out_planes\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        #print(\"X\",out.shape)\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class BANUpdater(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.model = kwargs.pop(\"model\")\n",
    "        self.optimizer = kwargs.pop(\"optimizer\")\n",
    "        self.n_gen = kwargs.pop(\"n_gen\")\n",
    "        self.last_model = None\n",
    "        self.gen = 0\n",
    "\n",
    "    def update(self, inputs, targets, criterion):\n",
    "        self.optimizer.zero_grad()\n",
    "        outputs = self.model(inputs)\n",
    "        \n",
    "        if self.gen > 0:\n",
    "            teacher_outputs = self.last_model(inputs).detach()\n",
    "            loss = self.kd_loss(outputs, targets, teacher_outputs)\n",
    "        else:\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss\n",
    "\n",
    "    def register_last_model(self, weight):\n",
    "        if weight==\"\":\n",
    "            return\n",
    "        # ------------------------------------ 匹配正确 --------------------------------------------------\n",
    "        self.last_model =MobileNet(10)#ResNet18()# LeNet() #ResNet50() \n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            device = \"cpu\"\n",
    "        self.last_model.to(device)\n",
    "        \n",
    "        state=torch.load(weight)\n",
    "        self.last_model.load_state_dict(state)\n",
    "        \n",
    "        \n",
    "    \n",
    "    # ------------------------------------ 核心 Loss 计算 ------------------------------------------------\n",
    "    def kd_loss(self, outputs, labels, teacher_outputs, alpha=0.9, T=20):\n",
    "        KD_loss = nn.KLDivLoss()(F.log_softmax(outputs/T, dim=1),\n",
    "                                 F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T) + \\\n",
    "                                 F.cross_entropy(outputs, labels) * (1. - alpha)\n",
    "\n",
    "        return KD_loss\n",
    "\n",
    "    def __model(self):\n",
    "        return self.model\n",
    "\n",
    "    def __last_model(self):\n",
    "        return self.last_model\n",
    "\n",
    "    def __gen(self):\n",
    "        return self.gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "\n",
    "    def print_args(self):\n",
    "        print(\"weight: \", self.args.weight)\n",
    "        print(\"lr: \", self.args.lr)\n",
    "        print(\"n_epoch: \", self.args.n_epoch)\n",
    "        print(\"batch_size: \", self.args.batch_size)\n",
    "        print(\"n_gen: \", self.args.n_gen)\n",
    "        print(\"dataset: \", self.args.dataset)\n",
    "        print(\"outdir: \", self.args.outdir)\n",
    "        print(\"print_interval: \", self.args.print_interval)\n",
    "\n",
    "    def print_log(self, epoch, it, train_loss, val_loss,accuracy):\n",
    "        print(\"epoch: {}, iter: {}, train_loss: {}, test_loss: {},test accuracy: {}%\".format(\n",
    "            epoch, it, train_loss, val_loss,accuracy\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight:  None\n",
      "lr:  0.01\n",
      "n_epoch:  110\n",
      "batch_size:  256\n",
      "n_gen:  4\n",
      "dataset:  cifar10\n",
      "outdir:  snapshots\n",
      "print_interval:  500\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "40\n",
      "train...\n",
      "escaped time of this epoch:27.33865761756897\n",
      "epoch: 0, iter: 196, train_loss: 1.5186141048158919, test_loss: 1.181091320514679,test accuracy: 57.26%\n",
      "escaped time of this epoch:54.60605502128601\n",
      "epoch: 1, iter: 392, train_loss: 0.9834637252651915, test_loss: 0.9323847070336342,test accuracy: 67.87%\n",
      "escaped time of this epoch:81.70118522644043\n",
      "epoch: 2, iter: 588, train_loss: 0.750357023915466, test_loss: 0.7779528856277466,test accuracy: 73.53%\n",
      "escaped time of this epoch:108.90068888664246\n",
      "epoch: 3, iter: 784, train_loss: 0.6249317137562499, test_loss: 0.6175604403018952,test accuracy: 79.02%\n",
      "escaped time of this epoch:136.0862214565277\n",
      "epoch: 4, iter: 980, train_loss: 0.5364558488434675, test_loss: 0.617492663115263,test accuracy: 79.81%\n",
      "escaped time of this epoch:163.26309895515442\n",
      "epoch: 5, iter: 1176, train_loss: 0.4808261374733886, test_loss: 0.5845616981387138,test accuracy: 80.14%\n",
      "escaped time of this epoch:190.36377429962158\n",
      "epoch: 6, iter: 1372, train_loss: 0.4391590689822119, test_loss: 0.5488559179008007,test accuracy: 81.23%\n",
      "escaped time of this epoch:238.81249237060547\n",
      "epoch: 7, iter: 1568, train_loss: 0.4016912316485327, test_loss: 0.5818689070641995,test accuracy: 80.95%\n",
      "escaped time of this epoch:265.9616713523865\n",
      "epoch: 8, iter: 1764, train_loss: 0.3878211836729731, test_loss: 0.557329349219799,test accuracy: 81.87%\n",
      "escaped time of this epoch:293.10563707351685\n",
      "epoch: 9, iter: 1960, train_loss: 0.3652659209103, test_loss: 0.5277760997414589,test accuracy: 82.64%\n",
      "escaped time of this epoch:320.26579451560974\n",
      "epoch: 10, iter: 2156, train_loss: 0.3491993408878239, test_loss: 0.5141641400754452,test accuracy: 83.5%\n",
      "escaped time of this epoch:347.3403127193451\n",
      "epoch: 11, iter: 2352, train_loss: 0.341167827573966, test_loss: 0.5211399495601654,test accuracy: 82.64%\n",
      "escaped time of this epoch:374.47327399253845\n",
      "epoch: 12, iter: 2548, train_loss: 0.3218648073320486, test_loss: 0.5316065452992916,test accuracy: 82.82%\n",
      "escaped time of this epoch:401.6505534648895\n",
      "epoch: 13, iter: 2744, train_loss: 0.3164706766149219, test_loss: 0.4823790416121483,test accuracy: 84.33%\n",
      "escaped time of this epoch:428.75945353507996\n",
      "epoch: 14, iter: 2940, train_loss: 0.2987463692469256, test_loss: 0.48106962665915487,test accuracy: 84.26%\n",
      "escaped time of this epoch:455.8556513786316\n",
      "epoch: 15, iter: 3136, train_loss: 0.2987890188791314, test_loss: 0.5081530883908272,test accuracy: 83.35%\n",
      "escaped time of this epoch:483.0388765335083\n",
      "epoch: 16, iter: 3332, train_loss: 0.2870582521569972, test_loss: 0.5238180309534073,test accuracy: 83.32%\n",
      "escaped time of this epoch:510.1775767803192\n",
      "epoch: 17, iter: 3528, train_loss: 0.2828170264101758, test_loss: 0.5120186015963555,test accuracy: 83.45%\n",
      "escaped time of this epoch:537.2473165988922\n",
      "epoch: 18, iter: 3724, train_loss: 0.28385828100905125, test_loss: 0.4954197458922863,test accuracy: 84.33%\n",
      "escaped time of this epoch:564.3782832622528\n",
      "epoch: 19, iter: 3920, train_loss: 0.2825922456626989, test_loss: 0.5095452971756458,test accuracy: 83.9%\n",
      "escaped time of this epoch:591.5063302516937\n",
      "epoch: 20, iter: 4116, train_loss: 0.2711813996488951, test_loss: 0.5301295422017575,test accuracy: 82.95%\n",
      "escaped time of this epoch:618.6253831386566\n",
      "epoch: 21, iter: 4312, train_loss: 0.28166898020676207, test_loss: 0.48906625509262086,test accuracy: 84.61%\n",
      "escaped time of this epoch:645.7214314937592\n",
      "epoch: 22, iter: 4508, train_loss: 0.2732647277262746, test_loss: 0.5180263020098209,test accuracy: 83.84%\n",
      "escaped time of this epoch:672.9083335399628\n",
      "epoch: 23, iter: 4704, train_loss: 0.272777865051615, test_loss: 0.4919652625918388,test accuracy: 84.2%\n",
      "escaped time of this epoch:700.0726020336151\n",
      "epoch: 24, iter: 4900, train_loss: 0.26132599051509586, test_loss: 0.5030005909502506,test accuracy: 84.5%\n",
      "escaped time of this epoch:727.1602222919464\n",
      "epoch: 25, iter: 5096, train_loss: 0.2625501280536457, test_loss: 0.5078375190496445,test accuracy: 84.02%\n",
      "escaped time of this epoch:754.2717485427856\n",
      "epoch: 26, iter: 5292, train_loss: 0.2602670484659623, test_loss: 0.5125049956142902,test accuracy: 83.86%\n",
      "escaped time of this epoch:781.4634296894073\n",
      "epoch: 27, iter: 5488, train_loss: 0.26536592886764176, test_loss: 0.47083415240049364,test accuracy: 84.85%\n",
      "escaped time of this epoch:808.5246217250824\n",
      "epoch: 28, iter: 5684, train_loss: 0.2632161706533967, test_loss: 0.48078045547008513,test accuracy: 84.72%\n",
      "escaped time of this epoch:835.6307857036591\n",
      "epoch: 29, iter: 5880, train_loss: 0.25588748239132825, test_loss: 0.5159078627824784,test accuracy: 83.83%\n",
      "escaped time of this epoch:862.7734725475311\n",
      "epoch: 30, iter: 6076, train_loss: 0.2648805226294362, test_loss: 0.495941311866045,test accuracy: 83.96%\n",
      "escaped time of this epoch:889.8391358852386\n",
      "epoch: 31, iter: 6272, train_loss: 0.255353997632557, test_loss: 0.5090912386775017,test accuracy: 84.58%\n",
      "escaped time of this epoch:916.9549345970154\n",
      "epoch: 32, iter: 6468, train_loss: 0.2593215032651716, test_loss: 0.47251577079296114,test accuracy: 84.96%\n",
      "escaped time of this epoch:944.1149137020111\n",
      "epoch: 33, iter: 6664, train_loss: 0.25877194334657827, test_loss: 0.49108091443777085,test accuracy: 84.58%\n",
      "escaped time of this epoch:971.1637299060822\n",
      "epoch: 34, iter: 6860, train_loss: 0.26144419032700206, test_loss: 0.47467262148857114,test accuracy: 84.64%\n",
      "escaped time of this epoch:998.3009054660797\n",
      "epoch: 35, iter: 7056, train_loss: 0.25052421912550926, test_loss: 0.4980785891413689,test accuracy: 84.87%\n",
      "escaped time of this epoch:1025.424866437912\n",
      "epoch: 36, iter: 7252, train_loss: 0.2546461984059032, test_loss: 0.5207175485789776,test accuracy: 84.03%\n",
      "escaped time of this epoch:1052.5756361484528\n",
      "epoch: 37, iter: 7448, train_loss: 0.24565245013455955, test_loss: 0.47518991529941557,test accuracy: 85.19%\n",
      "escaped time of this epoch:1079.700523853302\n",
      "epoch: 38, iter: 7644, train_loss: 0.24590367937878688, test_loss: 0.5169789887964725,test accuracy: 83.89%\n",
      "escaped time of this epoch:1106.8880891799927\n",
      "epoch: 39, iter: 7840, train_loss: 0.24565006435221556, test_loss: 0.46449756175279616,test accuracy: 84.97%\n",
      "escaped time of this epoch:1133.9610159397125\n",
      "epoch: 40, iter: 8036, train_loss: 0.2395616065026546, test_loss: 0.4974177166819572,test accuracy: 84.96%\n",
      "escaped time of this epoch:1161.0806629657745\n",
      "epoch: 41, iter: 8232, train_loss: 0.10737796720801568, test_loss: 0.36928629204630853,test accuracy: 89.22%\n",
      "escaped time of this epoch:1188.160295009613\n",
      "epoch: 42, iter: 8428, train_loss: 0.046722830900428246, test_loss: 0.38350580483675,test accuracy: 89.23%\n",
      "escaped time of this epoch:1215.4684464931488\n",
      "epoch: 43, iter: 8624, train_loss: 0.027496759527914073, test_loss: 0.4028805635869503,test accuracy: 89.33%\n",
      "escaped time of this epoch:1242.5856783390045\n",
      "epoch: 44, iter: 8820, train_loss: 0.017295299050379163, test_loss: 0.4133475460112095,test accuracy: 89.28%\n",
      "escaped time of this epoch:1269.6454408168793\n",
      "epoch: 45, iter: 9016, train_loss: 0.012403972641735966, test_loss: 0.4274999499320984,test accuracy: 89.17%\n",
      "escaped time of this epoch:1296.7107965946198\n",
      "epoch: 46, iter: 9212, train_loss: 0.009214228527544409, test_loss: 0.43667514249682426,test accuracy: 89.2%\n",
      "escaped time of this epoch:1323.8551125526428\n",
      "epoch: 47, iter: 9408, train_loss: 0.007216931867166137, test_loss: 0.4447155974805355,test accuracy: 89.1%\n",
      "escaped time of this epoch:1350.9347200393677\n",
      "epoch: 48, iter: 9604, train_loss: 0.0064353319075034585, test_loss: 0.4540841393172741,test accuracy: 89.22%\n",
      "escaped time of this epoch:1378.0019552707672\n",
      "epoch: 49, iter: 9800, train_loss: 0.005363167995320899, test_loss: 0.45901801362633704,test accuracy: 89.2%\n",
      "escaped time of this epoch:1405.1235921382904\n",
      "epoch: 50, iter: 9996, train_loss: 0.004581298351249829, test_loss: 0.4629226587712765,test accuracy: 89.24%\n",
      "escaped time of this epoch:1432.216814994812\n",
      "epoch: 51, iter: 10192, train_loss: 0.00392411324689735, test_loss: 0.46301174983382226,test accuracy: 89.3%\n",
      "escaped time of this epoch:1459.366286277771\n",
      "epoch: 52, iter: 10388, train_loss: 0.004049949927673656, test_loss: 0.4653545156121254,test accuracy: 89.13%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escaped time of this epoch:1486.5013403892517\n",
      "epoch: 53, iter: 10584, train_loss: 0.003963698982261121, test_loss: 0.4689834304153919,test accuracy: 89.33%\n",
      "escaped time of this epoch:1513.6214578151703\n",
      "epoch: 54, iter: 10780, train_loss: 0.003345476358900873, test_loss: 0.47207449227571485,test accuracy: 89.33%\n",
      "escaped time of this epoch:1540.7544169425964\n",
      "epoch: 55, iter: 10976, train_loss: 0.002992336605010288, test_loss: 0.472307950258255,test accuracy: 89.27%\n",
      "escaped time of this epoch:1567.8727488517761\n",
      "epoch: 56, iter: 11172, train_loss: 0.0028579318634595493, test_loss: 0.47587345764040945,test accuracy: 89.22%\n",
      "escaped time of this epoch:1594.9918699264526\n",
      "epoch: 57, iter: 11368, train_loss: 0.002739743695461324, test_loss: 0.47728667557239535,test accuracy: 89.25%\n",
      "escaped time of this epoch:1622.0585527420044\n",
      "epoch: 58, iter: 11564, train_loss: 0.002517741349316677, test_loss: 0.4775057226419449,test accuracy: 89.29%\n",
      "escaped time of this epoch:1649.102724313736\n",
      "epoch: 59, iter: 11760, train_loss: 0.0025113967190287553, test_loss: 0.48059327378869054,test accuracy: 89.19%\n",
      "escaped time of this epoch:1676.1781768798828\n",
      "epoch: 60, iter: 11956, train_loss: 0.002370671183821194, test_loss: 0.4802573785185814,test accuracy: 89.2%\n",
      "escaped time of this epoch:1703.2787592411041\n",
      "epoch: 61, iter: 12152, train_loss: 0.0022752464948488133, test_loss: 0.4794207826256752,test accuracy: 89.23%\n",
      "escaped time of this epoch:1730.308690071106\n",
      "epoch: 62, iter: 12348, train_loss: 0.0022823381978942423, test_loss: 0.48001750707626345,test accuracy: 89.27%\n",
      "escaped time of this epoch:1757.363606452942\n",
      "epoch: 63, iter: 12544, train_loss: 0.002187322290633254, test_loss: 0.48020483925938606,test accuracy: 89.35%\n",
      "escaped time of this epoch:1784.4907777309418\n",
      "epoch: 64, iter: 12740, train_loss: 0.002158769522793591, test_loss: 0.4799280069768429,test accuracy: 89.33%\n",
      "escaped time of this epoch:1811.6034216880798\n",
      "epoch: 65, iter: 12936, train_loss: 0.0021677319844234356, test_loss: 0.48204963877797125,test accuracy: 89.34%\n",
      "escaped time of this epoch:1838.7204592227936\n",
      "epoch: 66, iter: 13132, train_loss: 0.002090784464487616, test_loss: 0.4829276315867901,test accuracy: 89.38%\n",
      "escaped time of this epoch:1865.8792672157288\n",
      "epoch: 67, iter: 13328, train_loss: 0.0020975661083903847, test_loss: 0.48461725637316705,test accuracy: 89.19%\n",
      "escaped time of this epoch:1893.0145545005798\n",
      "epoch: 68, iter: 13524, train_loss: 0.002122002368678852, test_loss: 0.48704245686531067,test accuracy: 89.19%\n",
      "escaped time of this epoch:1920.1022424697876\n",
      "epoch: 69, iter: 13720, train_loss: 0.002029273777782005, test_loss: 0.48794433996081354,test accuracy: 89.22%\n",
      "escaped time of this epoch:1947.1780922412872\n",
      "epoch: 70, iter: 13916, train_loss: 0.0019970457485344794, test_loss: 0.4884255610406399,test accuracy: 89.21%\n",
      "escaped time of this epoch:1974.3723921775818\n",
      "epoch: 71, iter: 14112, train_loss: 0.001957971391824017, test_loss: 0.48727032765746114,test accuracy: 89.23%\n",
      "escaped time of this epoch:2001.424246788025\n",
      "epoch: 72, iter: 14308, train_loss: 0.0018994071834473585, test_loss: 0.48901010900735853,test accuracy: 89.14%\n",
      "escaped time of this epoch:2028.507384777069\n",
      "epoch: 73, iter: 14504, train_loss: 0.0020674592197625612, test_loss: 0.49089720025658606,test accuracy: 89.13%\n",
      "escaped time of this epoch:2055.638186454773\n",
      "epoch: 74, iter: 14700, train_loss: 0.002735656819173268, test_loss: 0.49301697984337806,test accuracy: 89.09%\n",
      "escaped time of this epoch:2082.6781888008118\n",
      "epoch: 75, iter: 14896, train_loss: 0.0021701140272222005, test_loss: 0.4892995461821556,test accuracy: 89.09%\n",
      "escaped time of this epoch:2109.7893455028534\n",
      "epoch: 76, iter: 15092, train_loss: 0.002186890526399092, test_loss: 0.4956294514238834,test accuracy: 89.1%\n",
      "escaped time of this epoch:2136.936601638794\n",
      "epoch: 77, iter: 15288, train_loss: 0.0020174949444184192, test_loss: 0.4973723739385605,test accuracy: 89.06%\n",
      "escaped time of this epoch:2164.106699705124\n",
      "epoch: 78, iter: 15484, train_loss: 0.001916545238916059, test_loss: 0.49814905822277067,test accuracy: 89.04%\n",
      "escaped time of this epoch:2191.282993555069\n",
      "epoch: 79, iter: 15680, train_loss: 0.0018634288892511051, test_loss: 0.4977023534476757,test accuracy: 89.16%\n",
      "escaped time of this epoch:2218.457370519638\n",
      "epoch: 80, iter: 15876, train_loss: 0.0018243478012404271, test_loss: 0.4979887843132019,test accuracy: 89.21%\n",
      "escaped time of this epoch:2245.7225437164307\n",
      "epoch: 81, iter: 16072, train_loss: 0.0018393808206049155, test_loss: 0.49787232279777527,test accuracy: 89.23%\n",
      "escaped time of this epoch:2272.852570772171\n",
      "epoch: 82, iter: 16268, train_loss: 0.0018977808590256134, test_loss: 0.49808964803814887,test accuracy: 89.23%\n",
      "escaped time of this epoch:2300.01544547081\n",
      "epoch: 83, iter: 16464, train_loss: 0.0018342823890151875, test_loss: 0.49806190133094785,test accuracy: 89.23%\n",
      "escaped time of this epoch:2327.194106578827\n",
      "epoch: 84, iter: 16660, train_loss: 0.0018229117422193593, test_loss: 0.4983001448214054,test accuracy: 89.16%\n",
      "escaped time of this epoch:2354.329199552536\n",
      "epoch: 85, iter: 16856, train_loss: 0.00186342764550782, test_loss: 0.49878079146146775,test accuracy: 89.13%\n",
      "escaped time of this epoch:2381.4832665920258\n",
      "epoch: 86, iter: 17052, train_loss: 0.0018105467208851204, test_loss: 0.4990070410072803,test accuracy: 89.16%\n",
      "escaped time of this epoch:2408.5736413002014\n",
      "epoch: 87, iter: 17248, train_loss: 0.0018191706942755502, test_loss: 0.4989049106836319,test accuracy: 89.17%\n",
      "escaped time of this epoch:2435.666717529297\n",
      "epoch: 88, iter: 17444, train_loss: 0.001776037484702027, test_loss: 0.4987638421356678,test accuracy: 89.16%\n",
      "escaped time of this epoch:2462.7745547294617\n",
      "epoch: 89, iter: 17640, train_loss: 0.0017776486062330706, test_loss: 0.49871941208839415,test accuracy: 89.16%\n",
      "escaped time of this epoch:2489.8828916549683\n",
      "epoch: 90, iter: 17836, train_loss: 0.0017669634259191854, test_loss: 0.498857868462801,test accuracy: 89.2%\n",
      "escaped time of this epoch:2517.0047080516815\n",
      "epoch: 91, iter: 18032, train_loss: 0.0017258728051330059, test_loss: 0.498790879547596,test accuracy: 89.16%\n",
      "escaped time of this epoch:2544.1511187553406\n",
      "epoch: 92, iter: 18228, train_loss: 0.001739186759829065, test_loss: 0.49883687421679496,test accuracy: 89.19%\n",
      "escaped time of this epoch:2571.318160533905\n",
      "epoch: 93, iter: 18424, train_loss: 0.0017479293176676243, test_loss: 0.4988722652196884,test accuracy: 89.17%\n",
      "escaped time of this epoch:2598.379330396652\n",
      "epoch: 94, iter: 18620, train_loss: 0.0017892337292527817, test_loss: 0.4988213963806629,test accuracy: 89.17%\n",
      "escaped time of this epoch:2625.5233845710754\n",
      "epoch: 95, iter: 18816, train_loss: 0.001858909552612779, test_loss: 0.4990042865276337,test accuracy: 89.16%\n",
      "escaped time of this epoch:2652.699187040329\n",
      "epoch: 96, iter: 19012, train_loss: 0.001805601052331681, test_loss: 0.4989324644207954,test accuracy: 89.15%\n",
      "escaped time of this epoch:2679.8392837047577\n",
      "epoch: 97, iter: 19208, train_loss: 0.0017745296817691047, test_loss: 0.49901953935623167,test accuracy: 89.16%\n",
      "escaped time of this epoch:2707.0109565258026\n",
      "epoch: 98, iter: 19404, train_loss: 0.0018476458499208093, test_loss: 0.4989651069045067,test accuracy: 89.18%\n",
      "escaped time of this epoch:2734.140356063843\n",
      "epoch: 99, iter: 19600, train_loss: 0.0017723209481230195, test_loss: 0.4989695496857166,test accuracy: 89.16%\n",
      "escaped time of this epoch:2761.2926337718964\n",
      "epoch: 100, iter: 19796, train_loss: 0.0018072091827017007, test_loss: 0.49915953502058985,test accuracy: 89.16%\n",
      "escaped time of this epoch:2788.425352334976\n",
      "epoch: 101, iter: 19992, train_loss: 0.001764729015567169, test_loss: 0.4988946706056595,test accuracy: 89.2%\n",
      "escaped time of this epoch:2815.5824506282806\n",
      "epoch: 102, iter: 20188, train_loss: 0.0017705378574034085, test_loss: 0.4994554929435253,test accuracy: 89.2%\n",
      "escaped time of this epoch:2842.697711467743\n",
      "epoch: 103, iter: 20384, train_loss: 0.0017856926507582621, test_loss: 0.49938195422291753,test accuracy: 89.18%\n",
      "escaped time of this epoch:2869.8212559223175\n",
      "epoch: 104, iter: 20580, train_loss: 0.0018021719273635928, test_loss: 0.4992301344871521,test accuracy: 89.15%\n",
      "escaped time of this epoch:2896.9042570590973\n",
      "epoch: 105, iter: 20776, train_loss: 0.001793050394293719, test_loss: 0.49925129637122156,test accuracy: 89.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escaped time of this epoch:2923.995572090149\n",
      "epoch: 106, iter: 20972, train_loss: 0.0017752002221437134, test_loss: 0.49920338317751883,test accuracy: 89.15%\n",
      "escaped time of this epoch:2951.101505279541\n",
      "epoch: 107, iter: 21168, train_loss: 0.0018409550028415968, test_loss: 0.49924135208129883,test accuracy: 89.19%\n",
      "escaped time of this epoch:2978.2056651115417\n",
      "epoch: 108, iter: 21364, train_loss: 0.0018040428736380168, test_loss: 0.4991818740963936,test accuracy: 89.18%\n",
      "escaped time of this epoch:3005.3637115955353\n",
      "epoch: 109, iter: 21560, train_loss: 0.0018515893809345303, test_loss: 0.4992800407111645,test accuracy: 89.14%\n",
      "best loss:  0.36928629204630853\n",
      "Born Again...\n",
      "delete last model!!!\n",
      "escaped time of this epoch:27.23776912689209\n",
      "epoch: 0, iter: 21756, train_loss: 1.5386635624632543, test_loss: 1.2331116765737533,test accuracy: 55.54%\n",
      "escaped time of this epoch:54.42804145812988\n",
      "epoch: 1, iter: 21952, train_loss: 1.0386611265795571, test_loss: 0.9242540195584297,test accuracy: 67.86%\n",
      "escaped time of this epoch:81.64576363563538\n",
      "epoch: 2, iter: 22148, train_loss: 0.793933210324268, test_loss: 0.7828379705548286,test accuracy: 72.87%\n",
      "escaped time of this epoch:108.89829158782959\n",
      "epoch: 3, iter: 22344, train_loss: 0.6433383084985674, test_loss: 0.6737840756773948,test accuracy: 76.59%\n",
      "escaped time of this epoch:136.07453799247742\n",
      "epoch: 4, iter: 22540, train_loss: 0.5580450124582466, test_loss: 0.6073981672525406,test accuracy: 79.64%\n",
      "escaped time of this epoch:163.31100034713745\n",
      "epoch: 5, iter: 22736, train_loss: 0.5021598326916598, test_loss: 0.5984961099922657,test accuracy: 79.96%\n",
      "escaped time of this epoch:190.46358919143677\n",
      "epoch: 6, iter: 22932, train_loss: 0.44888622298532604, test_loss: 0.5740140467882157,test accuracy: 80.62%\n",
      "escaped time of this epoch:217.6178867816925\n",
      "epoch: 7, iter: 23128, train_loss: 0.41997054644993376, test_loss: 0.5448997512459754,test accuracy: 82.3%\n",
      "escaped time of this epoch:244.74475646018982\n",
      "epoch: 8, iter: 23324, train_loss: 0.40098875502542575, test_loss: 0.5610875442624093,test accuracy: 81.23%\n",
      "escaped time of this epoch:271.93794870376587\n",
      "epoch: 9, iter: 23520, train_loss: 0.3742091512041433, test_loss: 0.5347248211503028,test accuracy: 82.13%\n",
      "escaped time of this epoch:299.1718728542328\n",
      "epoch: 10, iter: 23716, train_loss: 0.3660960068203965, test_loss: 0.5276874460279941,test accuracy: 82.51%\n",
      "escaped time of this epoch:326.2464337348938\n",
      "epoch: 11, iter: 23912, train_loss: 0.3426823930776849, test_loss: 0.540438711643219,test accuracy: 82.51%\n",
      "escaped time of this epoch:353.3694956302643\n",
      "epoch: 12, iter: 24108, train_loss: 0.3337181088115488, test_loss: 0.5232621848583221,test accuracy: 83.12%\n",
      "escaped time of this epoch:380.5677001476288\n",
      "epoch: 13, iter: 24304, train_loss: 0.3220603951081938, test_loss: 0.5330272182822228,test accuracy: 82.44%\n",
      "escaped time of this epoch:407.8136866092682\n",
      "epoch: 14, iter: 24500, train_loss: 0.3225708935333758, test_loss: 0.5147242769598961,test accuracy: 83.34%\n",
      "escaped time of this epoch:435.0365915298462\n",
      "epoch: 15, iter: 24696, train_loss: 0.305994597092575, test_loss: 0.4893508069217205,test accuracy: 83.96%\n",
      "escaped time of this epoch:462.2252604961395\n",
      "epoch: 16, iter: 24892, train_loss: 0.3054204728378325, test_loss: 0.5250288374722004,test accuracy: 82.85%\n",
      "escaped time of this epoch:489.41250801086426\n",
      "epoch: 17, iter: 25088, train_loss: 0.29429300615982135, test_loss: 0.5224222809076309,test accuracy: 83.08%\n",
      "escaped time of this epoch:516.65030169487\n",
      "epoch: 18, iter: 25284, train_loss: 0.2880727882135887, test_loss: 0.5118523389101028,test accuracy: 83.6%\n",
      "escaped time of this epoch:543.8064529895782\n",
      "epoch: 19, iter: 25480, train_loss: 0.29242720675407624, test_loss: 0.5213625952601433,test accuracy: 83.08%\n",
      "escaped time of this epoch:570.9526007175446\n",
      "epoch: 20, iter: 25676, train_loss: 0.28247673262138756, test_loss: 0.4973442740738392,test accuracy: 84.16%\n",
      "escaped time of this epoch:598.1006762981415\n",
      "epoch: 21, iter: 25872, train_loss: 0.2829089431586314, test_loss: 0.5055448830127716,test accuracy: 83.92%\n",
      "escaped time of this epoch:625.2262156009674\n",
      "epoch: 22, iter: 26068, train_loss: 0.2792205899497684, test_loss: 0.49144159629940987,test accuracy: 84.46%\n",
      "escaped time of this epoch:652.4129145145416\n",
      "epoch: 23, iter: 26264, train_loss: 0.277034759901616, test_loss: 0.49535916075110437,test accuracy: 84.03%\n",
      "escaped time of this epoch:679.6511378288269\n",
      "epoch: 24, iter: 26460, train_loss: 0.27576013821728373, test_loss: 0.5138963840901851,test accuracy: 83.87%\n",
      "escaped time of this epoch:706.7409374713898\n",
      "epoch: 25, iter: 26656, train_loss: 0.27157614387723866, test_loss: 0.5027019724249839,test accuracy: 84.06%\n",
      "escaped time of this epoch:733.9000346660614\n",
      "epoch: 26, iter: 26852, train_loss: 0.27398042175538684, test_loss: 0.47146578282117846,test accuracy: 84.8%\n",
      "escaped time of this epoch:761.0891830921173\n",
      "epoch: 27, iter: 27048, train_loss: 0.26703198550611124, test_loss: 0.48839191272854804,test accuracy: 84.73%\n",
      "escaped time of this epoch:788.3146371841431\n",
      "epoch: 28, iter: 27244, train_loss: 0.2609761182446869, test_loss: 0.5429167591035367,test accuracy: 83.57%\n",
      "escaped time of this epoch:815.5124428272247\n",
      "epoch: 29, iter: 27440, train_loss: 0.26462910962956293, test_loss: 0.5049886107444763,test accuracy: 83.95%\n",
      "escaped time of this epoch:842.6949632167816\n",
      "epoch: 30, iter: 27636, train_loss: 0.2612554567809008, test_loss: 0.49646674171090127,test accuracy: 84.17%\n",
      "escaped time of this epoch:869.9418253898621\n",
      "epoch: 31, iter: 27832, train_loss: 0.26222524084911053, test_loss: 0.5011485934257507,test accuracy: 84.25%\n",
      "escaped time of this epoch:897.1377966403961\n",
      "epoch: 32, iter: 28028, train_loss: 0.2605814392469367, test_loss: 0.48963135331869123,test accuracy: 84.93%\n",
      "escaped time of this epoch:924.3633825778961\n",
      "epoch: 33, iter: 28224, train_loss: 0.2598908030028854, test_loss: 0.5034573473036289,test accuracy: 84.29%\n",
      "escaped time of this epoch:951.4494495391846\n",
      "epoch: 34, iter: 28420, train_loss: 0.25914234614798, test_loss: 0.4825230173766613,test accuracy: 84.61%\n",
      "escaped time of this epoch:978.5963861942291\n",
      "epoch: 35, iter: 28616, train_loss: 0.25904032892110396, test_loss: 0.480881118029356,test accuracy: 84.86%\n",
      "escaped time of this epoch:1005.7313642501831\n",
      "epoch: 36, iter: 28812, train_loss: 0.260734977808838, test_loss: 0.49451526775956156,test accuracy: 84.58%\n",
      "escaped time of this epoch:1032.823029756546\n",
      "epoch: 37, iter: 29008, train_loss: 0.25857100050364223, test_loss: 0.49880181849002836,test accuracy: 84.55%\n",
      "escaped time of this epoch:1059.9747047424316\n",
      "epoch: 38, iter: 29204, train_loss: 0.25205821977282056, test_loss: 0.5043573744595051,test accuracy: 84.4%\n",
      "escaped time of this epoch:1087.1466476917267\n",
      "epoch: 39, iter: 29400, train_loss: 0.25631776870209344, test_loss: 0.4618062674999237,test accuracy: 85.09%\n",
      "escaped time of this epoch:1114.1920914649963\n",
      "epoch: 40, iter: 29596, train_loss: 0.2523834556341171, test_loss: 0.4973897635936737,test accuracy: 84.51%\n",
      "escaped time of this epoch:1141.3923454284668\n",
      "epoch: 41, iter: 29792, train_loss: 0.11799170852315669, test_loss: 0.38245091028511524,test accuracy: 88.84%\n",
      "escaped time of this epoch:1168.5509057044983\n",
      "epoch: 42, iter: 29988, train_loss: 0.05218952733605188, test_loss: 0.3969566822052002,test accuracy: 89.04%\n",
      "escaped time of this epoch:1195.7287929058075\n",
      "epoch: 43, iter: 30184, train_loss: 0.03224077443972382, test_loss: 0.4132654458284378,test accuracy: 89.2%\n",
      "escaped time of this epoch:1222.8815174102783\n",
      "epoch: 44, iter: 30380, train_loss: 0.020459208932078005, test_loss: 0.42484835982322694,test accuracy: 89.42%\n",
      "escaped time of this epoch:1250.0840983390808\n",
      "epoch: 45, iter: 30576, train_loss: 0.014254280484794659, test_loss: 0.43973523899912836,test accuracy: 89.21%\n",
      "escaped time of this epoch:1277.2730865478516\n",
      "epoch: 46, iter: 30772, train_loss: 0.010376144726808203, test_loss: 0.4500420928001404,test accuracy: 89.23%\n",
      "escaped time of this epoch:1304.4548511505127\n",
      "epoch: 47, iter: 30968, train_loss: 0.00864068224874078, test_loss: 0.46010709926486015,test accuracy: 89.2%\n",
      "escaped time of this epoch:1331.7029700279236\n",
      "epoch: 48, iter: 31164, train_loss: 0.007318718691489526, test_loss: 0.46764005050063134,test accuracy: 89.13%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escaped time of this epoch:1358.9301190376282\n",
      "epoch: 49, iter: 31360, train_loss: 0.005992994477440204, test_loss: 0.47583772540092467,test accuracy: 89.19%\n",
      "escaped time of this epoch:1386.1467733383179\n",
      "epoch: 50, iter: 31556, train_loss: 0.005289831624024225, test_loss: 0.48092873468995095,test accuracy: 89.12%\n",
      "escaped time of this epoch:1413.3036875724792\n",
      "epoch: 51, iter: 31752, train_loss: 0.004594399807594565, test_loss: 0.483601126819849,test accuracy: 89.15%\n",
      "escaped time of this epoch:1440.424166917801\n",
      "epoch: 52, iter: 31948, train_loss: 0.004374461158235766, test_loss: 0.49057629331946373,test accuracy: 89.11%\n",
      "escaped time of this epoch:1467.522168636322\n",
      "epoch: 53, iter: 32144, train_loss: 0.004176663885805376, test_loss: 0.4948991656303406,test accuracy: 89.14%\n",
      "escaped time of this epoch:1494.6705956459045\n",
      "epoch: 54, iter: 32340, train_loss: 0.003352136679031715, test_loss: 0.4935164235532284,test accuracy: 89.15%\n",
      "escaped time of this epoch:1521.83269405365\n",
      "epoch: 55, iter: 32536, train_loss: 0.003218559225146868, test_loss: 0.49557420834898946,test accuracy: 89.17%\n",
      "escaped time of this epoch:1548.89000415802\n",
      "epoch: 56, iter: 32732, train_loss: 0.00289026854977924, test_loss: 0.497595826536417,test accuracy: 89.12%\n",
      "escaped time of this epoch:1576.0027594566345\n",
      "epoch: 57, iter: 32928, train_loss: 0.003234558059282753, test_loss: 0.5002896144986153,test accuracy: 89.0%\n",
      "escaped time of this epoch:1603.2036077976227\n",
      "epoch: 58, iter: 33124, train_loss: 0.0031268076011340836, test_loss: 0.5006958313286305,test accuracy: 89.1%\n",
      "escaped time of this epoch:1630.4719440937042\n",
      "epoch: 59, iter: 33320, train_loss: 0.0027304690411998605, test_loss: 0.5010524615645409,test accuracy: 88.99%\n",
      "escaped time of this epoch:1657.6379144191742\n",
      "epoch: 60, iter: 33516, train_loss: 0.002419741465520038, test_loss: 0.5022308856248856,test accuracy: 89.13%\n",
      "escaped time of this epoch:1684.9158697128296\n",
      "epoch: 61, iter: 33712, train_loss: 0.0023372535717350487, test_loss: 0.5010124444961548,test accuracy: 89.2%\n",
      "escaped time of this epoch:1712.0761787891388\n",
      "epoch: 62, iter: 33908, train_loss: 0.002198412168618976, test_loss: 0.5011229433119297,test accuracy: 89.18%\n",
      "escaped time of this epoch:1739.2347295284271\n",
      "epoch: 63, iter: 34104, train_loss: 0.002218468932016772, test_loss: 0.5020542360842228,test accuracy: 89.18%\n",
      "escaped time of this epoch:1766.4217677116394\n",
      "epoch: 64, iter: 34300, train_loss: 0.0023037629814970555, test_loss: 0.5037363760173321,test accuracy: 89.22%\n",
      "escaped time of this epoch:1793.5788309574127\n",
      "epoch: 65, iter: 34496, train_loss: 0.0023718347953518436, test_loss: 0.5084598757326603,test accuracy: 89.13%\n",
      "escaped time of this epoch:1820.6979069709778\n",
      "epoch: 66, iter: 34692, train_loss: 0.0026494110174172993, test_loss: 0.5070489943027496,test accuracy: 89.21%\n",
      "escaped time of this epoch:1847.8199870586395\n",
      "epoch: 67, iter: 34888, train_loss: 0.0023223877152694123, test_loss: 0.5056947372853756,test accuracy: 89.39%\n",
      "escaped time of this epoch:1875.0143675804138\n",
      "epoch: 68, iter: 35084, train_loss: 0.0019472263354275907, test_loss: 0.5040836706757545,test accuracy: 89.27%\n",
      "escaped time of this epoch:1902.1221106052399\n",
      "epoch: 69, iter: 35280, train_loss: 0.0021154366704464263, test_loss: 0.5059294991195202,test accuracy: 89.26%\n",
      "escaped time of this epoch:1929.306167125702\n",
      "epoch: 70, iter: 35476, train_loss: 0.0018814186689120774, test_loss: 0.5059948600828648,test accuracy: 89.4%\n",
      "escaped time of this epoch:1956.496646642685\n",
      "epoch: 71, iter: 35672, train_loss: 0.002249768322181641, test_loss: 0.5071416825056076,test accuracy: 89.39%\n",
      "escaped time of this epoch:1983.532730102539\n",
      "epoch: 72, iter: 35868, train_loss: 0.0024581996923578636, test_loss: 0.5093308620154857,test accuracy: 89.35%\n",
      "escaped time of this epoch:2010.720162153244\n",
      "epoch: 73, iter: 36064, train_loss: 0.0020334456467582863, test_loss: 0.5091708652675152,test accuracy: 89.34%\n",
      "escaped time of this epoch:2037.8743562698364\n",
      "epoch: 74, iter: 36260, train_loss: 0.0020218761732839806, test_loss: 0.5124400056898594,test accuracy: 89.17%\n",
      "escaped time of this epoch:2064.991309404373\n",
      "epoch: 75, iter: 36456, train_loss: 0.0018318769716828757, test_loss: 0.5128072291612625,test accuracy: 89.13%\n",
      "escaped time of this epoch:2092.1378593444824\n",
      "epoch: 76, iter: 36652, train_loss: 0.0018544446686472819, test_loss: 0.5149503566324711,test accuracy: 89.16%\n",
      "escaped time of this epoch:2119.3063719272614\n",
      "epoch: 77, iter: 36848, train_loss: 0.0019225920520827401, test_loss: 0.515117672085762,test accuracy: 89.15%\n",
      "escaped time of this epoch:2146.4427490234375\n",
      "epoch: 78, iter: 37044, train_loss: 0.0018279315542657764, test_loss: 0.5163057982921601,test accuracy: 89.12%\n",
      "escaped time of this epoch:2173.5995445251465\n",
      "epoch: 79, iter: 37240, train_loss: 0.0017300341682204483, test_loss: 0.5152760230004787,test accuracy: 89.18%\n",
      "escaped time of this epoch:2200.8371262550354\n",
      "epoch: 80, iter: 37436, train_loss: 0.0017917087296860255, test_loss: 0.5175739750266075,test accuracy: 89.13%\n",
      "escaped time of this epoch:2227.9842252731323\n",
      "epoch: 81, iter: 37632, train_loss: 0.0017241553073197755, test_loss: 0.5171289823949337,test accuracy: 89.16%\n",
      "escaped time of this epoch:2255.10271692276\n",
      "epoch: 82, iter: 37828, train_loss: 0.0017171260682219754, test_loss: 0.5170113243162632,test accuracy: 89.19%\n",
      "escaped time of this epoch:2282.307881832123\n",
      "epoch: 83, iter: 38024, train_loss: 0.001775581403920541, test_loss: 0.5169508866965771,test accuracy: 89.17%\n",
      "escaped time of this epoch:2309.472025156021\n",
      "epoch: 84, iter: 38220, train_loss: 0.0017740308260782718, test_loss: 0.5168063759803772,test accuracy: 89.23%\n",
      "escaped time of this epoch:2336.6184480190277\n",
      "epoch: 85, iter: 38416, train_loss: 0.0017375634924974293, test_loss: 0.5162899151444436,test accuracy: 89.24%\n",
      "escaped time of this epoch:2363.7977089881897\n",
      "epoch: 86, iter: 38612, train_loss: 0.001711388151826603, test_loss: 0.5162592209875584,test accuracy: 89.2%\n",
      "escaped time of this epoch:2390.9431750774384\n",
      "epoch: 87, iter: 38808, train_loss: 0.001775256329577188, test_loss: 0.5160548269748688,test accuracy: 89.26%\n",
      "escaped time of this epoch:2417.9716169834137\n",
      "epoch: 88, iter: 39004, train_loss: 0.0017093596469173779, test_loss: 0.5160001374781131,test accuracy: 89.23%\n",
      "escaped time of this epoch:2445.120881795883\n",
      "epoch: 89, iter: 39200, train_loss: 0.0017957934273444877, test_loss: 0.5158986523747444,test accuracy: 89.21%\n",
      "escaped time of this epoch:2472.275593996048\n",
      "epoch: 90, iter: 39396, train_loss: 0.0017861416325809397, test_loss: 0.5162749372422695,test accuracy: 89.24%\n",
      "escaped time of this epoch:2499.448819875717\n",
      "epoch: 91, iter: 39592, train_loss: 0.0017090065343001364, test_loss: 0.5162714645266533,test accuracy: 89.24%\n",
      "escaped time of this epoch:2526.5531272888184\n",
      "epoch: 92, iter: 39788, train_loss: 0.0018156512559638644, test_loss: 0.5161534614861012,test accuracy: 89.24%\n",
      "escaped time of this epoch:2553.68013048172\n",
      "epoch: 93, iter: 39984, train_loss: 0.001771840903603909, test_loss: 0.5159800477325917,test accuracy: 89.21%\n",
      "escaped time of this epoch:2580.8856921195984\n",
      "epoch: 94, iter: 40180, train_loss: 0.0017704996814932295, test_loss: 0.5159801304340362,test accuracy: 89.23%\n",
      "escaped time of this epoch:2608.045171022415\n",
      "epoch: 95, iter: 40376, train_loss: 0.0016529237689944555, test_loss: 0.5158985540270805,test accuracy: 89.23%\n",
      "escaped time of this epoch:2635.1941838264465\n",
      "epoch: 96, iter: 40572, train_loss: 0.0017902353132257657, test_loss: 0.5162507332861423,test accuracy: 89.2%\n",
      "escaped time of this epoch:2662.4182407855988\n",
      "epoch: 97, iter: 40768, train_loss: 0.0017186853463276842, test_loss: 0.5171049326658249,test accuracy: 89.19%\n",
      "escaped time of this epoch:2689.5766727924347\n",
      "epoch: 98, iter: 40964, train_loss: 0.001830217081635278, test_loss: 0.5169407516717911,test accuracy: 89.17%\n",
      "escaped time of this epoch:2716.734400510788\n",
      "epoch: 99, iter: 41160, train_loss: 0.0017528745116504403, test_loss: 0.5167536735534668,test accuracy: 89.13%\n",
      "escaped time of this epoch:2743.9245681762695\n",
      "epoch: 100, iter: 41356, train_loss: 0.0016912276041693985, test_loss: 0.516713359951973,test accuracy: 89.17%\n",
      "escaped time of this epoch:2771.09081864357\n",
      "epoch: 101, iter: 41552, train_loss: 0.0017346750531459646, test_loss: 0.5164444118738174,test accuracy: 89.17%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escaped time of this epoch:2798.282855272293\n",
      "epoch: 102, iter: 41748, train_loss: 0.0017396499336298024, test_loss: 0.5163183435797691,test accuracy: 89.16%\n",
      "escaped time of this epoch:2825.3329322338104\n",
      "epoch: 103, iter: 41944, train_loss: 0.0016750257262693985, test_loss: 0.5160164125263691,test accuracy: 89.14%\n",
      "escaped time of this epoch:2852.476901292801\n",
      "epoch: 104, iter: 42140, train_loss: 0.0017299981792552434, test_loss: 0.5161596842110157,test accuracy: 89.11%\n",
      "escaped time of this epoch:2879.6430280208588\n",
      "epoch: 105, iter: 42336, train_loss: 0.0017483028219727685, test_loss: 0.5160059414803981,test accuracy: 89.12%\n",
      "escaped time of this epoch:2906.8298869132996\n",
      "epoch: 106, iter: 42532, train_loss: 0.0017253106379197265, test_loss: 0.5159581288695335,test accuracy: 89.11%\n",
      "escaped time of this epoch:2934.0401322841644\n",
      "epoch: 107, iter: 42728, train_loss: 0.0018040065971982417, test_loss: 0.5158899493515492,test accuracy: 89.14%\n",
      "escaped time of this epoch:2961.2029848098755\n",
      "epoch: 108, iter: 42924, train_loss: 0.0019831681310446287, test_loss: 0.5161061830818653,test accuracy: 89.12%\n",
      "escaped time of this epoch:2988.370176553726\n",
      "epoch: 109, iter: 43120, train_loss: 0.0017352916528375782, test_loss: 0.5163480758666992,test accuracy: 89.16%\n",
      "best loss:  0.38245091028511524\n",
      "Born Again...\n",
      "delete last model!!!\n",
      "escaped time of this epoch:27.250467777252197\n",
      "epoch: 0, iter: 43316, train_loss: 1.5594970991416854, test_loss: 1.2071985870599746,test accuracy: 56.31%\n",
      "escaped time of this epoch:54.49036478996277\n",
      "epoch: 1, iter: 43512, train_loss: 1.0423452732514362, test_loss: 0.9212704434990883,test accuracy: 67.9%\n",
      "escaped time of this epoch:81.75562882423401\n",
      "epoch: 2, iter: 43708, train_loss: 0.7947063014215353, test_loss: 0.7522215873003006,test accuracy: 74.69%\n",
      "escaped time of this epoch:109.00589060783386\n",
      "epoch: 3, iter: 43904, train_loss: 0.6487231473533475, test_loss: 0.6619061581790447,test accuracy: 77.88%\n",
      "escaped time of this epoch:136.23436069488525\n",
      "epoch: 4, iter: 44100, train_loss: 0.5640883681421377, test_loss: 0.6060246735811233,test accuracy: 79.85%\n",
      "escaped time of this epoch:163.52270436286926\n",
      "epoch: 5, iter: 44296, train_loss: 0.4958106594122186, test_loss: 0.5978001691401005,test accuracy: 79.9%\n",
      "escaped time of this epoch:190.75089740753174\n",
      "epoch: 6, iter: 44492, train_loss: 0.45761793973494547, test_loss: 0.5847304970026016,test accuracy: 81.28%\n",
      "escaped time of this epoch:217.91187524795532\n",
      "epoch: 7, iter: 44688, train_loss: 0.42082030554207006, test_loss: 0.5523148804903031,test accuracy: 81.59%\n",
      "escaped time of this epoch:245.03585529327393\n",
      "epoch: 8, iter: 44884, train_loss: 0.3864868547843427, test_loss: 0.5711799345910549,test accuracy: 81.34%\n",
      "escaped time of this epoch:272.21277379989624\n",
      "epoch: 9, iter: 45080, train_loss: 0.37487533924226857, test_loss: 0.5527528643608093,test accuracy: 81.79%\n",
      "escaped time of this epoch:299.3682978153229\n",
      "epoch: 10, iter: 45276, train_loss: 0.3503389281733912, test_loss: 0.5408539555966854,test accuracy: 82.86%\n",
      "escaped time of this epoch:326.5564343929291\n",
      "epoch: 11, iter: 45472, train_loss: 0.3416879681148091, test_loss: 0.5165331296622753,test accuracy: 83.3%\n",
      "escaped time of this epoch:353.7411859035492\n",
      "epoch: 12, iter: 45668, train_loss: 0.32927118082131657, test_loss: 0.504146022349596,test accuracy: 83.5%\n",
      "escaped time of this epoch:380.90864157676697\n",
      "epoch: 13, iter: 45864, train_loss: 0.3193323920880045, test_loss: 0.5127265535295009,test accuracy: 83.71%\n",
      "escaped time of this epoch:408.0981788635254\n",
      "epoch: 14, iter: 46060, train_loss: 0.30599177058558075, test_loss: 0.5425193421542645,test accuracy: 82.94%\n",
      "escaped time of this epoch:435.27771282196045\n",
      "epoch: 15, iter: 46256, train_loss: 0.3129882947066609, test_loss: 0.5076534986495972,test accuracy: 83.97%\n",
      "escaped time of this epoch:462.4472122192383\n",
      "epoch: 16, iter: 46452, train_loss: 0.291406090086212, test_loss: 0.5070321537554264,test accuracy: 83.77%\n",
      "escaped time of this epoch:489.70778369903564\n",
      "epoch: 17, iter: 46648, train_loss: 0.294160964309561, test_loss: 0.5397315956652164,test accuracy: 83.33%\n",
      "escaped time of this epoch:517.0091218948364\n",
      "epoch: 18, iter: 46844, train_loss: 0.29769191199115347, test_loss: 0.510950518399477,test accuracy: 84.06%\n",
      "escaped time of this epoch:544.2416672706604\n",
      "epoch: 19, iter: 47040, train_loss: 0.283319177144036, test_loss: 0.5299845211207866,test accuracy: 83.47%\n",
      "escaped time of this epoch:571.532356262207\n",
      "epoch: 20, iter: 47236, train_loss: 0.28088283907546074, test_loss: 0.4794547639787197,test accuracy: 84.5%\n",
      "escaped time of this epoch:598.7236731052399\n",
      "epoch: 21, iter: 47432, train_loss: 0.2685126803663312, test_loss: 0.49698021858930586,test accuracy: 84.07%\n",
      "escaped time of this epoch:625.9772653579712\n",
      "epoch: 22, iter: 47628, train_loss: 0.27346037837619686, test_loss: 0.501291585713625,test accuracy: 84.49%\n",
      "escaped time of this epoch:653.2097697257996\n",
      "epoch: 23, iter: 47824, train_loss: 0.2728988285727647, test_loss: 0.4829364888370037,test accuracy: 84.87%\n",
      "escaped time of this epoch:680.4304163455963\n",
      "epoch: 24, iter: 48020, train_loss: 0.2670768556394139, test_loss: 0.4951166182756424,test accuracy: 84.14%\n",
      "escaped time of this epoch:707.648833990097\n",
      "epoch: 25, iter: 48216, train_loss: 0.26316099423839123, test_loss: 0.488398477435112,test accuracy: 84.57%\n",
      "escaped time of this epoch:734.8386378288269\n",
      "epoch: 26, iter: 48412, train_loss: 0.26361560821533203, test_loss: 0.479908162355423,test accuracy: 84.81%\n",
      "escaped time of this epoch:762.080864906311\n",
      "epoch: 27, iter: 48608, train_loss: 0.2702437853630708, test_loss: 0.46574596837162974,test accuracy: 84.92%\n",
      "escaped time of this epoch:789.2739803791046\n",
      "epoch: 28, iter: 48804, train_loss: 0.2679487980750142, test_loss: 0.49419920742511747,test accuracy: 84.19%\n",
      "escaped time of this epoch:816.4929280281067\n",
      "epoch: 29, iter: 49000, train_loss: 0.25942304449117914, test_loss: 0.5098843403160572,test accuracy: 84.09%\n",
      "escaped time of this epoch:843.7282269001007\n",
      "epoch: 30, iter: 49196, train_loss: 0.2629120355205877, test_loss: 0.5038797050714493,test accuracy: 84.44%\n",
      "escaped time of this epoch:870.985876083374\n",
      "epoch: 31, iter: 49392, train_loss: 0.25761044968147667, test_loss: 0.5017920725047589,test accuracy: 83.9%\n",
      "escaped time of this epoch:898.5000424385071\n",
      "epoch: 32, iter: 49588, train_loss: 0.2569450996055895, test_loss: 0.4750677190721035,test accuracy: 84.68%\n",
      "escaped time of this epoch:925.8409869670868\n",
      "epoch: 33, iter: 49784, train_loss: 0.2512450776614097, test_loss: 0.4941308818757534,test accuracy: 84.75%\n",
      "escaped time of this epoch:953.1969232559204\n",
      "epoch: 34, iter: 49980, train_loss: 0.2552739558931516, test_loss: 0.48805987387895583,test accuracy: 84.86%\n",
      "escaped time of this epoch:980.5132744312286\n",
      "epoch: 35, iter: 50176, train_loss: 0.2631608491801486, test_loss: 0.49634758159518244,test accuracy: 85.37%\n",
      "escaped time of this epoch:1007.8256258964539\n",
      "epoch: 36, iter: 50372, train_loss: 0.25240599538902847, test_loss: 0.47332165762782097,test accuracy: 84.94%\n",
      "escaped time of this epoch:1035.1113679409027\n",
      "epoch: 37, iter: 50568, train_loss: 0.25529354035246127, test_loss: 0.48472350686788557,test accuracy: 85.22%\n",
      "escaped time of this epoch:1062.3598880767822\n",
      "epoch: 38, iter: 50764, train_loss: 0.2611801823487087, test_loss: 0.49481005147099494,test accuracy: 84.83%\n",
      "escaped time of this epoch:1089.6627066135406\n",
      "epoch: 39, iter: 50960, train_loss: 0.2482447426538078, test_loss: 0.48472273871302607,test accuracy: 85.0%\n",
      "escaped time of this epoch:1117.0010695457458\n",
      "epoch: 40, iter: 51156, train_loss: 0.2596372766610311, test_loss: 0.48599577248096465,test accuracy: 84.32%\n",
      "escaped time of this epoch:1144.368884563446\n",
      "epoch: 41, iter: 51352, train_loss: 0.11620747332214093, test_loss: 0.376525703817606,test accuracy: 88.63%\n",
      "escaped time of this epoch:1171.6523232460022\n",
      "epoch: 42, iter: 51548, train_loss: 0.05117988826859058, test_loss: 0.3923683613538742,test accuracy: 88.98%\n",
      "escaped time of this epoch:1198.8723068237305\n",
      "epoch: 43, iter: 51744, train_loss: 0.029652572816655953, test_loss: 0.40787439942359927,test accuracy: 88.89%\n",
      "escaped time of this epoch:1226.1617965698242\n",
      "epoch: 44, iter: 51940, train_loss: 0.019711739336121446, test_loss: 0.42101601138710976,test accuracy: 88.99%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escaped time of this epoch:1253.4649560451508\n",
      "epoch: 45, iter: 52136, train_loss: 0.013168149371156278, test_loss: 0.43776816949248315,test accuracy: 89.08%\n",
      "escaped time of this epoch:1280.8309481143951\n",
      "epoch: 46, iter: 52332, train_loss: 0.009615151097579879, test_loss: 0.4476898044347763,test accuracy: 88.98%\n",
      "escaped time of this epoch:1308.3355901241302\n",
      "epoch: 47, iter: 52528, train_loss: 0.00788087870602553, test_loss: 0.4536604553461075,test accuracy: 89.13%\n",
      "escaped time of this epoch:1335.7245075702667\n",
      "epoch: 48, iter: 52724, train_loss: 0.005999254039013568, test_loss: 0.4628301620483398,test accuracy: 89.07%\n",
      "escaped time of this epoch:1363.0452995300293\n",
      "epoch: 49, iter: 52920, train_loss: 0.005333862965926528, test_loss: 0.4673816077411175,test accuracy: 89.13%\n",
      "escaped time of this epoch:1390.3545637130737\n",
      "epoch: 50, iter: 53116, train_loss: 0.004989138916039801, test_loss: 0.469623813778162,test accuracy: 89.05%\n",
      "escaped time of this epoch:1417.7281601428986\n",
      "epoch: 51, iter: 53312, train_loss: 0.004657363694883427, test_loss: 0.4727198578417301,test accuracy: 89.0%\n",
      "escaped time of this epoch:1445.20658659935\n",
      "epoch: 52, iter: 53508, train_loss: 0.003785383046547673, test_loss: 0.4730860099196434,test accuracy: 89.12%\n",
      "escaped time of this epoch:1472.5108029842377\n",
      "epoch: 53, iter: 53704, train_loss: 0.0035225988451239405, test_loss: 0.476626917719841,test accuracy: 89.17%\n",
      "escaped time of this epoch:1499.8769009113312\n",
      "epoch: 54, iter: 53900, train_loss: 0.003226118150395246, test_loss: 0.4784086927771568,test accuracy: 89.32%\n",
      "escaped time of this epoch:1527.2058532238007\n",
      "epoch: 55, iter: 54096, train_loss: 0.0030952164694210706, test_loss: 0.48048263788223267,test accuracy: 89.17%\n",
      "escaped time of this epoch:1554.6593699455261\n",
      "epoch: 56, iter: 54292, train_loss: 0.0026655715167978587, test_loss: 0.4822991840541363,test accuracy: 89.25%\n",
      "escaped time of this epoch:1582.0514271259308\n",
      "epoch: 57, iter: 54488, train_loss: 0.0028273992772613254, test_loss: 0.48251456394791603,test accuracy: 89.22%\n",
      "escaped time of this epoch:1609.3881113529205\n",
      "epoch: 58, iter: 54684, train_loss: 0.002791032613236077, test_loss: 0.48496906757354735,test accuracy: 89.2%\n",
      "escaped time of this epoch:1636.6668212413788\n",
      "epoch: 59, iter: 54880, train_loss: 0.0024394841997751166, test_loss: 0.48521056175231936,test accuracy: 89.13%\n",
      "escaped time of this epoch:1663.9223291873932\n",
      "epoch: 60, iter: 55076, train_loss: 0.0027846660208413186, test_loss: 0.48510008826851847,test accuracy: 89.15%\n",
      "escaped time of this epoch:1691.183270931244\n",
      "epoch: 61, iter: 55272, train_loss: 0.0029834020545478073, test_loss: 0.48650652840733527,test accuracy: 89.17%\n",
      "escaped time of this epoch:1718.43643450737\n",
      "epoch: 62, iter: 55468, train_loss: 0.002491782876729433, test_loss: 0.48887786343693734,test accuracy: 89.22%\n",
      "escaped time of this epoch:1745.7538952827454\n",
      "epoch: 63, iter: 55664, train_loss: 0.002705793723235933, test_loss: 0.4916648343205452,test accuracy: 89.19%\n",
      "escaped time of this epoch:1773.0918643474579\n",
      "epoch: 64, iter: 55860, train_loss: 0.00285675769614778, test_loss: 0.4900882750749588,test accuracy: 89.1%\n",
      "escaped time of this epoch:1800.4887669086456\n",
      "epoch: 65, iter: 56056, train_loss: 0.002857798396856809, test_loss: 0.4963785782456398,test accuracy: 89.16%\n",
      "escaped time of this epoch:1827.9212262630463\n",
      "epoch: 66, iter: 56252, train_loss: 0.0031609432225362683, test_loss: 0.49831624925136564,test accuracy: 89.34%\n",
      "escaped time of this epoch:1855.2995858192444\n",
      "epoch: 67, iter: 56448, train_loss: 0.002323221595843836, test_loss: 0.49773719906806946,test accuracy: 89.37%\n",
      "escaped time of this epoch:1882.6540813446045\n",
      "epoch: 68, iter: 56644, train_loss: 0.0020242198061540114, test_loss: 0.4983312875032425,test accuracy: 89.28%\n",
      "escaped time of this epoch:1909.9168741703033\n",
      "epoch: 69, iter: 56840, train_loss: 0.0020348908645766123, test_loss: 0.49814065769314764,test accuracy: 89.35%\n",
      "escaped time of this epoch:1937.2424383163452\n",
      "epoch: 70, iter: 57036, train_loss: 0.0020250891838983005, test_loss: 0.4988547690212727,test accuracy: 89.53%\n",
      "escaped time of this epoch:1964.5111198425293\n",
      "epoch: 71, iter: 57232, train_loss: 0.002039509877676562, test_loss: 0.49891288205981255,test accuracy: 89.34%\n",
      "escaped time of this epoch:1991.7298963069916\n",
      "epoch: 72, iter: 57428, train_loss: 0.001986697553752028, test_loss: 0.4982691310346127,test accuracy: 89.28%\n",
      "escaped time of this epoch:2019.0882196426392\n",
      "epoch: 73, iter: 57624, train_loss: 0.001977522909755305, test_loss: 0.49796080216765404,test accuracy: 89.28%\n",
      "escaped time of this epoch:2046.34668135643\n",
      "epoch: 74, iter: 57820, train_loss: 0.002052919509136403, test_loss: 0.4996799901127815,test accuracy: 89.22%\n",
      "escaped time of this epoch:2073.7081348896027\n",
      "epoch: 75, iter: 58016, train_loss: 0.0019258126587968093, test_loss: 0.49944276437163354,test accuracy: 89.21%\n",
      "escaped time of this epoch:2101.2849316596985\n",
      "epoch: 76, iter: 58212, train_loss: 0.0019776234545801977, test_loss: 0.505968763679266,test accuracy: 89.19%\n",
      "escaped time of this epoch:2128.8058590888977\n",
      "epoch: 77, iter: 58408, train_loss: 0.0019420093585908109, test_loss: 0.5053363561630249,test accuracy: 89.12%\n",
      "escaped time of this epoch:2156.140773296356\n",
      "epoch: 78, iter: 58604, train_loss: 0.0018902668986013349, test_loss: 0.5059037409722805,test accuracy: 89.15%\n",
      "escaped time of this epoch:2183.6157274246216\n",
      "epoch: 79, iter: 58800, train_loss: 0.0022544518626314036, test_loss: 0.50488291233778,test accuracy: 89.26%\n",
      "escaped time of this epoch:2211.252008676529\n",
      "epoch: 80, iter: 58996, train_loss: 0.001877728269948643, test_loss: 0.5051601894199849,test accuracy: 89.27%\n",
      "escaped time of this epoch:2238.6980290412903\n",
      "epoch: 81, iter: 59192, train_loss: 0.0018821293131771441, test_loss: 0.5051530867815017,test accuracy: 89.21%\n",
      "escaped time of this epoch:2265.997255086899\n",
      "epoch: 82, iter: 59388, train_loss: 0.0017892651887116383, test_loss: 0.5052566215395927,test accuracy: 89.23%\n",
      "escaped time of this epoch:2293.2780928611755\n",
      "epoch: 83, iter: 59584, train_loss: 0.0018562593839454408, test_loss: 0.505226069688797,test accuracy: 89.26%\n",
      "escaped time of this epoch:2320.721739292145\n",
      "epoch: 84, iter: 59780, train_loss: 0.0019538505668086664, test_loss: 0.505060737580061,test accuracy: 89.23%\n",
      "escaped time of this epoch:2348.1253287792206\n",
      "epoch: 85, iter: 59976, train_loss: 0.0018693170241764461, test_loss: 0.5050897896289825,test accuracy: 89.27%\n",
      "escaped time of this epoch:2375.412316799164\n",
      "epoch: 86, iter: 60172, train_loss: 0.0018137953320176018, test_loss: 0.5051728762686253,test accuracy: 89.24%\n",
      "escaped time of this epoch:2402.712401151657\n",
      "epoch: 87, iter: 60368, train_loss: 0.001774219206857438, test_loss: 0.5052215941250324,test accuracy: 89.24%\n",
      "escaped time of this epoch:2429.939489364624\n",
      "epoch: 88, iter: 60564, train_loss: 0.0017901025213567273, test_loss: 0.5055565655231475,test accuracy: 89.22%\n",
      "escaped time of this epoch:2457.17897105217\n",
      "epoch: 89, iter: 60760, train_loss: 0.0017486273540345458, test_loss: 0.5057780355215072,test accuracy: 89.23%\n",
      "escaped time of this epoch:2484.4529514312744\n",
      "epoch: 90, iter: 60956, train_loss: 0.0017564052036412212, test_loss: 0.5063868843019008,test accuracy: 89.21%\n",
      "escaped time of this epoch:2511.739603281021\n",
      "epoch: 91, iter: 61152, train_loss: 0.0018262186667368729, test_loss: 0.5067624241113663,test accuracy: 89.23%\n",
      "escaped time of this epoch:2538.9806962013245\n",
      "epoch: 92, iter: 61348, train_loss: 0.001988134627249472, test_loss: 0.5069120764732361,test accuracy: 89.28%\n",
      "escaped time of this epoch:2566.2782592773438\n",
      "epoch: 93, iter: 61544, train_loss: 0.0018035234142170877, test_loss: 0.5058636344969273,test accuracy: 89.22%\n",
      "escaped time of this epoch:2593.5184626579285\n",
      "epoch: 94, iter: 61740, train_loss: 0.0018180130923889121, test_loss: 0.5062095552682877,test accuracy: 89.23%\n",
      "escaped time of this epoch:2620.8414554595947\n",
      "epoch: 95, iter: 61936, train_loss: 0.001836152459798875, test_loss: 0.5065000712871551,test accuracy: 89.25%\n",
      "escaped time of this epoch:2648.1400039196014\n",
      "epoch: 96, iter: 62132, train_loss: 0.0017973717435130052, test_loss: 0.5066076189279556,test accuracy: 89.23%\n",
      "escaped time of this epoch:2675.442673921585\n",
      "epoch: 97, iter: 62328, train_loss: 0.0018373282010933118, test_loss: 0.506903937458992,test accuracy: 89.31%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escaped time of this epoch:2702.7071409225464\n",
      "epoch: 98, iter: 62524, train_loss: 0.001777634420194568, test_loss: 0.5070163302123547,test accuracy: 89.31%\n",
      "escaped time of this epoch:2730.0011541843414\n",
      "epoch: 99, iter: 62720, train_loss: 0.0017900510253954906, test_loss: 0.5069737985730172,test accuracy: 89.25%\n",
      "escaped time of this epoch:2757.2641036510468\n",
      "epoch: 100, iter: 62916, train_loss: 0.0016888193726748684, test_loss: 0.5072260648012161,test accuracy: 89.26%\n",
      "escaped time of this epoch:2784.572830915451\n",
      "epoch: 101, iter: 63112, train_loss: 0.0017046584552914208, test_loss: 0.5074964366853237,test accuracy: 89.28%\n",
      "escaped time of this epoch:2811.901654481888\n",
      "epoch: 102, iter: 63308, train_loss: 0.0016939723596917655, test_loss: 0.5078685790300369,test accuracy: 89.24%\n",
      "escaped time of this epoch:2839.1234724521637\n",
      "epoch: 103, iter: 63504, train_loss: 0.0016985241375977592, test_loss: 0.5075949765741825,test accuracy: 89.25%\n",
      "escaped time of this epoch:2866.480643749237\n",
      "epoch: 104, iter: 63700, train_loss: 0.0017236504556459127, test_loss: 0.5077822834253312,test accuracy: 89.22%\n",
      "escaped time of this epoch:2893.7834804058075\n",
      "epoch: 105, iter: 63896, train_loss: 0.0018167030256317587, test_loss: 0.5078916102647781,test accuracy: 89.22%\n",
      "escaped time of this epoch:2921.11576461792\n",
      "epoch: 106, iter: 64092, train_loss: 0.0018619932899517672, test_loss: 0.5083061583340168,test accuracy: 89.26%\n",
      "escaped time of this epoch:2948.444745540619\n",
      "epoch: 107, iter: 64288, train_loss: 0.0017671059360917733, test_loss: 0.5086706653237343,test accuracy: 89.18%\n",
      "escaped time of this epoch:2975.8208208084106\n",
      "epoch: 108, iter: 64484, train_loss: 0.001727786958122588, test_loss: 0.508489441871643,test accuracy: 89.21%\n",
      "escaped time of this epoch:3003.0985147953033\n",
      "epoch: 109, iter: 64680, train_loss: 0.0018308377332928382, test_loss: 0.5085135705769062,test accuracy: 89.26%\n",
      "best loss:  0.376525703817606\n",
      "Born Again...\n",
      "delete last model!!!\n",
      "escaped time of this epoch:27.29880404472351\n",
      "epoch: 0, iter: 64876, train_loss: 1.555255764601182, test_loss: 1.2815411269664765,test accuracy: 53.78%\n",
      "escaped time of this epoch:54.630879402160645\n",
      "epoch: 1, iter: 65072, train_loss: 1.052799875638923, test_loss: 0.8944498971104622,test accuracy: 69.0%\n",
      "escaped time of this epoch:81.97695922851562\n",
      "epoch: 2, iter: 65268, train_loss: 0.7800804729364357, test_loss: 0.774976558983326,test accuracy: 73.8%\n",
      "escaped time of this epoch:109.2640106678009\n",
      "epoch: 3, iter: 65464, train_loss: 0.6379840900095142, test_loss: 0.6498964205384254,test accuracy: 77.88%\n",
      "escaped time of this epoch:136.65099835395813\n",
      "epoch: 4, iter: 65660, train_loss: 0.5420295149087906, test_loss: 0.598659984767437,test accuracy: 80.35%\n",
      "escaped time of this epoch:164.02207374572754\n",
      "epoch: 5, iter: 65856, train_loss: 0.48772342305402366, test_loss: 0.5833701834082603,test accuracy: 81.12%\n",
      "escaped time of this epoch:191.30519080162048\n",
      "epoch: 6, iter: 66052, train_loss: 0.43755943541015896, test_loss: 0.5455368369817734,test accuracy: 81.73%\n",
      "escaped time of this epoch:218.5578145980835\n",
      "epoch: 7, iter: 66248, train_loss: 0.4117570960400056, test_loss: 0.5553846187889576,test accuracy: 81.62%\n",
      "escaped time of this epoch:245.84009671211243\n",
      "epoch: 8, iter: 66444, train_loss: 0.38388953715258717, test_loss: 0.5679589942097664,test accuracy: 81.27%\n",
      "escaped time of this epoch:273.1962938308716\n",
      "epoch: 9, iter: 66640, train_loss: 0.3646791566695486, test_loss: 0.5382883504033089,test accuracy: 82.47%\n",
      "escaped time of this epoch:300.4710738658905\n",
      "epoch: 10, iter: 66836, train_loss: 0.35281186999411, test_loss: 0.569065372645855,test accuracy: 81.42%\n",
      "escaped time of this epoch:327.88392329216003\n",
      "epoch: 11, iter: 67032, train_loss: 0.3326212556234428, test_loss: 0.5450852394104004,test accuracy: 82.62%\n",
      "escaped time of this epoch:355.21088433265686\n",
      "epoch: 12, iter: 67228, train_loss: 0.3251074349545703, test_loss: 0.5164150349795819,test accuracy: 82.85%\n",
      "escaped time of this epoch:382.4341502189636\n",
      "epoch: 13, iter: 67424, train_loss: 0.3083296225843381, test_loss: 0.5256128661334515,test accuracy: 82.74%\n",
      "escaped time of this epoch:409.79856848716736\n",
      "epoch: 14, iter: 67620, train_loss: 0.31175660197528043, test_loss: 0.5235921964049339,test accuracy: 83.05%\n",
      "escaped time of this epoch:437.19081592559814\n",
      "epoch: 15, iter: 67816, train_loss: 0.302789750147839, test_loss: 0.5112263962626458,test accuracy: 83.07%\n",
      "escaped time of this epoch:464.57400941848755\n",
      "epoch: 16, iter: 68012, train_loss: 0.30424689874053, test_loss: 0.5268481932580471,test accuracy: 83.4%\n",
      "escaped time of this epoch:491.87424516677856\n",
      "epoch: 17, iter: 68208, train_loss: 0.28382445917445787, test_loss: 0.49000257030129435,test accuracy: 84.15%\n",
      "escaped time of this epoch:519.1853535175323\n",
      "epoch: 18, iter: 68404, train_loss: 0.2874777083646278, test_loss: 0.5137580811977387,test accuracy: 83.67%\n",
      "escaped time of this epoch:546.5421936511993\n",
      "epoch: 19, iter: 68600, train_loss: 0.28895564803055357, test_loss: 0.5016224965453148,test accuracy: 84.19%\n",
      "escaped time of this epoch:573.8910796642303\n",
      "epoch: 20, iter: 68796, train_loss: 0.2823467706995351, test_loss: 0.5142083205282688,test accuracy: 83.43%\n",
      "escaped time of this epoch:601.1615946292877\n",
      "epoch: 21, iter: 68992, train_loss: 0.2742222573380081, test_loss: 0.49255587756633756,test accuracy: 84.51%\n",
      "escaped time of this epoch:628.468540430069\n",
      "epoch: 22, iter: 69188, train_loss: 0.27278973861616485, test_loss: 0.496611499786377,test accuracy: 84.49%\n",
      "escaped time of this epoch:655.7815170288086\n",
      "epoch: 23, iter: 69384, train_loss: 0.28065769838131205, test_loss: 0.4955120176076889,test accuracy: 83.88%\n",
      "escaped time of this epoch:683.1110992431641\n",
      "epoch: 24, iter: 69580, train_loss: 0.2810226535158498, test_loss: 0.47926296591758727,test accuracy: 84.62%\n",
      "escaped time of this epoch:710.4088716506958\n",
      "epoch: 25, iter: 69776, train_loss: 0.2789118387261216, test_loss: 0.5069274127483367,test accuracy: 83.81%\n",
      "escaped time of this epoch:737.6839435100555\n",
      "epoch: 26, iter: 69972, train_loss: 0.26621835709226377, test_loss: 0.4956455960869789,test accuracy: 84.3%\n",
      "escaped time of this epoch:764.9365830421448\n",
      "epoch: 27, iter: 70168, train_loss: 0.26586789234864466, test_loss: 0.5004021801054478,test accuracy: 84.5%\n",
      "escaped time of this epoch:792.2037885189056\n",
      "epoch: 28, iter: 70364, train_loss: 0.25773568877152037, test_loss: 0.5106120079755783,test accuracy: 83.38%\n",
      "escaped time of this epoch:819.4676995277405\n",
      "epoch: 29, iter: 70560, train_loss: 0.27493338689816244, test_loss: 0.495574077218771,test accuracy: 84.22%\n",
      "escaped time of this epoch:846.759566783905\n",
      "epoch: 30, iter: 70756, train_loss: 0.26216233354441976, test_loss: 0.49644156396389005,test accuracy: 84.11%\n",
      "escaped time of this epoch:874.0416452884674\n",
      "epoch: 31, iter: 70952, train_loss: 0.2607435548335922, test_loss: 0.5083077147603035,test accuracy: 84.16%\n",
      "escaped time of this epoch:901.3862273693085\n",
      "epoch: 32, iter: 71148, train_loss: 0.2665386653068114, test_loss: 0.5016113594174385,test accuracy: 84.4%\n",
      "escaped time of this epoch:928.8154718875885\n",
      "epoch: 33, iter: 71344, train_loss: 0.26930003354744037, test_loss: 0.4777001358568668,test accuracy: 84.85%\n",
      "escaped time of this epoch:956.0956201553345\n",
      "epoch: 34, iter: 71540, train_loss: 0.25213692770624646, test_loss: 0.47879101186990736,test accuracy: 84.47%\n",
      "escaped time of this epoch:983.4489669799805\n",
      "epoch: 35, iter: 71736, train_loss: 0.26706983453156996, test_loss: 0.4579457797110081,test accuracy: 85.75%\n",
      "escaped time of this epoch:1010.7391488552094\n",
      "epoch: 36, iter: 71932, train_loss: 0.2565804331810499, test_loss: 0.47255523726344106,test accuracy: 85.07%\n",
      "escaped time of this epoch:1038.2225103378296\n",
      "epoch: 37, iter: 72128, train_loss: 0.2563591340214622, test_loss: 0.4646195605397224,test accuracy: 84.89%\n",
      "escaped time of this epoch:1065.562863111496\n",
      "epoch: 38, iter: 72324, train_loss: 0.2596060722990304, test_loss: 0.47859288305044173,test accuracy: 84.82%\n",
      "escaped time of this epoch:1092.9348013401031\n",
      "epoch: 39, iter: 72520, train_loss: 0.25369139730322116, test_loss: 0.4735552124679089,test accuracy: 85.01%\n",
      "escaped time of this epoch:1120.210951089859\n",
      "epoch: 40, iter: 72716, train_loss: 0.25821547689182417, test_loss: 0.46785819306969645,test accuracy: 85.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escaped time of this epoch:1147.6354234218597\n",
      "epoch: 41, iter: 72912, train_loss: 0.11400213216108326, test_loss: 0.3643701419234276,test accuracy: 88.99%\n",
      "escaped time of this epoch:1174.944254398346\n",
      "epoch: 42, iter: 73108, train_loss: 0.05064123378572415, test_loss: 0.37366200722754,test accuracy: 89.18%\n",
      "escaped time of this epoch:1202.2271800041199\n",
      "epoch: 43, iter: 73304, train_loss: 0.029406244937824656, test_loss: 0.39011774137616156,test accuracy: 89.29%\n",
      "escaped time of this epoch:1229.5242726802826\n",
      "epoch: 44, iter: 73500, train_loss: 0.01924793219802027, test_loss: 0.40473023019731047,test accuracy: 89.43%\n",
      "escaped time of this epoch:1256.877123117447\n",
      "epoch: 45, iter: 73696, train_loss: 0.013528326925422465, test_loss: 0.4154531601816416,test accuracy: 89.23%\n",
      "escaped time of this epoch:1284.1357870101929\n",
      "epoch: 46, iter: 73892, train_loss: 0.01012238838747904, test_loss: 0.4276249945163727,test accuracy: 89.24%\n",
      "escaped time of this epoch:1311.3620903491974\n",
      "epoch: 47, iter: 74088, train_loss: 0.008105855537293365, test_loss: 0.43403248190879823,test accuracy: 89.38%\n",
      "escaped time of this epoch:1338.6606633663177\n",
      "epoch: 48, iter: 74284, train_loss: 0.006323991618974477, test_loss: 0.4409411959350109,test accuracy: 89.51%\n",
      "escaped time of this epoch:1366.0770716667175\n",
      "epoch: 49, iter: 74480, train_loss: 0.005582995955091046, test_loss: 0.4472029719501734,test accuracy: 89.4%\n",
      "escaped time of this epoch:1393.4978771209717\n",
      "epoch: 50, iter: 74676, train_loss: 0.00474464718955664, test_loss: 0.4514640212059021,test accuracy: 89.56%\n",
      "escaped time of this epoch:1420.8594675064087\n",
      "epoch: 51, iter: 74872, train_loss: 0.004204414269354727, test_loss: 0.45613677948713305,test accuracy: 89.31%\n",
      "escaped time of this epoch:1448.1991341114044\n",
      "epoch: 52, iter: 75068, train_loss: 0.0038704578099506243, test_loss: 0.45881096050143244,test accuracy: 89.5%\n",
      "escaped time of this epoch:1475.552838563919\n",
      "epoch: 53, iter: 75264, train_loss: 0.0035431621933584008, test_loss: 0.46163276210427284,test accuracy: 89.39%\n",
      "escaped time of this epoch:1502.8775799274445\n",
      "epoch: 54, iter: 75460, train_loss: 0.003557626604653743, test_loss: 0.4636919960379601,test accuracy: 89.37%\n",
      "escaped time of this epoch:1530.229567527771\n",
      "epoch: 55, iter: 75656, train_loss: 0.003488181021102533, test_loss: 0.46595648750662805,test accuracy: 89.31%\n",
      "escaped time of this epoch:1557.5103476047516\n",
      "epoch: 56, iter: 75852, train_loss: 0.0030123595711394995, test_loss: 0.46857199892401696,test accuracy: 89.27%\n",
      "escaped time of this epoch:1584.8221552371979\n",
      "epoch: 57, iter: 76048, train_loss: 0.0029039657603455137, test_loss: 0.468817176669836,test accuracy: 89.21%\n",
      "escaped time of this epoch:1612.1817514896393\n",
      "epoch: 58, iter: 76244, train_loss: 0.0027500339379838232, test_loss: 0.4715298794209957,test accuracy: 89.24%\n",
      "escaped time of this epoch:1639.60404753685\n",
      "epoch: 59, iter: 76440, train_loss: 0.0025573231336869754, test_loss: 0.4695334531366825,test accuracy: 89.27%\n",
      "escaped time of this epoch:1667.0079247951508\n",
      "epoch: 60, iter: 76636, train_loss: 0.0023985766705923845, test_loss: 0.4702443040907383,test accuracy: 89.31%\n",
      "escaped time of this epoch:1694.4229278564453\n",
      "epoch: 61, iter: 76832, train_loss: 0.002332877832208285, test_loss: 0.47134113907814024,test accuracy: 89.29%\n",
      "escaped time of this epoch:1721.7905566692352\n",
      "epoch: 62, iter: 77028, train_loss: 0.00239729185170513, test_loss: 0.4756078660488129,test accuracy: 89.25%\n",
      "escaped time of this epoch:1749.2009432315826\n",
      "epoch: 63, iter: 77224, train_loss: 0.002227175771733936, test_loss: 0.4747235082089901,test accuracy: 89.22%\n",
      "escaped time of this epoch:1776.6231501102448\n",
      "epoch: 64, iter: 77420, train_loss: 0.0021437175455503166, test_loss: 0.47432089075446127,test accuracy: 89.12%\n",
      "escaped time of this epoch:1804.062564611435\n",
      "epoch: 65, iter: 77616, train_loss: 0.002237132223018882, test_loss: 0.47520958408713343,test accuracy: 89.14%\n",
      "escaped time of this epoch:1831.426349401474\n",
      "epoch: 66, iter: 77812, train_loss: 0.0021307602375080542, test_loss: 0.4782759428024292,test accuracy: 89.18%\n",
      "escaped time of this epoch:1858.8486573696136\n",
      "epoch: 67, iter: 78008, train_loss: 0.002078763731964389, test_loss: 0.476627479493618,test accuracy: 89.19%\n",
      "escaped time of this epoch:1886.27050614357\n",
      "epoch: 68, iter: 78204, train_loss: 0.0020314757403328406, test_loss: 0.47675620689988135,test accuracy: 89.25%\n",
      "escaped time of this epoch:1913.6077971458435\n",
      "epoch: 69, iter: 78400, train_loss: 0.001969280639634829, test_loss: 0.478725366294384,test accuracy: 89.17%\n",
      "escaped time of this epoch:1941.0171661376953\n",
      "epoch: 70, iter: 78596, train_loss: 0.0020082634933083795, test_loss: 0.47957474961876867,test accuracy: 89.19%\n",
      "escaped time of this epoch:1968.3410034179688\n",
      "epoch: 71, iter: 78792, train_loss: 0.001994856649876705, test_loss: 0.4800458028912544,test accuracy: 89.18%\n",
      "escaped time of this epoch:1995.7289414405823\n",
      "epoch: 72, iter: 78988, train_loss: 0.0020353367970306047, test_loss: 0.4786946639418602,test accuracy: 89.2%\n",
      "escaped time of this epoch:2023.0761272907257\n",
      "epoch: 73, iter: 79184, train_loss: 0.001953779370523989, test_loss: 0.48034834042191504,test accuracy: 89.2%\n",
      "escaped time of this epoch:2050.473605155945\n",
      "epoch: 74, iter: 79380, train_loss: 0.002030006457804417, test_loss: 0.48004636391997335,test accuracy: 89.11%\n",
      "escaped time of this epoch:2077.858571767807\n",
      "epoch: 75, iter: 79576, train_loss: 0.0021044879353472163, test_loss: 0.4825645789504051,test accuracy: 89.19%\n",
      "escaped time of this epoch:2105.2357788085938\n",
      "epoch: 76, iter: 79772, train_loss: 0.001967892847831684, test_loss: 0.4849816389381886,test accuracy: 89.23%\n",
      "escaped time of this epoch:2132.618780374527\n",
      "epoch: 77, iter: 79968, train_loss: 0.0019150380857706983, test_loss: 0.4837823033332825,test accuracy: 89.18%\n",
      "escaped time of this epoch:2159.9700667858124\n",
      "epoch: 78, iter: 80164, train_loss: 0.0019337093488465311, test_loss: 0.48391514346003534,test accuracy: 89.2%\n",
      "escaped time of this epoch:2187.374139547348\n",
      "epoch: 79, iter: 80360, train_loss: 0.002049709313872213, test_loss: 0.48738994300365446,test accuracy: 89.15%\n",
      "escaped time of this epoch:2214.6921710968018\n",
      "epoch: 80, iter: 80556, train_loss: 0.001930069720030439, test_loss: 0.48675111681222916,test accuracy: 89.11%\n",
      "escaped time of this epoch:2242.17795753479\n",
      "epoch: 81, iter: 80752, train_loss: 0.0018578826625622353, test_loss: 0.48659407868981364,test accuracy: 89.12%\n",
      "escaped time of this epoch:2269.5613894462585\n",
      "epoch: 82, iter: 80948, train_loss: 0.0018146501946719174, test_loss: 0.4865972675383091,test accuracy: 89.14%\n",
      "escaped time of this epoch:2296.9740245342255\n",
      "epoch: 83, iter: 81144, train_loss: 0.0018153753278929057, test_loss: 0.48675930723547933,test accuracy: 89.11%\n",
      "escaped time of this epoch:2324.4336512088776\n",
      "epoch: 84, iter: 81340, train_loss: 0.0018411400746934268, test_loss: 0.48646953925490377,test accuracy: 89.15%\n",
      "escaped time of this epoch:2351.8619072437286\n",
      "epoch: 85, iter: 81536, train_loss: 0.001855977105299885, test_loss: 0.4865524508059025,test accuracy: 89.15%\n",
      "escaped time of this epoch:2379.206117630005\n",
      "epoch: 86, iter: 81732, train_loss: 0.0018949235779974535, test_loss: 0.48654190376400946,test accuracy: 89.14%\n",
      "escaped time of this epoch:2406.494640111923\n",
      "epoch: 87, iter: 81928, train_loss: 0.002032038042968025, test_loss: 0.48632231503725054,test accuracy: 89.14%\n",
      "escaped time of this epoch:2433.9055581092834\n",
      "epoch: 88, iter: 82124, train_loss: 0.0022786709251908623, test_loss: 0.4845991112291813,test accuracy: 89.19%\n",
      "escaped time of this epoch:2461.293697834015\n",
      "epoch: 89, iter: 82320, train_loss: 0.0019221037806829019, test_loss: 0.48634869381785395,test accuracy: 89.15%\n",
      "escaped time of this epoch:2488.572430372238\n",
      "epoch: 90, iter: 82516, train_loss: 0.0018752660146173165, test_loss: 0.48598082438111306,test accuracy: 89.17%\n",
      "escaped time of this epoch:2515.9224665164948\n",
      "epoch: 91, iter: 82712, train_loss: 0.0019017638001895072, test_loss: 0.4857265390455723,test accuracy: 89.13%\n",
      "escaped time of this epoch:2543.2960662841797\n",
      "epoch: 92, iter: 82908, train_loss: 0.0019278507204536274, test_loss: 0.48551018834114074,test accuracy: 89.13%\n",
      "escaped time of this epoch:2570.747158765793\n",
      "epoch: 93, iter: 83104, train_loss: 0.0019754577684691368, test_loss: 0.4851830258965492,test accuracy: 89.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escaped time of this epoch:2598.0662713050842\n",
      "epoch: 94, iter: 83300, train_loss: 0.0018722825833330198, test_loss: 0.48503536358475685,test accuracy: 89.19%\n",
      "escaped time of this epoch:2625.3931515216827\n",
      "epoch: 95, iter: 83496, train_loss: 0.0018458211181533275, test_loss: 0.4852078050374985,test accuracy: 89.2%\n",
      "escaped time of this epoch:2652.7343492507935\n",
      "epoch: 96, iter: 83692, train_loss: 0.001872966085009429, test_loss: 0.48537288084626196,test accuracy: 89.2%\n",
      "escaped time of this epoch:2680.128867149353\n",
      "epoch: 97, iter: 83888, train_loss: 0.0018096487061595734, test_loss: 0.4856234207749367,test accuracy: 89.21%\n",
      "escaped time of this epoch:2707.5683732032776\n",
      "epoch: 98, iter: 84084, train_loss: 0.0019971377986046125, test_loss: 0.48550191447138785,test accuracy: 89.2%\n",
      "escaped time of this epoch:2734.958096265793\n",
      "epoch: 99, iter: 84280, train_loss: 0.0018283173807763628, test_loss: 0.48563967272639275,test accuracy: 89.24%\n",
      "escaped time of this epoch:2762.239415168762\n",
      "epoch: 100, iter: 84476, train_loss: 0.0018267690189828982, test_loss: 0.4858368828892708,test accuracy: 89.24%\n",
      "escaped time of this epoch:2789.521175146103\n",
      "epoch: 101, iter: 84672, train_loss: 0.0018429238567775, test_loss: 0.4861429363489151,test accuracy: 89.25%\n",
      "escaped time of this epoch:2816.8249168395996\n",
      "epoch: 102, iter: 84868, train_loss: 0.0018392904466778344, test_loss: 0.4859567224979401,test accuracy: 89.22%\n",
      "escaped time of this epoch:2844.1638040542603\n",
      "epoch: 103, iter: 85064, train_loss: 0.0018335786904683526, test_loss: 0.4859443068504333,test accuracy: 89.25%\n",
      "escaped time of this epoch:2871.5248675346375\n",
      "epoch: 104, iter: 85260, train_loss: 0.0018206505052631302, test_loss: 0.48598519787192346,test accuracy: 89.25%\n",
      "escaped time of this epoch:2898.816769361496\n",
      "epoch: 105, iter: 85456, train_loss: 0.0018785851342337473, test_loss: 0.4862517736852169,test accuracy: 89.25%\n",
      "escaped time of this epoch:2926.3545365333557\n",
      "epoch: 106, iter: 85652, train_loss: 0.0018839787131137385, test_loss: 0.48619070276618004,test accuracy: 89.21%\n",
      "escaped time of this epoch:2953.7420978546143\n",
      "epoch: 107, iter: 85848, train_loss: 0.001796640814472066, test_loss: 0.4861728183925152,test accuracy: 89.23%\n",
      "escaped time of this epoch:2981.156527042389\n",
      "epoch: 108, iter: 86044, train_loss: 0.0018486503038878496, test_loss: 0.4862261116504669,test accuracy: 89.23%\n",
      "escaped time of this epoch:3008.4070167541504\n",
      "epoch: 109, iter: 86240, train_loss: 0.001861768628575136, test_loss: 0.48599490001797674,test accuracy: 89.22%\n",
      "best loss:  0.3643701419234276\n",
      "Born Again...\n",
      "Gen:  0 , best loss:  0.36928629204630853\n",
      "Gen:  1 , best loss:  0.38245091028511524\n",
      "Gen:  2 , best loss:  0.376525703817606\n",
      "Gen:  3 , best loss:  0.3643701419234276\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "\n",
    "class ArgParser(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.weight=None\n",
    "        self.lr=0.01\n",
    "        self.n_epoch=110#100\n",
    "        self.batch_size=256\n",
    "        self.n_gen=4\n",
    "        self.resume_gen=0\n",
    "        self.dataset=\"cifar10\"\n",
    "        self.outdir=\"snapshots\"\n",
    "        self.print_interval=500\n",
    "        \n",
    "        \n",
    "def main():\n",
    "\n",
    "    args=ArgParser()\n",
    "\n",
    "    logger = Logger(args)\n",
    "    logger.print_args()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    trainset = CIFAR10(root=\"./data\",\n",
    "                       train=True,\n",
    "                       download=True,\n",
    "                       transform=transform)\n",
    "    testset = CIFAR10(root=\"./data\",\n",
    "                      train=False,\n",
    "                      download=True,\n",
    "                      transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(trainset,\n",
    "                              batch_size=args.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=4)\n",
    "    test_loader = DataLoader(testset,\n",
    "                             batch_size=args.batch_size,\n",
    "                             shuffle=False,\n",
    "                             num_workers=4)\n",
    "    print(len(test_loader))\n",
    "    \n",
    "    i = 0\n",
    "   \n",
    "    best_loss_list = []\n",
    "\n",
    "    print(\"train...\")\n",
    "    last_model_weight=\"\"\n",
    "    for gen in range(args.resume_gen, args.n_gen):\n",
    "        \n",
    "        import gc\n",
    "        if \"model\" in locals() or 'model' in globals():\n",
    "            del model\n",
    "            print(\"delete last model!!!\")\n",
    "        gc.collect()\n",
    "        \n",
    "        # From https://github.com/kuangliu/pytorch-cifar \n",
    "        if torch.cuda.is_available():\n",
    "            model=MobileNet(10).cuda()\n",
    "        else:\n",
    "            model=MobileNet(10)\n",
    " \n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "        scheduler = StepLR(optimizer, step_size=40, gamma=0.1)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        kwargs = {\n",
    "            \"model\": model,\n",
    "            \"optimizer\": optimizer,\n",
    "            \"n_gen\": args.n_gen,\n",
    "        }\n",
    "        \n",
    "        updater = BANUpdater(**kwargs)\n",
    "        updater.register_last_model(last_model_weight)\n",
    "        \n",
    "        # -----------------------------------------------------------------------\n",
    "        best_loss = 1e+9\n",
    "        since=time.time()\n",
    "        for epoch in range(args.n_epoch):\n",
    "            \n",
    "            # ---------------------\n",
    "            train_loss = []\n",
    "            for idx, (inputs, targets) in enumerate(train_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                t_loss = updater.update(inputs, targets, criterion).item() # the loss of this batch\n",
    "                train_loss.append(t_loss)\n",
    "                i += 1\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            # ---------------------\n",
    "            val_loss = []\n",
    "            correct=0\n",
    "            with torch.no_grad():\n",
    "                for idx, (inputs, targets) in enumerate(test_loader):\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    outputs = updater.model(inputs)\n",
    "                    loss = criterion(outputs, targets).item()\n",
    "                    val_loss.append(loss)\n",
    "                    pred = outputs.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "                    correct += pred.eq(targets.data.view_as(pred)).sum()\n",
    "            \n",
    "            mean_val_loss = np.mean(val_loss)\n",
    "            mean_train_loss=np.mean(train_loss)\n",
    "            accuracy = 100. * correct.cpu().numpy() / len(test_loader.dataset)\n",
    "            \n",
    "            if mean_val_loss < best_loss:\n",
    "                best_loss = mean_val_loss\n",
    "                last_model_weight = os.path.join(args.outdir,\"model\"+str(gen)+\".p\")\n",
    "                torch.save(updater.model.state_dict(),last_model_weight)\n",
    "            \n",
    "            print(\"escaped time of this epoch:{}\".format(time.time()-since))\n",
    "            logger.print_log(epoch, i, mean_train_loss, mean_val_loss,accuracy)\n",
    "\n",
    "        print(\"best loss: \", best_loss)\n",
    "        print(\"Born Again...\")\n",
    "        updater.gen += 1\n",
    "        best_loss_list.append(best_loss)\n",
    "        best_loss = 1e+9 # reset \n",
    "\n",
    "    for gen in range(args.n_gen):\n",
    "        print(\"Gen: \", gen,\n",
    "              \", best loss: \", best_loss_list[gen])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.2055\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "f1=open(\"Train_Info.txt\",\"r\")\n",
    "num=0\n",
    "res=[]\n",
    "for aLine in f1:\n",
    "    num=num+1\n",
    "    tmp=[str(e) for e in aLine.strip(\"\\n\").split(\" \")]\n",
    "    if tmp[0]==\"epoch:\" and num>180:\n",
    "        res.append(float(tmp[-1].strip(\"%\")))\n",
    "    \n",
    "f1.close()\n",
    "print(np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gen 1: 89.17050000000002\n",
    "\n",
    "# gen 2: 89.17399999999999\n",
    "\n",
    "# gen 3: 89.245\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
