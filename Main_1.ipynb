{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1D卷积  ---等效于CNN做文本分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://op4a94iq8.bkt.clouddn.com/18-7-13/49813055.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: torch.Size([5, 2, 10])\n",
      "output size: torch.Size([5, 3, 4])\n",
      "filter size: torch.Size([3, 2, 4])\n",
      "<built-in method type of Parameter object at 0x7f8d25ff5990>\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "m = nn.Conv1d(2, 3, 4, stride=2,padding=0,groups=1,dilation=1)\n",
    "\n",
    "input = torch.randn(5, 2, 10)\n",
    "print(\"input size:\",input.shape)\n",
    "\n",
    "output = m(input)\n",
    "print(\"output size:\",output.shape)\n",
    "\n",
    "print(\"filter size:\",m.weight.shape)\n",
    "print(m.weight.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: torch.Size([1, 512, 14, 14])\n",
      "<built-in method type of Tensor object at 0x7f8d2612c1b0>\n",
      "output size: torch.Size([1, 512, 1, 1])\n",
      "avg size: torch.Size([1, 1, 512])\n",
      "out_1 size: torch.Size([1, 1024, 512])\n",
      "filter size: torch.Size([1024, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# pool of non-square window\n",
    "input = torch.randn(1, 512, 14, 14) # batch_size=1\n",
    "print(\"input size:\",input.shape)\n",
    "print(input.type)\n",
    "\n",
    "m = nn.AvgPool2d(14)\n",
    "\n",
    "output = m(input)\n",
    "print(\"output size:\",output.shape)\n",
    "\n",
    "avg=output.view(output.shape[0],1,output.shape[1])\n",
    "print(\"avg size:\",avg.shape)\n",
    "\n",
    "one_conv_filter = nn.Conv1d(1, 1024, 3, stride=1,padding=1,groups=1,dilation=1)\n",
    "\n",
    "out_1 = one_conv_filter(avg)\n",
    "print(\"out_1 size:\",out_1.shape)\n",
    "print(\"filter size:\",one_conv_filter.weight.shape)\n",
    "\n",
    "\n",
    "# --------------------- 加权融合 -----------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y size: torch.Size([2, 3, 1, 1])\n",
      "X size: torch.Size([3, 2, 2])\n",
      "torch.Size([2, 3, 2, 2])\n",
      "tensor([[[  0.2000,   0.2000],\n",
      "         [  0.2000,   0.2000]],\n",
      "\n",
      "        [[  0.8000,   0.8000],\n",
      "         [  0.8000,   0.8000]],\n",
      "\n",
      "        [[ 30.0000,  30.0000],\n",
      "         [ 30.0000,  30.0000]]])\n",
      "torch.Size([2, 2, 2])\n",
      "tensor([[[ 10.5000,  10.5000],\n",
      "         [ 10.5000,  10.5000]],\n",
      "\n",
      "        [[ 31.0000,  31.0000],\n",
      "         [ 31.0000,  31.0000]]])\n"
     ]
    }
   ],
   "source": [
    "# 不考虑batchsize时实现了1x1卷积\n",
    "y=torch.Tensor(\n",
    "    [\n",
    "       [[[0.1]],[[0.7]],[[3]],],\n",
    "       [[[0.2]],[[0.4]],[[10]],]\n",
    "    ])\n",
    "\n",
    "print(\"Y size:\",y.shape)\n",
    "\n",
    "x=torch.Tensor(\n",
    "    [\n",
    "        [[1,1,],[1,1,],],\n",
    "        \n",
    "        [[2,2,],[2,2,],],\n",
    "        \n",
    "        [[3,3,],[3,3,],],\n",
    "    ])\n",
    "\n",
    "print(\"X size:\",x.shape)\n",
    "\n",
    "out=x*y\n",
    "print(out.shape)\n",
    "print(out[1]) \n",
    "\n",
    "# ----------------- 聚合 ----------\n",
    "res=out.sum(dim=1)\n",
    "print(res.shape)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 1, 1])\n",
      "torch.Size([3, 2, 2])\n",
      "torch.Size([2, 3, 2, 2])\n",
      "tensor([[[[  0.1000,   0.1000],\n",
      "          [  0.1000,   0.1000]],\n",
      "\n",
      "         [[  0.0600,   0.0600],\n",
      "          [  0.0600,   0.0600]],\n",
      "\n",
      "         [[ 12.0000,  12.0000],\n",
      "          [ 12.0000,  12.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 20.0000,  20.0000],\n",
      "          [ 20.0000,  20.0000]],\n",
      "\n",
      "         [[  0.4000,   0.4000],\n",
      "          [  0.4000,   0.4000]],\n",
      "\n",
      "         [[  1.8000,   1.8000],\n",
      "          [  1.8000,   1.8000]]]])\n"
     ]
    }
   ],
   "source": [
    "y=torch.Tensor(\n",
    "    [\n",
    "       [[[0.1]],[[0.03]],[[4]]],\n",
    "       [[[20]],[[0.2]],[[0.6]]],\n",
    "    ])\n",
    "\n",
    "print(y.shape)\n",
    "\n",
    "x=torch.Tensor(\n",
    "    [\n",
    "        [[1,1,],[1,1,],],\n",
    "        \n",
    "        [[2,2,],[2,2,],],\n",
    "        \n",
    "        [[3,3,],[3,3,],],\n",
    "    ])\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "out=x*y\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 实验一下 mobienet中的机制添加\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "m = nn.Conv1d(2, 3, 4, stride=2,padding=0,groups=1,dilation=1)\n",
    "\n",
    "# 经典mobilenet输入\n",
    "input = torch.randn(64, 14, 14,512)\n",
    "avg=nn.AvgPool2d()\n",
    "\n",
    "\n",
    "print(\"input size:\",input.shape)\n",
    "\n",
    "output = m(input)\n",
    "print(\"output size:\",output.shape)\n",
    "\n",
    "print(\"filter size:\",m.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''MobileNet in PyTorch.\n",
    "See the paper \"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\"\n",
    "for more details.\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    '''Depthwise conv + Pointwise conv'''\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        \n",
    "        # 分组卷积数=输入通道数\n",
    "        self.conv1 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=in_planes, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        return out\n",
    "\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    # (128,2) means conv planes=128, conv stride=2, by default conv stride=1\n",
    "    cfg = [64, (128,2), 128, (256,2), 256, (512,2), 512, 512, 512, 512, 512, (1024,2), 1024]\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layers = self._make_layers(in_planes=32) # 自动化构建层\n",
    "        self.linear = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        layers = []\n",
    "        for x in self.cfg:\n",
    "            out_planes = x if isinstance(x, int) else x[0]\n",
    "            stride = 1 if isinstance(x, int) else x[1]\n",
    "            layers.append(Block(in_planes, out_planes, stride))\n",
    "            in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = MobileNet()\n",
    "    x = torch.randn(1,3,32,32)\n",
    "    y = net(x)\n",
    "    print(y.size())\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
