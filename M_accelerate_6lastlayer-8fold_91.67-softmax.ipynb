{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>MobileNet - Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step 1: Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MobileNet-Pytorch\n",
    "import argparse \n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from mobilenets import mobilenet\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cudause_cud  = torch.cuda.is_available()\n",
    "dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Train, Validate, Test. Heavily inspired by Kevinzakka https://github.com/kevinzakka/DenseNet/blob/master/data_loader.py\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "valid_size=0.1\n",
    "\n",
    "# define transforms\n",
    "valid_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "train_dataset = datasets.CIFAR10(root=\"data\", train=True, \n",
    "            download=True, transform=train_transform)\n",
    "\n",
    "valid_dataset = datasets.CIFAR10(root=\"data\", train=True, \n",
    "            download=True, transform=valid_transform)\n",
    "\n",
    "num_train = len(train_dataset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train)) #5w张图片的10%用来当做验证集\n",
    "\n",
    "\n",
    "np.random.seed(42)# 42\n",
    "np.random.shuffle(indices) # 随机乱序[0,1,...,49999]\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx) # 这个很有意思\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "###################################################################################\n",
    "# ------------------------- 使用不同的批次大小 ------------------------------------\n",
    "###################################################################################\n",
    "\n",
    "show_step=2  # 批次大，show_step就小点\n",
    "max_epoch=80  # 训练最大epoch数目\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                batch_size=256, sampler=train_sampler)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, \n",
    "                batch_size=256, sampler=valid_sampler)\n",
    "\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), normalize\n",
    "])\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root=\"data\", \n",
    "                                train=False, \n",
    "                                download=True,transform=test_transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                          batch_size=256, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Model Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 32  缩放5次到 1x1@1024 \n",
    "# From https://github.com/kuangliu/pytorch-cifar \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    '''Depthwise conv + Pointwise conv'''\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        \n",
    "        # 分组卷积数=输入通道数\n",
    "        self.conv1 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=in_planes, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        \n",
    "        \n",
    "        #self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "        one_conv_kernel_size = 3\n",
    "        self.conv1D= nn.Conv1d(1, out_planes, one_conv_kernel_size, stride=1,padding=1,groups=1,dilation=1,bias=False) # 在__init__初始化        \n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        # -------------------------- Attention -----------------------\n",
    "        w = F.avg_pool2d(x,x.shape[-1])  #最好在初始化层定义好\n",
    "        #print(w.shape)\n",
    "        # [bs,in_Channel,1,1]\n",
    "        w = w.view(w.shape[0],1,w.shape[1])\n",
    "        # [bs,1,in_Channel]\n",
    "        # one_conv_filter = nn.Conv1d(1, out_channel, one_conv_kernel_size, stride=1,padding=1,groups=1,dilation=1) # 在__init__初始化\n",
    "        # [bs,out_channel,in_Channel]\n",
    "        w = self.conv1D(w)\n",
    "        w = 0.5*F.tanh(w) # [-0.5,+0.5]\n",
    "        # -------------- softmax ---------------------------\n",
    "        #print(w.shape)\n",
    "        w = w.view(w.shape[0],w.shape[1],w.shape[2],1,1)\n",
    "        #print(w.shape)\n",
    "        \n",
    "        # ------------------------- fusion --------------------------\n",
    "        out=out.view(out.shape[0],1,out.shape[1],out.shape[2],out.shape[3])\n",
    "        #print(\"x size:\",out.shape)\n",
    "        \n",
    "        out=out*w\n",
    "        #print(\"after fusion x size:\",out.shape)\n",
    "        out=out.sum(dim=2)\n",
    "        \n",
    "        out = F.relu(self.bn2(out))\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    # (128,2) means conv planes=128, conv stride=2, by default conv stride=1\n",
    "    cfg = [64, (128,2), 128, (256,2), 256, (512,2), 512, 512, 512, 512, 512, (1024,2), 1024]\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layers = self._make_layers(in_planes=32) # 自动化构建层\n",
    "        self.linear = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        layers = []\n",
    "        for x in self.cfg:\n",
    "            out_planes = x if isinstance(x, int) else x[0]\n",
    "            stride = 1 if isinstance(x, int) else x[1]\n",
    "            layers.append(Block(in_planes, out_planes, stride))\n",
    "            in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 32  缩放5次到 1x1@1024 \n",
    "# From https://github.com/kuangliu/pytorch-cifar \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Block_Attention_HALF(nn.Module):\n",
    "    '''Depthwise conv + Pointwise conv'''\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(Block_Attention_HALF, self).__init__()\n",
    "        \n",
    "        # 分组卷积数=输入通道数\n",
    "        self.conv1 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=in_planes, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        \n",
    "        #------------------------ 一半 ------------------------------\n",
    "        self.conv2 = nn.Conv2d(in_planes, int(out_planes*0.125), kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        \n",
    "        #------------------------ 另一半 ----------------------------\n",
    "        self.scaleLayer= nn.Conv1d(1, 1, 1, stride=1,padding=0,groups=1,dilation=1,bias=True)\n",
    "        \n",
    "        one_conv_kernel_size = 17 # [3,7,9]\n",
    "        self.conv1D= nn.Conv1d(1, int(out_planes*0.875), one_conv_kernel_size, stride=1,padding=8,groups=1,dilation=1,bias=True) # 在__init__初始化        \n",
    "        \n",
    "        #------------------------------------------------------------\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = F.relu6(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        # -------------------------- Attention -----------------------\n",
    "        w = F.avg_pool2d(x,x.shape[-1])  #最好在初始化层定义好\n",
    "        #print(w.shape)\n",
    "        # [bs,in_Channel,1,1]\n",
    "        in_channel=w.shape[1]\n",
    "        #w = w.view(w.shape[0],1,w.shape[1])\n",
    "        # [bs,1,in_Channel]\n",
    "        # 对这批数据取平均 且保留第0维\n",
    "        \n",
    "        #w= w.mean(dim=0,keepdim=True)\n",
    "        \n",
    "        \n",
    "#         MAX=w.shape[0]\n",
    "#         NUM=torch.floor(MAX*torch.rand(1)).long()\n",
    "#         if NUM>=0 and NUM<MAX:\n",
    "#             w=w[NUM]\n",
    "#         else:\n",
    "#             w=w[0]\n",
    "        #w=w[0]-torch.mean(w[0])\n",
    "        w=torch.randn(w[0].shape).cuda()*1\n",
    "        \n",
    "        a=torch.randn(1).cuda()*0.1\n",
    "        if a>0.37:\n",
    "            print(w.shape)\n",
    "            print(w)\n",
    "        \n",
    "        w=w.view(1,1,in_channel)\n",
    "        w=self.scaleLayer(w)\n",
    "        if a>0.37:\n",
    "            print(self.scaleLayer.weight)\n",
    "        # [bs=1,1,in_Channel]\n",
    "        # one_conv_filter = nn.Conv1d(1, out_channel, one_conv_kernel_size, stride=1,padding=1,groups=1,dilation=1) # 在__init__初始化\n",
    "        # [bs=1,out_channel,in_Channel]\n",
    "        w = self.conv1D(w)\n",
    "        # [bs=1,out_channel,in_Channel]\n",
    "        \n",
    "        #-------------------------------------\n",
    "        #w = 0.1*F.tanh(w) # [-0.5,+0.5]\n",
    "        w=F.softmax(w,dim=2)\n",
    "        \n",
    "        if a>0.37:\n",
    "            print(w.shape)\n",
    "            print(w)\n",
    "            \n",
    "        # [bs=1,out_channel//2,in_Channel]\n",
    "        w=w.view(w.shape[1],w.shape[2],1,1)\n",
    "        # [out_channel//2,in_Channel,1,1]\n",
    "        \n",
    "        # -------------- softmax ---------------------------\n",
    "        #print(w.shape)\n",
    "        \n",
    "        # ------------------------- fusion --------------------------\n",
    "       \n",
    "        # conv 1x1\n",
    "        out_1=self.conv2(out)\n",
    "        out_2=F.conv2d(out,w,bias=None,stride=1,groups=1,dilation=1)\n",
    "        out=torch.cat([out_1,out_2],1)\n",
    "        \n",
    "        # ----------------------- 试一试不要用relu -------------------------------\n",
    "        out = F.relu6(self.bn2(out))\n",
    "        \n",
    "        return out\n",
    "\n",
    "class Block_Attention(nn.Module):\n",
    "    '''Depthwise conv + Pointwise conv'''\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(Block_Attention, self).__init__()\n",
    "        \n",
    "        # 分组卷积数=输入通道数\n",
    "        self.conv1 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=in_planes, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        \n",
    "        \n",
    "        #self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "        one_conv_kernel_size = 17 # [3,7,9]\n",
    "        self.conv1D= nn.Conv1d(1, out_planes, one_conv_kernel_size, stride=1,padding=8,groups=1,dilation=1,bias=False) # 在__init__初始化        \n",
    "        \n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        # -------------------------- Attention -----------------------\n",
    "        w = F.avg_pool2d(x,x.shape[-1])  #最好在初始化层定义好\n",
    "        #print(w.shape)\n",
    "        # [bs,in_Channel,1,1]\n",
    "        in_channel=w.shape[1]\n",
    "        #w = w.view(w.shape[0],1,w.shape[1])\n",
    "        # [bs,1,in_Channel]\n",
    "        # 对这批数据取平均 且保留第0维\n",
    "        \n",
    "        #w= w.mean(dim=0,keepdim=True)\n",
    "        \n",
    "        \n",
    "#         MAX=w.shape[0]\n",
    "#         NUM=torch.floor(MAX*torch.rand(1)).long()\n",
    "#         if NUM>=0 and NUM<MAX:\n",
    "#             w=w[NUM]\n",
    "#         else:\n",
    "#             w=w[0]\n",
    "        \n",
    "        w=w[0]\n",
    "        \n",
    "        w=w.view(1,1,in_channel)\n",
    "        # [bs=1,1,in_Channel]\n",
    "        # one_conv_filter = nn.Conv1d(1, out_channel, one_conv_kernel_size, stride=1,padding=1,groups=1,dilation=1) # 在__init__初始化\n",
    "        # [bs=1,out_channel,in_Channel]\n",
    "        w = self.conv1D(w)\n",
    "        # [bs=1,out_channel,in_Channel]\n",
    "        w = 0.5*F.tanh(w) # [-0.5,+0.5]\n",
    "         # [bs=1,out_channel,in_Channel]\n",
    "        w=w.view(w.shape[1],w.shape[2],1,1)\n",
    "        # [out_channel,in_Channel,1,1]\n",
    "        \n",
    "        # -------------- softmax ---------------------------\n",
    "        #print(w.shape)\n",
    "        \n",
    "        # ------------------------- fusion --------------------------\n",
    "       \n",
    "        # conv 1x1\n",
    "        out=F.conv2d(out,w,bias=None,stride=1,groups=1,dilation=1)\n",
    "\n",
    "        out = F.relu(self.bn2(out))\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    '''Depthwise conv + Pointwise conv'''\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        \n",
    "        # 分组卷积数=输入通道数\n",
    "        self.conv1 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=in_planes, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        return out\n",
    "\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    # (128,2) means conv planes=128, conv stride=2, by default conv stride=1\n",
    "    #cfg = [64, (128,2), 128, (256,2), 256, (512,2), 512, 512, 512, 512, 512, (1024,2), 1024]\n",
    "    \n",
    "    #cfg = [64, (128,2), 128, (256,2), 256, (512,2), 512, 512, 512, 512, 512, (1024,2), [1024,1]]\n",
    "    cfg = [64, (128,2), 128, 256, 256, (512,2), 512, [512,1], [512,1],[512,1], [512,1], [1024,1], [1024,1]]\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layers = self._make_layers(in_planes=32) # 自动化构建层\n",
    "        self.linear = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        layers = []\n",
    "        for x in self.cfg:\n",
    "            if isinstance(x, int):\n",
    "                out_planes = x\n",
    "                stride = 1 \n",
    "                layers.append(Block(in_planes, out_planes, stride))\n",
    "            elif isinstance(x, tuple):\n",
    "                out_planes = x[0]\n",
    "                stride = x[1]\n",
    "                layers.append(Block(in_planes, out_planes, stride))\n",
    "            # AC层通过list存放设置参数\n",
    "            elif isinstance(x, list):\n",
    "                out_planes= x[0]\n",
    "                stride = x[1] if len(x)==2 else 1\n",
    "                layers.append(Block_Attention_HALF(in_planes, out_planes, stride))   \n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            in_planes = out_planes\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From https://github.com/Z0m6ie/CIFAR-10_PyTorch\n",
    "#model = mobilenet(num_classes=10, large_img=False)\n",
    "\n",
    "# From https://github.com/kuangliu/pytorch-cifar \n",
    "if torch.cuda.is_available():\n",
    "    model=MobileNet(10).cuda()\n",
    "else:\n",
    "    model=MobileNet(10)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "#scheduler = StepLR(optimizer, step_size=70, gamma=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50,70,75,80], gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement validation\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    #writer = SummaryWriter()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        correct = 0\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        accuracy = 100. * (correct.cpu().numpy()/ len(output))\n",
    "        optimizer.step()\n",
    "        if batch_idx % 5*show_step == 0:\n",
    "#             if batch_idx % 2*show_step == 0:\n",
    "#                 print(model.layers[1].conv1D.weight.shape)\n",
    "#                 print(model.layers[1].conv1D.weight[0:2][0:2])\n",
    "            \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accuracy: {:.2f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(), accuracy))\n",
    "#             f1=open(\"Cifar10_INFO.txt\",\"a+\")\n",
    "#             f1.write(\"\\n\"+'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accuracy: {:.2f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), loss.item(), accuracy))\n",
    "#             f1.close()\n",
    "            \n",
    "            #writer.add_scalar('Loss/Loss', loss.item(), epoch)\n",
    "            #writer.add_scalar('Accuracy/Accuracy', accuracy, epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(epoch):\n",
    "    model.eval()\n",
    "    #writer = SummaryWriter()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in valid_loader:\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        valid_loss += F.cross_entropy(output, target, size_average=False).item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "    valid_loss /= len(valid_idx)\n",
    "    accuracy = 100. * correct.cpu().numpy() / len(valid_idx)\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        valid_loss, correct, len(valid_idx),\n",
    "        100. * correct / len(valid_idx)))\n",
    "    \n",
    "#     f1=open(\"Cifar10_INFO.txt\",\"a+\")\n",
    "#     f1.write('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "#         valid_loss, correct, len(valid_idx),\n",
    "#         100. * correct / len(valid_idx)))\n",
    "#     f1.close()\n",
    "    #writer.add_scalar('Loss/Validation_Loss', valid_loss, epoch)\n",
    "    #writer.add_scalar('Accuracy/Validation_Accuracy', accuracy, epoch)\n",
    "    return valid_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fix best model\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target, size_average=False).item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct.cpu().numpy() / len(test_loader.dataset)))\n",
    "    \n",
    "#     f1=open(\"Cifar10_INFO.txt\",\"a+\")\n",
    "#     f1.write('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "#         test_loss, correct, len(test_loader.dataset),\n",
    "#         100. * correct.cpu().numpy() / len(test_loader.dataset)))\n",
    "#     f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_best(loss, accuracy, best_loss, best_acc):\n",
    "    if best_loss == None:\n",
    "        best_loss = loss\n",
    "        best_acc = accuracy\n",
    "        file = 'saved_models/best_save_model.p'\n",
    "        torch.save(model.state_dict(), file)\n",
    "        \n",
    "    elif loss < best_loss and accuracy > best_acc:\n",
    "        best_loss = loss\n",
    "        best_acc = accuracy\n",
    "        file = 'saved_models/best_save_model.p'\n",
    "        torch.save(model.state_dict(), file)\n",
    "    return best_loss, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 2.321921, Accuracy: 13.28\n",
      "Train Epoch: 0 [1280/50000 (3%)]\tLoss: 2.697963, Accuracy: 12.50\n",
      "Train Epoch: 0 [2560/50000 (6%)]\tLoss: 2.295963, Accuracy: 13.67\n",
      "Train Epoch: 0 [3840/50000 (9%)]\tLoss: 2.228629, Accuracy: 11.72\n",
      "Train Epoch: 0 [5120/50000 (11%)]\tLoss: 2.152878, Accuracy: 16.80\n",
      "Train Epoch: 0 [6400/50000 (14%)]\tLoss: 2.250362, Accuracy: 14.84\n",
      "Train Epoch: 0 [7680/50000 (17%)]\tLoss: 2.094981, Accuracy: 17.97\n",
      "Train Epoch: 0 [8960/50000 (20%)]\tLoss: 2.055869, Accuracy: 21.09\n",
      "Train Epoch: 0 [10240/50000 (23%)]\tLoss: 2.010003, Accuracy: 23.44\n",
      "Train Epoch: 0 [11520/50000 (26%)]\tLoss: 1.964749, Accuracy: 20.70\n",
      "Train Epoch: 0 [12800/50000 (28%)]\tLoss: 2.021680, Accuracy: 23.83\n",
      "Train Epoch: 0 [14080/50000 (31%)]\tLoss: 1.959093, Accuracy: 21.48\n",
      "Train Epoch: 0 [15360/50000 (34%)]\tLoss: 1.864657, Accuracy: 22.27\n",
      "Train Epoch: 0 [16640/50000 (37%)]\tLoss: 1.942775, Accuracy: 23.05\n",
      "Train Epoch: 0 [17920/50000 (40%)]\tLoss: 1.841356, Accuracy: 23.83\n",
      "Train Epoch: 0 [19200/50000 (43%)]\tLoss: 1.844582, Accuracy: 25.00\n",
      "Train Epoch: 0 [20480/50000 (45%)]\tLoss: 1.890229, Accuracy: 23.83\n",
      "Train Epoch: 0 [21760/50000 (48%)]\tLoss: 1.806640, Accuracy: 26.56\n",
      "Train Epoch: 0 [23040/50000 (51%)]\tLoss: 1.880710, Accuracy: 28.12\n",
      "Train Epoch: 0 [24320/50000 (54%)]\tLoss: 1.789644, Accuracy: 27.34\n",
      "Train Epoch: 0 [25600/50000 (57%)]\tLoss: 1.831058, Accuracy: 24.61\n",
      "Train Epoch: 0 [26880/50000 (60%)]\tLoss: 1.771186, Accuracy: 31.64\n",
      "Train Epoch: 0 [28160/50000 (62%)]\tLoss: 1.782030, Accuracy: 26.56\n",
      "Train Epoch: 0 [29440/50000 (65%)]\tLoss: 1.848840, Accuracy: 30.08\n",
      "Train Epoch: 0 [30720/50000 (68%)]\tLoss: 1.767304, Accuracy: 35.55\n",
      "Train Epoch: 0 [32000/50000 (71%)]\tLoss: 1.783516, Accuracy: 32.03\n",
      "Train Epoch: 0 [33280/50000 (74%)]\tLoss: 1.723812, Accuracy: 27.34\n",
      "Train Epoch: 0 [34560/50000 (77%)]\tLoss: 1.740603, Accuracy: 32.81\n",
      "Train Epoch: 0 [35840/50000 (80%)]\tLoss: 1.682830, Accuracy: 32.03\n",
      "Train Epoch: 0 [37120/50000 (82%)]\tLoss: 1.785108, Accuracy: 33.59\n",
      "Train Epoch: 0 [38400/50000 (85%)]\tLoss: 1.721596, Accuracy: 29.69\n",
      "Train Epoch: 0 [39680/50000 (88%)]\tLoss: 1.611830, Accuracy: 36.72\n",
      "Train Epoch: 0 [40960/50000 (91%)]\tLoss: 1.706668, Accuracy: 37.11\n",
      "Train Epoch: 0 [42240/50000 (94%)]\tLoss: 1.631160, Accuracy: 37.50\n",
      "Train Epoch: 0 [43520/50000 (97%)]\tLoss: 1.652769, Accuracy: 35.16\n",
      "Train Epoch: 0 [35000/50000 (99%)]\tLoss: 1.626865, Accuracy: 35.00\n",
      "\n",
      "Validation set: Average loss: 1.6948, Accuracy: 1619/5000 (32.00%)\n",
      "\n",
      "the time of this epoch:[37.3601438999176 s]\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 1.573110, Accuracy: 38.28\n",
      "Train Epoch: 1 [1280/50000 (3%)]\tLoss: 1.598990, Accuracy: 32.81\n",
      "Train Epoch: 1 [2560/50000 (6%)]\tLoss: 1.629053, Accuracy: 37.11\n",
      "Train Epoch: 1 [3840/50000 (9%)]\tLoss: 1.591395, Accuracy: 37.89\n",
      "Train Epoch: 1 [5120/50000 (11%)]\tLoss: 1.607906, Accuracy: 35.16\n",
      "Train Epoch: 1 [6400/50000 (14%)]\tLoss: 1.700132, Accuracy: 35.94\n",
      "Train Epoch: 1 [7680/50000 (17%)]\tLoss: 1.712665, Accuracy: 31.25\n",
      "Train Epoch: 1 [8960/50000 (20%)]\tLoss: 1.595023, Accuracy: 35.55\n",
      "Train Epoch: 1 [10240/50000 (23%)]\tLoss: 1.675472, Accuracy: 32.42\n",
      "Train Epoch: 1 [11520/50000 (26%)]\tLoss: 1.593461, Accuracy: 35.55\n",
      "Train Epoch: 1 [12800/50000 (28%)]\tLoss: 1.609068, Accuracy: 38.67\n",
      "Train Epoch: 1 [14080/50000 (31%)]\tLoss: 1.601527, Accuracy: 37.11\n",
      "Train Epoch: 1 [15360/50000 (34%)]\tLoss: 1.606322, Accuracy: 37.89\n",
      "Train Epoch: 1 [16640/50000 (37%)]\tLoss: 1.565800, Accuracy: 38.67\n",
      "Train Epoch: 1 [17920/50000 (40%)]\tLoss: 1.570580, Accuracy: 41.02\n",
      "Train Epoch: 1 [19200/50000 (43%)]\tLoss: 1.642336, Accuracy: 33.98\n",
      "Train Epoch: 1 [20480/50000 (45%)]\tLoss: 1.548128, Accuracy: 36.33\n",
      "Train Epoch: 1 [21760/50000 (48%)]\tLoss: 1.437625, Accuracy: 44.92\n",
      "Train Epoch: 1 [23040/50000 (51%)]\tLoss: 1.606924, Accuracy: 42.19\n",
      "Train Epoch: 1 [24320/50000 (54%)]\tLoss: 1.438141, Accuracy: 44.14\n",
      "Train Epoch: 1 [25600/50000 (57%)]\tLoss: 1.392640, Accuracy: 46.88\n",
      "Train Epoch: 1 [26880/50000 (60%)]\tLoss: 1.531510, Accuracy: 39.45\n",
      "Train Epoch: 1 [28160/50000 (62%)]\tLoss: 1.476598, Accuracy: 45.70\n",
      "Train Epoch: 1 [29440/50000 (65%)]\tLoss: 1.426564, Accuracy: 47.27\n",
      "Train Epoch: 1 [30720/50000 (68%)]\tLoss: 1.492425, Accuracy: 46.09\n",
      "Train Epoch: 1 [32000/50000 (71%)]\tLoss: 1.473938, Accuracy: 48.44\n",
      "Train Epoch: 1 [33280/50000 (74%)]\tLoss: 1.492243, Accuracy: 47.66\n",
      "Train Epoch: 1 [34560/50000 (77%)]\tLoss: 1.538474, Accuracy: 43.36\n",
      "Train Epoch: 1 [35840/50000 (80%)]\tLoss: 1.473911, Accuracy: 43.36\n",
      "Train Epoch: 1 [37120/50000 (82%)]\tLoss: 1.479215, Accuracy: 42.97\n",
      "Train Epoch: 1 [38400/50000 (85%)]\tLoss: 1.324520, Accuracy: 50.78\n",
      "Train Epoch: 1 [39680/50000 (88%)]\tLoss: 1.400000, Accuracy: 47.27\n",
      "Train Epoch: 1 [40960/50000 (91%)]\tLoss: 1.503144, Accuracy: 45.31\n",
      "Train Epoch: 1 [42240/50000 (94%)]\tLoss: 1.398590, Accuracy: 44.53\n",
      "Train Epoch: 1 [43520/50000 (97%)]\tLoss: 1.382702, Accuracy: 46.48\n",
      "Train Epoch: 1 [35000/50000 (99%)]\tLoss: 1.422750, Accuracy: 49.50\n",
      "\n",
      "Validation set: Average loss: 1.9694, Accuracy: 1846/5000 (36.00%)\n",
      "\n",
      "the time of this epoch:[37.185709714889526 s]\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.390140, Accuracy: 51.95\n",
      "Train Epoch: 2 [1280/50000 (3%)]\tLoss: 1.339110, Accuracy: 51.95\n",
      "Train Epoch: 2 [2560/50000 (6%)]\tLoss: 1.271364, Accuracy: 53.12\n",
      "Train Epoch: 2 [3840/50000 (9%)]\tLoss: 1.364186, Accuracy: 48.44\n",
      "Train Epoch: 2 [5120/50000 (11%)]\tLoss: 1.350841, Accuracy: 48.05\n",
      "Train Epoch: 2 [6400/50000 (14%)]\tLoss: 1.264023, Accuracy: 56.64\n",
      "Train Epoch: 2 [7680/50000 (17%)]\tLoss: 1.324662, Accuracy: 50.78\n",
      "Train Epoch: 2 [8960/50000 (20%)]\tLoss: 1.312688, Accuracy: 54.30\n",
      "Train Epoch: 2 [10240/50000 (23%)]\tLoss: 1.301860, Accuracy: 54.30\n",
      "Train Epoch: 2 [11520/50000 (26%)]\tLoss: 1.242379, Accuracy: 55.86\n",
      "Train Epoch: 2 [12800/50000 (28%)]\tLoss: 1.229074, Accuracy: 54.69\n",
      "Train Epoch: 2 [14080/50000 (31%)]\tLoss: 1.252267, Accuracy: 55.47\n",
      "Train Epoch: 2 [15360/50000 (34%)]\tLoss: 1.245355, Accuracy: 51.17\n",
      "Train Epoch: 2 [16640/50000 (37%)]\tLoss: 1.276619, Accuracy: 51.56\n",
      "Train Epoch: 2 [17920/50000 (40%)]\tLoss: 1.246151, Accuracy: 54.69\n",
      "Train Epoch: 2 [19200/50000 (43%)]\tLoss: 1.218821, Accuracy: 52.73\n",
      "Train Epoch: 2 [20480/50000 (45%)]\tLoss: 1.195422, Accuracy: 60.16\n",
      "Train Epoch: 2 [21760/50000 (48%)]\tLoss: 1.254396, Accuracy: 55.47\n",
      "Train Epoch: 2 [23040/50000 (51%)]\tLoss: 1.259385, Accuracy: 54.30\n",
      "Train Epoch: 2 [24320/50000 (54%)]\tLoss: 1.222591, Accuracy: 60.16\n",
      "Train Epoch: 2 [25600/50000 (57%)]\tLoss: 1.269211, Accuracy: 54.69\n",
      "Train Epoch: 2 [26880/50000 (60%)]\tLoss: 1.146814, Accuracy: 57.42\n",
      "Train Epoch: 2 [28160/50000 (62%)]\tLoss: 1.244109, Accuracy: 55.47\n",
      "Train Epoch: 2 [29440/50000 (65%)]\tLoss: 1.142473, Accuracy: 64.06\n",
      "Train Epoch: 2 [30720/50000 (68%)]\tLoss: 1.236539, Accuracy: 55.08\n",
      "Train Epoch: 2 [32000/50000 (71%)]\tLoss: 1.190992, Accuracy: 58.98\n",
      "Train Epoch: 2 [33280/50000 (74%)]\tLoss: 1.046160, Accuracy: 62.11\n",
      "Train Epoch: 2 [34560/50000 (77%)]\tLoss: 1.226481, Accuracy: 53.91\n",
      "Train Epoch: 2 [35840/50000 (80%)]\tLoss: 1.110669, Accuracy: 61.33\n",
      "Train Epoch: 2 [37120/50000 (82%)]\tLoss: 1.249066, Accuracy: 58.98\n",
      "Train Epoch: 2 [38400/50000 (85%)]\tLoss: 1.070700, Accuracy: 62.11\n",
      "Train Epoch: 2 [39680/50000 (88%)]\tLoss: 1.011722, Accuracy: 62.89\n",
      "Train Epoch: 2 [40960/50000 (91%)]\tLoss: 1.140078, Accuracy: 60.94\n",
      "Train Epoch: 2 [42240/50000 (94%)]\tLoss: 1.184745, Accuracy: 58.59\n",
      "Train Epoch: 2 [43520/50000 (97%)]\tLoss: 1.165105, Accuracy: 58.20\n",
      "torch.Size([512, 1, 1])\n",
      "tensor([[[-1.0534]],\n",
      "\n",
      "        [[-0.6472]],\n",
      "\n",
      "        [[-0.5280]],\n",
      "\n",
      "        [[ 0.2544]],\n",
      "\n",
      "        [[-0.3785]],\n",
      "\n",
      "        [[-0.4503]],\n",
      "\n",
      "        [[ 0.9606]],\n",
      "\n",
      "        [[ 0.5559]],\n",
      "\n",
      "        [[-0.0965]],\n",
      "\n",
      "        [[ 0.8977]],\n",
      "\n",
      "        [[ 0.8086]],\n",
      "\n",
      "        [[ 0.7007]],\n",
      "\n",
      "        [[ 0.6965]],\n",
      "\n",
      "        [[-0.2444]],\n",
      "\n",
      "        [[ 0.0736]],\n",
      "\n",
      "        [[ 0.2121]],\n",
      "\n",
      "        [[-0.1180]],\n",
      "\n",
      "        [[ 0.4818]],\n",
      "\n",
      "        [[ 1.2403]],\n",
      "\n",
      "        [[ 1.7812]],\n",
      "\n",
      "        [[ 1.3529]],\n",
      "\n",
      "        [[-1.0803]],\n",
      "\n",
      "        [[ 0.3001]],\n",
      "\n",
      "        [[-0.1821]],\n",
      "\n",
      "        [[-0.5412]],\n",
      "\n",
      "        [[-0.5333]],\n",
      "\n",
      "        [[-1.3487]],\n",
      "\n",
      "        [[ 0.5401]],\n",
      "\n",
      "        [[-0.6429]],\n",
      "\n",
      "        [[ 0.7888]],\n",
      "\n",
      "        [[ 2.2419]],\n",
      "\n",
      "        [[-0.9298]],\n",
      "\n",
      "        [[-1.6005]],\n",
      "\n",
      "        [[ 0.4779]],\n",
      "\n",
      "        [[ 0.7698]],\n",
      "\n",
      "        [[ 1.0703]],\n",
      "\n",
      "        [[-1.5756]],\n",
      "\n",
      "        [[-1.5506]],\n",
      "\n",
      "        [[ 1.1094]],\n",
      "\n",
      "        [[-0.2924]],\n",
      "\n",
      "        [[-0.9987]],\n",
      "\n",
      "        [[ 0.7928]],\n",
      "\n",
      "        [[-0.8746]],\n",
      "\n",
      "        [[-0.5416]],\n",
      "\n",
      "        [[-0.9813]],\n",
      "\n",
      "        [[-0.7046]],\n",
      "\n",
      "        [[ 0.9721]],\n",
      "\n",
      "        [[-1.7511]],\n",
      "\n",
      "        [[ 0.1308]],\n",
      "\n",
      "        [[ 1.0004]],\n",
      "\n",
      "        [[ 0.4859]],\n",
      "\n",
      "        [[-0.9686]],\n",
      "\n",
      "        [[-2.1888]],\n",
      "\n",
      "        [[ 1.7081]],\n",
      "\n",
      "        [[ 0.2644]],\n",
      "\n",
      "        [[ 0.8645]],\n",
      "\n",
      "        [[-0.7792]],\n",
      "\n",
      "        [[-1.1650]],\n",
      "\n",
      "        [[ 0.8176]],\n",
      "\n",
      "        [[-0.2140]],\n",
      "\n",
      "        [[-0.2335]],\n",
      "\n",
      "        [[ 1.1991]],\n",
      "\n",
      "        [[ 2.8394]],\n",
      "\n",
      "        [[-1.0537]],\n",
      "\n",
      "        [[ 1.3416]],\n",
      "\n",
      "        [[-0.2206]],\n",
      "\n",
      "        [[ 1.4946]],\n",
      "\n",
      "        [[ 0.3673]],\n",
      "\n",
      "        [[ 0.2975]],\n",
      "\n",
      "        [[-0.1715]],\n",
      "\n",
      "        [[ 0.4376]],\n",
      "\n",
      "        [[ 0.8554]],\n",
      "\n",
      "        [[-1.1259]],\n",
      "\n",
      "        [[ 0.1138]],\n",
      "\n",
      "        [[ 0.9582]],\n",
      "\n",
      "        [[ 0.2687]],\n",
      "\n",
      "        [[-0.6088]],\n",
      "\n",
      "        [[-0.2957]],\n",
      "\n",
      "        [[-0.3761]],\n",
      "\n",
      "        [[ 1.0704]],\n",
      "\n",
      "        [[-1.0440]],\n",
      "\n",
      "        [[-0.7301]],\n",
      "\n",
      "        [[-0.4059]],\n",
      "\n",
      "        [[-0.1577]],\n",
      "\n",
      "        [[ 0.6720]],\n",
      "\n",
      "        [[-0.5877]],\n",
      "\n",
      "        [[ 0.5393]],\n",
      "\n",
      "        [[-0.0970]],\n",
      "\n",
      "        [[-2.3794]],\n",
      "\n",
      "        [[ 1.1209]],\n",
      "\n",
      "        [[-0.0454]],\n",
      "\n",
      "        [[-1.8018]],\n",
      "\n",
      "        [[ 0.1720]],\n",
      "\n",
      "        [[-1.4171]],\n",
      "\n",
      "        [[-2.5694]],\n",
      "\n",
      "        [[-0.2280]],\n",
      "\n",
      "        [[-0.1820]],\n",
      "\n",
      "        [[-0.1785]],\n",
      "\n",
      "        [[-0.8859]],\n",
      "\n",
      "        [[-0.1298]],\n",
      "\n",
      "        [[ 0.8283]],\n",
      "\n",
      "        [[-0.5214]],\n",
      "\n",
      "        [[-0.7226]],\n",
      "\n",
      "        [[-1.9584]],\n",
      "\n",
      "        [[ 0.1368]],\n",
      "\n",
      "        [[ 1.0081]],\n",
      "\n",
      "        [[-1.3819]],\n",
      "\n",
      "        [[ 1.3643]],\n",
      "\n",
      "        [[-0.7070]],\n",
      "\n",
      "        [[-0.6422]],\n",
      "\n",
      "        [[ 0.2816]],\n",
      "\n",
      "        [[ 0.3317]],\n",
      "\n",
      "        [[ 1.0696]],\n",
      "\n",
      "        [[-1.6633]],\n",
      "\n",
      "        [[ 0.6488]],\n",
      "\n",
      "        [[ 0.5049]],\n",
      "\n",
      "        [[-0.7548]],\n",
      "\n",
      "        [[-0.0053]],\n",
      "\n",
      "        [[ 1.1052]],\n",
      "\n",
      "        [[-0.4756]],\n",
      "\n",
      "        [[-2.8908]],\n",
      "\n",
      "        [[-0.7150]],\n",
      "\n",
      "        [[-1.3585]],\n",
      "\n",
      "        [[ 0.3413]],\n",
      "\n",
      "        [[-1.6097]],\n",
      "\n",
      "        [[ 0.2392]],\n",
      "\n",
      "        [[-2.0744]],\n",
      "\n",
      "        [[ 0.6054]],\n",
      "\n",
      "        [[ 1.7573]],\n",
      "\n",
      "        [[ 1.0395]],\n",
      "\n",
      "        [[ 0.7612]],\n",
      "\n",
      "        [[-0.2773]],\n",
      "\n",
      "        [[ 0.2867]],\n",
      "\n",
      "        [[-1.6919]],\n",
      "\n",
      "        [[-0.2735]],\n",
      "\n",
      "        [[-0.2503]],\n",
      "\n",
      "        [[-0.5500]],\n",
      "\n",
      "        [[ 0.0450]],\n",
      "\n",
      "        [[ 0.7576]],\n",
      "\n",
      "        [[ 1.3240]],\n",
      "\n",
      "        [[-0.1379]],\n",
      "\n",
      "        [[-0.4316]],\n",
      "\n",
      "        [[-1.9836]],\n",
      "\n",
      "        [[ 0.2777]],\n",
      "\n",
      "        [[ 0.5264]],\n",
      "\n",
      "        [[ 0.0677]],\n",
      "\n",
      "        [[-0.0792]],\n",
      "\n",
      "        [[-1.3324]],\n",
      "\n",
      "        [[-0.0542]],\n",
      "\n",
      "        [[ 0.3120]],\n",
      "\n",
      "        [[-1.6201]],\n",
      "\n",
      "        [[-0.4450]],\n",
      "\n",
      "        [[-0.8598]],\n",
      "\n",
      "        [[ 1.0954]],\n",
      "\n",
      "        [[-0.2013]],\n",
      "\n",
      "        [[-1.1146]],\n",
      "\n",
      "        [[-0.6315]],\n",
      "\n",
      "        [[-0.3108]],\n",
      "\n",
      "        [[-1.0907]],\n",
      "\n",
      "        [[-0.6799]],\n",
      "\n",
      "        [[ 0.9168]],\n",
      "\n",
      "        [[ 0.5626]],\n",
      "\n",
      "        [[-0.6063]],\n",
      "\n",
      "        [[-0.1458]],\n",
      "\n",
      "        [[-0.6571]],\n",
      "\n",
      "        [[ 0.3789]],\n",
      "\n",
      "        [[ 0.3498]],\n",
      "\n",
      "        [[ 0.4670]],\n",
      "\n",
      "        [[ 0.4759]],\n",
      "\n",
      "        [[ 0.1245]],\n",
      "\n",
      "        [[ 1.8387]],\n",
      "\n",
      "        [[-1.3880]],\n",
      "\n",
      "        [[-1.2369]],\n",
      "\n",
      "        [[-0.4350]],\n",
      "\n",
      "        [[ 0.0213]],\n",
      "\n",
      "        [[ 2.7913]],\n",
      "\n",
      "        [[ 0.1311]],\n",
      "\n",
      "        [[-0.0268]],\n",
      "\n",
      "        [[-1.6389]],\n",
      "\n",
      "        [[ 0.5044]],\n",
      "\n",
      "        [[ 2.6958]],\n",
      "\n",
      "        [[-0.1361]],\n",
      "\n",
      "        [[ 1.5446]],\n",
      "\n",
      "        [[-0.5673]],\n",
      "\n",
      "        [[-1.6132]],\n",
      "\n",
      "        [[ 1.3037]],\n",
      "\n",
      "        [[-0.7578]],\n",
      "\n",
      "        [[ 1.0940]],\n",
      "\n",
      "        [[-0.2443]],\n",
      "\n",
      "        [[-0.8514]],\n",
      "\n",
      "        [[ 0.5783]],\n",
      "\n",
      "        [[ 0.6823]],\n",
      "\n",
      "        [[-0.3700]],\n",
      "\n",
      "        [[-0.5720]],\n",
      "\n",
      "        [[-0.1062]],\n",
      "\n",
      "        [[ 1.4828]],\n",
      "\n",
      "        [[-1.4400]],\n",
      "\n",
      "        [[ 0.5332]],\n",
      "\n",
      "        [[ 0.0942]],\n",
      "\n",
      "        [[ 0.3874]],\n",
      "\n",
      "        [[-0.4773]],\n",
      "\n",
      "        [[ 0.0943]],\n",
      "\n",
      "        [[ 0.5556]],\n",
      "\n",
      "        [[-0.8382]],\n",
      "\n",
      "        [[ 0.2452]],\n",
      "\n",
      "        [[ 1.1178]],\n",
      "\n",
      "        [[ 0.1877]],\n",
      "\n",
      "        [[-0.4173]],\n",
      "\n",
      "        [[ 0.3323]],\n",
      "\n",
      "        [[-0.3973]],\n",
      "\n",
      "        [[ 0.2971]],\n",
      "\n",
      "        [[-0.0512]],\n",
      "\n",
      "        [[ 1.0913]],\n",
      "\n",
      "        [[ 0.4589]],\n",
      "\n",
      "        [[ 0.1606]],\n",
      "\n",
      "        [[ 0.3317]],\n",
      "\n",
      "        [[-0.1331]],\n",
      "\n",
      "        [[-0.0963]],\n",
      "\n",
      "        [[-0.1637]],\n",
      "\n",
      "        [[-0.5988]],\n",
      "\n",
      "        [[ 1.0695]],\n",
      "\n",
      "        [[ 1.2766]],\n",
      "\n",
      "        [[ 0.8305]],\n",
      "\n",
      "        [[ 0.7869]],\n",
      "\n",
      "        [[-0.9479]],\n",
      "\n",
      "        [[ 0.7162]],\n",
      "\n",
      "        [[-0.7771]],\n",
      "\n",
      "        [[ 0.8609]],\n",
      "\n",
      "        [[ 1.7847]],\n",
      "\n",
      "        [[-0.0793]],\n",
      "\n",
      "        [[-0.2850]],\n",
      "\n",
      "        [[ 1.2767]],\n",
      "\n",
      "        [[-0.3908]],\n",
      "\n",
      "        [[-0.8193]],\n",
      "\n",
      "        [[-1.3273]],\n",
      "\n",
      "        [[-2.2956]],\n",
      "\n",
      "        [[-1.1719]],\n",
      "\n",
      "        [[ 0.0210]],\n",
      "\n",
      "        [[ 0.0715]],\n",
      "\n",
      "        [[-0.0598]],\n",
      "\n",
      "        [[ 0.3919]],\n",
      "\n",
      "        [[-1.2930]],\n",
      "\n",
      "        [[ 0.6845]],\n",
      "\n",
      "        [[ 0.0816]],\n",
      "\n",
      "        [[ 1.7704]],\n",
      "\n",
      "        [[-0.9898]],\n",
      "\n",
      "        [[-0.7200]],\n",
      "\n",
      "        [[-1.6560]],\n",
      "\n",
      "        [[-0.3953]],\n",
      "\n",
      "        [[ 1.5513]],\n",
      "\n",
      "        [[-1.5698]],\n",
      "\n",
      "        [[-1.9278]],\n",
      "\n",
      "        [[-1.2722]],\n",
      "\n",
      "        [[ 0.3355]],\n",
      "\n",
      "        [[ 0.2952]],\n",
      "\n",
      "        [[ 1.8070]],\n",
      "\n",
      "        [[-1.1473]],\n",
      "\n",
      "        [[ 1.9140]],\n",
      "\n",
      "        [[ 0.2101]],\n",
      "\n",
      "        [[-0.7102]],\n",
      "\n",
      "        [[ 0.9322]],\n",
      "\n",
      "        [[ 0.5096]],\n",
      "\n",
      "        [[ 1.0607]],\n",
      "\n",
      "        [[-0.7001]],\n",
      "\n",
      "        [[ 0.3504]],\n",
      "\n",
      "        [[-0.3518]],\n",
      "\n",
      "        [[-1.6758]],\n",
      "\n",
      "        [[ 0.3747]],\n",
      "\n",
      "        [[ 1.3407]],\n",
      "\n",
      "        [[-0.6801]],\n",
      "\n",
      "        [[-0.5624]],\n",
      "\n",
      "        [[ 1.0982]],\n",
      "\n",
      "        [[ 2.2890]],\n",
      "\n",
      "        [[ 0.0779]],\n",
      "\n",
      "        [[ 1.1529]],\n",
      "\n",
      "        [[-0.8141]],\n",
      "\n",
      "        [[-0.1788]],\n",
      "\n",
      "        [[-0.3494]],\n",
      "\n",
      "        [[ 0.1416]],\n",
      "\n",
      "        [[-1.2790]],\n",
      "\n",
      "        [[-0.1035]],\n",
      "\n",
      "        [[-0.8879]],\n",
      "\n",
      "        [[-0.8109]],\n",
      "\n",
      "        [[-0.6477]],\n",
      "\n",
      "        [[-0.8276]],\n",
      "\n",
      "        [[ 1.3726]],\n",
      "\n",
      "        [[ 1.6783]],\n",
      "\n",
      "        [[ 0.8265]],\n",
      "\n",
      "        [[ 0.9063]],\n",
      "\n",
      "        [[-0.1319]],\n",
      "\n",
      "        [[-1.3621]],\n",
      "\n",
      "        [[ 0.3533]],\n",
      "\n",
      "        [[-0.4252]],\n",
      "\n",
      "        [[ 1.1276]],\n",
      "\n",
      "        [[ 1.1080]],\n",
      "\n",
      "        [[-0.4762]],\n",
      "\n",
      "        [[ 0.6329]],\n",
      "\n",
      "        [[-0.3817]],\n",
      "\n",
      "        [[-0.7508]],\n",
      "\n",
      "        [[ 0.7018]],\n",
      "\n",
      "        [[ 0.3947]],\n",
      "\n",
      "        [[-0.8998]],\n",
      "\n",
      "        [[-1.1368]],\n",
      "\n",
      "        [[-0.2827]],\n",
      "\n",
      "        [[-1.6727]],\n",
      "\n",
      "        [[-0.1381]],\n",
      "\n",
      "        [[ 0.8571]],\n",
      "\n",
      "        [[ 0.3444]],\n",
      "\n",
      "        [[ 1.2136]],\n",
      "\n",
      "        [[ 1.4390]],\n",
      "\n",
      "        [[ 0.2209]],\n",
      "\n",
      "        [[ 0.1201]],\n",
      "\n",
      "        [[ 0.5410]],\n",
      "\n",
      "        [[ 1.1282]],\n",
      "\n",
      "        [[-0.9522]],\n",
      "\n",
      "        [[ 0.1772]],\n",
      "\n",
      "        [[ 0.6092]],\n",
      "\n",
      "        [[ 1.2201]],\n",
      "\n",
      "        [[-0.9505]],\n",
      "\n",
      "        [[ 0.3905]],\n",
      "\n",
      "        [[-0.3953]],\n",
      "\n",
      "        [[-0.4160]],\n",
      "\n",
      "        [[ 0.7489]],\n",
      "\n",
      "        [[-1.2785]],\n",
      "\n",
      "        [[-1.1694]],\n",
      "\n",
      "        [[ 0.0650]],\n",
      "\n",
      "        [[ 0.2346]],\n",
      "\n",
      "        [[-0.0226]],\n",
      "\n",
      "        [[-0.5069]],\n",
      "\n",
      "        [[ 0.1595]],\n",
      "\n",
      "        [[-0.8774]],\n",
      "\n",
      "        [[-0.7931]],\n",
      "\n",
      "        [[-2.1281]],\n",
      "\n",
      "        [[ 0.4315]],\n",
      "\n",
      "        [[-0.0610]],\n",
      "\n",
      "        [[ 0.3390]],\n",
      "\n",
      "        [[ 0.7309]],\n",
      "\n",
      "        [[ 0.6109]],\n",
      "\n",
      "        [[-0.6932]],\n",
      "\n",
      "        [[-0.3842]],\n",
      "\n",
      "        [[ 0.1495]],\n",
      "\n",
      "        [[-0.0991]],\n",
      "\n",
      "        [[-0.5731]],\n",
      "\n",
      "        [[-0.1017]],\n",
      "\n",
      "        [[-1.8765]],\n",
      "\n",
      "        [[ 0.5763]],\n",
      "\n",
      "        [[-0.0185]],\n",
      "\n",
      "        [[-0.9294]],\n",
      "\n",
      "        [[-0.7090]],\n",
      "\n",
      "        [[-0.5310]],\n",
      "\n",
      "        [[-0.2073]],\n",
      "\n",
      "        [[-0.3008]],\n",
      "\n",
      "        [[-0.3853]],\n",
      "\n",
      "        [[-0.4339]],\n",
      "\n",
      "        [[ 0.1742]],\n",
      "\n",
      "        [[ 0.3674]],\n",
      "\n",
      "        [[-0.9268]],\n",
      "\n",
      "        [[-0.5664]],\n",
      "\n",
      "        [[-0.2563]],\n",
      "\n",
      "        [[ 0.3916]],\n",
      "\n",
      "        [[-0.5568]],\n",
      "\n",
      "        [[ 0.3434]],\n",
      "\n",
      "        [[ 0.7153]],\n",
      "\n",
      "        [[ 0.9778]],\n",
      "\n",
      "        [[ 0.6687]],\n",
      "\n",
      "        [[ 0.1339]],\n",
      "\n",
      "        [[ 0.2105]],\n",
      "\n",
      "        [[-0.2962]],\n",
      "\n",
      "        [[-1.1646]],\n",
      "\n",
      "        [[ 0.2647]],\n",
      "\n",
      "        [[-1.4042]],\n",
      "\n",
      "        [[ 0.6708]],\n",
      "\n",
      "        [[ 0.3407]],\n",
      "\n",
      "        [[-0.6685]],\n",
      "\n",
      "        [[ 1.2663]],\n",
      "\n",
      "        [[ 1.1698]],\n",
      "\n",
      "        [[ 1.2880]],\n",
      "\n",
      "        [[-0.6381]],\n",
      "\n",
      "        [[-1.2352]],\n",
      "\n",
      "        [[-0.2668]],\n",
      "\n",
      "        [[ 0.3100]],\n",
      "\n",
      "        [[-0.1485]],\n",
      "\n",
      "        [[-0.1662]],\n",
      "\n",
      "        [[-1.3848]],\n",
      "\n",
      "        [[-0.2212]],\n",
      "\n",
      "        [[ 0.8678]],\n",
      "\n",
      "        [[-0.3447]],\n",
      "\n",
      "        [[ 0.0501]],\n",
      "\n",
      "        [[-1.4752]],\n",
      "\n",
      "        [[ 1.0561]],\n",
      "\n",
      "        [[ 0.9704]],\n",
      "\n",
      "        [[ 0.4979]],\n",
      "\n",
      "        [[-1.1857]],\n",
      "\n",
      "        [[-1.8138]],\n",
      "\n",
      "        [[ 0.4906]],\n",
      "\n",
      "        [[ 0.3956]],\n",
      "\n",
      "        [[ 1.1710]],\n",
      "\n",
      "        [[-0.8492]],\n",
      "\n",
      "        [[ 0.2936]],\n",
      "\n",
      "        [[-1.1701]],\n",
      "\n",
      "        [[ 0.3683]],\n",
      "\n",
      "        [[-1.0431]],\n",
      "\n",
      "        [[-0.4396]],\n",
      "\n",
      "        [[-0.8130]],\n",
      "\n",
      "        [[-0.0595]],\n",
      "\n",
      "        [[ 0.3922]],\n",
      "\n",
      "        [[ 2.1013]],\n",
      "\n",
      "        [[-1.8088]],\n",
      "\n",
      "        [[-1.6257]],\n",
      "\n",
      "        [[ 1.7555]],\n",
      "\n",
      "        [[-0.2078]],\n",
      "\n",
      "        [[-0.2890]],\n",
      "\n",
      "        [[-0.9864]],\n",
      "\n",
      "        [[-0.4314]],\n",
      "\n",
      "        [[ 1.3261]],\n",
      "\n",
      "        [[ 2.5352]],\n",
      "\n",
      "        [[ 0.0310]],\n",
      "\n",
      "        [[-2.3771]],\n",
      "\n",
      "        [[-0.4385]],\n",
      "\n",
      "        [[-0.6817]],\n",
      "\n",
      "        [[ 1.3020]],\n",
      "\n",
      "        [[ 0.1270]],\n",
      "\n",
      "        [[-1.2297]],\n",
      "\n",
      "        [[ 0.0239]],\n",
      "\n",
      "        [[ 0.8264]],\n",
      "\n",
      "        [[-0.0874]],\n",
      "\n",
      "        [[-1.2297]],\n",
      "\n",
      "        [[-1.7042]],\n",
      "\n",
      "        [[-0.0137]],\n",
      "\n",
      "        [[ 0.6598]],\n",
      "\n",
      "        [[-0.4195]],\n",
      "\n",
      "        [[ 0.1919]],\n",
      "\n",
      "        [[ 0.9138]],\n",
      "\n",
      "        [[ 0.8347]],\n",
      "\n",
      "        [[-0.3120]],\n",
      "\n",
      "        [[-1.3963]],\n",
      "\n",
      "        [[ 0.6859]],\n",
      "\n",
      "        [[ 0.9772]],\n",
      "\n",
      "        [[-0.0032]],\n",
      "\n",
      "        [[ 0.6320]],\n",
      "\n",
      "        [[-0.8913]],\n",
      "\n",
      "        [[ 0.3260]],\n",
      "\n",
      "        [[-1.0520]],\n",
      "\n",
      "        [[ 0.2979]],\n",
      "\n",
      "        [[ 1.4209]],\n",
      "\n",
      "        [[-0.9339]],\n",
      "\n",
      "        [[-1.3213]],\n",
      "\n",
      "        [[-0.6483]],\n",
      "\n",
      "        [[ 0.1665]],\n",
      "\n",
      "        [[ 1.4372]],\n",
      "\n",
      "        [[-1.4346]],\n",
      "\n",
      "        [[-0.7334]],\n",
      "\n",
      "        [[ 0.5265]],\n",
      "\n",
      "        [[ 1.4691]],\n",
      "\n",
      "        [[ 0.4718]],\n",
      "\n",
      "        [[ 0.3317]],\n",
      "\n",
      "        [[ 0.2816]],\n",
      "\n",
      "        [[ 0.7294]],\n",
      "\n",
      "        [[ 0.1305]],\n",
      "\n",
      "        [[ 0.7758]],\n",
      "\n",
      "        [[ 0.0074]],\n",
      "\n",
      "        [[ 0.8879]],\n",
      "\n",
      "        [[ 0.2344]],\n",
      "\n",
      "        [[ 1.5196]],\n",
      "\n",
      "        [[ 0.6668]],\n",
      "\n",
      "        [[ 0.3241]],\n",
      "\n",
      "        [[-0.2443]],\n",
      "\n",
      "        [[ 1.5406]],\n",
      "\n",
      "        [[ 0.2301]],\n",
      "\n",
      "        [[-1.0967]],\n",
      "\n",
      "        [[ 0.5534]],\n",
      "\n",
      "        [[-0.0295]],\n",
      "\n",
      "        [[-0.1352]],\n",
      "\n",
      "        [[-0.4183]],\n",
      "\n",
      "        [[-0.8414]],\n",
      "\n",
      "        [[ 0.4920]],\n",
      "\n",
      "        [[-0.0484]],\n",
      "\n",
      "        [[-0.1013]],\n",
      "\n",
      "        [[ 1.3733]],\n",
      "\n",
      "        [[-0.2675]],\n",
      "\n",
      "        [[ 0.0595]],\n",
      "\n",
      "        [[-1.0526]],\n",
      "\n",
      "        [[-0.8951]],\n",
      "\n",
      "        [[-0.6234]],\n",
      "\n",
      "        [[-0.5213]],\n",
      "\n",
      "        [[-0.9870]],\n",
      "\n",
      "        [[ 1.3184]],\n",
      "\n",
      "        [[-0.3872]],\n",
      "\n",
      "        [[ 0.0534]],\n",
      "\n",
      "        [[ 0.9475]],\n",
      "\n",
      "        [[-1.4609]],\n",
      "\n",
      "        [[ 0.9481]],\n",
      "\n",
      "        [[ 2.1554]],\n",
      "\n",
      "        [[ 0.8413]],\n",
      "\n",
      "        [[ 0.6148]],\n",
      "\n",
      "        [[-1.1541]],\n",
      "\n",
      "        [[ 1.4287]],\n",
      "\n",
      "        [[-1.3543]],\n",
      "\n",
      "        [[ 0.9177]],\n",
      "\n",
      "        [[ 1.0869]],\n",
      "\n",
      "        [[ 0.3542]],\n",
      "\n",
      "        [[ 1.1700]],\n",
      "\n",
      "        [[-0.3738]],\n",
      "\n",
      "        [[ 0.7239]],\n",
      "\n",
      "        [[ 0.6715]],\n",
      "\n",
      "        [[ 1.5532]],\n",
      "\n",
      "        [[ 1.3744]],\n",
      "\n",
      "        [[ 2.5495]],\n",
      "\n",
      "        [[ 0.6953]],\n",
      "\n",
      "        [[-0.0080]],\n",
      "\n",
      "        [[-0.0585]],\n",
      "\n",
      "        [[ 1.1550]]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[[-0.5357]]], device='cuda:0')\n",
      "torch.Size([1, 448, 512])\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 2.2422,  1.7268,  1.7074,  ...,  1.6103,  1.8023,  2.0353],\n",
      "         [ 1.3915,  1.4046,  1.4638,  ...,  1.1064,  1.1058,  1.5203],\n",
      "         [ 1.4023,  1.4849,  1.9651,  ...,  1.3456,  1.6901,  1.5245],\n",
      "         ...,\n",
      "         [ 1.5245,  1.7916,  2.4033,  ...,  1.2867,  2.1212,  2.1252],\n",
      "         [ 1.9005,  2.0268,  1.3456,  ...,  2.6820,  1.9625,  1.9661],\n",
      "         [ 1.4257,  2.2024,  1.6807,  ...,  2.0837,  1.6874,  1.2929]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [35000/50000 (99%)]\tLoss: 1.037163, Accuracy: 61.50\n",
      "\n",
      "Validation set: Average loss: 1.2850, Accuracy: 2738/5000 (54.00%)\n",
      "\n",
      "the time of this epoch:[37.23303699493408 s]\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.066273, Accuracy: 62.11\n",
      "Train Epoch: 3 [1280/50000 (3%)]\tLoss: 1.035068, Accuracy: 62.50\n",
      "Train Epoch: 3 [2560/50000 (6%)]\tLoss: 0.928706, Accuracy: 67.58\n",
      "Train Epoch: 3 [3840/50000 (9%)]\tLoss: 1.222573, Accuracy: 60.16\n",
      "Train Epoch: 3 [5120/50000 (11%)]\tLoss: 1.064418, Accuracy: 65.23\n",
      "Train Epoch: 3 [6400/50000 (14%)]\tLoss: 0.974463, Accuracy: 67.19\n",
      "Train Epoch: 3 [7680/50000 (17%)]\tLoss: 0.996837, Accuracy: 66.80\n",
      "Train Epoch: 3 [8960/50000 (20%)]\tLoss: 0.949750, Accuracy: 69.53\n",
      "Train Epoch: 3 [10240/50000 (23%)]\tLoss: 1.016648, Accuracy: 63.28\n",
      "Train Epoch: 3 [11520/50000 (26%)]\tLoss: 1.085958, Accuracy: 61.72\n",
      "Train Epoch: 3 [12800/50000 (28%)]\tLoss: 0.962692, Accuracy: 64.84\n",
      "Train Epoch: 3 [14080/50000 (31%)]\tLoss: 1.002265, Accuracy: 63.67\n",
      "Train Epoch: 3 [15360/50000 (34%)]\tLoss: 1.083079, Accuracy: 60.55\n",
      "Train Epoch: 3 [16640/50000 (37%)]\tLoss: 1.099305, Accuracy: 59.77\n",
      "Train Epoch: 3 [17920/50000 (40%)]\tLoss: 1.053419, Accuracy: 61.72\n",
      "Train Epoch: 3 [19200/50000 (43%)]\tLoss: 0.937042, Accuracy: 66.80\n",
      "Train Epoch: 3 [20480/50000 (45%)]\tLoss: 1.019152, Accuracy: 64.84\n",
      "Train Epoch: 3 [21760/50000 (48%)]\tLoss: 0.870205, Accuracy: 69.14\n",
      "Train Epoch: 3 [23040/50000 (51%)]\tLoss: 0.893801, Accuracy: 71.09\n",
      "Train Epoch: 3 [24320/50000 (54%)]\tLoss: 0.914059, Accuracy: 67.58\n",
      "Train Epoch: 3 [25600/50000 (57%)]\tLoss: 1.039682, Accuracy: 60.16\n",
      "Train Epoch: 3 [26880/50000 (60%)]\tLoss: 1.008369, Accuracy: 62.89\n",
      "Train Epoch: 3 [28160/50000 (62%)]\tLoss: 0.999090, Accuracy: 64.84\n",
      "Train Epoch: 3 [29440/50000 (65%)]\tLoss: 0.955316, Accuracy: 70.31\n",
      "Train Epoch: 3 [30720/50000 (68%)]\tLoss: 0.920613, Accuracy: 71.48\n",
      "Train Epoch: 3 [32000/50000 (71%)]\tLoss: 0.956047, Accuracy: 66.41\n",
      "Train Epoch: 3 [33280/50000 (74%)]\tLoss: 0.903939, Accuracy: 72.27\n",
      "Train Epoch: 3 [34560/50000 (77%)]\tLoss: 0.994406, Accuracy: 62.11\n",
      "Train Epoch: 3 [35840/50000 (80%)]\tLoss: 0.892391, Accuracy: 69.53\n",
      "Train Epoch: 3 [37120/50000 (82%)]\tLoss: 0.956388, Accuracy: 67.58\n",
      "Train Epoch: 3 [38400/50000 (85%)]\tLoss: 1.059389, Accuracy: 62.89\n",
      "Train Epoch: 3 [39680/50000 (88%)]\tLoss: 0.899911, Accuracy: 69.92\n",
      "Train Epoch: 3 [40960/50000 (91%)]\tLoss: 0.866324, Accuracy: 70.70\n",
      "Train Epoch: 3 [42240/50000 (94%)]\tLoss: 0.896874, Accuracy: 68.36\n",
      "Train Epoch: 3 [43520/50000 (97%)]\tLoss: 0.905201, Accuracy: 69.53\n",
      "Train Epoch: 3 [35000/50000 (99%)]\tLoss: 0.912269, Accuracy: 69.50\n",
      "\n",
      "Validation set: Average loss: 1.0069, Accuracy: 3199/5000 (63.00%)\n",
      "\n",
      "the time of this epoch:[37.15618181228638 s]\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.915437, Accuracy: 71.48\n",
      "Train Epoch: 4 [1280/50000 (3%)]\tLoss: 0.808917, Accuracy: 71.09\n",
      "Train Epoch: 4 [2560/50000 (6%)]\tLoss: 0.815047, Accuracy: 74.22\n",
      "Train Epoch: 4 [3840/50000 (9%)]\tLoss: 0.824796, Accuracy: 68.36\n",
      "Train Epoch: 4 [5120/50000 (11%)]\tLoss: 0.960237, Accuracy: 65.62\n",
      "Train Epoch: 4 [6400/50000 (14%)]\tLoss: 0.870389, Accuracy: 70.31\n",
      "Train Epoch: 4 [7680/50000 (17%)]\tLoss: 0.850572, Accuracy: 71.09\n",
      "Train Epoch: 4 [8960/50000 (20%)]\tLoss: 0.881765, Accuracy: 69.92\n",
      "Train Epoch: 4 [10240/50000 (23%)]\tLoss: 0.844398, Accuracy: 70.31\n",
      "Train Epoch: 4 [11520/50000 (26%)]\tLoss: 0.861190, Accuracy: 69.14\n",
      "Train Epoch: 4 [12800/50000 (28%)]\tLoss: 0.873027, Accuracy: 68.75\n",
      "Train Epoch: 4 [14080/50000 (31%)]\tLoss: 0.979707, Accuracy: 65.23\n",
      "Train Epoch: 4 [15360/50000 (34%)]\tLoss: 0.829823, Accuracy: 70.70\n",
      "Train Epoch: 4 [16640/50000 (37%)]\tLoss: 0.795222, Accuracy: 69.53\n",
      "Train Epoch: 4 [17920/50000 (40%)]\tLoss: 1.069627, Accuracy: 63.67\n",
      "Train Epoch: 4 [19200/50000 (43%)]\tLoss: 0.827680, Accuracy: 73.44\n",
      "Train Epoch: 4 [20480/50000 (45%)]\tLoss: 0.890028, Accuracy: 69.92\n",
      "Train Epoch: 4 [21760/50000 (48%)]\tLoss: 0.896200, Accuracy: 67.97\n",
      "Train Epoch: 4 [23040/50000 (51%)]\tLoss: 0.854998, Accuracy: 70.70\n",
      "Train Epoch: 4 [24320/50000 (54%)]\tLoss: 0.907079, Accuracy: 68.36\n",
      "Train Epoch: 4 [25600/50000 (57%)]\tLoss: 0.837528, Accuracy: 71.88\n",
      "Train Epoch: 4 [26880/50000 (60%)]\tLoss: 0.884032, Accuracy: 68.75\n",
      "Train Epoch: 4 [28160/50000 (62%)]\tLoss: 0.882218, Accuracy: 68.75\n",
      "Train Epoch: 4 [29440/50000 (65%)]\tLoss: 0.868936, Accuracy: 72.66\n",
      "Train Epoch: 4 [30720/50000 (68%)]\tLoss: 0.900908, Accuracy: 68.36\n",
      "Train Epoch: 4 [32000/50000 (71%)]\tLoss: 0.845866, Accuracy: 70.70\n",
      "Train Epoch: 4 [33280/50000 (74%)]\tLoss: 0.825056, Accuracy: 68.75\n",
      "Train Epoch: 4 [34560/50000 (77%)]\tLoss: 0.947962, Accuracy: 65.62\n",
      "Train Epoch: 4 [35840/50000 (80%)]\tLoss: 0.846381, Accuracy: 70.70\n",
      "Train Epoch: 4 [37120/50000 (82%)]\tLoss: 0.962863, Accuracy: 67.58\n",
      "Train Epoch: 4 [38400/50000 (85%)]\tLoss: 0.783683, Accuracy: 72.27\n",
      "Train Epoch: 4 [39680/50000 (88%)]\tLoss: 0.793486, Accuracy: 72.66\n",
      "Train Epoch: 4 [40960/50000 (91%)]\tLoss: 0.831379, Accuracy: 71.88\n",
      "Train Epoch: 4 [42240/50000 (94%)]\tLoss: 0.789117, Accuracy: 73.44\n",
      "Train Epoch: 4 [43520/50000 (97%)]\tLoss: 0.780471, Accuracy: 73.44\n",
      "Train Epoch: 4 [35000/50000 (99%)]\tLoss: 0.743036, Accuracy: 74.50\n",
      "\n",
      "Validation set: Average loss: 1.0948, Accuracy: 3231/5000 (64.00%)\n",
      "\n",
      "the time of this epoch:[37.13479709625244 s]\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.776562, Accuracy: 73.05\n",
      "Train Epoch: 5 [1280/50000 (3%)]\tLoss: 0.777143, Accuracy: 75.39\n",
      "Train Epoch: 5 [2560/50000 (6%)]\tLoss: 0.736995, Accuracy: 75.00\n",
      "Train Epoch: 5 [3840/50000 (9%)]\tLoss: 0.760447, Accuracy: 73.83\n",
      "Train Epoch: 5 [5120/50000 (11%)]\tLoss: 0.867420, Accuracy: 69.92\n",
      "Train Epoch: 5 [6400/50000 (14%)]\tLoss: 0.838720, Accuracy: 70.31\n",
      "Train Epoch: 5 [7680/50000 (17%)]\tLoss: 0.768380, Accuracy: 73.83\n",
      "Train Epoch: 5 [8960/50000 (20%)]\tLoss: 0.778690, Accuracy: 74.22\n",
      "Train Epoch: 5 [10240/50000 (23%)]\tLoss: 0.771321, Accuracy: 74.22\n",
      "Train Epoch: 5 [11520/50000 (26%)]\tLoss: 0.869944, Accuracy: 70.31\n",
      "Train Epoch: 5 [12800/50000 (28%)]\tLoss: 0.819518, Accuracy: 69.92\n",
      "Train Epoch: 5 [14080/50000 (31%)]\tLoss: 0.653852, Accuracy: 78.91\n",
      "Train Epoch: 5 [15360/50000 (34%)]\tLoss: 0.842225, Accuracy: 71.48\n",
      "Train Epoch: 5 [16640/50000 (37%)]\tLoss: 0.901632, Accuracy: 66.02\n",
      "Train Epoch: 5 [17920/50000 (40%)]\tLoss: 0.818667, Accuracy: 71.88\n",
      "Train Epoch: 5 [19200/50000 (43%)]\tLoss: 0.778384, Accuracy: 73.44\n",
      "Train Epoch: 5 [20480/50000 (45%)]\tLoss: 0.750222, Accuracy: 76.95\n",
      "Train Epoch: 5 [21760/50000 (48%)]\tLoss: 0.781417, Accuracy: 70.31\n",
      "Train Epoch: 5 [23040/50000 (51%)]\tLoss: 0.770103, Accuracy: 73.05\n",
      "Train Epoch: 5 [24320/50000 (54%)]\tLoss: 0.747540, Accuracy: 72.66\n",
      "Train Epoch: 5 [25600/50000 (57%)]\tLoss: 0.758419, Accuracy: 78.12\n",
      "Train Epoch: 5 [26880/50000 (60%)]\tLoss: 0.776527, Accuracy: 71.48\n",
      "Train Epoch: 5 [28160/50000 (62%)]\tLoss: 0.670183, Accuracy: 75.00\n",
      "Train Epoch: 5 [29440/50000 (65%)]\tLoss: 0.800536, Accuracy: 73.05\n",
      "Train Epoch: 5 [30720/50000 (68%)]\tLoss: 0.815374, Accuracy: 72.27\n",
      "Train Epoch: 5 [32000/50000 (71%)]\tLoss: 0.781752, Accuracy: 72.66\n",
      "Train Epoch: 5 [33280/50000 (74%)]\tLoss: 0.748420, Accuracy: 74.22\n",
      "Train Epoch: 5 [34560/50000 (77%)]\tLoss: 0.778536, Accuracy: 71.88\n",
      "Train Epoch: 5 [35840/50000 (80%)]\tLoss: 0.714660, Accuracy: 75.00\n",
      "Train Epoch: 5 [37120/50000 (82%)]\tLoss: 0.694659, Accuracy: 76.17\n",
      "torch.Size([512, 1, 1])\n",
      "tensor([[[ 2.1821]],\n",
      "\n",
      "        [[ 0.7467]],\n",
      "\n",
      "        [[-0.2951]],\n",
      "\n",
      "        [[ 0.5204]],\n",
      "\n",
      "        [[ 1.1182]],\n",
      "\n",
      "        [[-0.6074]],\n",
      "\n",
      "        [[-0.7291]],\n",
      "\n",
      "        [[-1.5790]],\n",
      "\n",
      "        [[-0.6671]],\n",
      "\n",
      "        [[-0.6294]],\n",
      "\n",
      "        [[ 0.1769]],\n",
      "\n",
      "        [[-0.0819]],\n",
      "\n",
      "        [[ 0.0481]],\n",
      "\n",
      "        [[-0.7819]],\n",
      "\n",
      "        [[-0.0790]],\n",
      "\n",
      "        [[ 0.1349]],\n",
      "\n",
      "        [[ 1.2710]],\n",
      "\n",
      "        [[-0.1176]],\n",
      "\n",
      "        [[-1.1982]],\n",
      "\n",
      "        [[ 0.6623]],\n",
      "\n",
      "        [[-0.0198]],\n",
      "\n",
      "        [[ 0.3102]],\n",
      "\n",
      "        [[ 0.6904]],\n",
      "\n",
      "        [[ 0.0988]],\n",
      "\n",
      "        [[ 0.7096]],\n",
      "\n",
      "        [[ 0.5503]],\n",
      "\n",
      "        [[-1.6042]],\n",
      "\n",
      "        [[-0.8787]],\n",
      "\n",
      "        [[-1.3090]],\n",
      "\n",
      "        [[ 0.1095]],\n",
      "\n",
      "        [[ 0.4465]],\n",
      "\n",
      "        [[ 2.0307]],\n",
      "\n",
      "        [[ 0.1144]],\n",
      "\n",
      "        [[ 0.5085]],\n",
      "\n",
      "        [[-0.2248]],\n",
      "\n",
      "        [[-0.0127]],\n",
      "\n",
      "        [[ 0.2278]],\n",
      "\n",
      "        [[ 0.0883]],\n",
      "\n",
      "        [[ 0.4570]],\n",
      "\n",
      "        [[-0.1817]],\n",
      "\n",
      "        [[-1.2650]],\n",
      "\n",
      "        [[-1.9736]],\n",
      "\n",
      "        [[ 2.5097]],\n",
      "\n",
      "        [[-0.2897]],\n",
      "\n",
      "        [[ 1.0067]],\n",
      "\n",
      "        [[ 0.7372]],\n",
      "\n",
      "        [[-0.5539]],\n",
      "\n",
      "        [[ 0.5000]],\n",
      "\n",
      "        [[-1.8403]],\n",
      "\n",
      "        [[-0.4169]],\n",
      "\n",
      "        [[-0.1708]],\n",
      "\n",
      "        [[ 0.3540]],\n",
      "\n",
      "        [[-0.7442]],\n",
      "\n",
      "        [[-0.6207]],\n",
      "\n",
      "        [[ 1.0266]],\n",
      "\n",
      "        [[ 3.4427]],\n",
      "\n",
      "        [[-0.4152]],\n",
      "\n",
      "        [[-0.7414]],\n",
      "\n",
      "        [[ 0.9556]],\n",
      "\n",
      "        [[-0.2187]],\n",
      "\n",
      "        [[-1.2105]],\n",
      "\n",
      "        [[-0.8226]],\n",
      "\n",
      "        [[-2.0399]],\n",
      "\n",
      "        [[-1.7518]],\n",
      "\n",
      "        [[-0.0599]],\n",
      "\n",
      "        [[ 0.7157]],\n",
      "\n",
      "        [[-0.2497]],\n",
      "\n",
      "        [[-1.4035]],\n",
      "\n",
      "        [[ 0.7645]],\n",
      "\n",
      "        [[ 1.4200]],\n",
      "\n",
      "        [[-0.8808]],\n",
      "\n",
      "        [[-0.1319]],\n",
      "\n",
      "        [[ 0.1218]],\n",
      "\n",
      "        [[-0.3119]],\n",
      "\n",
      "        [[ 0.0189]],\n",
      "\n",
      "        [[-0.8449]],\n",
      "\n",
      "        [[-0.8325]],\n",
      "\n",
      "        [[-1.2633]],\n",
      "\n",
      "        [[-0.2361]],\n",
      "\n",
      "        [[-0.3923]],\n",
      "\n",
      "        [[-0.1650]],\n",
      "\n",
      "        [[-1.1053]],\n",
      "\n",
      "        [[ 0.1483]],\n",
      "\n",
      "        [[ 0.1216]],\n",
      "\n",
      "        [[ 0.8002]],\n",
      "\n",
      "        [[ 0.0400]],\n",
      "\n",
      "        [[-0.1460]],\n",
      "\n",
      "        [[-0.2800]],\n",
      "\n",
      "        [[-1.2347]],\n",
      "\n",
      "        [[ 1.6593]],\n",
      "\n",
      "        [[-1.8232]],\n",
      "\n",
      "        [[ 0.5204]],\n",
      "\n",
      "        [[ 0.4207]],\n",
      "\n",
      "        [[ 0.6815]],\n",
      "\n",
      "        [[-0.8071]],\n",
      "\n",
      "        [[-1.7700]],\n",
      "\n",
      "        [[ 0.3515]],\n",
      "\n",
      "        [[ 0.1126]],\n",
      "\n",
      "        [[-1.9131]],\n",
      "\n",
      "        [[ 0.3239]],\n",
      "\n",
      "        [[-2.3759]],\n",
      "\n",
      "        [[ 0.5058]],\n",
      "\n",
      "        [[ 1.7204]],\n",
      "\n",
      "        [[-1.1277]],\n",
      "\n",
      "        [[-0.0988]],\n",
      "\n",
      "        [[-0.2088]],\n",
      "\n",
      "        [[-2.2163]],\n",
      "\n",
      "        [[ 1.8645]],\n",
      "\n",
      "        [[ 0.2382]],\n",
      "\n",
      "        [[-0.1605]],\n",
      "\n",
      "        [[-1.9516]],\n",
      "\n",
      "        [[ 0.9238]],\n",
      "\n",
      "        [[-0.2992]],\n",
      "\n",
      "        [[ 0.9938]],\n",
      "\n",
      "        [[ 0.0456]],\n",
      "\n",
      "        [[-0.5649]],\n",
      "\n",
      "        [[-1.1302]],\n",
      "\n",
      "        [[ 0.1850]],\n",
      "\n",
      "        [[-0.4081]],\n",
      "\n",
      "        [[-1.2179]],\n",
      "\n",
      "        [[ 1.9959]],\n",
      "\n",
      "        [[ 2.4584]],\n",
      "\n",
      "        [[ 0.1582]],\n",
      "\n",
      "        [[ 0.3728]],\n",
      "\n",
      "        [[ 0.8613]],\n",
      "\n",
      "        [[ 0.7020]],\n",
      "\n",
      "        [[ 1.0084]],\n",
      "\n",
      "        [[ 0.3975]],\n",
      "\n",
      "        [[ 0.4201]],\n",
      "\n",
      "        [[ 1.3003]],\n",
      "\n",
      "        [[ 1.6766]],\n",
      "\n",
      "        [[ 0.1541]],\n",
      "\n",
      "        [[-1.9875]],\n",
      "\n",
      "        [[ 0.2325]],\n",
      "\n",
      "        [[-0.9636]],\n",
      "\n",
      "        [[ 1.3033]],\n",
      "\n",
      "        [[ 0.8942]],\n",
      "\n",
      "        [[-0.1577]],\n",
      "\n",
      "        [[ 1.4964]],\n",
      "\n",
      "        [[ 0.2390]],\n",
      "\n",
      "        [[-1.5492]],\n",
      "\n",
      "        [[ 1.9738]],\n",
      "\n",
      "        [[-0.2108]],\n",
      "\n",
      "        [[-0.6366]],\n",
      "\n",
      "        [[ 0.8065]],\n",
      "\n",
      "        [[-0.7787]],\n",
      "\n",
      "        [[-0.0076]],\n",
      "\n",
      "        [[-0.1997]],\n",
      "\n",
      "        [[-0.0794]],\n",
      "\n",
      "        [[-1.9933]],\n",
      "\n",
      "        [[-0.8705]],\n",
      "\n",
      "        [[ 0.3901]],\n",
      "\n",
      "        [[-1.2301]],\n",
      "\n",
      "        [[ 1.2785]],\n",
      "\n",
      "        [[-0.8954]],\n",
      "\n",
      "        [[-0.7501]],\n",
      "\n",
      "        [[-0.3397]],\n",
      "\n",
      "        [[ 0.1901]],\n",
      "\n",
      "        [[-2.2677]],\n",
      "\n",
      "        [[-0.0604]],\n",
      "\n",
      "        [[-1.8377]],\n",
      "\n",
      "        [[-0.5977]],\n",
      "\n",
      "        [[ 0.9510]],\n",
      "\n",
      "        [[-0.4146]],\n",
      "\n",
      "        [[ 0.1938]],\n",
      "\n",
      "        [[ 0.5822]],\n",
      "\n",
      "        [[-0.4636]],\n",
      "\n",
      "        [[-0.3438]],\n",
      "\n",
      "        [[ 0.3829]],\n",
      "\n",
      "        [[-0.0810]],\n",
      "\n",
      "        [[-0.4776]],\n",
      "\n",
      "        [[-1.5495]],\n",
      "\n",
      "        [[ 1.7131]],\n",
      "\n",
      "        [[ 1.4105]],\n",
      "\n",
      "        [[-1.2257]],\n",
      "\n",
      "        [[-0.5705]],\n",
      "\n",
      "        [[-0.6388]],\n",
      "\n",
      "        [[-0.5083]],\n",
      "\n",
      "        [[-0.3653]],\n",
      "\n",
      "        [[ 2.1167]],\n",
      "\n",
      "        [[ 0.1452]],\n",
      "\n",
      "        [[-0.0727]],\n",
      "\n",
      "        [[ 0.5325]],\n",
      "\n",
      "        [[-0.8580]],\n",
      "\n",
      "        [[ 0.8552]],\n",
      "\n",
      "        [[-1.2658]],\n",
      "\n",
      "        [[ 0.5094]],\n",
      "\n",
      "        [[-0.1321]],\n",
      "\n",
      "        [[-0.9109]],\n",
      "\n",
      "        [[ 0.4847]],\n",
      "\n",
      "        [[-1.5655]],\n",
      "\n",
      "        [[ 0.1698]],\n",
      "\n",
      "        [[-0.5606]],\n",
      "\n",
      "        [[-0.0100]],\n",
      "\n",
      "        [[-0.4441]],\n",
      "\n",
      "        [[-1.0383]],\n",
      "\n",
      "        [[ 0.6389]],\n",
      "\n",
      "        [[ 1.3350]],\n",
      "\n",
      "        [[ 0.1679]],\n",
      "\n",
      "        [[-1.2336]],\n",
      "\n",
      "        [[-1.2091]],\n",
      "\n",
      "        [[ 0.5872]],\n",
      "\n",
      "        [[ 0.2530]],\n",
      "\n",
      "        [[ 0.7722]],\n",
      "\n",
      "        [[ 0.0138]],\n",
      "\n",
      "        [[-1.1267]],\n",
      "\n",
      "        [[ 0.4481]],\n",
      "\n",
      "        [[ 0.1834]],\n",
      "\n",
      "        [[-1.0641]],\n",
      "\n",
      "        [[ 0.6312]],\n",
      "\n",
      "        [[ 0.1988]],\n",
      "\n",
      "        [[-1.3344]],\n",
      "\n",
      "        [[-1.7651]],\n",
      "\n",
      "        [[ 0.0247]],\n",
      "\n",
      "        [[-0.3284]],\n",
      "\n",
      "        [[-0.0946]],\n",
      "\n",
      "        [[-1.5622]],\n",
      "\n",
      "        [[-1.1468]],\n",
      "\n",
      "        [[ 1.8281]],\n",
      "\n",
      "        [[-0.6111]],\n",
      "\n",
      "        [[ 0.7751]],\n",
      "\n",
      "        [[-0.9268]],\n",
      "\n",
      "        [[ 3.2088]],\n",
      "\n",
      "        [[ 0.9776]],\n",
      "\n",
      "        [[ 0.4360]],\n",
      "\n",
      "        [[-1.4042]],\n",
      "\n",
      "        [[-0.0126]],\n",
      "\n",
      "        [[-0.8496]],\n",
      "\n",
      "        [[ 0.0642]],\n",
      "\n",
      "        [[ 0.3914]],\n",
      "\n",
      "        [[-0.3957]],\n",
      "\n",
      "        [[ 0.9633]],\n",
      "\n",
      "        [[-0.4333]],\n",
      "\n",
      "        [[ 0.4069]],\n",
      "\n",
      "        [[ 1.6868]],\n",
      "\n",
      "        [[-0.0659]],\n",
      "\n",
      "        [[-1.1339]],\n",
      "\n",
      "        [[ 1.1883]],\n",
      "\n",
      "        [[-0.7346]],\n",
      "\n",
      "        [[ 0.5306]],\n",
      "\n",
      "        [[-1.3197]],\n",
      "\n",
      "        [[ 0.0167]],\n",
      "\n",
      "        [[-2.1593]],\n",
      "\n",
      "        [[-0.1630]],\n",
      "\n",
      "        [[-1.0517]],\n",
      "\n",
      "        [[-0.7616]],\n",
      "\n",
      "        [[-0.7820]],\n",
      "\n",
      "        [[-0.1771]],\n",
      "\n",
      "        [[-1.0315]],\n",
      "\n",
      "        [[-0.5333]],\n",
      "\n",
      "        [[ 0.3136]],\n",
      "\n",
      "        [[ 1.1914]],\n",
      "\n",
      "        [[ 1.0711]],\n",
      "\n",
      "        [[ 0.5039]],\n",
      "\n",
      "        [[ 0.3898]],\n",
      "\n",
      "        [[-0.1266]],\n",
      "\n",
      "        [[ 2.5072]],\n",
      "\n",
      "        [[-0.1788]],\n",
      "\n",
      "        [[ 2.6035]],\n",
      "\n",
      "        [[ 0.3786]],\n",
      "\n",
      "        [[ 0.5196]],\n",
      "\n",
      "        [[-0.4395]],\n",
      "\n",
      "        [[ 0.0015]],\n",
      "\n",
      "        [[ 1.4101]],\n",
      "\n",
      "        [[ 0.6875]],\n",
      "\n",
      "        [[ 0.4133]],\n",
      "\n",
      "        [[-1.4977]],\n",
      "\n",
      "        [[-0.3821]],\n",
      "\n",
      "        [[-0.2709]],\n",
      "\n",
      "        [[ 0.9016]],\n",
      "\n",
      "        [[-0.5485]],\n",
      "\n",
      "        [[ 1.6012]],\n",
      "\n",
      "        [[ 1.4781]],\n",
      "\n",
      "        [[ 0.7263]],\n",
      "\n",
      "        [[ 0.2521]],\n",
      "\n",
      "        [[-2.3385]],\n",
      "\n",
      "        [[-0.2112]],\n",
      "\n",
      "        [[-0.8526]],\n",
      "\n",
      "        [[ 0.8758]],\n",
      "\n",
      "        [[-2.2302]],\n",
      "\n",
      "        [[-0.4879]],\n",
      "\n",
      "        [[-2.2818]],\n",
      "\n",
      "        [[ 0.9804]],\n",
      "\n",
      "        [[-0.4090]],\n",
      "\n",
      "        [[ 1.0996]],\n",
      "\n",
      "        [[-2.0999]],\n",
      "\n",
      "        [[ 0.4667]],\n",
      "\n",
      "        [[ 0.8425]],\n",
      "\n",
      "        [[ 1.6427]],\n",
      "\n",
      "        [[-0.3926]],\n",
      "\n",
      "        [[ 1.0117]],\n",
      "\n",
      "        [[-1.5844]],\n",
      "\n",
      "        [[-0.1263]],\n",
      "\n",
      "        [[-0.4205]],\n",
      "\n",
      "        [[ 2.0973]],\n",
      "\n",
      "        [[-0.9703]],\n",
      "\n",
      "        [[-0.9247]],\n",
      "\n",
      "        [[ 0.5265]],\n",
      "\n",
      "        [[-1.0071]],\n",
      "\n",
      "        [[-0.2385]],\n",
      "\n",
      "        [[-0.8364]],\n",
      "\n",
      "        [[ 0.0511]],\n",
      "\n",
      "        [[-0.6924]],\n",
      "\n",
      "        [[-1.7536]],\n",
      "\n",
      "        [[-0.6315]],\n",
      "\n",
      "        [[-2.0769]],\n",
      "\n",
      "        [[ 0.3358]],\n",
      "\n",
      "        [[-0.9069]],\n",
      "\n",
      "        [[ 0.6110]],\n",
      "\n",
      "        [[-0.9447]],\n",
      "\n",
      "        [[ 1.6035]],\n",
      "\n",
      "        [[ 0.7419]],\n",
      "\n",
      "        [[-0.9415]],\n",
      "\n",
      "        [[ 0.1694]],\n",
      "\n",
      "        [[-0.9666]],\n",
      "\n",
      "        [[-0.8096]],\n",
      "\n",
      "        [[ 2.2003]],\n",
      "\n",
      "        [[-0.3494]],\n",
      "\n",
      "        [[ 0.9858]],\n",
      "\n",
      "        [[ 1.8831]],\n",
      "\n",
      "        [[ 0.4822]],\n",
      "\n",
      "        [[ 0.5081]],\n",
      "\n",
      "        [[ 0.2107]],\n",
      "\n",
      "        [[-0.8706]],\n",
      "\n",
      "        [[ 0.2682]],\n",
      "\n",
      "        [[ 0.2891]],\n",
      "\n",
      "        [[ 0.2541]],\n",
      "\n",
      "        [[ 0.7243]],\n",
      "\n",
      "        [[ 0.1966]],\n",
      "\n",
      "        [[ 0.1528]],\n",
      "\n",
      "        [[-0.7583]],\n",
      "\n",
      "        [[-0.4327]],\n",
      "\n",
      "        [[-0.1314]],\n",
      "\n",
      "        [[ 1.1416]],\n",
      "\n",
      "        [[-1.0059]],\n",
      "\n",
      "        [[ 0.3786]],\n",
      "\n",
      "        [[-1.2980]],\n",
      "\n",
      "        [[ 1.4698]],\n",
      "\n",
      "        [[-0.2812]],\n",
      "\n",
      "        [[-1.3820]],\n",
      "\n",
      "        [[-0.0665]],\n",
      "\n",
      "        [[-0.9118]],\n",
      "\n",
      "        [[ 0.3195]],\n",
      "\n",
      "        [[ 0.0570]],\n",
      "\n",
      "        [[-0.1092]],\n",
      "\n",
      "        [[-0.2581]],\n",
      "\n",
      "        [[-0.5544]],\n",
      "\n",
      "        [[ 1.6615]],\n",
      "\n",
      "        [[-0.3094]],\n",
      "\n",
      "        [[ 2.8190]],\n",
      "\n",
      "        [[-0.5146]],\n",
      "\n",
      "        [[ 0.1451]],\n",
      "\n",
      "        [[-1.4665]],\n",
      "\n",
      "        [[-0.9241]],\n",
      "\n",
      "        [[-0.1158]],\n",
      "\n",
      "        [[-0.1879]],\n",
      "\n",
      "        [[ 1.8976]],\n",
      "\n",
      "        [[-1.4962]],\n",
      "\n",
      "        [[-0.8505]],\n",
      "\n",
      "        [[-0.0706]],\n",
      "\n",
      "        [[ 0.0629]],\n",
      "\n",
      "        [[-0.5893]],\n",
      "\n",
      "        [[ 1.3081]],\n",
      "\n",
      "        [[ 0.6419]],\n",
      "\n",
      "        [[-1.1395]],\n",
      "\n",
      "        [[-0.8667]],\n",
      "\n",
      "        [[ 0.8074]],\n",
      "\n",
      "        [[-1.7531]],\n",
      "\n",
      "        [[ 0.8911]],\n",
      "\n",
      "        [[ 0.7618]],\n",
      "\n",
      "        [[ 1.4170]],\n",
      "\n",
      "        [[-0.1348]],\n",
      "\n",
      "        [[ 0.5445]],\n",
      "\n",
      "        [[-0.4787]],\n",
      "\n",
      "        [[-0.9774]],\n",
      "\n",
      "        [[ 0.3474]],\n",
      "\n",
      "        [[-1.4021]],\n",
      "\n",
      "        [[-0.8740]],\n",
      "\n",
      "        [[ 0.0294]],\n",
      "\n",
      "        [[ 0.5671]],\n",
      "\n",
      "        [[-0.7266]],\n",
      "\n",
      "        [[ 0.6342]],\n",
      "\n",
      "        [[-0.2734]],\n",
      "\n",
      "        [[ 0.4428]],\n",
      "\n",
      "        [[ 0.3948]],\n",
      "\n",
      "        [[ 2.0933]],\n",
      "\n",
      "        [[ 0.1165]],\n",
      "\n",
      "        [[-1.4139]],\n",
      "\n",
      "        [[ 0.2041]],\n",
      "\n",
      "        [[-0.2178]],\n",
      "\n",
      "        [[ 1.2332]],\n",
      "\n",
      "        [[ 0.1120]],\n",
      "\n",
      "        [[-1.1957]],\n",
      "\n",
      "        [[-0.5527]],\n",
      "\n",
      "        [[-1.2639]],\n",
      "\n",
      "        [[ 1.7685]],\n",
      "\n",
      "        [[ 0.7507]],\n",
      "\n",
      "        [[-2.0775]],\n",
      "\n",
      "        [[ 0.6175]],\n",
      "\n",
      "        [[-2.2107]],\n",
      "\n",
      "        [[ 0.4634]],\n",
      "\n",
      "        [[ 1.0991]],\n",
      "\n",
      "        [[-0.3590]],\n",
      "\n",
      "        [[-1.1133]],\n",
      "\n",
      "        [[-1.7803]],\n",
      "\n",
      "        [[ 0.9682]],\n",
      "\n",
      "        [[ 0.0078]],\n",
      "\n",
      "        [[-0.0257]],\n",
      "\n",
      "        [[ 1.0532]],\n",
      "\n",
      "        [[-0.0068]],\n",
      "\n",
      "        [[ 0.0558]],\n",
      "\n",
      "        [[-0.7617]],\n",
      "\n",
      "        [[-0.2957]],\n",
      "\n",
      "        [[ 0.7864]],\n",
      "\n",
      "        [[-1.4188]],\n",
      "\n",
      "        [[ 1.9004]],\n",
      "\n",
      "        [[ 2.4015]],\n",
      "\n",
      "        [[-1.7426]],\n",
      "\n",
      "        [[-1.5065]],\n",
      "\n",
      "        [[-0.1901]],\n",
      "\n",
      "        [[-0.2680]],\n",
      "\n",
      "        [[ 0.7382]],\n",
      "\n",
      "        [[ 0.7747]],\n",
      "\n",
      "        [[-1.6210]],\n",
      "\n",
      "        [[ 0.2359]],\n",
      "\n",
      "        [[-1.2402]],\n",
      "\n",
      "        [[ 0.8728]],\n",
      "\n",
      "        [[ 0.1862]],\n",
      "\n",
      "        [[-1.2059]],\n",
      "\n",
      "        [[ 1.1177]],\n",
      "\n",
      "        [[ 2.0251]],\n",
      "\n",
      "        [[-0.0891]],\n",
      "\n",
      "        [[ 2.0031]],\n",
      "\n",
      "        [[-0.0156]],\n",
      "\n",
      "        [[-0.7762]],\n",
      "\n",
      "        [[ 1.4381]],\n",
      "\n",
      "        [[-0.5970]],\n",
      "\n",
      "        [[-0.0516]],\n",
      "\n",
      "        [[-1.1307]],\n",
      "\n",
      "        [[ 1.3525]],\n",
      "\n",
      "        [[ 0.5960]],\n",
      "\n",
      "        [[ 0.0361]],\n",
      "\n",
      "        [[ 0.3171]],\n",
      "\n",
      "        [[ 0.3484]],\n",
      "\n",
      "        [[ 0.4120]],\n",
      "\n",
      "        [[-2.4729]],\n",
      "\n",
      "        [[ 1.1536]],\n",
      "\n",
      "        [[ 1.7229]],\n",
      "\n",
      "        [[-0.1704]],\n",
      "\n",
      "        [[ 0.0896]],\n",
      "\n",
      "        [[-1.6251]],\n",
      "\n",
      "        [[-0.4333]],\n",
      "\n",
      "        [[ 1.0656]],\n",
      "\n",
      "        [[-2.0674]],\n",
      "\n",
      "        [[-1.5875]],\n",
      "\n",
      "        [[-0.3809]],\n",
      "\n",
      "        [[ 1.2569]],\n",
      "\n",
      "        [[ 0.1457]],\n",
      "\n",
      "        [[-0.4041]],\n",
      "\n",
      "        [[ 1.6220]],\n",
      "\n",
      "        [[-0.8398]],\n",
      "\n",
      "        [[ 0.2430]],\n",
      "\n",
      "        [[-0.1092]],\n",
      "\n",
      "        [[ 0.1907]],\n",
      "\n",
      "        [[ 0.0769]],\n",
      "\n",
      "        [[-1.1944]],\n",
      "\n",
      "        [[-1.2699]],\n",
      "\n",
      "        [[ 0.1391]],\n",
      "\n",
      "        [[-2.9999]],\n",
      "\n",
      "        [[ 1.8341]],\n",
      "\n",
      "        [[-0.3654]],\n",
      "\n",
      "        [[-0.7275]],\n",
      "\n",
      "        [[ 1.5166]],\n",
      "\n",
      "        [[ 1.3469]],\n",
      "\n",
      "        [[-1.7142]],\n",
      "\n",
      "        [[ 1.6459]],\n",
      "\n",
      "        [[-0.3763]],\n",
      "\n",
      "        [[ 1.1370]],\n",
      "\n",
      "        [[-0.7169]],\n",
      "\n",
      "        [[ 1.1597]],\n",
      "\n",
      "        [[ 0.4927]],\n",
      "\n",
      "        [[-0.6000]],\n",
      "\n",
      "        [[ 0.3737]],\n",
      "\n",
      "        [[ 0.8198]],\n",
      "\n",
      "        [[-0.3043]],\n",
      "\n",
      "        [[ 0.1167]],\n",
      "\n",
      "        [[ 0.0877]],\n",
      "\n",
      "        [[-0.1410]],\n",
      "\n",
      "        [[-0.1732]],\n",
      "\n",
      "        [[-0.3361]],\n",
      "\n",
      "        [[-0.2136]],\n",
      "\n",
      "        [[ 0.6528]],\n",
      "\n",
      "        [[-0.3884]],\n",
      "\n",
      "        [[ 0.0578]],\n",
      "\n",
      "        [[-0.5623]],\n",
      "\n",
      "        [[-1.0142]],\n",
      "\n",
      "        [[ 0.0344]],\n",
      "\n",
      "        [[-1.2311]],\n",
      "\n",
      "        [[-1.7993]],\n",
      "\n",
      "        [[ 2.1304]],\n",
      "\n",
      "        [[ 0.0455]],\n",
      "\n",
      "        [[-1.0044]],\n",
      "\n",
      "        [[ 0.8872]],\n",
      "\n",
      "        [[-0.4794]],\n",
      "\n",
      "        [[ 1.8221]],\n",
      "\n",
      "        [[-1.0628]],\n",
      "\n",
      "        [[ 1.9506]],\n",
      "\n",
      "        [[ 0.5235]],\n",
      "\n",
      "        [[-0.0752]],\n",
      "\n",
      "        [[ 0.3105]],\n",
      "\n",
      "        [[ 1.4957]],\n",
      "\n",
      "        [[ 0.4597]]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[[-0.4133]]], device='cuda:0')\n",
      "torch.Size([1, 448, 512])\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 2.0761,  2.4645,  2.0055,  ...,  1.7897,  1.8498,  2.2734],\n",
      "         [ 2.1177,  1.9848,  1.6440,  ...,  1.4383,  1.9465,  1.4762],\n",
      "         [ 1.7679,  1.6426,  1.7483,  ...,  1.7801,  1.8838,  1.5068],\n",
      "         ...,\n",
      "         [ 2.1828,  1.8259,  1.9458,  ...,  2.0926,  1.9732,  1.7836],\n",
      "         [ 2.1491,  2.2198,  2.0729,  ...,  1.9579,  2.3671,  1.9130],\n",
      "         [ 1.8916,  1.7238,  2.0614,  ...,  1.8777,  1.8275,  1.4298]]], device='cuda:0')\n",
      "Train Epoch: 5 [38400/50000 (85%)]\tLoss: 0.721326, Accuracy: 75.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [39680/50000 (88%)]\tLoss: 0.667401, Accuracy: 78.12\n",
      "Train Epoch: 5 [40960/50000 (91%)]\tLoss: 0.755858, Accuracy: 73.83\n",
      "Train Epoch: 5 [42240/50000 (94%)]\tLoss: 0.686147, Accuracy: 75.39\n",
      "Train Epoch: 5 [43520/50000 (97%)]\tLoss: 0.749370, Accuracy: 73.44\n",
      "Train Epoch: 5 [35000/50000 (99%)]\tLoss: 0.817995, Accuracy: 72.00\n",
      "\n",
      "Validation set: Average loss: 0.8467, Accuracy: 3485/5000 (69.00%)\n",
      "\n",
      "the time of this epoch:[37.137524366378784 s]\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.674195, Accuracy: 75.39\n",
      "Train Epoch: 6 [1280/50000 (3%)]\tLoss: 0.653373, Accuracy: 77.73\n",
      "Train Epoch: 6 [2560/50000 (6%)]\tLoss: 0.786067, Accuracy: 74.22\n",
      "Train Epoch: 6 [3840/50000 (9%)]\tLoss: 0.651057, Accuracy: 79.69\n",
      "Train Epoch: 6 [5120/50000 (11%)]\tLoss: 0.865275, Accuracy: 71.88\n",
      "Train Epoch: 6 [6400/50000 (14%)]\tLoss: 0.646114, Accuracy: 77.73\n",
      "Train Epoch: 6 [7680/50000 (17%)]\tLoss: 0.709238, Accuracy: 76.17\n",
      "Train Epoch: 6 [8960/50000 (20%)]\tLoss: 0.670643, Accuracy: 78.52\n",
      "Train Epoch: 6 [10240/50000 (23%)]\tLoss: 0.573506, Accuracy: 80.47\n",
      "Train Epoch: 6 [11520/50000 (26%)]\tLoss: 0.721262, Accuracy: 75.39\n",
      "Train Epoch: 6 [12800/50000 (28%)]\tLoss: 0.770424, Accuracy: 72.66\n",
      "Train Epoch: 6 [14080/50000 (31%)]\tLoss: 0.760949, Accuracy: 73.44\n",
      "Train Epoch: 6 [15360/50000 (34%)]\tLoss: 0.707030, Accuracy: 76.17\n",
      "Train Epoch: 6 [16640/50000 (37%)]\tLoss: 0.744936, Accuracy: 75.39\n",
      "Train Epoch: 6 [17920/50000 (40%)]\tLoss: 0.807862, Accuracy: 70.31\n",
      "Train Epoch: 6 [19200/50000 (43%)]\tLoss: 0.787037, Accuracy: 70.70\n",
      "Train Epoch: 6 [20480/50000 (45%)]\tLoss: 0.646457, Accuracy: 76.17\n",
      "Train Epoch: 6 [21760/50000 (48%)]\tLoss: 0.761196, Accuracy: 73.05\n",
      "Train Epoch: 6 [23040/50000 (51%)]\tLoss: 0.614399, Accuracy: 78.12\n",
      "Train Epoch: 6 [24320/50000 (54%)]\tLoss: 0.763668, Accuracy: 75.78\n",
      "Train Epoch: 6 [25600/50000 (57%)]\tLoss: 0.594374, Accuracy: 81.64\n",
      "Train Epoch: 6 [26880/50000 (60%)]\tLoss: 0.660153, Accuracy: 78.91\n",
      "Train Epoch: 6 [28160/50000 (62%)]\tLoss: 0.623132, Accuracy: 76.56\n",
      "Train Epoch: 6 [29440/50000 (65%)]\tLoss: 0.629875, Accuracy: 80.08\n",
      "Train Epoch: 6 [30720/50000 (68%)]\tLoss: 0.794904, Accuracy: 73.44\n",
      "Train Epoch: 6 [32000/50000 (71%)]\tLoss: 0.662888, Accuracy: 77.73\n",
      "Train Epoch: 6 [33280/50000 (74%)]\tLoss: 0.677255, Accuracy: 75.78\n",
      "Train Epoch: 6 [34560/50000 (77%)]\tLoss: 0.655946, Accuracy: 81.64\n",
      "Train Epoch: 6 [35840/50000 (80%)]\tLoss: 0.716479, Accuracy: 75.78\n",
      "Train Epoch: 6 [37120/50000 (82%)]\tLoss: 0.650738, Accuracy: 78.12\n",
      "Train Epoch: 6 [38400/50000 (85%)]\tLoss: 0.573708, Accuracy: 80.47\n",
      "Train Epoch: 6 [39680/50000 (88%)]\tLoss: 0.670505, Accuracy: 74.61\n",
      "Train Epoch: 6 [40960/50000 (91%)]\tLoss: 0.642603, Accuracy: 78.91\n",
      "Train Epoch: 6 [42240/50000 (94%)]\tLoss: 0.691841, Accuracy: 77.73\n",
      "Train Epoch: 6 [43520/50000 (97%)]\tLoss: 0.704606, Accuracy: 71.88\n",
      "Train Epoch: 6 [35000/50000 (99%)]\tLoss: 0.657208, Accuracy: 77.50\n",
      "\n",
      "Validation set: Average loss: 1.3487, Accuracy: 2809/5000 (56.00%)\n",
      "\n",
      "the time of this epoch:[37.10053110122681 s]\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.758031, Accuracy: 75.78\n",
      "Train Epoch: 7 [1280/50000 (3%)]\tLoss: 0.653439, Accuracy: 78.12\n",
      "Train Epoch: 7 [2560/50000 (6%)]\tLoss: 0.634634, Accuracy: 78.52\n",
      "Train Epoch: 7 [3840/50000 (9%)]\tLoss: 0.602946, Accuracy: 77.73\n",
      "Train Epoch: 7 [5120/50000 (11%)]\tLoss: 0.534517, Accuracy: 83.20\n",
      "Train Epoch: 7 [6400/50000 (14%)]\tLoss: 0.682349, Accuracy: 75.78\n",
      "Train Epoch: 7 [7680/50000 (17%)]\tLoss: 0.642009, Accuracy: 76.95\n",
      "Train Epoch: 7 [8960/50000 (20%)]\tLoss: 0.574187, Accuracy: 82.03\n",
      "Train Epoch: 7 [10240/50000 (23%)]\tLoss: 0.638639, Accuracy: 78.12\n",
      "Train Epoch: 7 [11520/50000 (26%)]\tLoss: 0.565714, Accuracy: 82.42\n",
      "Train Epoch: 7 [12800/50000 (28%)]\tLoss: 0.613124, Accuracy: 80.08\n",
      "Train Epoch: 7 [14080/50000 (31%)]\tLoss: 0.601473, Accuracy: 78.91\n",
      "Train Epoch: 7 [15360/50000 (34%)]\tLoss: 0.516162, Accuracy: 83.20\n",
      "Train Epoch: 7 [16640/50000 (37%)]\tLoss: 0.630867, Accuracy: 80.86\n",
      "Train Epoch: 7 [17920/50000 (40%)]\tLoss: 0.683506, Accuracy: 77.73\n",
      "Train Epoch: 7 [19200/50000 (43%)]\tLoss: 0.637928, Accuracy: 76.95\n",
      "Train Epoch: 7 [20480/50000 (45%)]\tLoss: 0.690377, Accuracy: 73.05\n",
      "Train Epoch: 7 [21760/50000 (48%)]\tLoss: 0.687125, Accuracy: 77.73\n",
      "Train Epoch: 7 [23040/50000 (51%)]\tLoss: 0.621029, Accuracy: 77.73\n",
      "Train Epoch: 7 [24320/50000 (54%)]\tLoss: 0.679829, Accuracy: 78.12\n",
      "Train Epoch: 7 [25600/50000 (57%)]\tLoss: 0.699197, Accuracy: 75.78\n",
      "Train Epoch: 7 [26880/50000 (60%)]\tLoss: 0.678442, Accuracy: 79.30\n",
      "Train Epoch: 7 [28160/50000 (62%)]\tLoss: 0.614634, Accuracy: 80.08\n",
      "Train Epoch: 7 [29440/50000 (65%)]\tLoss: 0.639554, Accuracy: 76.95\n",
      "Train Epoch: 7 [30720/50000 (68%)]\tLoss: 0.708067, Accuracy: 76.17\n",
      "Train Epoch: 7 [32000/50000 (71%)]\tLoss: 0.517009, Accuracy: 83.20\n",
      "Train Epoch: 7 [33280/50000 (74%)]\tLoss: 0.581199, Accuracy: 78.12\n",
      "Train Epoch: 7 [34560/50000 (77%)]\tLoss: 0.633241, Accuracy: 81.25\n",
      "Train Epoch: 7 [35840/50000 (80%)]\tLoss: 0.591418, Accuracy: 77.73\n",
      "Train Epoch: 7 [37120/50000 (82%)]\tLoss: 0.548549, Accuracy: 81.64\n",
      "Train Epoch: 7 [38400/50000 (85%)]\tLoss: 0.694837, Accuracy: 76.56\n",
      "Train Epoch: 7 [39680/50000 (88%)]\tLoss: 0.713700, Accuracy: 74.61\n",
      "Train Epoch: 7 [40960/50000 (91%)]\tLoss: 0.728209, Accuracy: 72.66\n",
      "Train Epoch: 7 [42240/50000 (94%)]\tLoss: 0.665178, Accuracy: 77.73\n",
      "Train Epoch: 7 [43520/50000 (97%)]\tLoss: 0.560255, Accuracy: 80.47\n",
      "Train Epoch: 7 [35000/50000 (99%)]\tLoss: 0.712185, Accuracy: 74.00\n",
      "\n",
      "Validation set: Average loss: 0.7956, Accuracy: 3640/5000 (72.00%)\n",
      "\n",
      "the time of this epoch:[37.138898611068726 s]\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.693091, Accuracy: 76.56\n",
      "Train Epoch: 8 [1280/50000 (3%)]\tLoss: 0.646019, Accuracy: 76.95\n",
      "Train Epoch: 8 [2560/50000 (6%)]\tLoss: 0.574813, Accuracy: 83.59\n",
      "Train Epoch: 8 [3840/50000 (9%)]\tLoss: 0.599441, Accuracy: 81.25\n",
      "Train Epoch: 8 [5120/50000 (11%)]\tLoss: 0.633287, Accuracy: 78.12\n",
      "Train Epoch: 8 [6400/50000 (14%)]\tLoss: 0.563048, Accuracy: 82.03\n",
      "Train Epoch: 8 [7680/50000 (17%)]\tLoss: 0.529508, Accuracy: 81.25\n",
      "Train Epoch: 8 [8960/50000 (20%)]\tLoss: 0.719579, Accuracy: 79.69\n",
      "Train Epoch: 8 [10240/50000 (23%)]\tLoss: 0.604484, Accuracy: 79.30\n",
      "Train Epoch: 8 [11520/50000 (26%)]\tLoss: 0.533166, Accuracy: 80.86\n",
      "Train Epoch: 8 [12800/50000 (28%)]\tLoss: 0.646395, Accuracy: 77.34\n",
      "Train Epoch: 8 [14080/50000 (31%)]\tLoss: 0.652838, Accuracy: 77.73\n",
      "Train Epoch: 8 [15360/50000 (34%)]\tLoss: 0.634551, Accuracy: 81.64\n",
      "Train Epoch: 8 [16640/50000 (37%)]\tLoss: 0.537931, Accuracy: 82.03\n",
      "Train Epoch: 8 [17920/50000 (40%)]\tLoss: 0.627058, Accuracy: 77.73\n",
      "Train Epoch: 8 [19200/50000 (43%)]\tLoss: 0.622257, Accuracy: 79.69\n",
      "Train Epoch: 8 [20480/50000 (45%)]\tLoss: 0.657566, Accuracy: 76.17\n",
      "Train Epoch: 8 [21760/50000 (48%)]\tLoss: 0.565237, Accuracy: 83.20\n",
      "Train Epoch: 8 [23040/50000 (51%)]\tLoss: 0.641374, Accuracy: 76.17\n",
      "Train Epoch: 8 [24320/50000 (54%)]\tLoss: 0.571143, Accuracy: 79.30\n",
      "Train Epoch: 8 [25600/50000 (57%)]\tLoss: 0.621955, Accuracy: 78.91\n",
      "Train Epoch: 8 [26880/50000 (60%)]\tLoss: 0.646547, Accuracy: 79.69\n",
      "Train Epoch: 8 [28160/50000 (62%)]\tLoss: 0.569233, Accuracy: 82.42\n",
      "Train Epoch: 8 [29440/50000 (65%)]\tLoss: 0.744318, Accuracy: 73.83\n",
      "Train Epoch: 8 [30720/50000 (68%)]\tLoss: 0.670593, Accuracy: 76.17\n",
      "Train Epoch: 8 [32000/50000 (71%)]\tLoss: 0.633802, Accuracy: 78.12\n",
      "Train Epoch: 8 [33280/50000 (74%)]\tLoss: 0.588112, Accuracy: 79.30\n",
      "Train Epoch: 8 [34560/50000 (77%)]\tLoss: 0.681263, Accuracy: 76.17\n",
      "Train Epoch: 8 [35840/50000 (80%)]\tLoss: 0.514549, Accuracy: 81.64\n",
      "Train Epoch: 8 [37120/50000 (82%)]\tLoss: 0.584124, Accuracy: 81.25\n",
      "Train Epoch: 8 [38400/50000 (85%)]\tLoss: 0.610157, Accuracy: 77.34\n",
      "Train Epoch: 8 [39680/50000 (88%)]\tLoss: 0.662845, Accuracy: 77.34\n",
      "Train Epoch: 8 [40960/50000 (91%)]\tLoss: 0.487258, Accuracy: 85.16\n",
      "Train Epoch: 8 [42240/50000 (94%)]\tLoss: 0.589427, Accuracy: 78.12\n",
      "Train Epoch: 8 [43520/50000 (97%)]\tLoss: 0.662502, Accuracy: 77.34\n",
      "Train Epoch: 8 [35000/50000 (99%)]\tLoss: 0.610096, Accuracy: 78.50\n",
      "\n",
      "Validation set: Average loss: 0.7405, Accuracy: 3740/5000 (74.00%)\n",
      "\n",
      "the time of this epoch:[37.089364767074585 s]\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.758657, Accuracy: 73.05\n",
      "Train Epoch: 9 [1280/50000 (3%)]\tLoss: 0.609030, Accuracy: 82.03\n",
      "Train Epoch: 9 [2560/50000 (6%)]\tLoss: 0.658737, Accuracy: 77.73\n",
      "Train Epoch: 9 [3840/50000 (9%)]\tLoss: 0.520895, Accuracy: 79.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [5120/50000 (11%)]\tLoss: 0.605156, Accuracy: 77.34\n",
      "Train Epoch: 9 [6400/50000 (14%)]\tLoss: 0.582304, Accuracy: 78.52\n",
      "Train Epoch: 9 [7680/50000 (17%)]\tLoss: 0.546707, Accuracy: 78.91\n",
      "Train Epoch: 9 [8960/50000 (20%)]\tLoss: 0.652473, Accuracy: 77.73\n",
      "Train Epoch: 9 [10240/50000 (23%)]\tLoss: 0.666497, Accuracy: 78.12\n",
      "Train Epoch: 9 [11520/50000 (26%)]\tLoss: 0.583656, Accuracy: 78.91\n",
      "Train Epoch: 9 [12800/50000 (28%)]\tLoss: 0.655082, Accuracy: 78.91\n",
      "Train Epoch: 9 [14080/50000 (31%)]\tLoss: 0.556977, Accuracy: 81.25\n",
      "Train Epoch: 9 [15360/50000 (34%)]\tLoss: 0.603689, Accuracy: 79.69\n",
      "Train Epoch: 9 [16640/50000 (37%)]\tLoss: 0.662443, Accuracy: 80.08\n",
      "Train Epoch: 9 [17920/50000 (40%)]\tLoss: 0.624766, Accuracy: 77.34\n",
      "Train Epoch: 9 [19200/50000 (43%)]\tLoss: 0.509140, Accuracy: 80.47\n",
      "Train Epoch: 9 [20480/50000 (45%)]\tLoss: 0.600016, Accuracy: 79.69\n",
      "Train Epoch: 9 [21760/50000 (48%)]\tLoss: 0.609634, Accuracy: 78.91\n",
      "Train Epoch: 9 [23040/50000 (51%)]\tLoss: 0.531410, Accuracy: 82.81\n",
      "Train Epoch: 9 [24320/50000 (54%)]\tLoss: 0.544114, Accuracy: 82.42\n",
      "Train Epoch: 9 [25600/50000 (57%)]\tLoss: 0.567744, Accuracy: 80.86\n",
      "Train Epoch: 9 [26880/50000 (60%)]\tLoss: 0.619077, Accuracy: 78.12\n",
      "Train Epoch: 9 [28160/50000 (62%)]\tLoss: 0.563320, Accuracy: 81.25\n",
      "Train Epoch: 9 [29440/50000 (65%)]\tLoss: 0.560699, Accuracy: 81.25\n",
      "Train Epoch: 9 [30720/50000 (68%)]\tLoss: 0.647812, Accuracy: 78.52\n",
      "Train Epoch: 9 [32000/50000 (71%)]\tLoss: 0.586865, Accuracy: 78.52\n",
      "Train Epoch: 9 [33280/50000 (74%)]\tLoss: 0.482363, Accuracy: 84.77\n",
      "Train Epoch: 9 [34560/50000 (77%)]\tLoss: 0.435857, Accuracy: 88.67\n",
      "Train Epoch: 9 [35840/50000 (80%)]\tLoss: 0.521927, Accuracy: 81.64\n",
      "Train Epoch: 9 [37120/50000 (82%)]\tLoss: 0.516145, Accuracy: 85.55\n",
      "Train Epoch: 9 [38400/50000 (85%)]\tLoss: 0.535732, Accuracy: 82.81\n",
      "Train Epoch: 9 [39680/50000 (88%)]\tLoss: 0.628688, Accuracy: 79.69\n",
      "Train Epoch: 9 [40960/50000 (91%)]\tLoss: 0.625001, Accuracy: 76.95\n",
      "Train Epoch: 9 [42240/50000 (94%)]\tLoss: 0.596672, Accuracy: 81.25\n",
      "Train Epoch: 9 [43520/50000 (97%)]\tLoss: 0.648938, Accuracy: 78.12\n",
      "Train Epoch: 9 [35000/50000 (99%)]\tLoss: 0.575141, Accuracy: 79.50\n",
      "\n",
      "Validation set: Average loss: 0.6955, Accuracy: 3849/5000 (76.00%)\n",
      "\n",
      "the time of this epoch:[37.11281633377075 s]\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.618044, Accuracy: 78.52\n",
      "Train Epoch: 10 [1280/50000 (3%)]\tLoss: 0.642195, Accuracy: 80.08\n",
      "Train Epoch: 10 [2560/50000 (6%)]\tLoss: 0.517571, Accuracy: 81.25\n",
      "Train Epoch: 10 [3840/50000 (9%)]\tLoss: 0.610334, Accuracy: 80.08\n",
      "Train Epoch: 10 [5120/50000 (11%)]\tLoss: 0.488687, Accuracy: 81.64\n",
      "Train Epoch: 10 [6400/50000 (14%)]\tLoss: 0.510778, Accuracy: 83.20\n",
      "Train Epoch: 10 [7680/50000 (17%)]\tLoss: 0.603695, Accuracy: 80.47\n",
      "Train Epoch: 10 [8960/50000 (20%)]\tLoss: 0.521379, Accuracy: 82.81\n",
      "Train Epoch: 10 [10240/50000 (23%)]\tLoss: 0.730906, Accuracy: 76.56\n",
      "Train Epoch: 10 [11520/50000 (26%)]\tLoss: 0.477786, Accuracy: 83.98\n",
      "Train Epoch: 10 [12800/50000 (28%)]\tLoss: 0.475909, Accuracy: 84.38\n",
      "Train Epoch: 10 [14080/50000 (31%)]\tLoss: 0.515163, Accuracy: 83.59\n",
      "Train Epoch: 10 [15360/50000 (34%)]\tLoss: 0.531203, Accuracy: 79.69\n",
      "Train Epoch: 10 [16640/50000 (37%)]\tLoss: 0.651556, Accuracy: 77.73\n",
      "Train Epoch: 10 [17920/50000 (40%)]\tLoss: 0.594913, Accuracy: 81.25\n",
      "Train Epoch: 10 [19200/50000 (43%)]\tLoss: 0.616238, Accuracy: 77.73\n",
      "Train Epoch: 10 [20480/50000 (45%)]\tLoss: 0.626548, Accuracy: 78.52\n",
      "Train Epoch: 10 [21760/50000 (48%)]\tLoss: 0.569122, Accuracy: 80.47\n",
      "Train Epoch: 10 [23040/50000 (51%)]\tLoss: 0.750074, Accuracy: 75.39\n",
      "Train Epoch: 10 [24320/50000 (54%)]\tLoss: 0.487163, Accuracy: 82.81\n",
      "Train Epoch: 10 [25600/50000 (57%)]\tLoss: 0.518171, Accuracy: 83.20\n",
      "Train Epoch: 10 [26880/50000 (60%)]\tLoss: 0.558365, Accuracy: 80.47\n",
      "Train Epoch: 10 [28160/50000 (62%)]\tLoss: 0.499026, Accuracy: 84.77\n",
      "Train Epoch: 10 [29440/50000 (65%)]\tLoss: 0.603082, Accuracy: 78.52\n",
      "Train Epoch: 10 [30720/50000 (68%)]\tLoss: 0.584477, Accuracy: 79.69\n",
      "Train Epoch: 10 [32000/50000 (71%)]\tLoss: 0.683343, Accuracy: 77.73\n",
      "Train Epoch: 10 [33280/50000 (74%)]\tLoss: 0.555467, Accuracy: 80.47\n",
      "Train Epoch: 10 [34560/50000 (77%)]\tLoss: 0.555445, Accuracy: 80.08\n",
      "Train Epoch: 10 [35840/50000 (80%)]\tLoss: 0.618574, Accuracy: 78.91\n",
      "Train Epoch: 10 [37120/50000 (82%)]\tLoss: 0.591425, Accuracy: 81.25\n",
      "Train Epoch: 10 [38400/50000 (85%)]\tLoss: 0.530539, Accuracy: 81.25\n",
      "Train Epoch: 10 [39680/50000 (88%)]\tLoss: 0.586651, Accuracy: 79.30\n",
      "Train Epoch: 10 [40960/50000 (91%)]\tLoss: 0.651612, Accuracy: 80.47\n",
      "Train Epoch: 10 [42240/50000 (94%)]\tLoss: 0.409351, Accuracy: 86.72\n",
      "Train Epoch: 10 [43520/50000 (97%)]\tLoss: 0.611337, Accuracy: 78.91\n",
      "Train Epoch: 10 [35000/50000 (99%)]\tLoss: 0.538681, Accuracy: 84.00\n",
      "\n",
      "Validation set: Average loss: 0.7240, Accuracy: 3750/5000 (75.00%)\n",
      "\n",
      "the time of this epoch:[37.1572802066803 s]\n",
      "\n",
      "Test set: Average loss: 0.7277, Accuracy: 7530/10000 (75.30%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.587358, Accuracy: 81.64\n",
      "Train Epoch: 11 [1280/50000 (3%)]\tLoss: 0.493064, Accuracy: 82.03\n",
      "Train Epoch: 11 [2560/50000 (6%)]\tLoss: 0.402346, Accuracy: 86.33\n",
      "Train Epoch: 11 [3840/50000 (9%)]\tLoss: 0.548423, Accuracy: 80.08\n",
      "Train Epoch: 11 [5120/50000 (11%)]\tLoss: 0.673746, Accuracy: 76.95\n",
      "Train Epoch: 11 [6400/50000 (14%)]\tLoss: 0.571758, Accuracy: 81.25\n",
      "Train Epoch: 11 [7680/50000 (17%)]\tLoss: 0.524735, Accuracy: 80.86\n",
      "Train Epoch: 11 [8960/50000 (20%)]\tLoss: 0.547496, Accuracy: 83.20\n",
      "Train Epoch: 11 [10240/50000 (23%)]\tLoss: 0.501488, Accuracy: 83.59\n",
      "Train Epoch: 11 [11520/50000 (26%)]\tLoss: 0.522829, Accuracy: 81.25\n",
      "Train Epoch: 11 [12800/50000 (28%)]\tLoss: 0.621061, Accuracy: 80.08\n",
      "Train Epoch: 11 [14080/50000 (31%)]\tLoss: 0.526250, Accuracy: 82.03\n",
      "Train Epoch: 11 [15360/50000 (34%)]\tLoss: 0.526425, Accuracy: 82.42\n",
      "Train Epoch: 11 [16640/50000 (37%)]\tLoss: 0.410854, Accuracy: 85.94\n",
      "Train Epoch: 11 [17920/50000 (40%)]\tLoss: 0.517370, Accuracy: 83.20\n",
      "Train Epoch: 11 [19200/50000 (43%)]\tLoss: 0.604446, Accuracy: 80.47\n",
      "Train Epoch: 11 [20480/50000 (45%)]\tLoss: 0.530824, Accuracy: 82.03\n",
      "Train Epoch: 11 [21760/50000 (48%)]\tLoss: 0.537512, Accuracy: 83.59\n",
      "Train Epoch: 11 [23040/50000 (51%)]\tLoss: 0.455557, Accuracy: 86.33\n",
      "Train Epoch: 11 [24320/50000 (54%)]\tLoss: 0.614653, Accuracy: 80.08\n",
      "Train Epoch: 11 [25600/50000 (57%)]\tLoss: 0.554050, Accuracy: 80.47\n",
      "Train Epoch: 11 [26880/50000 (60%)]\tLoss: 0.552616, Accuracy: 82.42\n",
      "Train Epoch: 11 [28160/50000 (62%)]\tLoss: 0.511886, Accuracy: 81.64\n",
      "Train Epoch: 11 [29440/50000 (65%)]\tLoss: 0.526840, Accuracy: 82.03\n",
      "Train Epoch: 11 [30720/50000 (68%)]\tLoss: 0.471258, Accuracy: 84.38\n",
      "Train Epoch: 11 [32000/50000 (71%)]\tLoss: 0.528509, Accuracy: 81.25\n",
      "Train Epoch: 11 [33280/50000 (74%)]\tLoss: 0.597121, Accuracy: 77.34\n",
      "Train Epoch: 11 [34560/50000 (77%)]\tLoss: 0.487343, Accuracy: 83.20\n",
      "Train Epoch: 11 [35840/50000 (80%)]\tLoss: 0.542118, Accuracy: 81.64\n",
      "Train Epoch: 11 [37120/50000 (82%)]\tLoss: 0.606523, Accuracy: 78.91\n",
      "Train Epoch: 11 [38400/50000 (85%)]\tLoss: 0.546949, Accuracy: 83.98\n",
      "Train Epoch: 11 [39680/50000 (88%)]\tLoss: 0.526306, Accuracy: 82.03\n",
      "Train Epoch: 11 [40960/50000 (91%)]\tLoss: 0.672645, Accuracy: 79.69\n",
      "Train Epoch: 11 [42240/50000 (94%)]\tLoss: 0.491464, Accuracy: 82.81\n",
      "Train Epoch: 11 [43520/50000 (97%)]\tLoss: 0.648517, Accuracy: 78.52\n",
      "Train Epoch: 11 [35000/50000 (99%)]\tLoss: 0.530229, Accuracy: 81.50\n",
      "\n",
      "Validation set: Average loss: 0.7245, Accuracy: 3808/5000 (76.00%)\n",
      "\n",
      "the time of this epoch:[40.32056951522827 s]\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.481034, Accuracy: 83.59\n",
      "Train Epoch: 12 [1280/50000 (3%)]\tLoss: 0.542752, Accuracy: 82.03\n",
      "Train Epoch: 12 [2560/50000 (6%)]\tLoss: 0.446708, Accuracy: 84.38\n",
      "Train Epoch: 12 [3840/50000 (9%)]\tLoss: 0.595349, Accuracy: 80.86\n",
      "Train Epoch: 12 [5120/50000 (11%)]\tLoss: 0.478007, Accuracy: 83.20\n",
      "Train Epoch: 12 [6400/50000 (14%)]\tLoss: 0.507554, Accuracy: 80.86\n",
      "Train Epoch: 12 [7680/50000 (17%)]\tLoss: 0.441891, Accuracy: 84.77\n",
      "Train Epoch: 12 [8960/50000 (20%)]\tLoss: 0.526100, Accuracy: 83.20\n",
      "Train Epoch: 12 [10240/50000 (23%)]\tLoss: 0.591859, Accuracy: 78.91\n",
      "Train Epoch: 12 [11520/50000 (26%)]\tLoss: 0.434441, Accuracy: 84.77\n",
      "Train Epoch: 12 [12800/50000 (28%)]\tLoss: 0.425118, Accuracy: 86.33\n",
      "Train Epoch: 12 [14080/50000 (31%)]\tLoss: 0.465924, Accuracy: 83.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [15360/50000 (34%)]\tLoss: 0.463897, Accuracy: 81.25\n",
      "Train Epoch: 12 [16640/50000 (37%)]\tLoss: 0.530624, Accuracy: 82.03\n",
      "Train Epoch: 12 [17920/50000 (40%)]\tLoss: 0.525829, Accuracy: 80.86\n",
      "Train Epoch: 12 [19200/50000 (43%)]\tLoss: 0.556878, Accuracy: 82.03\n",
      "Train Epoch: 12 [20480/50000 (45%)]\tLoss: 0.492058, Accuracy: 81.64\n",
      "Train Epoch: 12 [21760/50000 (48%)]\tLoss: 0.554443, Accuracy: 82.03\n",
      "Train Epoch: 12 [23040/50000 (51%)]\tLoss: 0.437036, Accuracy: 86.33\n",
      "Train Epoch: 12 [24320/50000 (54%)]\tLoss: 0.525989, Accuracy: 80.86\n",
      "Train Epoch: 12 [25600/50000 (57%)]\tLoss: 0.603295, Accuracy: 81.25\n",
      "Train Epoch: 12 [26880/50000 (60%)]\tLoss: 0.594421, Accuracy: 82.81\n",
      "torch.Size([512, 1, 1])\n",
      "tensor([[[ 1.0249e+00]],\n",
      "\n",
      "        [[ 2.4982e-01]],\n",
      "\n",
      "        [[ 6.7892e-01]],\n",
      "\n",
      "        [[ 2.0729e+00]],\n",
      "\n",
      "        [[ 3.4217e-02]],\n",
      "\n",
      "        [[-1.5033e+00]],\n",
      "\n",
      "        [[-2.3495e-01]],\n",
      "\n",
      "        [[-2.1329e-01]],\n",
      "\n",
      "        [[-8.8490e-01]],\n",
      "\n",
      "        [[-5.0810e-01]],\n",
      "\n",
      "        [[-1.5447e+00]],\n",
      "\n",
      "        [[-8.2947e-02]],\n",
      "\n",
      "        [[-5.3878e-01]],\n",
      "\n",
      "        [[ 3.2644e-02]],\n",
      "\n",
      "        [[-5.9891e-01]],\n",
      "\n",
      "        [[-1.1378e+00]],\n",
      "\n",
      "        [[ 9.3449e-02]],\n",
      "\n",
      "        [[ 8.5870e-01]],\n",
      "\n",
      "        [[ 7.8542e-01]],\n",
      "\n",
      "        [[-2.5657e-01]],\n",
      "\n",
      "        [[-6.2626e-01]],\n",
      "\n",
      "        [[-1.6045e-02]],\n",
      "\n",
      "        [[ 1.9980e+00]],\n",
      "\n",
      "        [[ 6.9105e-01]],\n",
      "\n",
      "        [[ 1.0323e-01]],\n",
      "\n",
      "        [[-4.0352e-01]],\n",
      "\n",
      "        [[-8.3220e-01]],\n",
      "\n",
      "        [[ 3.9085e-01]],\n",
      "\n",
      "        [[-1.2140e+00]],\n",
      "\n",
      "        [[-3.0995e-01]],\n",
      "\n",
      "        [[ 2.7756e-01]],\n",
      "\n",
      "        [[-1.1132e+00]],\n",
      "\n",
      "        [[ 8.3117e-01]],\n",
      "\n",
      "        [[-1.3078e+00]],\n",
      "\n",
      "        [[ 9.0584e-03]],\n",
      "\n",
      "        [[-1.2219e+00]],\n",
      "\n",
      "        [[-1.2087e+00]],\n",
      "\n",
      "        [[ 4.4567e-01]],\n",
      "\n",
      "        [[-5.1761e-01]],\n",
      "\n",
      "        [[ 3.4407e-01]],\n",
      "\n",
      "        [[-7.3205e-01]],\n",
      "\n",
      "        [[-7.1501e-01]],\n",
      "\n",
      "        [[ 6.6953e-02]],\n",
      "\n",
      "        [[ 1.3391e-01]],\n",
      "\n",
      "        [[ 2.3172e+00]],\n",
      "\n",
      "        [[ 7.7933e-01]],\n",
      "\n",
      "        [[-3.6777e-02]],\n",
      "\n",
      "        [[-5.8994e-01]],\n",
      "\n",
      "        [[ 1.3288e+00]],\n",
      "\n",
      "        [[-3.9679e-01]],\n",
      "\n",
      "        [[-9.2450e-01]],\n",
      "\n",
      "        [[ 1.1384e+00]],\n",
      "\n",
      "        [[-5.5630e-01]],\n",
      "\n",
      "        [[-3.9365e-01]],\n",
      "\n",
      "        [[ 4.4635e-01]],\n",
      "\n",
      "        [[-3.1177e-01]],\n",
      "\n",
      "        [[ 4.6528e-01]],\n",
      "\n",
      "        [[ 4.4134e-01]],\n",
      "\n",
      "        [[-1.9067e+00]],\n",
      "\n",
      "        [[-1.1123e+00]],\n",
      "\n",
      "        [[-1.9539e-01]],\n",
      "\n",
      "        [[ 1.0404e+00]],\n",
      "\n",
      "        [[-4.4339e-01]],\n",
      "\n",
      "        [[ 1.7765e+00]],\n",
      "\n",
      "        [[-3.5155e-01]],\n",
      "\n",
      "        [[ 1.4110e+00]],\n",
      "\n",
      "        [[ 1.5003e-01]],\n",
      "\n",
      "        [[-1.4642e+00]],\n",
      "\n",
      "        [[ 1.0450e+00]],\n",
      "\n",
      "        [[ 6.0544e-01]],\n",
      "\n",
      "        [[-7.8746e-01]],\n",
      "\n",
      "        [[-1.0174e+00]],\n",
      "\n",
      "        [[ 7.8191e-01]],\n",
      "\n",
      "        [[-2.0814e-02]],\n",
      "\n",
      "        [[-2.2728e-01]],\n",
      "\n",
      "        [[ 4.1635e-01]],\n",
      "\n",
      "        [[ 1.1541e+00]],\n",
      "\n",
      "        [[-1.7264e-01]],\n",
      "\n",
      "        [[ 4.3663e-01]],\n",
      "\n",
      "        [[ 4.9926e-02]],\n",
      "\n",
      "        [[-9.5575e-02]],\n",
      "\n",
      "        [[-8.5583e-01]],\n",
      "\n",
      "        [[-5.8395e-01]],\n",
      "\n",
      "        [[ 7.9149e-01]],\n",
      "\n",
      "        [[-5.4569e-01]],\n",
      "\n",
      "        [[-9.3282e-01]],\n",
      "\n",
      "        [[-1.0885e+00]],\n",
      "\n",
      "        [[-3.3226e-01]],\n",
      "\n",
      "        [[ 1.0015e+00]],\n",
      "\n",
      "        [[-6.2583e-02]],\n",
      "\n",
      "        [[ 2.7149e-01]],\n",
      "\n",
      "        [[ 8.4035e-01]],\n",
      "\n",
      "        [[ 5.0986e-01]],\n",
      "\n",
      "        [[ 1.7137e+00]],\n",
      "\n",
      "        [[-5.7148e-01]],\n",
      "\n",
      "        [[-8.7198e-01]],\n",
      "\n",
      "        [[-1.8198e+00]],\n",
      "\n",
      "        [[-8.0815e-01]],\n",
      "\n",
      "        [[ 1.3187e+00]],\n",
      "\n",
      "        [[-9.0419e-01]],\n",
      "\n",
      "        [[-1.0657e+00]],\n",
      "\n",
      "        [[ 1.1481e+00]],\n",
      "\n",
      "        [[-1.7780e+00]],\n",
      "\n",
      "        [[ 9.3111e-01]],\n",
      "\n",
      "        [[ 2.2263e-01]],\n",
      "\n",
      "        [[-1.4634e+00]],\n",
      "\n",
      "        [[ 9.0442e-01]],\n",
      "\n",
      "        [[ 1.1256e+00]],\n",
      "\n",
      "        [[-7.8380e-01]],\n",
      "\n",
      "        [[ 3.9035e-01]],\n",
      "\n",
      "        [[-8.1591e-01]],\n",
      "\n",
      "        [[-9.9993e-02]],\n",
      "\n",
      "        [[-1.5925e-01]],\n",
      "\n",
      "        [[ 5.8833e-01]],\n",
      "\n",
      "        [[ 4.6388e-01]],\n",
      "\n",
      "        [[ 1.2247e-01]],\n",
      "\n",
      "        [[ 8.1178e-01]],\n",
      "\n",
      "        [[ 1.1035e+00]],\n",
      "\n",
      "        [[-1.2419e+00]],\n",
      "\n",
      "        [[-1.7147e+00]],\n",
      "\n",
      "        [[ 4.9170e-01]],\n",
      "\n",
      "        [[ 3.0700e-01]],\n",
      "\n",
      "        [[ 4.8424e-01]],\n",
      "\n",
      "        [[-5.2297e-02]],\n",
      "\n",
      "        [[-9.7313e-02]],\n",
      "\n",
      "        [[ 1.7206e-01]],\n",
      "\n",
      "        [[ 1.0957e+00]],\n",
      "\n",
      "        [[ 9.2432e-01]],\n",
      "\n",
      "        [[ 2.7122e-01]],\n",
      "\n",
      "        [[-1.1953e+00]],\n",
      "\n",
      "        [[ 8.5025e-01]],\n",
      "\n",
      "        [[ 1.4382e-01]],\n",
      "\n",
      "        [[-1.7699e+00]],\n",
      "\n",
      "        [[ 8.6932e-02]],\n",
      "\n",
      "        [[-1.9928e+00]],\n",
      "\n",
      "        [[-6.4478e-01]],\n",
      "\n",
      "        [[-8.7707e-01]],\n",
      "\n",
      "        [[-1.3509e+00]],\n",
      "\n",
      "        [[-4.9563e-01]],\n",
      "\n",
      "        [[ 1.0225e+00]],\n",
      "\n",
      "        [[ 6.1946e-01]],\n",
      "\n",
      "        [[-6.9861e-01]],\n",
      "\n",
      "        [[-8.9717e-01]],\n",
      "\n",
      "        [[ 7.1987e-01]],\n",
      "\n",
      "        [[-2.1807e+00]],\n",
      "\n",
      "        [[ 5.1731e-01]],\n",
      "\n",
      "        [[ 1.8187e+00]],\n",
      "\n",
      "        [[-4.0478e-01]],\n",
      "\n",
      "        [[-1.2492e+00]],\n",
      "\n",
      "        [[ 1.0957e-01]],\n",
      "\n",
      "        [[-3.8152e-01]],\n",
      "\n",
      "        [[-1.3263e-01]],\n",
      "\n",
      "        [[ 3.0490e-01]],\n",
      "\n",
      "        [[-1.4948e+00]],\n",
      "\n",
      "        [[-1.0847e+00]],\n",
      "\n",
      "        [[-6.8614e-01]],\n",
      "\n",
      "        [[ 1.5476e+00]],\n",
      "\n",
      "        [[-2.7927e-01]],\n",
      "\n",
      "        [[ 1.2780e+00]],\n",
      "\n",
      "        [[-2.6160e-01]],\n",
      "\n",
      "        [[ 7.5798e-01]],\n",
      "\n",
      "        [[-4.6510e-01]],\n",
      "\n",
      "        [[ 3.6670e-01]],\n",
      "\n",
      "        [[ 7.9145e-01]],\n",
      "\n",
      "        [[ 1.3755e+00]],\n",
      "\n",
      "        [[-1.1322e+00]],\n",
      "\n",
      "        [[-6.5762e-01]],\n",
      "\n",
      "        [[-1.0645e+00]],\n",
      "\n",
      "        [[ 2.5038e+00]],\n",
      "\n",
      "        [[ 1.6877e-01]],\n",
      "\n",
      "        [[ 2.0444e+00]],\n",
      "\n",
      "        [[ 7.4374e-01]],\n",
      "\n",
      "        [[-2.1097e-02]],\n",
      "\n",
      "        [[-9.8060e-01]],\n",
      "\n",
      "        [[-7.0953e-01]],\n",
      "\n",
      "        [[ 1.0644e+00]],\n",
      "\n",
      "        [[ 1.7875e+00]],\n",
      "\n",
      "        [[ 2.3721e-01]],\n",
      "\n",
      "        [[ 1.1468e+00]],\n",
      "\n",
      "        [[-1.5373e+00]],\n",
      "\n",
      "        [[ 1.4473e+00]],\n",
      "\n",
      "        [[-1.5370e+00]],\n",
      "\n",
      "        [[ 1.2468e+00]],\n",
      "\n",
      "        [[-3.0407e-01]],\n",
      "\n",
      "        [[-5.3740e-01]],\n",
      "\n",
      "        [[ 8.4939e-01]],\n",
      "\n",
      "        [[ 1.4037e+00]],\n",
      "\n",
      "        [[-1.5438e+00]],\n",
      "\n",
      "        [[ 2.1010e-01]],\n",
      "\n",
      "        [[ 1.5882e+00]],\n",
      "\n",
      "        [[ 1.2786e+00]],\n",
      "\n",
      "        [[ 1.6062e+00]],\n",
      "\n",
      "        [[-2.5410e-01]],\n",
      "\n",
      "        [[-3.7712e-01]],\n",
      "\n",
      "        [[ 4.7092e-01]],\n",
      "\n",
      "        [[-4.2478e-01]],\n",
      "\n",
      "        [[-1.4732e-01]],\n",
      "\n",
      "        [[ 2.0748e+00]],\n",
      "\n",
      "        [[ 9.8921e-01]],\n",
      "\n",
      "        [[ 4.8669e-01]],\n",
      "\n",
      "        [[ 5.1335e-01]],\n",
      "\n",
      "        [[ 6.3405e-01]],\n",
      "\n",
      "        [[-3.0591e-02]],\n",
      "\n",
      "        [[ 1.4492e+00]],\n",
      "\n",
      "        [[ 2.0460e-02]],\n",
      "\n",
      "        [[ 1.5964e+00]],\n",
      "\n",
      "        [[ 2.8732e-01]],\n",
      "\n",
      "        [[ 8.7308e-01]],\n",
      "\n",
      "        [[-4.0180e-01]],\n",
      "\n",
      "        [[ 2.1291e-01]],\n",
      "\n",
      "        [[-6.3017e-01]],\n",
      "\n",
      "        [[ 4.7892e-01]],\n",
      "\n",
      "        [[ 1.6859e-01]],\n",
      "\n",
      "        [[ 8.0159e-01]],\n",
      "\n",
      "        [[ 1.6577e+00]],\n",
      "\n",
      "        [[ 8.5522e-01]],\n",
      "\n",
      "        [[ 6.0655e-01]],\n",
      "\n",
      "        [[-1.2290e+00]],\n",
      "\n",
      "        [[ 7.3070e-01]],\n",
      "\n",
      "        [[ 7.1066e-02]],\n",
      "\n",
      "        [[-1.3148e-01]],\n",
      "\n",
      "        [[-1.7453e+00]],\n",
      "\n",
      "        [[-2.3615e+00]],\n",
      "\n",
      "        [[ 9.0792e-01]],\n",
      "\n",
      "        [[ 9.6748e-01]],\n",
      "\n",
      "        [[-1.1701e-01]],\n",
      "\n",
      "        [[-3.3477e-01]],\n",
      "\n",
      "        [[ 1.0198e+00]],\n",
      "\n",
      "        [[-2.4453e-01]],\n",
      "\n",
      "        [[-1.4896e-01]],\n",
      "\n",
      "        [[ 2.9723e-01]],\n",
      "\n",
      "        [[ 2.8565e+00]],\n",
      "\n",
      "        [[ 1.0972e+00]],\n",
      "\n",
      "        [[-9.4285e-01]],\n",
      "\n",
      "        [[ 6.5133e-01]],\n",
      "\n",
      "        [[-3.4024e-01]],\n",
      "\n",
      "        [[ 6.2933e-01]],\n",
      "\n",
      "        [[-1.0133e+00]],\n",
      "\n",
      "        [[ 5.8014e-01]],\n",
      "\n",
      "        [[-6.0327e-01]],\n",
      "\n",
      "        [[ 1.6227e+00]],\n",
      "\n",
      "        [[-9.8122e-01]],\n",
      "\n",
      "        [[-9.5008e-01]],\n",
      "\n",
      "        [[ 1.3232e+00]],\n",
      "\n",
      "        [[-2.2876e-01]],\n",
      "\n",
      "        [[ 1.5666e-01]],\n",
      "\n",
      "        [[ 2.1965e-01]],\n",
      "\n",
      "        [[-1.5274e+00]],\n",
      "\n",
      "        [[-4.9706e-01]],\n",
      "\n",
      "        [[-7.2608e-01]],\n",
      "\n",
      "        [[ 3.1856e-05]],\n",
      "\n",
      "        [[ 7.0579e-01]],\n",
      "\n",
      "        [[-9.8884e-02]],\n",
      "\n",
      "        [[ 4.4080e-01]],\n",
      "\n",
      "        [[ 4.3032e-01]],\n",
      "\n",
      "        [[-3.5627e-01]],\n",
      "\n",
      "        [[ 7.0237e-01]],\n",
      "\n",
      "        [[ 8.3691e-01]],\n",
      "\n",
      "        [[ 1.1267e-01]],\n",
      "\n",
      "        [[ 5.8948e-01]],\n",
      "\n",
      "        [[ 8.6212e-01]],\n",
      "\n",
      "        [[-1.0075e-01]],\n",
      "\n",
      "        [[-9.0662e-01]],\n",
      "\n",
      "        [[-2.6843e-01]],\n",
      "\n",
      "        [[ 1.4707e+00]],\n",
      "\n",
      "        [[ 6.1366e-01]],\n",
      "\n",
      "        [[-1.3275e-02]],\n",
      "\n",
      "        [[-8.3719e-02]],\n",
      "\n",
      "        [[-3.0849e-01]],\n",
      "\n",
      "        [[-1.1016e+00]],\n",
      "\n",
      "        [[-9.0193e-01]],\n",
      "\n",
      "        [[-8.3363e-01]],\n",
      "\n",
      "        [[ 1.0146e+00]],\n",
      "\n",
      "        [[-6.7743e-01]],\n",
      "\n",
      "        [[-1.8871e+00]],\n",
      "\n",
      "        [[-1.1540e-01]],\n",
      "\n",
      "        [[ 9.2046e-01]],\n",
      "\n",
      "        [[-9.3323e-01]],\n",
      "\n",
      "        [[ 1.1500e+00]],\n",
      "\n",
      "        [[-4.6232e-01]],\n",
      "\n",
      "        [[-1.7227e-01]],\n",
      "\n",
      "        [[-7.4274e-01]],\n",
      "\n",
      "        [[-1.2804e+00]],\n",
      "\n",
      "        [[ 1.9660e-01]],\n",
      "\n",
      "        [[-7.0311e-01]],\n",
      "\n",
      "        [[-3.7346e-01]],\n",
      "\n",
      "        [[-2.6923e+00]],\n",
      "\n",
      "        [[-2.4004e+00]],\n",
      "\n",
      "        [[ 8.8626e-01]],\n",
      "\n",
      "        [[ 5.0810e-01]],\n",
      "\n",
      "        [[ 8.0211e-01]],\n",
      "\n",
      "        [[ 1.9907e+00]],\n",
      "\n",
      "        [[-5.7335e-01]],\n",
      "\n",
      "        [[ 2.1557e-01]],\n",
      "\n",
      "        [[ 9.6077e-01]],\n",
      "\n",
      "        [[ 7.3908e-01]],\n",
      "\n",
      "        [[-2.0457e-01]],\n",
      "\n",
      "        [[-7.1179e-01]],\n",
      "\n",
      "        [[ 3.2641e-01]],\n",
      "\n",
      "        [[ 7.2475e-01]],\n",
      "\n",
      "        [[ 8.9641e-01]],\n",
      "\n",
      "        [[ 7.7743e-02]],\n",
      "\n",
      "        [[-3.2390e-01]],\n",
      "\n",
      "        [[-4.9880e-01]],\n",
      "\n",
      "        [[ 2.2262e+00]],\n",
      "\n",
      "        [[-2.1001e-01]],\n",
      "\n",
      "        [[-1.7191e-01]],\n",
      "\n",
      "        [[-2.3612e-02]],\n",
      "\n",
      "        [[-1.1848e+00]],\n",
      "\n",
      "        [[ 5.4892e-01]],\n",
      "\n",
      "        [[-1.3340e+00]],\n",
      "\n",
      "        [[-1.5142e+00]],\n",
      "\n",
      "        [[ 4.6609e-01]],\n",
      "\n",
      "        [[-2.2891e+00]],\n",
      "\n",
      "        [[ 8.7406e-02]],\n",
      "\n",
      "        [[ 6.8769e-01]],\n",
      "\n",
      "        [[-9.4700e-02]],\n",
      "\n",
      "        [[ 5.4753e-01]],\n",
      "\n",
      "        [[-1.9091e+00]],\n",
      "\n",
      "        [[ 2.7379e-01]],\n",
      "\n",
      "        [[-6.2505e-01]],\n",
      "\n",
      "        [[-1.5267e+00]],\n",
      "\n",
      "        [[ 5.4573e-01]],\n",
      "\n",
      "        [[-8.0552e-01]],\n",
      "\n",
      "        [[-4.9782e-01]],\n",
      "\n",
      "        [[-1.4890e+00]],\n",
      "\n",
      "        [[ 8.9999e-02]],\n",
      "\n",
      "        [[ 1.0218e+00]],\n",
      "\n",
      "        [[-6.2943e-01]],\n",
      "\n",
      "        [[ 6.8048e-01]],\n",
      "\n",
      "        [[ 1.0723e+00]],\n",
      "\n",
      "        [[-2.3317e+00]],\n",
      "\n",
      "        [[ 1.2669e+00]],\n",
      "\n",
      "        [[-7.8734e-01]],\n",
      "\n",
      "        [[-2.3096e-01]],\n",
      "\n",
      "        [[-6.4714e-01]],\n",
      "\n",
      "        [[-2.8162e-01]],\n",
      "\n",
      "        [[-5.0889e-01]],\n",
      "\n",
      "        [[-8.0020e-01]],\n",
      "\n",
      "        [[-2.4308e-02]],\n",
      "\n",
      "        [[-1.7062e+00]],\n",
      "\n",
      "        [[ 8.3922e-02]],\n",
      "\n",
      "        [[-4.6245e-01]],\n",
      "\n",
      "        [[-2.2526e-01]],\n",
      "\n",
      "        [[-3.8143e-01]],\n",
      "\n",
      "        [[-1.0449e+00]],\n",
      "\n",
      "        [[-6.1434e-01]],\n",
      "\n",
      "        [[ 6.8603e-01]],\n",
      "\n",
      "        [[-4.8928e-01]],\n",
      "\n",
      "        [[ 2.1168e+00]],\n",
      "\n",
      "        [[-2.7998e+00]],\n",
      "\n",
      "        [[ 1.8185e-01]],\n",
      "\n",
      "        [[ 2.0577e+00]],\n",
      "\n",
      "        [[-8.8315e-03]],\n",
      "\n",
      "        [[ 2.5215e-01]],\n",
      "\n",
      "        [[-6.1474e-01]],\n",
      "\n",
      "        [[ 7.1930e-01]],\n",
      "\n",
      "        [[ 1.8636e-01]],\n",
      "\n",
      "        [[ 3.6188e-02]],\n",
      "\n",
      "        [[ 2.8570e-01]],\n",
      "\n",
      "        [[-1.8976e+00]],\n",
      "\n",
      "        [[-8.5914e-01]],\n",
      "\n",
      "        [[-8.5202e-01]],\n",
      "\n",
      "        [[ 6.9143e-01]],\n",
      "\n",
      "        [[ 1.6724e+00]],\n",
      "\n",
      "        [[-1.7130e+00]],\n",
      "\n",
      "        [[ 9.3290e-01]],\n",
      "\n",
      "        [[-5.6105e-01]],\n",
      "\n",
      "        [[-3.4899e-01]],\n",
      "\n",
      "        [[ 7.3078e-01]],\n",
      "\n",
      "        [[ 4.1085e-01]],\n",
      "\n",
      "        [[-8.4224e-01]],\n",
      "\n",
      "        [[ 1.0829e+00]],\n",
      "\n",
      "        [[-1.3027e-01]],\n",
      "\n",
      "        [[ 3.8671e-01]],\n",
      "\n",
      "        [[ 1.6898e+00]],\n",
      "\n",
      "        [[ 1.5111e+00]],\n",
      "\n",
      "        [[-1.8206e-01]],\n",
      "\n",
      "        [[ 2.1411e-01]],\n",
      "\n",
      "        [[ 7.3564e-01]],\n",
      "\n",
      "        [[-1.6920e+00]],\n",
      "\n",
      "        [[ 8.1109e-01]],\n",
      "\n",
      "        [[-8.3152e-01]],\n",
      "\n",
      "        [[ 6.8982e-01]],\n",
      "\n",
      "        [[ 7.9089e-01]],\n",
      "\n",
      "        [[-1.2057e+00]],\n",
      "\n",
      "        [[-1.6322e+00]],\n",
      "\n",
      "        [[-1.7410e+00]],\n",
      "\n",
      "        [[-1.2550e-02]],\n",
      "\n",
      "        [[-6.0939e-01]],\n",
      "\n",
      "        [[-1.7929e-01]],\n",
      "\n",
      "        [[-2.5809e-01]],\n",
      "\n",
      "        [[-6.5257e-02]],\n",
      "\n",
      "        [[-1.3486e+00]],\n",
      "\n",
      "        [[ 6.2353e-01]],\n",
      "\n",
      "        [[-2.2910e-01]],\n",
      "\n",
      "        [[ 3.2969e-01]],\n",
      "\n",
      "        [[-8.8357e-01]],\n",
      "\n",
      "        [[ 7.4490e-01]],\n",
      "\n",
      "        [[-2.9010e+00]],\n",
      "\n",
      "        [[-1.3814e+00]],\n",
      "\n",
      "        [[ 9.1106e-01]],\n",
      "\n",
      "        [[ 7.8841e-01]],\n",
      "\n",
      "        [[ 1.4129e+00]],\n",
      "\n",
      "        [[-6.8789e-01]],\n",
      "\n",
      "        [[ 4.7046e-01]],\n",
      "\n",
      "        [[ 1.1345e-01]],\n",
      "\n",
      "        [[-4.5389e-01]],\n",
      "\n",
      "        [[-9.5075e-03]],\n",
      "\n",
      "        [[-6.9864e-01]],\n",
      "\n",
      "        [[ 9.8026e-01]],\n",
      "\n",
      "        [[ 1.6486e+00]],\n",
      "\n",
      "        [[-9.1489e-01]],\n",
      "\n",
      "        [[-2.5527e+00]],\n",
      "\n",
      "        [[-1.2184e-01]],\n",
      "\n",
      "        [[-1.2300e+00]],\n",
      "\n",
      "        [[-2.9794e-01]],\n",
      "\n",
      "        [[-6.8303e-01]],\n",
      "\n",
      "        [[ 7.9404e-01]],\n",
      "\n",
      "        [[-9.7185e-01]],\n",
      "\n",
      "        [[ 1.6339e+00]],\n",
      "\n",
      "        [[ 6.3022e-02]],\n",
      "\n",
      "        [[-2.0377e+00]],\n",
      "\n",
      "        [[-4.5772e-02]],\n",
      "\n",
      "        [[-1.5672e+00]],\n",
      "\n",
      "        [[ 2.0760e+00]],\n",
      "\n",
      "        [[ 5.2671e-01]],\n",
      "\n",
      "        [[ 1.6828e+00]],\n",
      "\n",
      "        [[-2.1037e-01]],\n",
      "\n",
      "        [[ 6.9862e-01]],\n",
      "\n",
      "        [[ 7.7349e-01]],\n",
      "\n",
      "        [[ 1.0428e+00]],\n",
      "\n",
      "        [[ 2.1250e-01]],\n",
      "\n",
      "        [[ 7.3654e-01]],\n",
      "\n",
      "        [[-1.0843e+00]],\n",
      "\n",
      "        [[-7.3367e-01]],\n",
      "\n",
      "        [[-8.4426e-01]],\n",
      "\n",
      "        [[ 7.7429e-01]],\n",
      "\n",
      "        [[-1.1040e+00]],\n",
      "\n",
      "        [[-1.2186e+00]],\n",
      "\n",
      "        [[ 4.2580e-01]],\n",
      "\n",
      "        [[ 1.1741e+00]],\n",
      "\n",
      "        [[ 4.2489e-01]],\n",
      "\n",
      "        [[ 8.7393e-01]],\n",
      "\n",
      "        [[-3.9618e-01]],\n",
      "\n",
      "        [[ 6.8990e-01]],\n",
      "\n",
      "        [[ 9.6102e-01]],\n",
      "\n",
      "        [[ 1.2005e+00]],\n",
      "\n",
      "        [[-7.5828e-01]],\n",
      "\n",
      "        [[ 1.8037e+00]],\n",
      "\n",
      "        [[ 1.0259e-01]],\n",
      "\n",
      "        [[-1.7021e+00]],\n",
      "\n",
      "        [[ 9.7413e-03]],\n",
      "\n",
      "        [[ 1.2738e+00]],\n",
      "\n",
      "        [[ 3.3793e-01]],\n",
      "\n",
      "        [[ 4.7537e-02]],\n",
      "\n",
      "        [[ 4.8285e-01]],\n",
      "\n",
      "        [[-6.3434e-01]],\n",
      "\n",
      "        [[-1.2121e+00]],\n",
      "\n",
      "        [[-7.4066e-01]],\n",
      "\n",
      "        [[ 1.4636e+00]],\n",
      "\n",
      "        [[-1.4381e+00]],\n",
      "\n",
      "        [[-1.6932e-01]],\n",
      "\n",
      "        [[-6.1153e-01]],\n",
      "\n",
      "        [[-1.7399e+00]],\n",
      "\n",
      "        [[ 2.0572e-01]],\n",
      "\n",
      "        [[-1.4004e+00]],\n",
      "\n",
      "        [[ 6.4342e-01]],\n",
      "\n",
      "        [[-8.4362e-01]],\n",
      "\n",
      "        [[ 7.2499e-01]],\n",
      "\n",
      "        [[ 9.7631e-01]],\n",
      "\n",
      "        [[ 9.0035e-01]],\n",
      "\n",
      "        [[-9.5085e-01]],\n",
      "\n",
      "        [[-2.2509e-01]],\n",
      "\n",
      "        [[-8.9663e-01]],\n",
      "\n",
      "        [[ 4.6583e-01]],\n",
      "\n",
      "        [[ 1.6777e+00]],\n",
      "\n",
      "        [[-9.0281e-01]],\n",
      "\n",
      "        [[ 9.7429e-01]],\n",
      "\n",
      "        [[-8.8628e-01]],\n",
      "\n",
      "        [[ 4.8798e-02]],\n",
      "\n",
      "        [[ 2.2407e-01]],\n",
      "\n",
      "        [[-9.3058e-01]],\n",
      "\n",
      "        [[-4.4368e-01]],\n",
      "\n",
      "        [[-3.8244e-01]],\n",
      "\n",
      "        [[-1.8278e+00]],\n",
      "\n",
      "        [[-4.5294e-01]],\n",
      "\n",
      "        [[ 1.0066e-01]],\n",
      "\n",
      "        [[ 9.8404e-01]],\n",
      "\n",
      "        [[-2.6471e-01]],\n",
      "\n",
      "        [[ 2.0277e+00]],\n",
      "\n",
      "        [[-2.2397e-01]],\n",
      "\n",
      "        [[-3.2095e-01]],\n",
      "\n",
      "        [[ 1.6912e-01]],\n",
      "\n",
      "        [[-6.8738e-01]],\n",
      "\n",
      "        [[-1.4003e+00]],\n",
      "\n",
      "        [[ 1.0829e+00]],\n",
      "\n",
      "        [[ 1.2889e+00]],\n",
      "\n",
      "        [[-9.9999e-01]],\n",
      "\n",
      "        [[ 1.2182e+00]],\n",
      "\n",
      "        [[ 1.6703e+00]],\n",
      "\n",
      "        [[-8.4845e-01]],\n",
      "\n",
      "        [[ 7.3170e-01]],\n",
      "\n",
      "        [[ 2.7077e-01]],\n",
      "\n",
      "        [[ 3.5890e-02]],\n",
      "\n",
      "        [[ 6.8691e-01]],\n",
      "\n",
      "        [[ 4.5146e-03]],\n",
      "\n",
      "        [[ 1.5561e+00]],\n",
      "\n",
      "        [[-4.4180e-01]],\n",
      "\n",
      "        [[-6.6588e-01]],\n",
      "\n",
      "        [[-2.4610e-01]],\n",
      "\n",
      "        [[-3.3086e-01]]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[[-0.2276]]], device='cuda:0')\n",
      "torch.Size([1, 448, 512])\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 2.0408,  1.9615,  1.8854,  ...,  1.9902,  1.8823,  1.9257],\n",
      "         [ 1.9359,  1.9084,  1.9220,  ...,  1.8520,  1.8135,  1.9094],\n",
      "         [ 1.9053,  1.9064,  2.0034,  ...,  1.8406,  1.9504,  1.9277],\n",
      "         ...,\n",
      "         [ 1.9304,  1.9365,  2.0422,  ...,  1.8829,  1.9436,  1.9398],\n",
      "         [ 2.0424,  2.0943,  1.9426,  ...,  1.9929,  1.9586,  1.9569],\n",
      "         [ 1.8381,  1.9243,  1.9506,  ...,  1.9672,  1.9457,  1.8684]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [28160/50000 (62%)]\tLoss: 0.617025, Accuracy: 78.52\n",
      "Train Epoch: 12 [29440/50000 (65%)]\tLoss: 0.539521, Accuracy: 82.03\n",
      "Train Epoch: 12 [30720/50000 (68%)]\tLoss: 0.461722, Accuracy: 83.98\n",
      "Train Epoch: 12 [32000/50000 (71%)]\tLoss: 0.521079, Accuracy: 82.03\n",
      "Train Epoch: 12 [33280/50000 (74%)]\tLoss: 0.492417, Accuracy: 80.47\n",
      "Train Epoch: 12 [34560/50000 (77%)]\tLoss: 0.523238, Accuracy: 83.20\n",
      "Train Epoch: 12 [35840/50000 (80%)]\tLoss: 0.422706, Accuracy: 83.98\n",
      "Train Epoch: 12 [37120/50000 (82%)]\tLoss: 0.583637, Accuracy: 83.59\n",
      "Train Epoch: 12 [38400/50000 (85%)]\tLoss: 0.650664, Accuracy: 79.69\n",
      "Train Epoch: 12 [39680/50000 (88%)]\tLoss: 0.548782, Accuracy: 82.81\n",
      "Train Epoch: 12 [40960/50000 (91%)]\tLoss: 0.437934, Accuracy: 84.77\n",
      "Train Epoch: 12 [42240/50000 (94%)]\tLoss: 0.476372, Accuracy: 83.20\n",
      "Train Epoch: 12 [43520/50000 (97%)]\tLoss: 0.563801, Accuracy: 81.25\n",
      "Train Epoch: 12 [35000/50000 (99%)]\tLoss: 0.549606, Accuracy: 83.50\n",
      "\n",
      "Validation set: Average loss: 1.1080, Accuracy: 3359/5000 (67.00%)\n",
      "\n",
      "the time of this epoch:[37.17225766181946 s]\n",
      "\n",
      "Test set: Average loss: 1.1427, Accuracy: 6673/10000 (66.73%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.511792, Accuracy: 82.81\n",
      "Train Epoch: 13 [1280/50000 (3%)]\tLoss: 0.559405, Accuracy: 79.30\n",
      "Train Epoch: 13 [2560/50000 (6%)]\tLoss: 0.452132, Accuracy: 85.16\n",
      "Train Epoch: 13 [3840/50000 (9%)]\tLoss: 0.469102, Accuracy: 83.98\n",
      "Train Epoch: 13 [5120/50000 (11%)]\tLoss: 0.578870, Accuracy: 79.69\n",
      "Train Epoch: 13 [6400/50000 (14%)]\tLoss: 0.507761, Accuracy: 82.03\n",
      "Train Epoch: 13 [7680/50000 (17%)]\tLoss: 0.436718, Accuracy: 86.33\n",
      "Train Epoch: 13 [8960/50000 (20%)]\tLoss: 0.575475, Accuracy: 82.81\n",
      "Train Epoch: 13 [10240/50000 (23%)]\tLoss: 0.489335, Accuracy: 83.98\n",
      "Train Epoch: 13 [11520/50000 (26%)]\tLoss: 0.421800, Accuracy: 87.89\n",
      "Train Epoch: 13 [12800/50000 (28%)]\tLoss: 0.424500, Accuracy: 87.50\n",
      "Train Epoch: 13 [14080/50000 (31%)]\tLoss: 0.727560, Accuracy: 74.61\n",
      "Train Epoch: 13 [15360/50000 (34%)]\tLoss: 0.514754, Accuracy: 83.20\n",
      "Train Epoch: 13 [16640/50000 (37%)]\tLoss: 0.428638, Accuracy: 85.16\n",
      "Train Epoch: 13 [17920/50000 (40%)]\tLoss: 0.556890, Accuracy: 80.47\n",
      "Train Epoch: 13 [19200/50000 (43%)]\tLoss: 0.483341, Accuracy: 83.59\n",
      "Train Epoch: 13 [20480/50000 (45%)]\tLoss: 0.605718, Accuracy: 80.47\n",
      "Train Epoch: 13 [21760/50000 (48%)]\tLoss: 0.567664, Accuracy: 82.03\n",
      "Train Epoch: 13 [23040/50000 (51%)]\tLoss: 0.554672, Accuracy: 78.91\n",
      "Train Epoch: 13 [24320/50000 (54%)]\tLoss: 0.608942, Accuracy: 78.12\n",
      "Train Epoch: 13 [25600/50000 (57%)]\tLoss: 0.574641, Accuracy: 79.69\n",
      "Train Epoch: 13 [26880/50000 (60%)]\tLoss: 0.424701, Accuracy: 84.38\n",
      "Train Epoch: 13 [28160/50000 (62%)]\tLoss: 0.478965, Accuracy: 80.86\n",
      "Train Epoch: 13 [29440/50000 (65%)]\tLoss: 0.575270, Accuracy: 82.03\n",
      "Train Epoch: 13 [30720/50000 (68%)]\tLoss: 0.474963, Accuracy: 82.81\n",
      "Train Epoch: 13 [32000/50000 (71%)]\tLoss: 0.521668, Accuracy: 80.86\n",
      "Train Epoch: 13 [33280/50000 (74%)]\tLoss: 0.441993, Accuracy: 85.16\n",
      "Train Epoch: 13 [34560/50000 (77%)]\tLoss: 0.462949, Accuracy: 84.77\n",
      "Train Epoch: 13 [35840/50000 (80%)]\tLoss: 0.504705, Accuracy: 85.16\n",
      "Train Epoch: 13 [37120/50000 (82%)]\tLoss: 0.442407, Accuracy: 83.20\n",
      "Train Epoch: 13 [38400/50000 (85%)]\tLoss: 0.445433, Accuracy: 84.38\n",
      "Train Epoch: 13 [39680/50000 (88%)]\tLoss: 0.515037, Accuracy: 83.20\n",
      "Train Epoch: 13 [40960/50000 (91%)]\tLoss: 0.470339, Accuracy: 84.38\n",
      "Train Epoch: 13 [42240/50000 (94%)]\tLoss: 0.537495, Accuracy: 83.20\n",
      "Train Epoch: 13 [43520/50000 (97%)]\tLoss: 0.534545, Accuracy: 81.64\n",
      "Train Epoch: 13 [35000/50000 (99%)]\tLoss: 0.548782, Accuracy: 82.00\n",
      "\n",
      "Validation set: Average loss: 0.7912, Accuracy: 3776/5000 (75.00%)\n",
      "\n",
      "the time of this epoch:[40.28104019165039 s]\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.562531, Accuracy: 78.12\n",
      "Train Epoch: 14 [1280/50000 (3%)]\tLoss: 0.606411, Accuracy: 78.91\n",
      "Train Epoch: 14 [2560/50000 (6%)]\tLoss: 0.488368, Accuracy: 80.86\n",
      "Train Epoch: 14 [3840/50000 (9%)]\tLoss: 0.485308, Accuracy: 84.77\n",
      "Train Epoch: 14 [5120/50000 (11%)]\tLoss: 0.510742, Accuracy: 83.20\n",
      "Train Epoch: 14 [6400/50000 (14%)]\tLoss: 0.504237, Accuracy: 83.20\n",
      "Train Epoch: 14 [7680/50000 (17%)]\tLoss: 0.521728, Accuracy: 81.25\n",
      "Train Epoch: 14 [8960/50000 (20%)]\tLoss: 0.430162, Accuracy: 85.55\n",
      "Train Epoch: 14 [10240/50000 (23%)]\tLoss: 0.488494, Accuracy: 83.59\n",
      "Train Epoch: 14 [11520/50000 (26%)]\tLoss: 0.541374, Accuracy: 82.03\n",
      "Train Epoch: 14 [12800/50000 (28%)]\tLoss: 0.554775, Accuracy: 84.38\n",
      "Train Epoch: 14 [14080/50000 (31%)]\tLoss: 0.457588, Accuracy: 85.16\n",
      "Train Epoch: 14 [15360/50000 (34%)]\tLoss: 0.622663, Accuracy: 77.34\n",
      "Train Epoch: 14 [16640/50000 (37%)]\tLoss: 0.547951, Accuracy: 80.08\n",
      "Train Epoch: 14 [17920/50000 (40%)]\tLoss: 0.619957, Accuracy: 76.56\n",
      "Train Epoch: 14 [19200/50000 (43%)]\tLoss: 0.538376, Accuracy: 82.03\n",
      "Train Epoch: 14 [20480/50000 (45%)]\tLoss: 0.456043, Accuracy: 84.77\n",
      "Train Epoch: 14 [21760/50000 (48%)]\tLoss: 0.505593, Accuracy: 79.69\n",
      "Train Epoch: 14 [23040/50000 (51%)]\tLoss: 0.605950, Accuracy: 78.52\n",
      "Train Epoch: 14 [24320/50000 (54%)]\tLoss: 0.374221, Accuracy: 89.84\n",
      "Train Epoch: 14 [25600/50000 (57%)]\tLoss: 0.443849, Accuracy: 87.50\n",
      "Train Epoch: 14 [26880/50000 (60%)]\tLoss: 0.461295, Accuracy: 84.77\n",
      "Train Epoch: 14 [28160/50000 (62%)]\tLoss: 0.475271, Accuracy: 85.16\n",
      "Train Epoch: 14 [29440/50000 (65%)]\tLoss: 0.510480, Accuracy: 81.25\n",
      "Train Epoch: 14 [30720/50000 (68%)]\tLoss: 0.571898, Accuracy: 77.73\n",
      "Train Epoch: 14 [32000/50000 (71%)]\tLoss: 0.393911, Accuracy: 84.77\n",
      "Train Epoch: 14 [33280/50000 (74%)]\tLoss: 0.448204, Accuracy: 84.38\n",
      "Train Epoch: 14 [34560/50000 (77%)]\tLoss: 0.531557, Accuracy: 82.03\n",
      "Train Epoch: 14 [35840/50000 (80%)]\tLoss: 0.668131, Accuracy: 78.12\n",
      "Train Epoch: 14 [37120/50000 (82%)]\tLoss: 0.515540, Accuracy: 82.42\n",
      "Train Epoch: 14 [38400/50000 (85%)]\tLoss: 0.513796, Accuracy: 81.25\n",
      "Train Epoch: 14 [39680/50000 (88%)]\tLoss: 0.539747, Accuracy: 84.38\n",
      "Train Epoch: 14 [40960/50000 (91%)]\tLoss: 0.528178, Accuracy: 84.38\n",
      "Train Epoch: 14 [42240/50000 (94%)]\tLoss: 0.545652, Accuracy: 80.86\n",
      "Train Epoch: 14 [43520/50000 (97%)]\tLoss: 0.535569, Accuracy: 81.25\n",
      "Train Epoch: 14 [35000/50000 (99%)]\tLoss: 0.352193, Accuracy: 87.50\n",
      "\n",
      "Validation set: Average loss: 0.8674, Accuracy: 3574/5000 (71.00%)\n",
      "\n",
      "the time of this epoch:[37.14040923118591 s]\n",
      "\n",
      "Test set: Average loss: 0.8516, Accuracy: 7167/10000 (71.67%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.465348, Accuracy: 83.98\n",
      "Train Epoch: 15 [1280/50000 (3%)]\tLoss: 0.417477, Accuracy: 86.33\n",
      "Train Epoch: 15 [2560/50000 (6%)]\tLoss: 0.446349, Accuracy: 85.16\n",
      "Train Epoch: 15 [3840/50000 (9%)]\tLoss: 0.451266, Accuracy: 86.33\n",
      "Train Epoch: 15 [5120/50000 (11%)]\tLoss: 0.476019, Accuracy: 83.98\n",
      "Train Epoch: 15 [6400/50000 (14%)]\tLoss: 0.568984, Accuracy: 78.91\n",
      "Train Epoch: 15 [7680/50000 (17%)]\tLoss: 0.443433, Accuracy: 84.77\n",
      "Train Epoch: 15 [8960/50000 (20%)]\tLoss: 0.432226, Accuracy: 84.77\n",
      "Train Epoch: 15 [10240/50000 (23%)]\tLoss: 0.496131, Accuracy: 82.42\n",
      "Train Epoch: 15 [11520/50000 (26%)]\tLoss: 0.537311, Accuracy: 80.86\n",
      "Train Epoch: 15 [12800/50000 (28%)]\tLoss: 0.616251, Accuracy: 80.08\n",
      "Train Epoch: 15 [14080/50000 (31%)]\tLoss: 0.381877, Accuracy: 87.50\n",
      "Train Epoch: 15 [15360/50000 (34%)]\tLoss: 0.355478, Accuracy: 86.33\n",
      "Train Epoch: 15 [16640/50000 (37%)]\tLoss: 0.550922, Accuracy: 82.81\n",
      "Train Epoch: 15 [17920/50000 (40%)]\tLoss: 0.568705, Accuracy: 81.25\n",
      "Train Epoch: 15 [19200/50000 (43%)]\tLoss: 0.538739, Accuracy: 80.47\n",
      "Train Epoch: 15 [20480/50000 (45%)]\tLoss: 0.491131, Accuracy: 82.42\n",
      "Train Epoch: 15 [21760/50000 (48%)]\tLoss: 0.421023, Accuracy: 85.55\n",
      "Train Epoch: 15 [23040/50000 (51%)]\tLoss: 0.560526, Accuracy: 80.86\n",
      "Train Epoch: 15 [24320/50000 (54%)]\tLoss: 0.458769, Accuracy: 85.94\n",
      "Train Epoch: 15 [25600/50000 (57%)]\tLoss: 0.555459, Accuracy: 83.20\n",
      "Train Epoch: 15 [26880/50000 (60%)]\tLoss: 0.430937, Accuracy: 86.33\n",
      "Train Epoch: 15 [28160/50000 (62%)]\tLoss: 0.583468, Accuracy: 82.81\n",
      "Train Epoch: 15 [29440/50000 (65%)]\tLoss: 0.473978, Accuracy: 84.38\n",
      "Train Epoch: 15 [30720/50000 (68%)]\tLoss: 0.502267, Accuracy: 82.42\n",
      "Train Epoch: 15 [32000/50000 (71%)]\tLoss: 0.473521, Accuracy: 84.77\n",
      "Train Epoch: 15 [33280/50000 (74%)]\tLoss: 0.497850, Accuracy: 82.03\n",
      "Train Epoch: 15 [34560/50000 (77%)]\tLoss: 0.520952, Accuracy: 79.69\n",
      "Train Epoch: 15 [35840/50000 (80%)]\tLoss: 0.440689, Accuracy: 87.50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [37120/50000 (82%)]\tLoss: 0.350279, Accuracy: 88.28\n",
      "Train Epoch: 15 [38400/50000 (85%)]\tLoss: 0.460340, Accuracy: 84.77\n",
      "Train Epoch: 15 [39680/50000 (88%)]\tLoss: 0.520668, Accuracy: 82.81\n",
      "Train Epoch: 15 [40960/50000 (91%)]\tLoss: 0.440665, Accuracy: 85.55\n",
      "Train Epoch: 15 [42240/50000 (94%)]\tLoss: 0.482746, Accuracy: 84.38\n",
      "Train Epoch: 15 [43520/50000 (97%)]\tLoss: 0.546832, Accuracy: 80.86\n",
      "Train Epoch: 15 [35000/50000 (99%)]\tLoss: 0.558348, Accuracy: 80.50\n",
      "\n",
      "Validation set: Average loss: 0.7722, Accuracy: 3683/5000 (73.00%)\n",
      "\n",
      "the time of this epoch:[40.39142417907715 s]\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.438759, Accuracy: 85.94\n",
      "Train Epoch: 16 [1280/50000 (3%)]\tLoss: 0.438488, Accuracy: 84.77\n",
      "Train Epoch: 16 [2560/50000 (6%)]\tLoss: 0.501893, Accuracy: 82.03\n",
      "Train Epoch: 16 [3840/50000 (9%)]\tLoss: 0.552238, Accuracy: 83.20\n",
      "Train Epoch: 16 [5120/50000 (11%)]\tLoss: 0.556648, Accuracy: 77.73\n",
      "Train Epoch: 16 [6400/50000 (14%)]\tLoss: 0.552949, Accuracy: 80.08\n",
      "Train Epoch: 16 [7680/50000 (17%)]\tLoss: 0.443409, Accuracy: 82.81\n",
      "Train Epoch: 16 [8960/50000 (20%)]\tLoss: 0.343743, Accuracy: 89.45\n",
      "Train Epoch: 16 [10240/50000 (23%)]\tLoss: 0.494758, Accuracy: 83.59\n",
      "Train Epoch: 16 [11520/50000 (26%)]\tLoss: 0.389667, Accuracy: 87.50\n",
      "Train Epoch: 16 [12800/50000 (28%)]\tLoss: 0.462449, Accuracy: 82.03\n",
      "Train Epoch: 16 [14080/50000 (31%)]\tLoss: 0.494292, Accuracy: 81.64\n",
      "Train Epoch: 16 [15360/50000 (34%)]\tLoss: 0.508032, Accuracy: 82.03\n",
      "Train Epoch: 16 [16640/50000 (37%)]\tLoss: 0.511617, Accuracy: 78.52\n",
      "Train Epoch: 16 [17920/50000 (40%)]\tLoss: 0.447765, Accuracy: 83.98\n",
      "Train Epoch: 16 [19200/50000 (43%)]\tLoss: 0.406879, Accuracy: 87.50\n",
      "Train Epoch: 16 [20480/50000 (45%)]\tLoss: 0.406966, Accuracy: 83.59\n",
      "Train Epoch: 16 [21760/50000 (48%)]\tLoss: 0.526499, Accuracy: 83.20\n",
      "Train Epoch: 16 [23040/50000 (51%)]\tLoss: 0.542265, Accuracy: 82.03\n",
      "Train Epoch: 16 [24320/50000 (54%)]\tLoss: 0.480702, Accuracy: 84.38\n",
      "Train Epoch: 16 [25600/50000 (57%)]\tLoss: 0.543775, Accuracy: 80.86\n",
      "Train Epoch: 16 [26880/50000 (60%)]\tLoss: 0.584745, Accuracy: 81.64\n",
      "Train Epoch: 16 [28160/50000 (62%)]\tLoss: 0.503152, Accuracy: 84.38\n",
      "Train Epoch: 16 [29440/50000 (65%)]\tLoss: 0.431148, Accuracy: 84.38\n",
      "Train Epoch: 16 [30720/50000 (68%)]\tLoss: 0.404265, Accuracy: 87.50\n",
      "Train Epoch: 16 [32000/50000 (71%)]\tLoss: 0.396990, Accuracy: 87.89\n",
      "Train Epoch: 16 [33280/50000 (74%)]\tLoss: 0.449806, Accuracy: 86.33\n",
      "Train Epoch: 16 [34560/50000 (77%)]\tLoss: 0.487000, Accuracy: 84.77\n",
      "Train Epoch: 16 [35840/50000 (80%)]\tLoss: 0.550002, Accuracy: 81.25\n",
      "Train Epoch: 16 [37120/50000 (82%)]\tLoss: 0.524383, Accuracy: 80.47\n",
      "Train Epoch: 16 [38400/50000 (85%)]\tLoss: 0.555864, Accuracy: 81.25\n",
      "Train Epoch: 16 [39680/50000 (88%)]\tLoss: 0.475665, Accuracy: 84.77\n",
      "Train Epoch: 16 [40960/50000 (91%)]\tLoss: 0.547295, Accuracy: 82.03\n",
      "Train Epoch: 16 [42240/50000 (94%)]\tLoss: 0.414410, Accuracy: 87.50\n",
      "Train Epoch: 16 [43520/50000 (97%)]\tLoss: 0.618641, Accuracy: 79.69\n",
      "Train Epoch: 16 [35000/50000 (99%)]\tLoss: 0.470127, Accuracy: 84.00\n",
      "\n",
      "Validation set: Average loss: 0.8357, Accuracy: 3669/5000 (73.00%)\n",
      "\n",
      "the time of this epoch:[37.11090087890625 s]\n",
      "\n",
      "Test set: Average loss: 0.8640, Accuracy: 7285/10000 (72.85%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.500808, Accuracy: 83.20\n",
      "Train Epoch: 17 [1280/50000 (3%)]\tLoss: 0.437042, Accuracy: 84.77\n",
      "Train Epoch: 17 [2560/50000 (6%)]\tLoss: 0.395874, Accuracy: 86.72\n",
      "Train Epoch: 17 [3840/50000 (9%)]\tLoss: 0.408010, Accuracy: 87.89\n",
      "Train Epoch: 17 [5120/50000 (11%)]\tLoss: 0.361643, Accuracy: 90.23\n",
      "Train Epoch: 17 [6400/50000 (14%)]\tLoss: 0.394772, Accuracy: 86.33\n",
      "Train Epoch: 17 [7680/50000 (17%)]\tLoss: 0.482820, Accuracy: 85.94\n",
      "Train Epoch: 17 [8960/50000 (20%)]\tLoss: 0.452649, Accuracy: 86.72\n",
      "Train Epoch: 17 [10240/50000 (23%)]\tLoss: 0.470986, Accuracy: 83.20\n",
      "Train Epoch: 17 [11520/50000 (26%)]\tLoss: 0.337087, Accuracy: 89.45\n",
      "Train Epoch: 17 [12800/50000 (28%)]\tLoss: 0.533756, Accuracy: 80.08\n",
      "Train Epoch: 17 [14080/50000 (31%)]\tLoss: 0.461617, Accuracy: 82.03\n",
      "Train Epoch: 17 [15360/50000 (34%)]\tLoss: 0.564803, Accuracy: 81.25\n",
      "Train Epoch: 17 [16640/50000 (37%)]\tLoss: 0.444822, Accuracy: 87.50\n",
      "Train Epoch: 17 [17920/50000 (40%)]\tLoss: 0.412113, Accuracy: 87.50\n",
      "Train Epoch: 17 [19200/50000 (43%)]\tLoss: 0.441674, Accuracy: 84.38\n",
      "Train Epoch: 17 [20480/50000 (45%)]\tLoss: 0.529954, Accuracy: 83.59\n",
      "Train Epoch: 17 [21760/50000 (48%)]\tLoss: 0.413453, Accuracy: 87.11\n",
      "Train Epoch: 17 [23040/50000 (51%)]\tLoss: 0.526887, Accuracy: 81.64\n",
      "Train Epoch: 17 [24320/50000 (54%)]\tLoss: 0.566327, Accuracy: 78.91\n",
      "Train Epoch: 17 [25600/50000 (57%)]\tLoss: 0.376328, Accuracy: 86.72\n",
      "Train Epoch: 17 [26880/50000 (60%)]\tLoss: 0.318506, Accuracy: 90.62\n",
      "Train Epoch: 17 [28160/50000 (62%)]\tLoss: 0.638331, Accuracy: 78.91\n",
      "Train Epoch: 17 [29440/50000 (65%)]\tLoss: 0.529591, Accuracy: 80.86\n",
      "Train Epoch: 17 [30720/50000 (68%)]\tLoss: 0.504928, Accuracy: 81.64\n",
      "Train Epoch: 17 [32000/50000 (71%)]\tLoss: 0.575739, Accuracy: 81.25\n",
      "Train Epoch: 17 [33280/50000 (74%)]\tLoss: 0.509890, Accuracy: 82.03\n",
      "Train Epoch: 17 [34560/50000 (77%)]\tLoss: 0.610342, Accuracy: 77.73\n",
      "Train Epoch: 17 [35840/50000 (80%)]\tLoss: 0.500904, Accuracy: 82.42\n",
      "Train Epoch: 17 [37120/50000 (82%)]\tLoss: 0.522105, Accuracy: 83.59\n",
      "Train Epoch: 17 [38400/50000 (85%)]\tLoss: 0.452580, Accuracy: 85.94\n",
      "Train Epoch: 17 [39680/50000 (88%)]\tLoss: 0.492182, Accuracy: 83.20\n",
      "Train Epoch: 17 [40960/50000 (91%)]\tLoss: 0.484465, Accuracy: 82.42\n",
      "Train Epoch: 17 [42240/50000 (94%)]\tLoss: 0.484356, Accuracy: 81.25\n",
      "Train Epoch: 17 [43520/50000 (97%)]\tLoss: 0.474578, Accuracy: 83.98\n",
      "Train Epoch: 17 [35000/50000 (99%)]\tLoss: 0.481162, Accuracy: 84.00\n",
      "\n",
      "Validation set: Average loss: 1.2167, Accuracy: 3174/5000 (63.00%)\n",
      "\n",
      "the time of this epoch:[40.291462659835815 s]\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.492284, Accuracy: 83.59\n",
      "Train Epoch: 18 [1280/50000 (3%)]\tLoss: 0.532757, Accuracy: 78.12\n",
      "Train Epoch: 18 [2560/50000 (6%)]\tLoss: 0.393957, Accuracy: 86.72\n",
      "Train Epoch: 18 [3840/50000 (9%)]\tLoss: 0.484504, Accuracy: 83.98\n",
      "Train Epoch: 18 [5120/50000 (11%)]\tLoss: 0.361503, Accuracy: 86.33\n",
      "Train Epoch: 18 [6400/50000 (14%)]\tLoss: 0.449809, Accuracy: 83.98\n",
      "Train Epoch: 18 [7680/50000 (17%)]\tLoss: 0.473563, Accuracy: 83.59\n",
      "Train Epoch: 18 [8960/50000 (20%)]\tLoss: 0.463009, Accuracy: 85.16\n",
      "Train Epoch: 18 [10240/50000 (23%)]\tLoss: 0.522121, Accuracy: 84.77\n",
      "Train Epoch: 18 [11520/50000 (26%)]\tLoss: 0.473264, Accuracy: 85.16\n",
      "Train Epoch: 18 [12800/50000 (28%)]\tLoss: 0.491818, Accuracy: 83.20\n",
      "Train Epoch: 18 [14080/50000 (31%)]\tLoss: 0.457208, Accuracy: 83.98\n",
      "Train Epoch: 18 [15360/50000 (34%)]\tLoss: 0.459984, Accuracy: 86.33\n",
      "Train Epoch: 18 [16640/50000 (37%)]\tLoss: 0.398691, Accuracy: 87.89\n",
      "Train Epoch: 18 [17920/50000 (40%)]\tLoss: 0.471918, Accuracy: 82.42\n",
      "Train Epoch: 18 [19200/50000 (43%)]\tLoss: 0.416012, Accuracy: 86.72\n",
      "Train Epoch: 18 [20480/50000 (45%)]\tLoss: 0.445868, Accuracy: 83.20\n",
      "Train Epoch: 18 [21760/50000 (48%)]\tLoss: 0.434957, Accuracy: 83.98\n",
      "Train Epoch: 18 [23040/50000 (51%)]\tLoss: 0.564681, Accuracy: 80.47\n",
      "Train Epoch: 18 [24320/50000 (54%)]\tLoss: 0.409605, Accuracy: 86.72\n",
      "Train Epoch: 18 [25600/50000 (57%)]\tLoss: 0.456224, Accuracy: 83.59\n",
      "Train Epoch: 18 [26880/50000 (60%)]\tLoss: 0.441380, Accuracy: 83.98\n",
      "Train Epoch: 18 [28160/50000 (62%)]\tLoss: 0.475769, Accuracy: 85.16\n",
      "Train Epoch: 18 [29440/50000 (65%)]\tLoss: 0.392450, Accuracy: 87.89\n",
      "Train Epoch: 18 [30720/50000 (68%)]\tLoss: 0.448158, Accuracy: 85.55\n",
      "Train Epoch: 18 [32000/50000 (71%)]\tLoss: 0.522504, Accuracy: 83.98\n",
      "Train Epoch: 18 [33280/50000 (74%)]\tLoss: 0.410280, Accuracy: 84.38\n",
      "Train Epoch: 18 [34560/50000 (77%)]\tLoss: 0.445392, Accuracy: 83.20\n",
      "Train Epoch: 18 [35840/50000 (80%)]\tLoss: 0.435987, Accuracy: 84.38\n",
      "Train Epoch: 18 [37120/50000 (82%)]\tLoss: 0.483676, Accuracy: 85.16\n",
      "Train Epoch: 18 [38400/50000 (85%)]\tLoss: 0.552718, Accuracy: 83.59\n",
      "Train Epoch: 18 [39680/50000 (88%)]\tLoss: 0.426849, Accuracy: 85.55\n",
      "Train Epoch: 18 [40960/50000 (91%)]\tLoss: 0.506525, Accuracy: 82.42\n",
      "Train Epoch: 18 [42240/50000 (94%)]\tLoss: 0.574176, Accuracy: 78.52\n",
      "Train Epoch: 18 [43520/50000 (97%)]\tLoss: 0.435783, Accuracy: 86.33\n",
      "Train Epoch: 18 [35000/50000 (99%)]\tLoss: 0.488916, Accuracy: 81.00\n",
      "\n",
      "Validation set: Average loss: 0.6310, Accuracy: 3949/5000 (78.00%)\n",
      "\n",
      "the time of this epoch:[37.15380048751831 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6559, Accuracy: 7829/10000 (78.29%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.326682, Accuracy: 89.84\n",
      "Train Epoch: 19 [1280/50000 (3%)]\tLoss: 0.505289, Accuracy: 82.81\n",
      "Train Epoch: 19 [2560/50000 (6%)]\tLoss: 0.393750, Accuracy: 87.11\n",
      "Train Epoch: 19 [3840/50000 (9%)]\tLoss: 0.438517, Accuracy: 82.81\n",
      "Train Epoch: 19 [5120/50000 (11%)]\tLoss: 0.402575, Accuracy: 86.33\n",
      "Train Epoch: 19 [6400/50000 (14%)]\tLoss: 0.405082, Accuracy: 86.72\n",
      "Train Epoch: 19 [7680/50000 (17%)]\tLoss: 0.457305, Accuracy: 84.38\n",
      "Train Epoch: 19 [8960/50000 (20%)]\tLoss: 0.479024, Accuracy: 85.16\n",
      "Train Epoch: 19 [10240/50000 (23%)]\tLoss: 0.526395, Accuracy: 84.38\n",
      "Train Epoch: 19 [11520/50000 (26%)]\tLoss: 0.376206, Accuracy: 87.50\n",
      "Train Epoch: 19 [12800/50000 (28%)]\tLoss: 0.448292, Accuracy: 84.77\n",
      "Train Epoch: 19 [14080/50000 (31%)]\tLoss: 0.451676, Accuracy: 85.55\n",
      "Train Epoch: 19 [15360/50000 (34%)]\tLoss: 0.487461, Accuracy: 84.38\n",
      "Train Epoch: 19 [16640/50000 (37%)]\tLoss: 0.513386, Accuracy: 82.42\n",
      "Train Epoch: 19 [17920/50000 (40%)]\tLoss: 0.396874, Accuracy: 88.67\n",
      "Train Epoch: 19 [19200/50000 (43%)]\tLoss: 0.524973, Accuracy: 85.16\n",
      "Train Epoch: 19 [20480/50000 (45%)]\tLoss: 0.339754, Accuracy: 89.45\n",
      "Train Epoch: 19 [21760/50000 (48%)]\tLoss: 0.532612, Accuracy: 82.81\n",
      "Train Epoch: 19 [23040/50000 (51%)]\tLoss: 0.463186, Accuracy: 83.20\n",
      "Train Epoch: 19 [24320/50000 (54%)]\tLoss: 0.637193, Accuracy: 79.69\n",
      "Train Epoch: 19 [25600/50000 (57%)]\tLoss: 0.503841, Accuracy: 81.64\n",
      "Train Epoch: 19 [26880/50000 (60%)]\tLoss: 0.576521, Accuracy: 81.64\n",
      "Train Epoch: 19 [28160/50000 (62%)]\tLoss: 0.441921, Accuracy: 85.55\n",
      "Train Epoch: 19 [29440/50000 (65%)]\tLoss: 0.441290, Accuracy: 85.55\n",
      "Train Epoch: 19 [30720/50000 (68%)]\tLoss: 0.397634, Accuracy: 86.72\n",
      "Train Epoch: 19 [32000/50000 (71%)]\tLoss: 0.445446, Accuracy: 86.72\n",
      "Train Epoch: 19 [33280/50000 (74%)]\tLoss: 0.351355, Accuracy: 88.28\n",
      "Train Epoch: 19 [34560/50000 (77%)]\tLoss: 0.331380, Accuracy: 88.67\n",
      "Train Epoch: 19 [35840/50000 (80%)]\tLoss: 0.447658, Accuracy: 85.55\n",
      "Train Epoch: 19 [37120/50000 (82%)]\tLoss: 0.410845, Accuracy: 85.55\n",
      "Train Epoch: 19 [38400/50000 (85%)]\tLoss: 0.516424, Accuracy: 82.42\n",
      "Train Epoch: 19 [39680/50000 (88%)]\tLoss: 0.491663, Accuracy: 83.98\n",
      "Train Epoch: 19 [40960/50000 (91%)]\tLoss: 0.397374, Accuracy: 85.55\n",
      "Train Epoch: 19 [42240/50000 (94%)]\tLoss: 0.425259, Accuracy: 83.59\n",
      "Train Epoch: 19 [43520/50000 (97%)]\tLoss: 0.500137, Accuracy: 80.08\n",
      "Train Epoch: 19 [35000/50000 (99%)]\tLoss: 0.441328, Accuracy: 84.00\n",
      "\n",
      "Validation set: Average loss: 1.0284, Accuracy: 3455/5000 (69.00%)\n",
      "\n",
      "the time of this epoch:[61.22569179534912 s]\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.436528, Accuracy: 86.72\n",
      "Train Epoch: 20 [1280/50000 (3%)]\tLoss: 0.447272, Accuracy: 85.94\n",
      "Train Epoch: 20 [2560/50000 (6%)]\tLoss: 0.389417, Accuracy: 85.55\n",
      "Train Epoch: 20 [3840/50000 (9%)]\tLoss: 0.352729, Accuracy: 88.28\n",
      "Train Epoch: 20 [5120/50000 (11%)]\tLoss: 0.348976, Accuracy: 87.50\n",
      "Train Epoch: 20 [6400/50000 (14%)]\tLoss: 0.450162, Accuracy: 84.38\n",
      "Train Epoch: 20 [7680/50000 (17%)]\tLoss: 0.337762, Accuracy: 88.67\n",
      "Train Epoch: 20 [8960/50000 (20%)]\tLoss: 0.441109, Accuracy: 85.94\n",
      "Train Epoch: 20 [10240/50000 (23%)]\tLoss: 0.420692, Accuracy: 85.55\n",
      "Train Epoch: 20 [11520/50000 (26%)]\tLoss: 0.452796, Accuracy: 84.77\n",
      "Train Epoch: 20 [12800/50000 (28%)]\tLoss: 0.379005, Accuracy: 87.11\n",
      "Train Epoch: 20 [14080/50000 (31%)]\tLoss: 0.406403, Accuracy: 86.72\n",
      "Train Epoch: 20 [15360/50000 (34%)]\tLoss: 0.386355, Accuracy: 85.94\n",
      "Train Epoch: 20 [16640/50000 (37%)]\tLoss: 0.577031, Accuracy: 79.69\n",
      "Train Epoch: 20 [17920/50000 (40%)]\tLoss: 0.406710, Accuracy: 83.98\n",
      "Train Epoch: 20 [19200/50000 (43%)]\tLoss: 0.349352, Accuracy: 86.72\n",
      "Train Epoch: 20 [20480/50000 (45%)]\tLoss: 0.503725, Accuracy: 83.98\n",
      "Train Epoch: 20 [21760/50000 (48%)]\tLoss: 0.449795, Accuracy: 84.38\n",
      "Train Epoch: 20 [23040/50000 (51%)]\tLoss: 0.522546, Accuracy: 81.25\n",
      "Train Epoch: 20 [24320/50000 (54%)]\tLoss: 0.447243, Accuracy: 85.94\n",
      "Train Epoch: 20 [25600/50000 (57%)]\tLoss: 0.400667, Accuracy: 86.33\n",
      "Train Epoch: 20 [26880/50000 (60%)]\tLoss: 0.484019, Accuracy: 81.25\n",
      "Train Epoch: 20 [28160/50000 (62%)]\tLoss: 0.445113, Accuracy: 84.77\n",
      "Train Epoch: 20 [29440/50000 (65%)]\tLoss: 0.608654, Accuracy: 80.47\n",
      "Train Epoch: 20 [30720/50000 (68%)]\tLoss: 0.591013, Accuracy: 82.81\n",
      "Train Epoch: 20 [32000/50000 (71%)]\tLoss: 0.483886, Accuracy: 82.42\n",
      "Train Epoch: 20 [33280/50000 (74%)]\tLoss: 0.417542, Accuracy: 86.72\n",
      "Train Epoch: 20 [34560/50000 (77%)]\tLoss: 0.475177, Accuracy: 86.33\n",
      "torch.Size([512, 1, 1])\n",
      "tensor([[[ 8.5922e-02]],\n",
      "\n",
      "        [[ 6.7244e-01]],\n",
      "\n",
      "        [[-2.0659e-01]],\n",
      "\n",
      "        [[-8.1695e-01]],\n",
      "\n",
      "        [[-6.4264e-01]],\n",
      "\n",
      "        [[ 2.8415e-01]],\n",
      "\n",
      "        [[-7.0346e-01]],\n",
      "\n",
      "        [[ 1.8216e+00]],\n",
      "\n",
      "        [[ 2.6764e-01]],\n",
      "\n",
      "        [[-1.5322e+00]],\n",
      "\n",
      "        [[-1.1002e+00]],\n",
      "\n",
      "        [[-2.2647e-01]],\n",
      "\n",
      "        [[ 1.7350e-01]],\n",
      "\n",
      "        [[ 4.4901e-01]],\n",
      "\n",
      "        [[ 1.1082e-01]],\n",
      "\n",
      "        [[ 7.8982e-01]],\n",
      "\n",
      "        [[ 1.5762e+00]],\n",
      "\n",
      "        [[ 1.8679e-01]],\n",
      "\n",
      "        [[-2.8843e+00]],\n",
      "\n",
      "        [[-1.7395e+00]],\n",
      "\n",
      "        [[ 1.2033e-01]],\n",
      "\n",
      "        [[-7.8453e-01]],\n",
      "\n",
      "        [[ 3.6129e-01]],\n",
      "\n",
      "        [[-9.0549e-01]],\n",
      "\n",
      "        [[-1.4395e+00]],\n",
      "\n",
      "        [[ 1.1145e+00]],\n",
      "\n",
      "        [[-3.3289e-01]],\n",
      "\n",
      "        [[ 5.3617e-01]],\n",
      "\n",
      "        [[-1.7430e-01]],\n",
      "\n",
      "        [[ 2.3163e-01]],\n",
      "\n",
      "        [[ 6.7111e-02]],\n",
      "\n",
      "        [[ 4.2278e-02]],\n",
      "\n",
      "        [[-2.0324e+00]],\n",
      "\n",
      "        [[ 1.0912e+00]],\n",
      "\n",
      "        [[ 2.7790e-01]],\n",
      "\n",
      "        [[-2.0452e-01]],\n",
      "\n",
      "        [[-2.9026e-01]],\n",
      "\n",
      "        [[ 1.4360e+00]],\n",
      "\n",
      "        [[-1.1085e+00]],\n",
      "\n",
      "        [[ 1.0588e+00]],\n",
      "\n",
      "        [[ 1.7841e-01]],\n",
      "\n",
      "        [[-1.0526e+00]],\n",
      "\n",
      "        [[-1.4598e+00]],\n",
      "\n",
      "        [[ 7.4283e-01]],\n",
      "\n",
      "        [[-1.9662e+00]],\n",
      "\n",
      "        [[ 4.9298e-01]],\n",
      "\n",
      "        [[-5.8496e-01]],\n",
      "\n",
      "        [[-7.3414e-02]],\n",
      "\n",
      "        [[ 8.4347e-01]],\n",
      "\n",
      "        [[-4.4576e-01]],\n",
      "\n",
      "        [[-4.8972e-01]],\n",
      "\n",
      "        [[-1.0828e-01]],\n",
      "\n",
      "        [[-2.0819e+00]],\n",
      "\n",
      "        [[-3.4555e-01]],\n",
      "\n",
      "        [[-4.1585e-01]],\n",
      "\n",
      "        [[ 1.9528e-01]],\n",
      "\n",
      "        [[ 7.1641e-01]],\n",
      "\n",
      "        [[ 2.9607e+00]],\n",
      "\n",
      "        [[ 1.0622e+00]],\n",
      "\n",
      "        [[ 6.1427e-01]],\n",
      "\n",
      "        [[ 6.0830e-01]],\n",
      "\n",
      "        [[-8.9998e-01]],\n",
      "\n",
      "        [[ 4.3132e-03]],\n",
      "\n",
      "        [[-5.0322e-01]],\n",
      "\n",
      "        [[-4.9211e-01]],\n",
      "\n",
      "        [[-1.0677e+00]],\n",
      "\n",
      "        [[-2.8089e-01]],\n",
      "\n",
      "        [[ 2.8684e-01]],\n",
      "\n",
      "        [[-1.1815e+00]],\n",
      "\n",
      "        [[-6.8847e-01]],\n",
      "\n",
      "        [[ 2.1803e+00]],\n",
      "\n",
      "        [[ 9.3142e-01]],\n",
      "\n",
      "        [[ 7.4579e-01]],\n",
      "\n",
      "        [[ 3.0280e-01]],\n",
      "\n",
      "        [[ 6.3487e-01]],\n",
      "\n",
      "        [[-5.8104e-01]],\n",
      "\n",
      "        [[-4.3268e-01]],\n",
      "\n",
      "        [[ 1.9429e-01]],\n",
      "\n",
      "        [[-1.9583e+00]],\n",
      "\n",
      "        [[-2.0023e-01]],\n",
      "\n",
      "        [[-7.4620e-01]],\n",
      "\n",
      "        [[-1.8196e-01]],\n",
      "\n",
      "        [[ 8.3708e-01]],\n",
      "\n",
      "        [[ 1.1430e+00]],\n",
      "\n",
      "        [[-3.6742e-01]],\n",
      "\n",
      "        [[-1.4043e+00]],\n",
      "\n",
      "        [[ 2.8108e-01]],\n",
      "\n",
      "        [[-4.8923e-01]],\n",
      "\n",
      "        [[-1.5132e+00]],\n",
      "\n",
      "        [[ 2.2478e+00]],\n",
      "\n",
      "        [[-7.6176e-01]],\n",
      "\n",
      "        [[ 1.3631e-01]],\n",
      "\n",
      "        [[-6.7470e-01]],\n",
      "\n",
      "        [[ 1.4027e-01]],\n",
      "\n",
      "        [[ 4.9563e-01]],\n",
      "\n",
      "        [[ 1.2025e+00]],\n",
      "\n",
      "        [[-2.9219e-01]],\n",
      "\n",
      "        [[-8.8766e-01]],\n",
      "\n",
      "        [[ 1.9404e-01]],\n",
      "\n",
      "        [[ 2.4397e-01]],\n",
      "\n",
      "        [[-1.4842e+00]],\n",
      "\n",
      "        [[-1.2305e+00]],\n",
      "\n",
      "        [[ 7.9911e-01]],\n",
      "\n",
      "        [[-3.2632e-05]],\n",
      "\n",
      "        [[-3.1163e-01]],\n",
      "\n",
      "        [[-8.0494e-01]],\n",
      "\n",
      "        [[ 4.4754e-01]],\n",
      "\n",
      "        [[ 7.2797e-01]],\n",
      "\n",
      "        [[ 1.0512e+00]],\n",
      "\n",
      "        [[ 1.3627e+00]],\n",
      "\n",
      "        [[ 1.2283e+00]],\n",
      "\n",
      "        [[ 6.1740e-01]],\n",
      "\n",
      "        [[ 6.0262e-01]],\n",
      "\n",
      "        [[-2.1220e-03]],\n",
      "\n",
      "        [[-8.8153e-01]],\n",
      "\n",
      "        [[-1.7572e+00]],\n",
      "\n",
      "        [[-3.4083e-01]],\n",
      "\n",
      "        [[ 1.6255e-01]],\n",
      "\n",
      "        [[-8.4927e-01]],\n",
      "\n",
      "        [[-1.8462e+00]],\n",
      "\n",
      "        [[ 4.2625e-01]],\n",
      "\n",
      "        [[-2.6539e-01]],\n",
      "\n",
      "        [[-8.7303e-01]],\n",
      "\n",
      "        [[-1.8856e+00]],\n",
      "\n",
      "        [[-7.4941e-01]],\n",
      "\n",
      "        [[ 4.8347e-01]],\n",
      "\n",
      "        [[ 9.0544e-01]],\n",
      "\n",
      "        [[ 9.7801e-02]],\n",
      "\n",
      "        [[ 6.2650e-01]],\n",
      "\n",
      "        [[-7.9155e-01]],\n",
      "\n",
      "        [[-5.2464e-02]],\n",
      "\n",
      "        [[ 2.1460e+00]],\n",
      "\n",
      "        [[-1.9393e-01]],\n",
      "\n",
      "        [[ 1.0349e+00]],\n",
      "\n",
      "        [[ 1.4614e+00]],\n",
      "\n",
      "        [[-6.6801e-02]],\n",
      "\n",
      "        [[ 1.3294e+00]],\n",
      "\n",
      "        [[ 4.2903e-01]],\n",
      "\n",
      "        [[ 6.0128e-02]],\n",
      "\n",
      "        [[ 1.8739e+00]],\n",
      "\n",
      "        [[ 1.4844e+00]],\n",
      "\n",
      "        [[ 6.2418e-01]],\n",
      "\n",
      "        [[ 1.2829e-01]],\n",
      "\n",
      "        [[-1.3650e+00]],\n",
      "\n",
      "        [[-7.0722e-01]],\n",
      "\n",
      "        [[-7.8236e-01]],\n",
      "\n",
      "        [[-3.9716e-01]],\n",
      "\n",
      "        [[-1.3156e+00]],\n",
      "\n",
      "        [[-1.2305e+00]],\n",
      "\n",
      "        [[-6.2421e-01]],\n",
      "\n",
      "        [[ 7.2075e-01]],\n",
      "\n",
      "        [[ 1.5803e-01]],\n",
      "\n",
      "        [[ 6.8073e-01]],\n",
      "\n",
      "        [[ 3.5399e-02]],\n",
      "\n",
      "        [[-1.2250e+00]],\n",
      "\n",
      "        [[ 2.6086e-01]],\n",
      "\n",
      "        [[ 1.3630e+00]],\n",
      "\n",
      "        [[-1.6088e+00]],\n",
      "\n",
      "        [[ 4.4555e-01]],\n",
      "\n",
      "        [[ 1.5314e-01]],\n",
      "\n",
      "        [[-1.5681e+00]],\n",
      "\n",
      "        [[-6.9805e-01]],\n",
      "\n",
      "        [[ 2.2555e+00]],\n",
      "\n",
      "        [[-8.0170e-01]],\n",
      "\n",
      "        [[-6.5408e-01]],\n",
      "\n",
      "        [[ 2.6743e-01]],\n",
      "\n",
      "        [[ 1.0110e-01]],\n",
      "\n",
      "        [[-6.0598e-01]],\n",
      "\n",
      "        [[-6.3740e-01]],\n",
      "\n",
      "        [[ 4.6588e-01]],\n",
      "\n",
      "        [[ 1.3846e+00]],\n",
      "\n",
      "        [[ 4.8249e-01]],\n",
      "\n",
      "        [[ 9.5454e-01]],\n",
      "\n",
      "        [[-1.1512e+00]],\n",
      "\n",
      "        [[ 2.0708e+00]],\n",
      "\n",
      "        [[-9.7816e-01]],\n",
      "\n",
      "        [[-9.1743e-01]],\n",
      "\n",
      "        [[ 1.7739e+00]],\n",
      "\n",
      "        [[-2.2744e+00]],\n",
      "\n",
      "        [[-8.7178e-01]],\n",
      "\n",
      "        [[ 2.4007e-01]],\n",
      "\n",
      "        [[ 1.2873e+00]],\n",
      "\n",
      "        [[-1.4041e-01]],\n",
      "\n",
      "        [[-2.1347e+00]],\n",
      "\n",
      "        [[-2.5788e-01]],\n",
      "\n",
      "        [[-1.4482e+00]],\n",
      "\n",
      "        [[ 1.4539e-01]],\n",
      "\n",
      "        [[ 9.4020e-01]],\n",
      "\n",
      "        [[-1.2310e+00]],\n",
      "\n",
      "        [[-6.2905e-02]],\n",
      "\n",
      "        [[-1.6016e+00]],\n",
      "\n",
      "        [[-8.0971e-01]],\n",
      "\n",
      "        [[-1.5358e+00]],\n",
      "\n",
      "        [[ 9.3414e-01]],\n",
      "\n",
      "        [[ 7.3819e-01]],\n",
      "\n",
      "        [[ 5.1234e-01]],\n",
      "\n",
      "        [[ 4.3784e-01]],\n",
      "\n",
      "        [[ 5.3363e-02]],\n",
      "\n",
      "        [[-3.8048e-01]],\n",
      "\n",
      "        [[ 9.2639e-01]],\n",
      "\n",
      "        [[-7.8652e-01]],\n",
      "\n",
      "        [[ 4.7902e-01]],\n",
      "\n",
      "        [[-1.3576e+00]],\n",
      "\n",
      "        [[-2.9423e-01]],\n",
      "\n",
      "        [[ 1.3318e-02]],\n",
      "\n",
      "        [[-1.2013e+00]],\n",
      "\n",
      "        [[ 2.6298e-01]],\n",
      "\n",
      "        [[ 5.4459e-01]],\n",
      "\n",
      "        [[ 4.3405e-01]],\n",
      "\n",
      "        [[ 4.6549e-02]],\n",
      "\n",
      "        [[ 4.1211e-01]],\n",
      "\n",
      "        [[ 6.6833e-02]],\n",
      "\n",
      "        [[ 2.2827e+00]],\n",
      "\n",
      "        [[ 1.5609e-01]],\n",
      "\n",
      "        [[-6.9768e-01]],\n",
      "\n",
      "        [[ 5.2874e-01]],\n",
      "\n",
      "        [[ 1.3988e+00]],\n",
      "\n",
      "        [[-4.6180e-01]],\n",
      "\n",
      "        [[-4.7447e-01]],\n",
      "\n",
      "        [[-3.5938e-01]],\n",
      "\n",
      "        [[-1.7516e-01]],\n",
      "\n",
      "        [[-2.8796e-01]],\n",
      "\n",
      "        [[ 8.1087e-01]],\n",
      "\n",
      "        [[ 2.6995e-01]],\n",
      "\n",
      "        [[ 1.0333e+00]],\n",
      "\n",
      "        [[-8.8799e-02]],\n",
      "\n",
      "        [[ 1.3330e+00]],\n",
      "\n",
      "        [[-5.2954e-01]],\n",
      "\n",
      "        [[-8.2402e-02]],\n",
      "\n",
      "        [[ 9.5352e-01]],\n",
      "\n",
      "        [[ 3.0976e-01]],\n",
      "\n",
      "        [[ 1.6406e+00]],\n",
      "\n",
      "        [[ 1.1885e+00]],\n",
      "\n",
      "        [[ 8.2359e-01]],\n",
      "\n",
      "        [[-7.7658e-01]],\n",
      "\n",
      "        [[-3.4934e-01]],\n",
      "\n",
      "        [[-9.2479e-02]],\n",
      "\n",
      "        [[ 1.1967e+00]],\n",
      "\n",
      "        [[ 6.1422e-01]],\n",
      "\n",
      "        [[ 3.7841e-01]],\n",
      "\n",
      "        [[-1.0722e+00]],\n",
      "\n",
      "        [[ 7.8607e-01]],\n",
      "\n",
      "        [[-5.7178e-01]],\n",
      "\n",
      "        [[-3.0537e+00]],\n",
      "\n",
      "        [[ 3.4669e-01]],\n",
      "\n",
      "        [[-1.6677e+00]],\n",
      "\n",
      "        [[ 1.8953e-01]],\n",
      "\n",
      "        [[ 4.8814e-02]],\n",
      "\n",
      "        [[ 2.1580e-01]],\n",
      "\n",
      "        [[-1.3997e-01]],\n",
      "\n",
      "        [[-4.8089e-01]],\n",
      "\n",
      "        [[-9.0899e-01]],\n",
      "\n",
      "        [[ 4.8251e-01]],\n",
      "\n",
      "        [[-5.1199e-01]],\n",
      "\n",
      "        [[-2.2411e-01]],\n",
      "\n",
      "        [[ 1.0790e+00]],\n",
      "\n",
      "        [[-4.9135e-01]],\n",
      "\n",
      "        [[ 8.6218e-01]],\n",
      "\n",
      "        [[-3.5040e-01]],\n",
      "\n",
      "        [[ 7.0390e-01]],\n",
      "\n",
      "        [[-1.2135e+00]],\n",
      "\n",
      "        [[ 9.0389e-02]],\n",
      "\n",
      "        [[-4.5404e-01]],\n",
      "\n",
      "        [[-5.8970e-01]],\n",
      "\n",
      "        [[-5.0599e-01]],\n",
      "\n",
      "        [[-1.2359e-01]],\n",
      "\n",
      "        [[ 9.9791e-01]],\n",
      "\n",
      "        [[ 9.7478e-01]],\n",
      "\n",
      "        [[-5.4839e-01]],\n",
      "\n",
      "        [[ 3.8232e-01]],\n",
      "\n",
      "        [[ 1.0865e+00]],\n",
      "\n",
      "        [[-1.2968e+00]],\n",
      "\n",
      "        [[ 3.2475e-01]],\n",
      "\n",
      "        [[-7.0067e-01]],\n",
      "\n",
      "        [[ 1.3461e+00]],\n",
      "\n",
      "        [[ 1.6175e+00]],\n",
      "\n",
      "        [[-7.7523e-01]],\n",
      "\n",
      "        [[ 4.8942e-01]],\n",
      "\n",
      "        [[-1.2296e+00]],\n",
      "\n",
      "        [[ 1.0674e+00]],\n",
      "\n",
      "        [[-7.4003e-01]],\n",
      "\n",
      "        [[ 4.0542e-01]],\n",
      "\n",
      "        [[-1.4107e+00]],\n",
      "\n",
      "        [[ 7.9308e-01]],\n",
      "\n",
      "        [[ 1.1176e+00]],\n",
      "\n",
      "        [[-8.0115e-01]],\n",
      "\n",
      "        [[-2.8947e-01]],\n",
      "\n",
      "        [[ 2.5017e-01]],\n",
      "\n",
      "        [[-4.9001e-01]],\n",
      "\n",
      "        [[ 2.2348e-01]],\n",
      "\n",
      "        [[-1.8536e+00]],\n",
      "\n",
      "        [[-4.6188e-01]],\n",
      "\n",
      "        [[ 7.0196e-01]],\n",
      "\n",
      "        [[ 1.3886e+00]],\n",
      "\n",
      "        [[ 1.2494e+00]],\n",
      "\n",
      "        [[-8.5599e-01]],\n",
      "\n",
      "        [[ 8.5883e-02]],\n",
      "\n",
      "        [[-5.0830e-01]],\n",
      "\n",
      "        [[-6.0248e-01]],\n",
      "\n",
      "        [[ 1.5981e+00]],\n",
      "\n",
      "        [[ 7.5658e-01]],\n",
      "\n",
      "        [[ 3.9664e-01]],\n",
      "\n",
      "        [[ 2.8163e-01]],\n",
      "\n",
      "        [[-2.4331e-01]],\n",
      "\n",
      "        [[ 3.6110e-01]],\n",
      "\n",
      "        [[-5.2878e-01]],\n",
      "\n",
      "        [[-5.7034e-01]],\n",
      "\n",
      "        [[-1.7575e+00]],\n",
      "\n",
      "        [[ 1.7883e+00]],\n",
      "\n",
      "        [[-2.9090e-01]],\n",
      "\n",
      "        [[ 8.0704e-03]],\n",
      "\n",
      "        [[ 6.8191e-01]],\n",
      "\n",
      "        [[-6.4204e-01]],\n",
      "\n",
      "        [[-1.9529e+00]],\n",
      "\n",
      "        [[-5.2193e-01]],\n",
      "\n",
      "        [[-1.1139e-01]],\n",
      "\n",
      "        [[-3.2286e-01]],\n",
      "\n",
      "        [[-5.7612e-01]],\n",
      "\n",
      "        [[ 2.0899e+00]],\n",
      "\n",
      "        [[-8.8764e-01]],\n",
      "\n",
      "        [[ 9.8661e-01]],\n",
      "\n",
      "        [[-8.3859e-02]],\n",
      "\n",
      "        [[ 7.6982e-01]],\n",
      "\n",
      "        [[ 1.3894e+00]],\n",
      "\n",
      "        [[ 1.1831e-01]],\n",
      "\n",
      "        [[-8.9565e-01]],\n",
      "\n",
      "        [[ 8.8599e-01]],\n",
      "\n",
      "        [[-8.0500e-01]],\n",
      "\n",
      "        [[-1.2581e-01]],\n",
      "\n",
      "        [[ 1.8716e+00]],\n",
      "\n",
      "        [[-1.3723e+00]],\n",
      "\n",
      "        [[ 2.2841e-01]],\n",
      "\n",
      "        [[ 1.5695e-01]],\n",
      "\n",
      "        [[ 3.9044e-02]],\n",
      "\n",
      "        [[-3.9923e-01]],\n",
      "\n",
      "        [[ 7.5703e-01]],\n",
      "\n",
      "        [[-3.8647e-01]],\n",
      "\n",
      "        [[ 7.9144e-01]],\n",
      "\n",
      "        [[ 5.8724e-01]],\n",
      "\n",
      "        [[ 2.2348e-01]],\n",
      "\n",
      "        [[ 6.3613e-01]],\n",
      "\n",
      "        [[ 1.3357e+00]],\n",
      "\n",
      "        [[ 8.5447e-01]],\n",
      "\n",
      "        [[ 2.2936e+00]],\n",
      "\n",
      "        [[ 4.3967e-01]],\n",
      "\n",
      "        [[-6.7486e-01]],\n",
      "\n",
      "        [[-3.7177e-01]],\n",
      "\n",
      "        [[ 7.4022e-01]],\n",
      "\n",
      "        [[ 1.1065e+00]],\n",
      "\n",
      "        [[ 9.5826e-01]],\n",
      "\n",
      "        [[ 1.0011e+00]],\n",
      "\n",
      "        [[-2.1858e+00]],\n",
      "\n",
      "        [[ 3.6800e-01]],\n",
      "\n",
      "        [[-3.6920e-01]],\n",
      "\n",
      "        [[-1.6464e+00]],\n",
      "\n",
      "        [[-2.7106e+00]],\n",
      "\n",
      "        [[ 1.8528e-01]],\n",
      "\n",
      "        [[ 5.5845e-01]],\n",
      "\n",
      "        [[ 5.9743e-01]],\n",
      "\n",
      "        [[-8.1539e-01]],\n",
      "\n",
      "        [[ 1.1271e+00]],\n",
      "\n",
      "        [[-6.9080e-01]],\n",
      "\n",
      "        [[-4.3223e-01]],\n",
      "\n",
      "        [[-5.4512e-02]],\n",
      "\n",
      "        [[ 3.1391e-01]],\n",
      "\n",
      "        [[-2.2034e-01]],\n",
      "\n",
      "        [[ 8.2832e-01]],\n",
      "\n",
      "        [[-4.2793e-02]],\n",
      "\n",
      "        [[-3.3074e-02]],\n",
      "\n",
      "        [[ 3.2523e-01]],\n",
      "\n",
      "        [[-1.0757e-02]],\n",
      "\n",
      "        [[-8.3023e-01]],\n",
      "\n",
      "        [[-1.3567e-01]],\n",
      "\n",
      "        [[ 4.9027e-01]],\n",
      "\n",
      "        [[ 1.5338e+00]],\n",
      "\n",
      "        [[-8.3043e-01]],\n",
      "\n",
      "        [[-8.3431e-01]],\n",
      "\n",
      "        [[-7.1635e-01]],\n",
      "\n",
      "        [[ 8.8113e-01]],\n",
      "\n",
      "        [[ 7.8390e-02]],\n",
      "\n",
      "        [[ 1.5073e+00]],\n",
      "\n",
      "        [[ 9.2870e-01]],\n",
      "\n",
      "        [[-9.2187e-01]],\n",
      "\n",
      "        [[-4.8656e-02]],\n",
      "\n",
      "        [[-5.2294e-01]],\n",
      "\n",
      "        [[ 1.1710e+00]],\n",
      "\n",
      "        [[-1.0773e+00]],\n",
      "\n",
      "        [[-1.5019e+00]],\n",
      "\n",
      "        [[ 7.9201e-01]],\n",
      "\n",
      "        [[-1.1195e+00]],\n",
      "\n",
      "        [[-1.9418e+00]],\n",
      "\n",
      "        [[ 1.6724e+00]],\n",
      "\n",
      "        [[-1.1167e+00]],\n",
      "\n",
      "        [[ 8.9164e-01]],\n",
      "\n",
      "        [[-5.5195e-01]],\n",
      "\n",
      "        [[ 4.7103e-01]],\n",
      "\n",
      "        [[ 5.3656e-01]],\n",
      "\n",
      "        [[-5.2527e-01]],\n",
      "\n",
      "        [[ 7.6522e-01]],\n",
      "\n",
      "        [[-2.3368e+00]],\n",
      "\n",
      "        [[-5.6738e-01]],\n",
      "\n",
      "        [[ 2.2553e-01]],\n",
      "\n",
      "        [[ 1.9553e+00]],\n",
      "\n",
      "        [[ 2.0523e-01]],\n",
      "\n",
      "        [[-5.7284e-02]],\n",
      "\n",
      "        [[-8.2986e-01]],\n",
      "\n",
      "        [[ 8.5411e-02]],\n",
      "\n",
      "        [[-8.3201e-01]],\n",
      "\n",
      "        [[ 1.0087e+00]],\n",
      "\n",
      "        [[ 4.6810e-01]],\n",
      "\n",
      "        [[-4.1872e-01]],\n",
      "\n",
      "        [[-2.2200e-01]],\n",
      "\n",
      "        [[-6.7198e-01]],\n",
      "\n",
      "        [[-1.0866e-01]],\n",
      "\n",
      "        [[ 8.5390e-01]],\n",
      "\n",
      "        [[ 4.0453e-01]],\n",
      "\n",
      "        [[ 1.3180e+00]],\n",
      "\n",
      "        [[ 2.9496e-02]],\n",
      "\n",
      "        [[-4.3731e-01]],\n",
      "\n",
      "        [[-2.3867e+00]],\n",
      "\n",
      "        [[ 2.1186e-01]],\n",
      "\n",
      "        [[ 1.4758e-01]],\n",
      "\n",
      "        [[ 1.4718e-01]],\n",
      "\n",
      "        [[ 4.4556e-01]],\n",
      "\n",
      "        [[-4.8970e-01]],\n",
      "\n",
      "        [[ 7.2521e-01]],\n",
      "\n",
      "        [[ 4.7801e-01]],\n",
      "\n",
      "        [[-1.6366e+00]],\n",
      "\n",
      "        [[-1.6932e+00]],\n",
      "\n",
      "        [[ 1.0353e+00]],\n",
      "\n",
      "        [[ 1.5152e+00]],\n",
      "\n",
      "        [[-1.7696e+00]],\n",
      "\n",
      "        [[-1.2283e+00]],\n",
      "\n",
      "        [[-6.0754e-01]],\n",
      "\n",
      "        [[ 8.8732e-01]],\n",
      "\n",
      "        [[ 3.3905e-01]],\n",
      "\n",
      "        [[-2.7729e-01]],\n",
      "\n",
      "        [[ 6.9381e-01]],\n",
      "\n",
      "        [[-6.3383e-01]],\n",
      "\n",
      "        [[-2.0326e+00]],\n",
      "\n",
      "        [[ 9.0304e-01]],\n",
      "\n",
      "        [[ 9.0727e-01]],\n",
      "\n",
      "        [[-7.3027e-01]],\n",
      "\n",
      "        [[-4.4615e-01]],\n",
      "\n",
      "        [[-9.3515e-01]],\n",
      "\n",
      "        [[-1.1596e+00]],\n",
      "\n",
      "        [[ 1.1288e+00]],\n",
      "\n",
      "        [[ 1.1190e+00]],\n",
      "\n",
      "        [[-1.6474e+00]],\n",
      "\n",
      "        [[ 1.1261e+00]],\n",
      "\n",
      "        [[-1.3182e+00]],\n",
      "\n",
      "        [[ 7.7097e-01]],\n",
      "\n",
      "        [[ 4.0964e-01]],\n",
      "\n",
      "        [[-9.3309e-01]],\n",
      "\n",
      "        [[-4.7663e-01]],\n",
      "\n",
      "        [[-7.7160e-01]],\n",
      "\n",
      "        [[-1.1017e+00]],\n",
      "\n",
      "        [[ 1.3668e+00]],\n",
      "\n",
      "        [[-3.9478e-01]],\n",
      "\n",
      "        [[ 4.5610e-01]],\n",
      "\n",
      "        [[ 6.6710e-01]],\n",
      "\n",
      "        [[ 9.3902e-02]],\n",
      "\n",
      "        [[ 1.0167e+00]],\n",
      "\n",
      "        [[-2.7642e-01]],\n",
      "\n",
      "        [[-1.9570e+00]],\n",
      "\n",
      "        [[ 6.2593e-01]],\n",
      "\n",
      "        [[-2.9893e-01]],\n",
      "\n",
      "        [[-4.0570e-01]],\n",
      "\n",
      "        [[-4.1961e-02]],\n",
      "\n",
      "        [[ 1.5703e+00]],\n",
      "\n",
      "        [[-6.3994e-01]],\n",
      "\n",
      "        [[-1.7635e+00]],\n",
      "\n",
      "        [[-4.9864e-01]],\n",
      "\n",
      "        [[-1.4920e+00]],\n",
      "\n",
      "        [[-7.2084e-01]],\n",
      "\n",
      "        [[ 4.2465e-01]],\n",
      "\n",
      "        [[-9.1938e-01]],\n",
      "\n",
      "        [[-1.2181e+00]],\n",
      "\n",
      "        [[ 4.5443e-01]],\n",
      "\n",
      "        [[-4.5410e-02]],\n",
      "\n",
      "        [[-9.7195e-01]],\n",
      "\n",
      "        [[ 2.3000e+00]],\n",
      "\n",
      "        [[ 4.1647e-01]],\n",
      "\n",
      "        [[-1.9387e-01]],\n",
      "\n",
      "        [[ 6.0237e-01]],\n",
      "\n",
      "        [[ 1.0416e+00]],\n",
      "\n",
      "        [[-2.5125e+00]],\n",
      "\n",
      "        [[ 9.3906e-01]],\n",
      "\n",
      "        [[ 3.3553e-01]],\n",
      "\n",
      "        [[ 6.0162e-01]],\n",
      "\n",
      "        [[ 2.4660e-01]],\n",
      "\n",
      "        [[ 1.7930e+00]],\n",
      "\n",
      "        [[ 1.4977e+00]],\n",
      "\n",
      "        [[ 9.2054e-01]],\n",
      "\n",
      "        [[-4.6843e-01]],\n",
      "\n",
      "        [[-9.8941e-01]],\n",
      "\n",
      "        [[ 3.5690e-01]],\n",
      "\n",
      "        [[ 2.4196e-02]],\n",
      "\n",
      "        [[-7.7082e-01]],\n",
      "\n",
      "        [[-9.3353e-01]],\n",
      "\n",
      "        [[ 1.3481e+00]],\n",
      "\n",
      "        [[-2.1124e-01]],\n",
      "\n",
      "        [[-3.9250e-01]],\n",
      "\n",
      "        [[-8.8492e-01]],\n",
      "\n",
      "        [[-1.1347e+00]],\n",
      "\n",
      "        [[ 2.1729e+00]],\n",
      "\n",
      "        [[-1.2692e+00]],\n",
      "\n",
      "        [[-7.9363e-03]],\n",
      "\n",
      "        [[-1.0955e+00]],\n",
      "\n",
      "        [[ 8.8766e-02]],\n",
      "\n",
      "        [[ 6.8854e-02]],\n",
      "\n",
      "        [[ 5.1445e-01]]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[[ 0.1544]]], device='cuda:0')\n",
      "torch.Size([1, 896, 512])\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 1.9204,  1.9427,  1.9444,  ...,  1.9808,  1.9774,  1.9293],\n",
      "         [ 1.9068,  1.9430,  1.9672,  ...,  1.9437,  1.9346,  1.9361],\n",
      "         [ 1.9661,  1.9854,  1.9509,  ...,  1.9373,  1.9489,  1.9799],\n",
      "         ...,\n",
      "         [ 1.9511,  1.9646,  1.9321,  ...,  1.9518,  1.9114,  1.9370],\n",
      "         [ 1.9573,  1.9918,  1.9496,  ...,  1.9848,  1.9790,  1.9529],\n",
      "         [ 1.9743,  1.9430,  1.9317,  ...,  1.9590,  1.9396,  1.9477]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [35840/50000 (80%)]\tLoss: 0.437083, Accuracy: 85.55\n",
      "Train Epoch: 20 [37120/50000 (82%)]\tLoss: 0.501975, Accuracy: 81.25\n",
      "Train Epoch: 20 [38400/50000 (85%)]\tLoss: 0.511496, Accuracy: 82.03\n",
      "Train Epoch: 20 [39680/50000 (88%)]\tLoss: 0.480808, Accuracy: 82.42\n",
      "Train Epoch: 20 [40960/50000 (91%)]\tLoss: 0.447748, Accuracy: 85.55\n",
      "Train Epoch: 20 [42240/50000 (94%)]\tLoss: 0.421141, Accuracy: 87.50\n",
      "Train Epoch: 20 [43520/50000 (97%)]\tLoss: 0.455027, Accuracy: 85.55\n",
      "Train Epoch: 20 [35000/50000 (99%)]\tLoss: 0.411448, Accuracy: 86.00\n",
      "\n",
      "Validation set: Average loss: 0.6929, Accuracy: 3879/5000 (77.00%)\n",
      "\n",
      "the time of this epoch:[37.1706805229187 s]\n",
      "\n",
      "Test set: Average loss: 0.7072, Accuracy: 7746/10000 (77.46%)\n",
      "\n",
      "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.395908, Accuracy: 87.89\n",
      "Train Epoch: 21 [1280/50000 (3%)]\tLoss: 0.406675, Accuracy: 85.94\n",
      "Train Epoch: 21 [2560/50000 (6%)]\tLoss: 0.356312, Accuracy: 87.89\n",
      "Train Epoch: 21 [3840/50000 (9%)]\tLoss: 0.429910, Accuracy: 83.59\n",
      "Train Epoch: 21 [5120/50000 (11%)]\tLoss: 0.418308, Accuracy: 87.50\n",
      "Train Epoch: 21 [6400/50000 (14%)]\tLoss: 0.329110, Accuracy: 88.67\n",
      "Train Epoch: 21 [7680/50000 (17%)]\tLoss: 0.517967, Accuracy: 81.25\n",
      "Train Epoch: 21 [8960/50000 (20%)]\tLoss: 0.382328, Accuracy: 87.89\n",
      "Train Epoch: 21 [10240/50000 (23%)]\tLoss: 0.455195, Accuracy: 84.77\n",
      "Train Epoch: 21 [11520/50000 (26%)]\tLoss: 0.514457, Accuracy: 82.03\n",
      "Train Epoch: 21 [12800/50000 (28%)]\tLoss: 0.473657, Accuracy: 82.81\n",
      "Train Epoch: 21 [14080/50000 (31%)]\tLoss: 0.424141, Accuracy: 86.72\n",
      "Train Epoch: 21 [15360/50000 (34%)]\tLoss: 0.461581, Accuracy: 84.77\n",
      "Train Epoch: 21 [16640/50000 (37%)]\tLoss: 0.388087, Accuracy: 87.11\n",
      "Train Epoch: 21 [17920/50000 (40%)]\tLoss: 0.399053, Accuracy: 87.50\n",
      "Train Epoch: 21 [19200/50000 (43%)]\tLoss: 0.362688, Accuracy: 89.45\n",
      "Train Epoch: 21 [20480/50000 (45%)]\tLoss: 0.570479, Accuracy: 81.25\n",
      "Train Epoch: 21 [21760/50000 (48%)]\tLoss: 0.459546, Accuracy: 83.20\n",
      "Train Epoch: 21 [23040/50000 (51%)]\tLoss: 0.449322, Accuracy: 84.38\n",
      "Train Epoch: 21 [24320/50000 (54%)]\tLoss: 0.420245, Accuracy: 85.16\n",
      "Train Epoch: 21 [25600/50000 (57%)]\tLoss: 0.449263, Accuracy: 85.94\n",
      "Train Epoch: 21 [26880/50000 (60%)]\tLoss: 0.502733, Accuracy: 83.98\n",
      "Train Epoch: 21 [28160/50000 (62%)]\tLoss: 0.517156, Accuracy: 83.20\n",
      "Train Epoch: 21 [29440/50000 (65%)]\tLoss: 0.487413, Accuracy: 80.86\n",
      "Train Epoch: 21 [30720/50000 (68%)]\tLoss: 0.529906, Accuracy: 82.81\n",
      "Train Epoch: 21 [32000/50000 (71%)]\tLoss: 0.478376, Accuracy: 83.59\n",
      "Train Epoch: 21 [33280/50000 (74%)]\tLoss: 0.564445, Accuracy: 82.03\n",
      "Train Epoch: 21 [34560/50000 (77%)]\tLoss: 0.424362, Accuracy: 87.50\n",
      "Train Epoch: 21 [35840/50000 (80%)]\tLoss: 0.535429, Accuracy: 82.81\n",
      "Train Epoch: 21 [37120/50000 (82%)]\tLoss: 0.451784, Accuracy: 83.98\n",
      "Train Epoch: 21 [38400/50000 (85%)]\tLoss: 0.500475, Accuracy: 83.98\n",
      "Train Epoch: 21 [39680/50000 (88%)]\tLoss: 0.414325, Accuracy: 84.38\n",
      "Train Epoch: 21 [40960/50000 (91%)]\tLoss: 0.525555, Accuracy: 83.59\n",
      "Train Epoch: 21 [42240/50000 (94%)]\tLoss: 0.482135, Accuracy: 83.20\n",
      "Train Epoch: 21 [43520/50000 (97%)]\tLoss: 0.467302, Accuracy: 84.77\n",
      "Train Epoch: 21 [35000/50000 (99%)]\tLoss: 0.433535, Accuracy: 85.00\n",
      "\n",
      "Validation set: Average loss: 0.6583, Accuracy: 3941/5000 (78.00%)\n",
      "\n",
      "the time of this epoch:[40.31634187698364 s]\n",
      "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.360950, Accuracy: 87.50\n",
      "Train Epoch: 22 [1280/50000 (3%)]\tLoss: 0.352531, Accuracy: 87.11\n",
      "Train Epoch: 22 [2560/50000 (6%)]\tLoss: 0.422615, Accuracy: 86.72\n",
      "Train Epoch: 22 [3840/50000 (9%)]\tLoss: 0.701611, Accuracy: 79.30\n",
      "Train Epoch: 22 [5120/50000 (11%)]\tLoss: 0.376116, Accuracy: 87.50\n",
      "Train Epoch: 22 [6400/50000 (14%)]\tLoss: 0.443335, Accuracy: 84.38\n",
      "Train Epoch: 22 [7680/50000 (17%)]\tLoss: 0.589950, Accuracy: 76.95\n",
      "Train Epoch: 22 [8960/50000 (20%)]\tLoss: 0.476393, Accuracy: 79.69\n",
      "Train Epoch: 22 [10240/50000 (23%)]\tLoss: 0.457552, Accuracy: 84.38\n",
      "Train Epoch: 22 [11520/50000 (26%)]\tLoss: 0.486716, Accuracy: 82.81\n",
      "Train Epoch: 22 [12800/50000 (28%)]\tLoss: 0.489128, Accuracy: 80.86\n",
      "Train Epoch: 22 [14080/50000 (31%)]\tLoss: 0.382945, Accuracy: 86.33\n",
      "Train Epoch: 22 [15360/50000 (34%)]\tLoss: 0.412441, Accuracy: 85.55\n",
      "Train Epoch: 22 [16640/50000 (37%)]\tLoss: 0.404031, Accuracy: 89.45\n",
      "Train Epoch: 22 [17920/50000 (40%)]\tLoss: 0.435485, Accuracy: 86.33\n",
      "Train Epoch: 22 [19200/50000 (43%)]\tLoss: 0.504300, Accuracy: 84.38\n",
      "Train Epoch: 22 [20480/50000 (45%)]\tLoss: 0.286532, Accuracy: 89.84\n",
      "Train Epoch: 22 [21760/50000 (48%)]\tLoss: 0.349877, Accuracy: 86.72\n",
      "Train Epoch: 22 [23040/50000 (51%)]\tLoss: 0.345219, Accuracy: 90.23\n",
      "Train Epoch: 22 [24320/50000 (54%)]\tLoss: 0.387875, Accuracy: 89.06\n",
      "Train Epoch: 22 [25600/50000 (57%)]\tLoss: 0.390458, Accuracy: 86.33\n",
      "Train Epoch: 22 [26880/50000 (60%)]\tLoss: 0.556158, Accuracy: 83.98\n",
      "Train Epoch: 22 [28160/50000 (62%)]\tLoss: 0.635318, Accuracy: 80.08\n",
      "Train Epoch: 22 [29440/50000 (65%)]\tLoss: 0.456161, Accuracy: 84.38\n",
      "Train Epoch: 22 [30720/50000 (68%)]\tLoss: 0.377445, Accuracy: 86.33\n",
      "Train Epoch: 22 [32000/50000 (71%)]\tLoss: 0.463483, Accuracy: 81.25\n",
      "Train Epoch: 22 [33280/50000 (74%)]\tLoss: 0.386836, Accuracy: 88.28\n",
      "Train Epoch: 22 [34560/50000 (77%)]\tLoss: 0.457118, Accuracy: 82.81\n",
      "Train Epoch: 22 [35840/50000 (80%)]\tLoss: 0.329053, Accuracy: 90.23\n",
      "Train Epoch: 22 [37120/50000 (82%)]\tLoss: 0.543196, Accuracy: 83.59\n",
      "Train Epoch: 22 [38400/50000 (85%)]\tLoss: 0.428821, Accuracy: 85.94\n",
      "Train Epoch: 22 [39680/50000 (88%)]\tLoss: 0.374636, Accuracy: 85.94\n",
      "Train Epoch: 22 [40960/50000 (91%)]\tLoss: 0.490533, Accuracy: 83.59\n",
      "Train Epoch: 22 [42240/50000 (94%)]\tLoss: 0.341050, Accuracy: 87.11\n",
      "Train Epoch: 22 [43520/50000 (97%)]\tLoss: 0.395562, Accuracy: 87.11\n",
      "Train Epoch: 22 [35000/50000 (99%)]\tLoss: 0.355425, Accuracy: 87.50\n",
      "\n",
      "Validation set: Average loss: 0.7433, Accuracy: 3842/5000 (76.00%)\n",
      "\n",
      "the time of this epoch:[37.096091747283936 s]\n",
      "\n",
      "Test set: Average loss: 0.7842, Accuracy: 7522/10000 (75.22%)\n",
      "\n",
      "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.504351, Accuracy: 84.77\n",
      "Train Epoch: 23 [1280/50000 (3%)]\tLoss: 0.358870, Accuracy: 88.67\n",
      "Train Epoch: 23 [2560/50000 (6%)]\tLoss: 0.401196, Accuracy: 87.89\n",
      "Train Epoch: 23 [3840/50000 (9%)]\tLoss: 0.421375, Accuracy: 85.94\n",
      "Train Epoch: 23 [5120/50000 (11%)]\tLoss: 0.456311, Accuracy: 84.38\n",
      "Train Epoch: 23 [6400/50000 (14%)]\tLoss: 0.428708, Accuracy: 83.98\n",
      "Train Epoch: 23 [7680/50000 (17%)]\tLoss: 0.564076, Accuracy: 82.81\n",
      "Train Epoch: 23 [8960/50000 (20%)]\tLoss: 0.477898, Accuracy: 84.77\n",
      "Train Epoch: 23 [10240/50000 (23%)]\tLoss: 0.414070, Accuracy: 86.33\n",
      "Train Epoch: 23 [11520/50000 (26%)]\tLoss: 0.383870, Accuracy: 88.28\n",
      "Train Epoch: 23 [12800/50000 (28%)]\tLoss: 0.368622, Accuracy: 87.11\n",
      "Train Epoch: 23 [14080/50000 (31%)]\tLoss: 0.412304, Accuracy: 83.98\n",
      "Train Epoch: 23 [15360/50000 (34%)]\tLoss: 0.406972, Accuracy: 87.11\n",
      "Train Epoch: 23 [16640/50000 (37%)]\tLoss: 0.384552, Accuracy: 87.11\n",
      "Train Epoch: 23 [17920/50000 (40%)]\tLoss: 0.441109, Accuracy: 85.16\n",
      "Train Epoch: 23 [19200/50000 (43%)]\tLoss: 0.397234, Accuracy: 84.77\n",
      "Train Epoch: 23 [20480/50000 (45%)]\tLoss: 0.410075, Accuracy: 87.89\n",
      "Train Epoch: 23 [21760/50000 (48%)]\tLoss: 0.424700, Accuracy: 85.94\n",
      "Train Epoch: 23 [23040/50000 (51%)]\tLoss: 0.501759, Accuracy: 83.59\n",
      "Train Epoch: 23 [24320/50000 (54%)]\tLoss: 0.378420, Accuracy: 85.94\n",
      "Train Epoch: 23 [25600/50000 (57%)]\tLoss: 0.428026, Accuracy: 86.33\n",
      "Train Epoch: 23 [26880/50000 (60%)]\tLoss: 0.480088, Accuracy: 84.77\n",
      "Train Epoch: 23 [28160/50000 (62%)]\tLoss: 0.444429, Accuracy: 85.16\n",
      "Train Epoch: 23 [29440/50000 (65%)]\tLoss: 0.317319, Accuracy: 90.23\n",
      "Train Epoch: 23 [30720/50000 (68%)]\tLoss: 0.437228, Accuracy: 84.38\n",
      "Train Epoch: 23 [32000/50000 (71%)]\tLoss: 0.414744, Accuracy: 83.59\n",
      "Train Epoch: 23 [33280/50000 (74%)]\tLoss: 0.430921, Accuracy: 84.38\n",
      "Train Epoch: 23 [34560/50000 (77%)]\tLoss: 0.452506, Accuracy: 83.98\n",
      "Train Epoch: 23 [35840/50000 (80%)]\tLoss: 0.324938, Accuracy: 87.50\n",
      "Train Epoch: 23 [37120/50000 (82%)]\tLoss: 0.429976, Accuracy: 85.16\n",
      "Train Epoch: 23 [38400/50000 (85%)]\tLoss: 0.427480, Accuracy: 83.59\n",
      "Train Epoch: 23 [39680/50000 (88%)]\tLoss: 0.430154, Accuracy: 84.38\n",
      "Train Epoch: 23 [40960/50000 (91%)]\tLoss: 0.482509, Accuracy: 83.20\n",
      "Train Epoch: 23 [42240/50000 (94%)]\tLoss: 0.425270, Accuracy: 83.98\n",
      "Train Epoch: 23 [43520/50000 (97%)]\tLoss: 0.433571, Accuracy: 85.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23 [35000/50000 (99%)]\tLoss: 0.461930, Accuracy: 87.00\n",
      "\n",
      "Validation set: Average loss: 0.6951, Accuracy: 3861/5000 (77.00%)\n",
      "\n",
      "the time of this epoch:[40.302571058273315 s]\n",
      "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.481626, Accuracy: 83.20\n",
      "Train Epoch: 24 [1280/50000 (3%)]\tLoss: 0.409597, Accuracy: 85.94\n",
      "Train Epoch: 24 [2560/50000 (6%)]\tLoss: 0.551067, Accuracy: 82.81\n",
      "Train Epoch: 24 [3840/50000 (9%)]\tLoss: 0.499101, Accuracy: 83.59\n",
      "Train Epoch: 24 [5120/50000 (11%)]\tLoss: 0.421533, Accuracy: 83.59\n",
      "Train Epoch: 24 [6400/50000 (14%)]\tLoss: 0.492672, Accuracy: 84.77\n",
      "Train Epoch: 24 [7680/50000 (17%)]\tLoss: 0.402756, Accuracy: 85.94\n",
      "Train Epoch: 24 [8960/50000 (20%)]\tLoss: 0.445505, Accuracy: 88.67\n",
      "Train Epoch: 24 [10240/50000 (23%)]\tLoss: 0.449359, Accuracy: 85.16\n",
      "Train Epoch: 24 [11520/50000 (26%)]\tLoss: 0.400743, Accuracy: 85.94\n",
      "Train Epoch: 24 [12800/50000 (28%)]\tLoss: 0.333999, Accuracy: 89.06\n",
      "Train Epoch: 24 [14080/50000 (31%)]\tLoss: 0.377827, Accuracy: 87.89\n",
      "Train Epoch: 24 [15360/50000 (34%)]\tLoss: 0.348768, Accuracy: 89.06\n",
      "Train Epoch: 24 [16640/50000 (37%)]\tLoss: 0.463428, Accuracy: 86.72\n",
      "Train Epoch: 24 [17920/50000 (40%)]\tLoss: 0.351560, Accuracy: 86.72\n",
      "Train Epoch: 24 [19200/50000 (43%)]\tLoss: 0.446513, Accuracy: 85.55\n",
      "Train Epoch: 24 [20480/50000 (45%)]\tLoss: 0.509909, Accuracy: 84.77\n",
      "Train Epoch: 24 [21760/50000 (48%)]\tLoss: 0.491183, Accuracy: 81.64\n",
      "Train Epoch: 24 [23040/50000 (51%)]\tLoss: 0.362067, Accuracy: 87.50\n",
      "Train Epoch: 24 [24320/50000 (54%)]\tLoss: 0.388060, Accuracy: 86.33\n",
      "Train Epoch: 24 [25600/50000 (57%)]\tLoss: 0.379379, Accuracy: 86.72\n",
      "Train Epoch: 24 [26880/50000 (60%)]\tLoss: 0.399810, Accuracy: 87.50\n",
      "Train Epoch: 24 [28160/50000 (62%)]\tLoss: 0.298669, Accuracy: 88.28\n",
      "Train Epoch: 24 [29440/50000 (65%)]\tLoss: 0.408903, Accuracy: 85.55\n",
      "torch.Size([512, 1, 1])\n",
      "tensor([[[-0.7500]],\n",
      "\n",
      "        [[ 1.7757]],\n",
      "\n",
      "        [[-0.2447]],\n",
      "\n",
      "        [[ 1.2007]],\n",
      "\n",
      "        [[ 0.7898]],\n",
      "\n",
      "        [[-0.8161]],\n",
      "\n",
      "        [[-0.8277]],\n",
      "\n",
      "        [[ 0.9550]],\n",
      "\n",
      "        [[-0.1314]],\n",
      "\n",
      "        [[ 0.5607]],\n",
      "\n",
      "        [[-0.3951]],\n",
      "\n",
      "        [[ 1.4989]],\n",
      "\n",
      "        [[ 1.2798]],\n",
      "\n",
      "        [[ 0.6412]],\n",
      "\n",
      "        [[-1.7151]],\n",
      "\n",
      "        [[-0.4931]],\n",
      "\n",
      "        [[ 0.9209]],\n",
      "\n",
      "        [[-0.0922]],\n",
      "\n",
      "        [[ 0.3166]],\n",
      "\n",
      "        [[-0.9081]],\n",
      "\n",
      "        [[ 0.0163]],\n",
      "\n",
      "        [[-1.4523]],\n",
      "\n",
      "        [[-1.4563]],\n",
      "\n",
      "        [[-0.1483]],\n",
      "\n",
      "        [[-1.4417]],\n",
      "\n",
      "        [[-1.5481]],\n",
      "\n",
      "        [[-0.2514]],\n",
      "\n",
      "        [[-0.2357]],\n",
      "\n",
      "        [[-0.0408]],\n",
      "\n",
      "        [[ 0.1781]],\n",
      "\n",
      "        [[-0.2509]],\n",
      "\n",
      "        [[ 0.8349]],\n",
      "\n",
      "        [[ 1.0053]],\n",
      "\n",
      "        [[ 0.4774]],\n",
      "\n",
      "        [[-0.3532]],\n",
      "\n",
      "        [[-0.0923]],\n",
      "\n",
      "        [[-0.1308]],\n",
      "\n",
      "        [[ 0.8887]],\n",
      "\n",
      "        [[ 0.5028]],\n",
      "\n",
      "        [[-1.6974]],\n",
      "\n",
      "        [[ 1.0484]],\n",
      "\n",
      "        [[-0.0232]],\n",
      "\n",
      "        [[ 0.2709]],\n",
      "\n",
      "        [[ 0.0062]],\n",
      "\n",
      "        [[-1.5383]],\n",
      "\n",
      "        [[-0.4586]],\n",
      "\n",
      "        [[ 2.4908]],\n",
      "\n",
      "        [[-0.2955]],\n",
      "\n",
      "        [[-0.0343]],\n",
      "\n",
      "        [[ 1.1678]],\n",
      "\n",
      "        [[-0.2609]],\n",
      "\n",
      "        [[ 0.8042]],\n",
      "\n",
      "        [[ 0.3066]],\n",
      "\n",
      "        [[-1.2787]],\n",
      "\n",
      "        [[ 1.6979]],\n",
      "\n",
      "        [[-0.4254]],\n",
      "\n",
      "        [[ 0.9469]],\n",
      "\n",
      "        [[-0.1562]],\n",
      "\n",
      "        [[-1.3248]],\n",
      "\n",
      "        [[ 1.7712]],\n",
      "\n",
      "        [[ 0.1677]],\n",
      "\n",
      "        [[ 0.4694]],\n",
      "\n",
      "        [[-0.3115]],\n",
      "\n",
      "        [[ 0.1000]],\n",
      "\n",
      "        [[-0.1882]],\n",
      "\n",
      "        [[-0.1466]],\n",
      "\n",
      "        [[ 0.4784]],\n",
      "\n",
      "        [[-2.8029]],\n",
      "\n",
      "        [[ 0.8062]],\n",
      "\n",
      "        [[-0.0642]],\n",
      "\n",
      "        [[ 0.3272]],\n",
      "\n",
      "        [[ 0.9183]],\n",
      "\n",
      "        [[-1.4048]],\n",
      "\n",
      "        [[ 0.4003]],\n",
      "\n",
      "        [[-0.8051]],\n",
      "\n",
      "        [[-0.5893]],\n",
      "\n",
      "        [[-0.6832]],\n",
      "\n",
      "        [[ 0.6667]],\n",
      "\n",
      "        [[ 0.3496]],\n",
      "\n",
      "        [[-0.9589]],\n",
      "\n",
      "        [[-2.1612]],\n",
      "\n",
      "        [[-0.3349]],\n",
      "\n",
      "        [[-0.1710]],\n",
      "\n",
      "        [[ 0.1005]],\n",
      "\n",
      "        [[-1.7190]],\n",
      "\n",
      "        [[ 0.4795]],\n",
      "\n",
      "        [[ 1.1611]],\n",
      "\n",
      "        [[ 0.7346]],\n",
      "\n",
      "        [[-0.8167]],\n",
      "\n",
      "        [[-0.4318]],\n",
      "\n",
      "        [[-0.4750]],\n",
      "\n",
      "        [[-1.0436]],\n",
      "\n",
      "        [[ 0.3674]],\n",
      "\n",
      "        [[ 0.9683]],\n",
      "\n",
      "        [[-0.3780]],\n",
      "\n",
      "        [[ 0.9683]],\n",
      "\n",
      "        [[ 0.1092]],\n",
      "\n",
      "        [[-1.5988]],\n",
      "\n",
      "        [[ 1.2766]],\n",
      "\n",
      "        [[-0.4096]],\n",
      "\n",
      "        [[-0.2914]],\n",
      "\n",
      "        [[ 0.6846]],\n",
      "\n",
      "        [[ 0.2211]],\n",
      "\n",
      "        [[ 0.3605]],\n",
      "\n",
      "        [[-0.1580]],\n",
      "\n",
      "        [[ 1.4127]],\n",
      "\n",
      "        [[ 0.5785]],\n",
      "\n",
      "        [[-1.9812]],\n",
      "\n",
      "        [[ 0.6732]],\n",
      "\n",
      "        [[ 0.6945]],\n",
      "\n",
      "        [[-1.2033]],\n",
      "\n",
      "        [[-2.2490]],\n",
      "\n",
      "        [[ 0.6356]],\n",
      "\n",
      "        [[-0.9789]],\n",
      "\n",
      "        [[ 0.2578]],\n",
      "\n",
      "        [[ 0.5987]],\n",
      "\n",
      "        [[ 1.8293]],\n",
      "\n",
      "        [[ 0.3437]],\n",
      "\n",
      "        [[-1.4050]],\n",
      "\n",
      "        [[-0.2131]],\n",
      "\n",
      "        [[-0.6879]],\n",
      "\n",
      "        [[-0.2582]],\n",
      "\n",
      "        [[ 0.4918]],\n",
      "\n",
      "        [[-0.2494]],\n",
      "\n",
      "        [[-0.1172]],\n",
      "\n",
      "        [[ 1.7446]],\n",
      "\n",
      "        [[-0.5857]],\n",
      "\n",
      "        [[ 0.1386]],\n",
      "\n",
      "        [[ 0.0027]],\n",
      "\n",
      "        [[-0.7491]],\n",
      "\n",
      "        [[ 0.3207]],\n",
      "\n",
      "        [[-1.5437]],\n",
      "\n",
      "        [[ 0.4255]],\n",
      "\n",
      "        [[-0.8436]],\n",
      "\n",
      "        [[-0.0426]],\n",
      "\n",
      "        [[-1.3978]],\n",
      "\n",
      "        [[ 0.1026]],\n",
      "\n",
      "        [[-1.3880]],\n",
      "\n",
      "        [[ 0.8498]],\n",
      "\n",
      "        [[-0.0797]],\n",
      "\n",
      "        [[-0.8512]],\n",
      "\n",
      "        [[ 2.1224]],\n",
      "\n",
      "        [[-0.0023]],\n",
      "\n",
      "        [[ 0.4774]],\n",
      "\n",
      "        [[-0.4350]],\n",
      "\n",
      "        [[ 0.0980]],\n",
      "\n",
      "        [[ 0.9284]],\n",
      "\n",
      "        [[-0.0680]],\n",
      "\n",
      "        [[-1.4146]],\n",
      "\n",
      "        [[-1.3595]],\n",
      "\n",
      "        [[-0.0077]],\n",
      "\n",
      "        [[-0.0141]],\n",
      "\n",
      "        [[ 0.6822]],\n",
      "\n",
      "        [[ 0.4519]],\n",
      "\n",
      "        [[ 1.4633]],\n",
      "\n",
      "        [[-1.2174]],\n",
      "\n",
      "        [[-0.3278]],\n",
      "\n",
      "        [[-0.7293]],\n",
      "\n",
      "        [[ 0.1025]],\n",
      "\n",
      "        [[-0.1623]],\n",
      "\n",
      "        [[ 0.6354]],\n",
      "\n",
      "        [[ 0.7396]],\n",
      "\n",
      "        [[ 1.7917]],\n",
      "\n",
      "        [[ 0.9824]],\n",
      "\n",
      "        [[ 1.4887]],\n",
      "\n",
      "        [[ 0.3174]],\n",
      "\n",
      "        [[ 1.3179]],\n",
      "\n",
      "        [[ 0.1016]],\n",
      "\n",
      "        [[-0.5148]],\n",
      "\n",
      "        [[ 0.0318]],\n",
      "\n",
      "        [[ 2.3952]],\n",
      "\n",
      "        [[ 1.2395]],\n",
      "\n",
      "        [[ 0.5538]],\n",
      "\n",
      "        [[-0.0561]],\n",
      "\n",
      "        [[ 1.0696]],\n",
      "\n",
      "        [[ 0.4447]],\n",
      "\n",
      "        [[-0.2805]],\n",
      "\n",
      "        [[-0.2982]],\n",
      "\n",
      "        [[-1.7685]],\n",
      "\n",
      "        [[ 1.7521]],\n",
      "\n",
      "        [[-1.1331]],\n",
      "\n",
      "        [[ 0.4387]],\n",
      "\n",
      "        [[ 0.7437]],\n",
      "\n",
      "        [[ 0.4155]],\n",
      "\n",
      "        [[-1.2165]],\n",
      "\n",
      "        [[-0.6299]],\n",
      "\n",
      "        [[ 2.4769]],\n",
      "\n",
      "        [[-1.9532]],\n",
      "\n",
      "        [[ 0.0672]],\n",
      "\n",
      "        [[-0.6568]],\n",
      "\n",
      "        [[ 1.7527]],\n",
      "\n",
      "        [[-0.7870]],\n",
      "\n",
      "        [[-0.6472]],\n",
      "\n",
      "        [[-0.0698]],\n",
      "\n",
      "        [[ 1.0708]],\n",
      "\n",
      "        [[ 1.1971]],\n",
      "\n",
      "        [[-0.3252]],\n",
      "\n",
      "        [[ 1.3421]],\n",
      "\n",
      "        [[ 0.5161]],\n",
      "\n",
      "        [[-0.5060]],\n",
      "\n",
      "        [[-0.0513]],\n",
      "\n",
      "        [[ 3.2676]],\n",
      "\n",
      "        [[-2.2938]],\n",
      "\n",
      "        [[-1.1155]],\n",
      "\n",
      "        [[ 1.5281]],\n",
      "\n",
      "        [[-0.3845]],\n",
      "\n",
      "        [[-1.0447]],\n",
      "\n",
      "        [[-0.1811]],\n",
      "\n",
      "        [[ 0.7402]],\n",
      "\n",
      "        [[-0.0315]],\n",
      "\n",
      "        [[ 0.2071]],\n",
      "\n",
      "        [[-0.7690]],\n",
      "\n",
      "        [[ 1.5498]],\n",
      "\n",
      "        [[ 1.0396]],\n",
      "\n",
      "        [[ 0.3663]],\n",
      "\n",
      "        [[ 0.8169]],\n",
      "\n",
      "        [[-0.1552]],\n",
      "\n",
      "        [[-0.8126]],\n",
      "\n",
      "        [[-0.4143]],\n",
      "\n",
      "        [[ 0.5165]],\n",
      "\n",
      "        [[-0.2160]],\n",
      "\n",
      "        [[-1.0185]],\n",
      "\n",
      "        [[-0.6832]],\n",
      "\n",
      "        [[ 1.3503]],\n",
      "\n",
      "        [[ 0.5900]],\n",
      "\n",
      "        [[ 0.1969]],\n",
      "\n",
      "        [[-1.1206]],\n",
      "\n",
      "        [[-1.2733]],\n",
      "\n",
      "        [[ 0.2020]],\n",
      "\n",
      "        [[-1.3781]],\n",
      "\n",
      "        [[-0.6940]],\n",
      "\n",
      "        [[ 0.0819]],\n",
      "\n",
      "        [[-1.6898]],\n",
      "\n",
      "        [[-0.1647]],\n",
      "\n",
      "        [[-0.5848]],\n",
      "\n",
      "        [[ 0.8440]],\n",
      "\n",
      "        [[ 1.1205]],\n",
      "\n",
      "        [[-0.6464]],\n",
      "\n",
      "        [[-0.3990]],\n",
      "\n",
      "        [[-1.3992]],\n",
      "\n",
      "        [[ 1.6838]],\n",
      "\n",
      "        [[ 0.2060]],\n",
      "\n",
      "        [[-1.7646]],\n",
      "\n",
      "        [[-0.3641]],\n",
      "\n",
      "        [[-1.0146]],\n",
      "\n",
      "        [[-0.3707]],\n",
      "\n",
      "        [[ 0.6889]],\n",
      "\n",
      "        [[ 0.9298]],\n",
      "\n",
      "        [[-0.2646]],\n",
      "\n",
      "        [[ 1.5979]],\n",
      "\n",
      "        [[-0.6083]],\n",
      "\n",
      "        [[-1.3964]],\n",
      "\n",
      "        [[-1.3123]],\n",
      "\n",
      "        [[-0.4534]],\n",
      "\n",
      "        [[ 1.2456]],\n",
      "\n",
      "        [[-0.3181]],\n",
      "\n",
      "        [[ 2.0822]],\n",
      "\n",
      "        [[ 0.3341]],\n",
      "\n",
      "        [[ 1.0087]],\n",
      "\n",
      "        [[ 0.2435]],\n",
      "\n",
      "        [[ 0.4523]],\n",
      "\n",
      "        [[ 0.4300]],\n",
      "\n",
      "        [[ 0.0059]],\n",
      "\n",
      "        [[-0.8746]],\n",
      "\n",
      "        [[-0.0980]],\n",
      "\n",
      "        [[ 0.0302]],\n",
      "\n",
      "        [[-0.6397]],\n",
      "\n",
      "        [[-0.0804]],\n",
      "\n",
      "        [[ 0.7195]],\n",
      "\n",
      "        [[ 1.4144]],\n",
      "\n",
      "        [[ 0.0791]],\n",
      "\n",
      "        [[ 1.6163]],\n",
      "\n",
      "        [[-0.6179]],\n",
      "\n",
      "        [[ 0.9190]],\n",
      "\n",
      "        [[ 0.1204]],\n",
      "\n",
      "        [[ 0.1261]],\n",
      "\n",
      "        [[-0.2402]],\n",
      "\n",
      "        [[ 0.2676]],\n",
      "\n",
      "        [[ 0.5952]],\n",
      "\n",
      "        [[-1.0666]],\n",
      "\n",
      "        [[-0.9659]],\n",
      "\n",
      "        [[-0.6526]],\n",
      "\n",
      "        [[ 1.2379]],\n",
      "\n",
      "        [[-0.7649]],\n",
      "\n",
      "        [[ 0.6892]],\n",
      "\n",
      "        [[-0.1538]],\n",
      "\n",
      "        [[ 2.4430]],\n",
      "\n",
      "        [[ 1.3966]],\n",
      "\n",
      "        [[ 0.8616]],\n",
      "\n",
      "        [[-0.2583]],\n",
      "\n",
      "        [[-0.4740]],\n",
      "\n",
      "        [[-1.1869]],\n",
      "\n",
      "        [[ 0.6311]],\n",
      "\n",
      "        [[-0.0388]],\n",
      "\n",
      "        [[ 0.6789]],\n",
      "\n",
      "        [[ 1.7137]],\n",
      "\n",
      "        [[ 1.6369]],\n",
      "\n",
      "        [[ 1.8218]],\n",
      "\n",
      "        [[-1.4383]],\n",
      "\n",
      "        [[ 0.6381]],\n",
      "\n",
      "        [[ 0.6173]],\n",
      "\n",
      "        [[-0.7901]],\n",
      "\n",
      "        [[ 0.3455]],\n",
      "\n",
      "        [[ 0.9761]],\n",
      "\n",
      "        [[-0.1108]],\n",
      "\n",
      "        [[ 0.1163]],\n",
      "\n",
      "        [[ 0.4025]],\n",
      "\n",
      "        [[-0.5934]],\n",
      "\n",
      "        [[ 0.3470]],\n",
      "\n",
      "        [[ 0.9603]],\n",
      "\n",
      "        [[ 2.1184]],\n",
      "\n",
      "        [[ 0.8101]],\n",
      "\n",
      "        [[-0.3280]],\n",
      "\n",
      "        [[ 0.2501]],\n",
      "\n",
      "        [[ 0.0922]],\n",
      "\n",
      "        [[ 0.2398]],\n",
      "\n",
      "        [[-0.8203]],\n",
      "\n",
      "        [[ 1.0486]],\n",
      "\n",
      "        [[-0.6186]],\n",
      "\n",
      "        [[ 0.1568]],\n",
      "\n",
      "        [[-0.8111]],\n",
      "\n",
      "        [[ 0.5950]],\n",
      "\n",
      "        [[-0.8212]],\n",
      "\n",
      "        [[ 0.7392]],\n",
      "\n",
      "        [[ 0.7520]],\n",
      "\n",
      "        [[ 0.6570]],\n",
      "\n",
      "        [[-0.2249]],\n",
      "\n",
      "        [[-0.3193]],\n",
      "\n",
      "        [[-1.8121]],\n",
      "\n",
      "        [[-1.7701]],\n",
      "\n",
      "        [[ 0.0621]],\n",
      "\n",
      "        [[-0.0995]],\n",
      "\n",
      "        [[-0.7233]],\n",
      "\n",
      "        [[-0.0918]],\n",
      "\n",
      "        [[ 1.7416]],\n",
      "\n",
      "        [[ 0.7987]],\n",
      "\n",
      "        [[-2.6201]],\n",
      "\n",
      "        [[ 0.0786]],\n",
      "\n",
      "        [[-1.5913]],\n",
      "\n",
      "        [[ 0.1133]],\n",
      "\n",
      "        [[ 0.1804]],\n",
      "\n",
      "        [[-0.5797]],\n",
      "\n",
      "        [[ 0.6241]],\n",
      "\n",
      "        [[-0.7372]],\n",
      "\n",
      "        [[ 1.4376]],\n",
      "\n",
      "        [[-0.0079]],\n",
      "\n",
      "        [[-0.1208]],\n",
      "\n",
      "        [[ 0.3906]],\n",
      "\n",
      "        [[-1.0425]],\n",
      "\n",
      "        [[-2.3965]],\n",
      "\n",
      "        [[ 0.8311]],\n",
      "\n",
      "        [[ 0.7251]],\n",
      "\n",
      "        [[-1.1822]],\n",
      "\n",
      "        [[ 0.5287]],\n",
      "\n",
      "        [[ 0.7210]],\n",
      "\n",
      "        [[-0.6454]],\n",
      "\n",
      "        [[ 0.6945]],\n",
      "\n",
      "        [[ 1.3567]],\n",
      "\n",
      "        [[ 0.2706]],\n",
      "\n",
      "        [[-0.1617]],\n",
      "\n",
      "        [[-0.5379]],\n",
      "\n",
      "        [[ 0.5496]],\n",
      "\n",
      "        [[ 1.7478]],\n",
      "\n",
      "        [[-0.0580]],\n",
      "\n",
      "        [[-0.3979]],\n",
      "\n",
      "        [[ 0.5103]],\n",
      "\n",
      "        [[-1.0485]],\n",
      "\n",
      "        [[ 0.9326]],\n",
      "\n",
      "        [[-0.1336]],\n",
      "\n",
      "        [[ 0.5522]],\n",
      "\n",
      "        [[-1.5305]],\n",
      "\n",
      "        [[-1.7631]],\n",
      "\n",
      "        [[-1.3070]],\n",
      "\n",
      "        [[ 0.0708]],\n",
      "\n",
      "        [[ 0.1068]],\n",
      "\n",
      "        [[ 0.7215]],\n",
      "\n",
      "        [[ 1.1546]],\n",
      "\n",
      "        [[-0.8019]],\n",
      "\n",
      "        [[ 0.7660]],\n",
      "\n",
      "        [[ 0.6486]],\n",
      "\n",
      "        [[ 0.0118]],\n",
      "\n",
      "        [[-1.3399]],\n",
      "\n",
      "        [[-0.3794]],\n",
      "\n",
      "        [[-0.5841]],\n",
      "\n",
      "        [[ 0.5446]],\n",
      "\n",
      "        [[ 0.0908]],\n",
      "\n",
      "        [[ 1.2805]],\n",
      "\n",
      "        [[-2.2435]],\n",
      "\n",
      "        [[-0.1892]],\n",
      "\n",
      "        [[-2.1963]],\n",
      "\n",
      "        [[-1.4655]],\n",
      "\n",
      "        [[-0.0601]],\n",
      "\n",
      "        [[ 1.6463]],\n",
      "\n",
      "        [[-1.1944]],\n",
      "\n",
      "        [[ 1.9178]],\n",
      "\n",
      "        [[-2.0180]],\n",
      "\n",
      "        [[ 0.0064]],\n",
      "\n",
      "        [[-1.2220]],\n",
      "\n",
      "        [[ 0.3234]],\n",
      "\n",
      "        [[-0.8822]],\n",
      "\n",
      "        [[ 0.4418]],\n",
      "\n",
      "        [[-1.2684]],\n",
      "\n",
      "        [[-0.4935]],\n",
      "\n",
      "        [[-0.7878]],\n",
      "\n",
      "        [[-0.0653]],\n",
      "\n",
      "        [[ 0.4382]],\n",
      "\n",
      "        [[ 0.1175]],\n",
      "\n",
      "        [[-1.8705]],\n",
      "\n",
      "        [[ 0.2939]],\n",
      "\n",
      "        [[ 0.4454]],\n",
      "\n",
      "        [[ 1.0321]],\n",
      "\n",
      "        [[ 1.6318]],\n",
      "\n",
      "        [[ 2.1487]],\n",
      "\n",
      "        [[-0.8796]],\n",
      "\n",
      "        [[-2.4171]],\n",
      "\n",
      "        [[-0.9062]],\n",
      "\n",
      "        [[-0.0766]],\n",
      "\n",
      "        [[-0.9396]],\n",
      "\n",
      "        [[-0.4406]],\n",
      "\n",
      "        [[-1.3720]],\n",
      "\n",
      "        [[-0.5534]],\n",
      "\n",
      "        [[-2.0475]],\n",
      "\n",
      "        [[-0.6167]],\n",
      "\n",
      "        [[-0.0421]],\n",
      "\n",
      "        [[ 0.3986]],\n",
      "\n",
      "        [[ 1.5605]],\n",
      "\n",
      "        [[ 1.8257]],\n",
      "\n",
      "        [[ 1.1138]],\n",
      "\n",
      "        [[-1.5079]],\n",
      "\n",
      "        [[ 0.7986]],\n",
      "\n",
      "        [[ 0.7690]],\n",
      "\n",
      "        [[-0.1611]],\n",
      "\n",
      "        [[-0.7614]],\n",
      "\n",
      "        [[ 0.3766]],\n",
      "\n",
      "        [[-0.8117]],\n",
      "\n",
      "        [[ 0.3749]],\n",
      "\n",
      "        [[ 0.8164]],\n",
      "\n",
      "        [[ 0.3546]],\n",
      "\n",
      "        [[ 0.6560]],\n",
      "\n",
      "        [[-1.7203]],\n",
      "\n",
      "        [[-0.0883]],\n",
      "\n",
      "        [[ 0.8399]],\n",
      "\n",
      "        [[-0.9142]],\n",
      "\n",
      "        [[-1.6968]],\n",
      "\n",
      "        [[-0.8852]],\n",
      "\n",
      "        [[ 0.3102]],\n",
      "\n",
      "        [[-0.9989]],\n",
      "\n",
      "        [[-1.6942]],\n",
      "\n",
      "        [[-1.1981]],\n",
      "\n",
      "        [[ 0.3509]],\n",
      "\n",
      "        [[ 0.5333]],\n",
      "\n",
      "        [[-1.8093]],\n",
      "\n",
      "        [[-0.8250]],\n",
      "\n",
      "        [[-0.3122]],\n",
      "\n",
      "        [[ 0.4428]],\n",
      "\n",
      "        [[-1.4607]],\n",
      "\n",
      "        [[-1.0609]],\n",
      "\n",
      "        [[-1.1078]],\n",
      "\n",
      "        [[-1.2684]],\n",
      "\n",
      "        [[ 2.2127]],\n",
      "\n",
      "        [[ 0.0870]],\n",
      "\n",
      "        [[-0.3002]],\n",
      "\n",
      "        [[ 1.0851]],\n",
      "\n",
      "        [[ 0.6921]],\n",
      "\n",
      "        [[-1.0120]],\n",
      "\n",
      "        [[-0.5494]],\n",
      "\n",
      "        [[-0.0948]],\n",
      "\n",
      "        [[ 1.1201]],\n",
      "\n",
      "        [[-0.6877]],\n",
      "\n",
      "        [[-0.0499]],\n",
      "\n",
      "        [[-1.4358]],\n",
      "\n",
      "        [[-0.9094]],\n",
      "\n",
      "        [[-2.0998]],\n",
      "\n",
      "        [[-0.2590]],\n",
      "\n",
      "        [[-0.5642]],\n",
      "\n",
      "        [[-1.6430]],\n",
      "\n",
      "        [[-0.2942]],\n",
      "\n",
      "        [[-1.2971]],\n",
      "\n",
      "        [[ 1.8857]],\n",
      "\n",
      "        [[-0.8596]],\n",
      "\n",
      "        [[-0.1677]],\n",
      "\n",
      "        [[ 0.1679]],\n",
      "\n",
      "        [[-1.4924]],\n",
      "\n",
      "        [[-3.5913]],\n",
      "\n",
      "        [[-0.2124]],\n",
      "\n",
      "        [[-0.2180]],\n",
      "\n",
      "        [[ 0.6453]],\n",
      "\n",
      "        [[ 0.5344]],\n",
      "\n",
      "        [[ 1.6394]],\n",
      "\n",
      "        [[-0.0362]],\n",
      "\n",
      "        [[-1.2702]],\n",
      "\n",
      "        [[-0.0157]],\n",
      "\n",
      "        [[ 1.6906]],\n",
      "\n",
      "        [[-0.2827]],\n",
      "\n",
      "        [[ 0.1197]],\n",
      "\n",
      "        [[ 0.6643]],\n",
      "\n",
      "        [[-0.9727]],\n",
      "\n",
      "        [[ 0.0795]],\n",
      "\n",
      "        [[-0.1793]],\n",
      "\n",
      "        [[-1.0868]],\n",
      "\n",
      "        [[-0.0454]],\n",
      "\n",
      "        [[-0.3674]],\n",
      "\n",
      "        [[-0.8595]],\n",
      "\n",
      "        [[ 1.2459]],\n",
      "\n",
      "        [[-0.2455]],\n",
      "\n",
      "        [[ 1.4412]],\n",
      "\n",
      "        [[-0.0178]],\n",
      "\n",
      "        [[ 0.9419]],\n",
      "\n",
      "        [[-0.2420]],\n",
      "\n",
      "        [[-0.1276]],\n",
      "\n",
      "        [[-0.8237]],\n",
      "\n",
      "        [[ 0.1921]]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor(1.00000e-02 *\n",
      "       [[[-7.7513]]], device='cuda:0')\n",
      "torch.Size([1, 448, 512])\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 1.9537,  1.9575,  1.9519,  ...,  1.9539,  1.9550,  1.9418],\n",
      "         [ 1.9392,  1.9485,  1.9441,  ...,  1.9513,  1.9344,  1.9478],\n",
      "         [ 1.9492,  1.9481,  1.9504,  ...,  1.9441,  1.9452,  1.9480],\n",
      "         ...,\n",
      "         [ 1.9530,  1.9561,  1.9544,  ...,  1.9453,  1.9539,  1.9519],\n",
      "         [ 1.9476,  1.9647,  1.9551,  ...,  1.9609,  1.9510,  1.9594],\n",
      "         [ 1.9422,  1.9478,  1.9395,  ...,  1.9551,  1.9448,  1.9497]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 [30720/50000 (68%)]\tLoss: 0.446593, Accuracy: 83.98\n",
      "Train Epoch: 24 [32000/50000 (71%)]\tLoss: 0.397583, Accuracy: 87.11\n",
      "Train Epoch: 24 [33280/50000 (74%)]\tLoss: 0.587445, Accuracy: 80.86\n",
      "Train Epoch: 24 [34560/50000 (77%)]\tLoss: 0.380614, Accuracy: 88.28\n",
      "Train Epoch: 24 [35840/50000 (80%)]\tLoss: 0.464266, Accuracy: 83.59\n",
      "Train Epoch: 24 [37120/50000 (82%)]\tLoss: 0.354633, Accuracy: 88.67\n",
      "Train Epoch: 24 [38400/50000 (85%)]\tLoss: 0.517249, Accuracy: 86.33\n",
      "Train Epoch: 24 [39680/50000 (88%)]\tLoss: 0.496121, Accuracy: 81.25\n",
      "Train Epoch: 24 [40960/50000 (91%)]\tLoss: 0.386531, Accuracy: 88.67\n",
      "Train Epoch: 24 [42240/50000 (94%)]\tLoss: 0.529417, Accuracy: 81.64\n",
      "Train Epoch: 24 [43520/50000 (97%)]\tLoss: 0.403443, Accuracy: 85.55\n",
      "Train Epoch: 24 [35000/50000 (99%)]\tLoss: 0.488615, Accuracy: 84.50\n",
      "\n",
      "Validation set: Average loss: 0.5440, Accuracy: 4073/5000 (81.00%)\n",
      "\n",
      "the time of this epoch:[37.15900182723999 s]\n",
      "\n",
      "Test set: Average loss: 0.5418, Accuracy: 8202/10000 (82.02%)\n",
      "\n",
      "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.460644, Accuracy: 85.16\n",
      "Train Epoch: 25 [1280/50000 (3%)]\tLoss: 0.359849, Accuracy: 88.28\n",
      "Train Epoch: 25 [2560/50000 (6%)]\tLoss: 0.386816, Accuracy: 85.16\n",
      "Train Epoch: 25 [3840/50000 (9%)]\tLoss: 0.395663, Accuracy: 87.50\n",
      "Train Epoch: 25 [5120/50000 (11%)]\tLoss: 0.365061, Accuracy: 87.11\n",
      "Train Epoch: 25 [6400/50000 (14%)]\tLoss: 0.438402, Accuracy: 84.77\n",
      "Train Epoch: 25 [7680/50000 (17%)]\tLoss: 0.439905, Accuracy: 85.55\n",
      "Train Epoch: 25 [8960/50000 (20%)]\tLoss: 0.553965, Accuracy: 81.25\n",
      "Train Epoch: 25 [10240/50000 (23%)]\tLoss: 0.450095, Accuracy: 84.77\n",
      "Train Epoch: 25 [11520/50000 (26%)]\tLoss: 0.324782, Accuracy: 90.23\n",
      "Train Epoch: 25 [12800/50000 (28%)]\tLoss: 0.355770, Accuracy: 87.50\n",
      "torch.Size([512, 1, 1])\n",
      "tensor([[[ 1.6204]],\n",
      "\n",
      "        [[ 1.1322]],\n",
      "\n",
      "        [[ 1.0677]],\n",
      "\n",
      "        [[ 0.0964]],\n",
      "\n",
      "        [[ 0.2148]],\n",
      "\n",
      "        [[-0.4828]],\n",
      "\n",
      "        [[ 2.2697]],\n",
      "\n",
      "        [[-0.8709]],\n",
      "\n",
      "        [[-1.6204]],\n",
      "\n",
      "        [[-0.3654]],\n",
      "\n",
      "        [[-2.1855]],\n",
      "\n",
      "        [[ 0.4777]],\n",
      "\n",
      "        [[ 0.2439]],\n",
      "\n",
      "        [[-0.3537]],\n",
      "\n",
      "        [[-0.4599]],\n",
      "\n",
      "        [[-1.0097]],\n",
      "\n",
      "        [[-0.7384]],\n",
      "\n",
      "        [[ 1.0637]],\n",
      "\n",
      "        [[ 1.3125]],\n",
      "\n",
      "        [[ 1.4165]],\n",
      "\n",
      "        [[-0.6459]],\n",
      "\n",
      "        [[-0.6789]],\n",
      "\n",
      "        [[-0.5468]],\n",
      "\n",
      "        [[ 1.9918]],\n",
      "\n",
      "        [[ 0.1605]],\n",
      "\n",
      "        [[-0.9143]],\n",
      "\n",
      "        [[ 0.8277]],\n",
      "\n",
      "        [[ 0.5067]],\n",
      "\n",
      "        [[-0.1948]],\n",
      "\n",
      "        [[ 0.3516]],\n",
      "\n",
      "        [[-0.9095]],\n",
      "\n",
      "        [[-0.4743]],\n",
      "\n",
      "        [[-0.9789]],\n",
      "\n",
      "        [[ 2.0326]],\n",
      "\n",
      "        [[ 0.1187]],\n",
      "\n",
      "        [[-0.4315]],\n",
      "\n",
      "        [[ 1.0911]],\n",
      "\n",
      "        [[ 0.3167]],\n",
      "\n",
      "        [[ 0.8005]],\n",
      "\n",
      "        [[ 0.8531]],\n",
      "\n",
      "        [[ 0.7709]],\n",
      "\n",
      "        [[ 0.0845]],\n",
      "\n",
      "        [[ 0.1794]],\n",
      "\n",
      "        [[ 0.1310]],\n",
      "\n",
      "        [[-0.6685]],\n",
      "\n",
      "        [[-0.3088]],\n",
      "\n",
      "        [[ 0.4005]],\n",
      "\n",
      "        [[-0.6381]],\n",
      "\n",
      "        [[ 0.7795]],\n",
      "\n",
      "        [[ 0.1739]],\n",
      "\n",
      "        [[ 0.0863]],\n",
      "\n",
      "        [[ 0.7292]],\n",
      "\n",
      "        [[ 1.6169]],\n",
      "\n",
      "        [[-0.1823]],\n",
      "\n",
      "        [[-0.1266]],\n",
      "\n",
      "        [[-0.7966]],\n",
      "\n",
      "        [[-1.0816]],\n",
      "\n",
      "        [[-1.0300]],\n",
      "\n",
      "        [[ 1.1247]],\n",
      "\n",
      "        [[-1.0441]],\n",
      "\n",
      "        [[-0.1337]],\n",
      "\n",
      "        [[ 0.8494]],\n",
      "\n",
      "        [[ 1.6368]],\n",
      "\n",
      "        [[ 1.4463]],\n",
      "\n",
      "        [[ 0.6486]],\n",
      "\n",
      "        [[-0.1084]],\n",
      "\n",
      "        [[ 2.5761]],\n",
      "\n",
      "        [[-1.7201]],\n",
      "\n",
      "        [[-0.1326]],\n",
      "\n",
      "        [[ 0.2913]],\n",
      "\n",
      "        [[ 2.8006]],\n",
      "\n",
      "        [[-0.1315]],\n",
      "\n",
      "        [[-0.7550]],\n",
      "\n",
      "        [[-0.0055]],\n",
      "\n",
      "        [[ 2.7227]],\n",
      "\n",
      "        [[-0.0548]],\n",
      "\n",
      "        [[ 2.0931]],\n",
      "\n",
      "        [[-0.4686]],\n",
      "\n",
      "        [[-0.2756]],\n",
      "\n",
      "        [[ 0.1962]],\n",
      "\n",
      "        [[-0.8871]],\n",
      "\n",
      "        [[ 0.2041]],\n",
      "\n",
      "        [[-0.4514]],\n",
      "\n",
      "        [[ 0.5935]],\n",
      "\n",
      "        [[ 0.9813]],\n",
      "\n",
      "        [[-0.1827]],\n",
      "\n",
      "        [[-0.0930]],\n",
      "\n",
      "        [[ 0.4658]],\n",
      "\n",
      "        [[ 0.4226]],\n",
      "\n",
      "        [[ 1.4247]],\n",
      "\n",
      "        [[ 0.0285]],\n",
      "\n",
      "        [[ 1.0348]],\n",
      "\n",
      "        [[-0.6259]],\n",
      "\n",
      "        [[-0.4560]],\n",
      "\n",
      "        [[-0.5677]],\n",
      "\n",
      "        [[-1.4405]],\n",
      "\n",
      "        [[ 1.5760]],\n",
      "\n",
      "        [[ 0.7366]],\n",
      "\n",
      "        [[ 0.2728]],\n",
      "\n",
      "        [[ 0.2680]],\n",
      "\n",
      "        [[ 1.3080]],\n",
      "\n",
      "        [[ 0.5460]],\n",
      "\n",
      "        [[-0.5153]],\n",
      "\n",
      "        [[ 0.3064]],\n",
      "\n",
      "        [[-1.0722]],\n",
      "\n",
      "        [[-1.9295]],\n",
      "\n",
      "        [[-0.4730]],\n",
      "\n",
      "        [[ 0.6777]],\n",
      "\n",
      "        [[-0.0213]],\n",
      "\n",
      "        [[ 0.8756]],\n",
      "\n",
      "        [[ 0.1023]],\n",
      "\n",
      "        [[ 0.0161]],\n",
      "\n",
      "        [[-1.0206]],\n",
      "\n",
      "        [[ 0.5640]],\n",
      "\n",
      "        [[ 1.5057]],\n",
      "\n",
      "        [[-0.7350]],\n",
      "\n",
      "        [[ 1.7514]],\n",
      "\n",
      "        [[-0.3280]],\n",
      "\n",
      "        [[ 0.5611]],\n",
      "\n",
      "        [[-0.2196]],\n",
      "\n",
      "        [[-1.7417]],\n",
      "\n",
      "        [[ 0.9032]],\n",
      "\n",
      "        [[ 0.4837]],\n",
      "\n",
      "        [[ 0.2087]],\n",
      "\n",
      "        [[ 0.0957]],\n",
      "\n",
      "        [[ 1.1889]],\n",
      "\n",
      "        [[ 1.4838]],\n",
      "\n",
      "        [[-1.6985]],\n",
      "\n",
      "        [[ 0.2018]],\n",
      "\n",
      "        [[-1.0642]],\n",
      "\n",
      "        [[ 0.2640]],\n",
      "\n",
      "        [[ 0.1572]],\n",
      "\n",
      "        [[-0.3337]],\n",
      "\n",
      "        [[-1.2734]],\n",
      "\n",
      "        [[ 0.6080]],\n",
      "\n",
      "        [[ 0.5071]],\n",
      "\n",
      "        [[-0.1198]],\n",
      "\n",
      "        [[ 0.9381]],\n",
      "\n",
      "        [[ 0.6603]],\n",
      "\n",
      "        [[-2.3064]],\n",
      "\n",
      "        [[-0.0301]],\n",
      "\n",
      "        [[ 0.0737]],\n",
      "\n",
      "        [[ 0.1003]],\n",
      "\n",
      "        [[-0.2901]],\n",
      "\n",
      "        [[-1.7046]],\n",
      "\n",
      "        [[-1.1752]],\n",
      "\n",
      "        [[ 0.9939]],\n",
      "\n",
      "        [[-0.7655]],\n",
      "\n",
      "        [[-1.0832]],\n",
      "\n",
      "        [[-0.3334]],\n",
      "\n",
      "        [[ 0.6110]],\n",
      "\n",
      "        [[ 0.0771]],\n",
      "\n",
      "        [[-0.8433]],\n",
      "\n",
      "        [[ 1.2916]],\n",
      "\n",
      "        [[ 0.3828]],\n",
      "\n",
      "        [[-0.2579]],\n",
      "\n",
      "        [[ 1.0256]],\n",
      "\n",
      "        [[-0.2986]],\n",
      "\n",
      "        [[-0.6217]],\n",
      "\n",
      "        [[ 0.5224]],\n",
      "\n",
      "        [[-0.4259]],\n",
      "\n",
      "        [[-1.1915]],\n",
      "\n",
      "        [[-2.3464]],\n",
      "\n",
      "        [[ 2.0885]],\n",
      "\n",
      "        [[ 2.0044]],\n",
      "\n",
      "        [[-0.1853]],\n",
      "\n",
      "        [[ 1.0597]],\n",
      "\n",
      "        [[ 0.7851]],\n",
      "\n",
      "        [[-0.6116]],\n",
      "\n",
      "        [[ 1.6030]],\n",
      "\n",
      "        [[ 0.9934]],\n",
      "\n",
      "        [[ 1.7593]],\n",
      "\n",
      "        [[-1.1834]],\n",
      "\n",
      "        [[ 0.8528]],\n",
      "\n",
      "        [[-0.4029]],\n",
      "\n",
      "        [[-0.8649]],\n",
      "\n",
      "        [[ 0.3429]],\n",
      "\n",
      "        [[-0.6938]],\n",
      "\n",
      "        [[ 0.6639]],\n",
      "\n",
      "        [[ 0.5688]],\n",
      "\n",
      "        [[ 1.5262]],\n",
      "\n",
      "        [[ 0.4904]],\n",
      "\n",
      "        [[-0.6289]],\n",
      "\n",
      "        [[-0.6576]],\n",
      "\n",
      "        [[-0.4811]],\n",
      "\n",
      "        [[-0.3253]],\n",
      "\n",
      "        [[ 0.0480]],\n",
      "\n",
      "        [[-0.1471]],\n",
      "\n",
      "        [[-0.3353]],\n",
      "\n",
      "        [[ 0.1714]],\n",
      "\n",
      "        [[-0.1377]],\n",
      "\n",
      "        [[-0.3101]],\n",
      "\n",
      "        [[ 1.5517]],\n",
      "\n",
      "        [[-1.1134]],\n",
      "\n",
      "        [[-0.2708]],\n",
      "\n",
      "        [[ 0.6225]],\n",
      "\n",
      "        [[-1.4875]],\n",
      "\n",
      "        [[-0.8729]],\n",
      "\n",
      "        [[-0.5086]],\n",
      "\n",
      "        [[-0.4539]],\n",
      "\n",
      "        [[ 1.7392]],\n",
      "\n",
      "        [[-1.2349]],\n",
      "\n",
      "        [[ 0.8620]],\n",
      "\n",
      "        [[-1.8216]],\n",
      "\n",
      "        [[ 1.1511]],\n",
      "\n",
      "        [[ 0.6183]],\n",
      "\n",
      "        [[-1.0623]],\n",
      "\n",
      "        [[ 0.2066]],\n",
      "\n",
      "        [[ 0.6603]],\n",
      "\n",
      "        [[ 1.3661]],\n",
      "\n",
      "        [[ 1.0404]],\n",
      "\n",
      "        [[-1.3558]],\n",
      "\n",
      "        [[-1.6341]],\n",
      "\n",
      "        [[ 1.0163]],\n",
      "\n",
      "        [[-0.0817]],\n",
      "\n",
      "        [[ 1.4582]],\n",
      "\n",
      "        [[ 1.5893]],\n",
      "\n",
      "        [[ 0.8067]],\n",
      "\n",
      "        [[ 0.6709]],\n",
      "\n",
      "        [[-1.3629]],\n",
      "\n",
      "        [[-1.4955]],\n",
      "\n",
      "        [[ 0.2990]],\n",
      "\n",
      "        [[ 1.9626]],\n",
      "\n",
      "        [[-1.4986]],\n",
      "\n",
      "        [[-0.7943]],\n",
      "\n",
      "        [[ 1.7189]],\n",
      "\n",
      "        [[ 0.6284]],\n",
      "\n",
      "        [[ 1.9750]],\n",
      "\n",
      "        [[ 0.5728]],\n",
      "\n",
      "        [[ 0.0663]],\n",
      "\n",
      "        [[ 1.1637]],\n",
      "\n",
      "        [[-0.8291]],\n",
      "\n",
      "        [[ 0.4381]],\n",
      "\n",
      "        [[ 1.5492]],\n",
      "\n",
      "        [[-0.1911]],\n",
      "\n",
      "        [[-0.5547]],\n",
      "\n",
      "        [[-0.7741]],\n",
      "\n",
      "        [[ 0.2123]],\n",
      "\n",
      "        [[-0.9210]],\n",
      "\n",
      "        [[-0.8207]],\n",
      "\n",
      "        [[-0.1117]],\n",
      "\n",
      "        [[-0.6505]],\n",
      "\n",
      "        [[-0.5364]],\n",
      "\n",
      "        [[-1.2348]],\n",
      "\n",
      "        [[ 0.9638]],\n",
      "\n",
      "        [[ 1.2488]],\n",
      "\n",
      "        [[-0.4801]],\n",
      "\n",
      "        [[ 2.1193]],\n",
      "\n",
      "        [[-0.1999]],\n",
      "\n",
      "        [[-0.5792]],\n",
      "\n",
      "        [[ 0.7279]],\n",
      "\n",
      "        [[ 0.1906]],\n",
      "\n",
      "        [[ 0.6085]],\n",
      "\n",
      "        [[ 0.1867]],\n",
      "\n",
      "        [[ 1.0498]],\n",
      "\n",
      "        [[ 0.1689]],\n",
      "\n",
      "        [[ 0.9946]],\n",
      "\n",
      "        [[ 0.0077]],\n",
      "\n",
      "        [[ 0.5060]],\n",
      "\n",
      "        [[ 0.5749]],\n",
      "\n",
      "        [[-0.3783]],\n",
      "\n",
      "        [[ 0.5077]],\n",
      "\n",
      "        [[ 1.0046]],\n",
      "\n",
      "        [[-0.4013]],\n",
      "\n",
      "        [[-0.0594]],\n",
      "\n",
      "        [[ 0.9830]],\n",
      "\n",
      "        [[-0.5291]],\n",
      "\n",
      "        [[ 1.7437]],\n",
      "\n",
      "        [[ 0.3485]],\n",
      "\n",
      "        [[ 0.7443]],\n",
      "\n",
      "        [[-1.8308]],\n",
      "\n",
      "        [[-0.9998]],\n",
      "\n",
      "        [[-0.0737]],\n",
      "\n",
      "        [[-0.4236]],\n",
      "\n",
      "        [[ 0.1778]],\n",
      "\n",
      "        [[ 1.2266]],\n",
      "\n",
      "        [[-2.3054]],\n",
      "\n",
      "        [[-0.6121]],\n",
      "\n",
      "        [[ 0.3400]],\n",
      "\n",
      "        [[ 0.8411]],\n",
      "\n",
      "        [[ 2.1506]],\n",
      "\n",
      "        [[-0.9881]],\n",
      "\n",
      "        [[ 0.8199]],\n",
      "\n",
      "        [[-0.3206]],\n",
      "\n",
      "        [[-0.5253]],\n",
      "\n",
      "        [[-3.1300]],\n",
      "\n",
      "        [[ 0.5893]],\n",
      "\n",
      "        [[ 1.3746]],\n",
      "\n",
      "        [[-1.7840]],\n",
      "\n",
      "        [[-0.6935]],\n",
      "\n",
      "        [[ 0.2464]],\n",
      "\n",
      "        [[-1.4974]],\n",
      "\n",
      "        [[-1.5862]],\n",
      "\n",
      "        [[ 0.2646]],\n",
      "\n",
      "        [[-0.7460]],\n",
      "\n",
      "        [[-0.2395]],\n",
      "\n",
      "        [[-1.3697]],\n",
      "\n",
      "        [[ 1.0895]],\n",
      "\n",
      "        [[ 0.5166]],\n",
      "\n",
      "        [[ 0.4799]],\n",
      "\n",
      "        [[-1.3205]],\n",
      "\n",
      "        [[ 0.7011]],\n",
      "\n",
      "        [[-1.1941]],\n",
      "\n",
      "        [[ 0.3206]],\n",
      "\n",
      "        [[-0.0717]],\n",
      "\n",
      "        [[-0.1239]],\n",
      "\n",
      "        [[ 0.3789]],\n",
      "\n",
      "        [[ 0.7148]],\n",
      "\n",
      "        [[-2.5955]],\n",
      "\n",
      "        [[-0.5892]],\n",
      "\n",
      "        [[-0.9091]],\n",
      "\n",
      "        [[ 0.2810]],\n",
      "\n",
      "        [[-0.8488]],\n",
      "\n",
      "        [[ 0.1826]],\n",
      "\n",
      "        [[ 2.0700]],\n",
      "\n",
      "        [[ 0.0466]],\n",
      "\n",
      "        [[-0.3490]],\n",
      "\n",
      "        [[ 0.0511]],\n",
      "\n",
      "        [[-2.2453]],\n",
      "\n",
      "        [[-0.5321]],\n",
      "\n",
      "        [[-0.6958]],\n",
      "\n",
      "        [[ 1.3984]],\n",
      "\n",
      "        [[ 0.4807]],\n",
      "\n",
      "        [[ 1.1837]],\n",
      "\n",
      "        [[-0.3393]],\n",
      "\n",
      "        [[-0.7177]],\n",
      "\n",
      "        [[-0.3135]],\n",
      "\n",
      "        [[ 1.7669]],\n",
      "\n",
      "        [[-1.3179]],\n",
      "\n",
      "        [[-0.6821]],\n",
      "\n",
      "        [[-1.8971]],\n",
      "\n",
      "        [[-1.8625]],\n",
      "\n",
      "        [[ 0.0936]],\n",
      "\n",
      "        [[ 1.3119]],\n",
      "\n",
      "        [[-0.8667]],\n",
      "\n",
      "        [[ 0.0388]],\n",
      "\n",
      "        [[ 1.4475]],\n",
      "\n",
      "        [[ 0.1600]],\n",
      "\n",
      "        [[-1.6628]],\n",
      "\n",
      "        [[ 0.3559]],\n",
      "\n",
      "        [[-1.4884]],\n",
      "\n",
      "        [[ 0.9372]],\n",
      "\n",
      "        [[-1.0928]],\n",
      "\n",
      "        [[-1.5214]],\n",
      "\n",
      "        [[ 0.3403]],\n",
      "\n",
      "        [[ 1.7333]],\n",
      "\n",
      "        [[-1.0649]],\n",
      "\n",
      "        [[-1.8269]],\n",
      "\n",
      "        [[ 1.9007]],\n",
      "\n",
      "        [[ 0.8575]],\n",
      "\n",
      "        [[ 0.9493]],\n",
      "\n",
      "        [[ 0.3491]],\n",
      "\n",
      "        [[-0.2009]],\n",
      "\n",
      "        [[-2.9795]],\n",
      "\n",
      "        [[-0.5435]],\n",
      "\n",
      "        [[-0.0601]],\n",
      "\n",
      "        [[-0.2664]],\n",
      "\n",
      "        [[ 0.8180]],\n",
      "\n",
      "        [[ 1.5973]],\n",
      "\n",
      "        [[ 0.0101]],\n",
      "\n",
      "        [[ 0.7367]],\n",
      "\n",
      "        [[-0.5279]],\n",
      "\n",
      "        [[ 1.7653]],\n",
      "\n",
      "        [[-0.5000]],\n",
      "\n",
      "        [[-0.6860]],\n",
      "\n",
      "        [[-1.3516]],\n",
      "\n",
      "        [[-0.2134]],\n",
      "\n",
      "        [[ 0.6785]],\n",
      "\n",
      "        [[-1.4849]],\n",
      "\n",
      "        [[ 1.2094]],\n",
      "\n",
      "        [[-1.0882]],\n",
      "\n",
      "        [[-0.3934]],\n",
      "\n",
      "        [[-2.0659]],\n",
      "\n",
      "        [[ 0.9439]],\n",
      "\n",
      "        [[ 0.7064]],\n",
      "\n",
      "        [[ 1.6212]],\n",
      "\n",
      "        [[ 1.0004]],\n",
      "\n",
      "        [[ 0.0965]],\n",
      "\n",
      "        [[-1.8745]],\n",
      "\n",
      "        [[-1.1185]],\n",
      "\n",
      "        [[-0.3216]],\n",
      "\n",
      "        [[ 0.8719]],\n",
      "\n",
      "        [[-0.9143]],\n",
      "\n",
      "        [[ 1.1070]],\n",
      "\n",
      "        [[ 0.4498]],\n",
      "\n",
      "        [[-1.4451]],\n",
      "\n",
      "        [[ 0.5649]],\n",
      "\n",
      "        [[-0.9591]],\n",
      "\n",
      "        [[-0.0595]],\n",
      "\n",
      "        [[-0.4452]],\n",
      "\n",
      "        [[-0.7512]],\n",
      "\n",
      "        [[-1.8954]],\n",
      "\n",
      "        [[ 1.0667]],\n",
      "\n",
      "        [[ 1.7390]],\n",
      "\n",
      "        [[ 0.8053]],\n",
      "\n",
      "        [[-1.1221]],\n",
      "\n",
      "        [[ 0.6240]],\n",
      "\n",
      "        [[ 0.7857]],\n",
      "\n",
      "        [[-1.6513]],\n",
      "\n",
      "        [[ 0.3376]],\n",
      "\n",
      "        [[-0.4510]],\n",
      "\n",
      "        [[ 2.8327]],\n",
      "\n",
      "        [[ 1.0683]],\n",
      "\n",
      "        [[-0.2844]],\n",
      "\n",
      "        [[ 0.7470]],\n",
      "\n",
      "        [[ 2.1011]],\n",
      "\n",
      "        [[ 1.1633]],\n",
      "\n",
      "        [[ 0.9377]],\n",
      "\n",
      "        [[-0.3166]],\n",
      "\n",
      "        [[ 0.8590]],\n",
      "\n",
      "        [[ 1.0759]],\n",
      "\n",
      "        [[-0.0563]],\n",
      "\n",
      "        [[ 0.2992]],\n",
      "\n",
      "        [[-0.0427]],\n",
      "\n",
      "        [[-0.8069]],\n",
      "\n",
      "        [[ 0.0493]],\n",
      "\n",
      "        [[-0.9706]],\n",
      "\n",
      "        [[-0.4243]],\n",
      "\n",
      "        [[-0.6809]],\n",
      "\n",
      "        [[-1.3371]],\n",
      "\n",
      "        [[-0.2472]],\n",
      "\n",
      "        [[-1.7505]],\n",
      "\n",
      "        [[ 1.4034]],\n",
      "\n",
      "        [[-1.1230]],\n",
      "\n",
      "        [[-1.5448]],\n",
      "\n",
      "        [[-0.2229]],\n",
      "\n",
      "        [[ 1.1386]],\n",
      "\n",
      "        [[ 0.0128]],\n",
      "\n",
      "        [[ 0.6322]],\n",
      "\n",
      "        [[-0.8165]],\n",
      "\n",
      "        [[-1.8340]],\n",
      "\n",
      "        [[ 0.4701]],\n",
      "\n",
      "        [[ 0.4490]],\n",
      "\n",
      "        [[-0.0330]],\n",
      "\n",
      "        [[ 1.7408]],\n",
      "\n",
      "        [[-0.0023]],\n",
      "\n",
      "        [[-0.8566]],\n",
      "\n",
      "        [[ 0.8615]],\n",
      "\n",
      "        [[ 0.2774]],\n",
      "\n",
      "        [[-1.0266]],\n",
      "\n",
      "        [[ 1.7157]],\n",
      "\n",
      "        [[-0.2268]],\n",
      "\n",
      "        [[-0.5719]],\n",
      "\n",
      "        [[-0.5885]],\n",
      "\n",
      "        [[ 0.7261]],\n",
      "\n",
      "        [[-0.2221]],\n",
      "\n",
      "        [[ 0.1341]],\n",
      "\n",
      "        [[-0.5957]],\n",
      "\n",
      "        [[-0.1141]],\n",
      "\n",
      "        [[ 0.8861]],\n",
      "\n",
      "        [[-1.4906]],\n",
      "\n",
      "        [[ 0.1466]],\n",
      "\n",
      "        [[ 0.6200]],\n",
      "\n",
      "        [[-0.2574]],\n",
      "\n",
      "        [[-0.9435]],\n",
      "\n",
      "        [[ 0.7561]],\n",
      "\n",
      "        [[ 0.0387]],\n",
      "\n",
      "        [[ 0.1086]],\n",
      "\n",
      "        [[ 0.9574]],\n",
      "\n",
      "        [[ 0.2503]],\n",
      "\n",
      "        [[ 1.3832]],\n",
      "\n",
      "        [[ 1.2538]],\n",
      "\n",
      "        [[ 0.3960]],\n",
      "\n",
      "        [[ 0.8712]],\n",
      "\n",
      "        [[ 0.4340]],\n",
      "\n",
      "        [[ 0.0069]],\n",
      "\n",
      "        [[ 1.5154]],\n",
      "\n",
      "        [[ 0.1263]],\n",
      "\n",
      "        [[ 0.7345]],\n",
      "\n",
      "        [[-0.6564]],\n",
      "\n",
      "        [[ 0.1211]],\n",
      "\n",
      "        [[-1.0058]],\n",
      "\n",
      "        [[-0.2715]],\n",
      "\n",
      "        [[-0.0379]],\n",
      "\n",
      "        [[-1.4729]],\n",
      "\n",
      "        [[ 1.1519]],\n",
      "\n",
      "        [[-2.4880]],\n",
      "\n",
      "        [[ 0.4505]],\n",
      "\n",
      "        [[-0.4474]],\n",
      "\n",
      "        [[ 1.1182]],\n",
      "\n",
      "        [[-0.2995]],\n",
      "\n",
      "        [[-0.2707]],\n",
      "\n",
      "        [[-0.6346]],\n",
      "\n",
      "        [[ 0.9164]],\n",
      "\n",
      "        [[ 1.1908]],\n",
      "\n",
      "        [[ 0.4740]],\n",
      "\n",
      "        [[-0.2288]],\n",
      "\n",
      "        [[ 0.3059]],\n",
      "\n",
      "        [[-2.4619]],\n",
      "\n",
      "        [[-0.0708]],\n",
      "\n",
      "        [[ 0.6600]],\n",
      "\n",
      "        [[-1.2771]],\n",
      "\n",
      "        [[ 0.6336]],\n",
      "\n",
      "        [[-0.6931]],\n",
      "\n",
      "        [[ 1.7959]],\n",
      "\n",
      "        [[ 0.6215]],\n",
      "\n",
      "        [[ 0.3748]],\n",
      "\n",
      "        [[-1.2652]],\n",
      "\n",
      "        [[ 0.4727]],\n",
      "\n",
      "        [[ 1.1237]],\n",
      "\n",
      "        [[-1.6141]],\n",
      "\n",
      "        [[-1.0794]],\n",
      "\n",
      "        [[ 0.8604]],\n",
      "\n",
      "        [[ 0.2214]],\n",
      "\n",
      "        [[-0.3326]],\n",
      "\n",
      "        [[ 1.6082]],\n",
      "\n",
      "        [[-0.6945]],\n",
      "\n",
      "        [[-0.1877]],\n",
      "\n",
      "        [[ 0.5796]],\n",
      "\n",
      "        [[-0.1643]],\n",
      "\n",
      "        [[ 0.3598]],\n",
      "\n",
      "        [[ 0.8776]]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor(1.00000e-02 *\n",
      "       [[[ 4.3332]]], device='cuda:0')\n",
      "torch.Size([1, 448, 512])\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 1.9524,  1.9554,  1.9520,  ...,  1.9562,  1.9556,  1.9508],\n",
      "         [ 1.9566,  1.9466,  1.9464,  ...,  1.9531,  1.9563,  1.9547],\n",
      "         [ 1.9476,  1.9526,  1.9449,  ...,  1.9549,  1.9568,  1.9557],\n",
      "         ...,\n",
      "         [ 1.9453,  1.9499,  1.9484,  ...,  1.9502,  1.9573,  1.9496],\n",
      "         [ 1.9535,  1.9494,  1.9461,  ...,  1.9554,  1.9540,  1.9554],\n",
      "         [ 1.9453,  1.9541,  1.9421,  ...,  1.9604,  1.9498,  1.9587]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25 [14080/50000 (31%)]\tLoss: 0.444423, Accuracy: 83.59\n",
      "Train Epoch: 25 [15360/50000 (34%)]\tLoss: 0.328208, Accuracy: 91.41\n",
      "Train Epoch: 25 [16640/50000 (37%)]\tLoss: 0.380212, Accuracy: 85.16\n",
      "Train Epoch: 25 [17920/50000 (40%)]\tLoss: 0.436097, Accuracy: 85.55\n",
      "Train Epoch: 25 [19200/50000 (43%)]\tLoss: 0.434314, Accuracy: 85.16\n",
      "Train Epoch: 25 [20480/50000 (45%)]\tLoss: 0.399607, Accuracy: 84.77\n",
      "Train Epoch: 25 [21760/50000 (48%)]\tLoss: 0.414025, Accuracy: 86.33\n",
      "Train Epoch: 25 [23040/50000 (51%)]\tLoss: 0.451177, Accuracy: 83.20\n",
      "Train Epoch: 25 [24320/50000 (54%)]\tLoss: 0.420077, Accuracy: 85.94\n",
      "Train Epoch: 25 [25600/50000 (57%)]\tLoss: 0.414275, Accuracy: 87.89\n",
      "Train Epoch: 25 [26880/50000 (60%)]\tLoss: 0.460718, Accuracy: 84.38\n",
      "Train Epoch: 25 [28160/50000 (62%)]\tLoss: 0.542330, Accuracy: 78.91\n",
      "Train Epoch: 25 [29440/50000 (65%)]\tLoss: 0.476538, Accuracy: 83.98\n",
      "Train Epoch: 25 [30720/50000 (68%)]\tLoss: 0.512883, Accuracy: 83.20\n",
      "Train Epoch: 25 [32000/50000 (71%)]\tLoss: 0.454698, Accuracy: 83.98\n",
      "Train Epoch: 25 [33280/50000 (74%)]\tLoss: 0.411468, Accuracy: 83.59\n",
      "Train Epoch: 25 [34560/50000 (77%)]\tLoss: 0.420987, Accuracy: 85.55\n",
      "Train Epoch: 25 [35840/50000 (80%)]\tLoss: 0.395655, Accuracy: 86.72\n",
      "Train Epoch: 25 [37120/50000 (82%)]\tLoss: 0.413167, Accuracy: 85.55\n",
      "Train Epoch: 25 [38400/50000 (85%)]\tLoss: 0.496754, Accuracy: 83.20\n",
      "Train Epoch: 25 [39680/50000 (88%)]\tLoss: 0.343720, Accuracy: 87.50\n",
      "Train Epoch: 25 [40960/50000 (91%)]\tLoss: 0.437988, Accuracy: 84.38\n",
      "Train Epoch: 25 [42240/50000 (94%)]\tLoss: 0.550316, Accuracy: 79.69\n",
      "Train Epoch: 25 [43520/50000 (97%)]\tLoss: 0.480866, Accuracy: 85.16\n",
      "Train Epoch: 25 [35000/50000 (99%)]\tLoss: 0.508585, Accuracy: 81.50\n",
      "\n",
      "Validation set: Average loss: 0.7380, Accuracy: 3822/5000 (76.00%)\n",
      "\n",
      "the time of this epoch:[40.36236882209778 s]\n",
      "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.364086, Accuracy: 86.33\n",
      "Train Epoch: 26 [1280/50000 (3%)]\tLoss: 0.463564, Accuracy: 83.20\n",
      "Train Epoch: 26 [2560/50000 (6%)]\tLoss: 0.425314, Accuracy: 85.94\n",
      "Train Epoch: 26 [3840/50000 (9%)]\tLoss: 0.338341, Accuracy: 88.28\n",
      "Train Epoch: 26 [5120/50000 (11%)]\tLoss: 0.501141, Accuracy: 83.20\n",
      "Train Epoch: 26 [6400/50000 (14%)]\tLoss: 0.371249, Accuracy: 88.28\n",
      "Train Epoch: 26 [7680/50000 (17%)]\tLoss: 0.495785, Accuracy: 85.16\n",
      "Train Epoch: 26 [8960/50000 (20%)]\tLoss: 0.355955, Accuracy: 89.84\n",
      "Train Epoch: 26 [10240/50000 (23%)]\tLoss: 0.442410, Accuracy: 85.16\n",
      "Train Epoch: 26 [11520/50000 (26%)]\tLoss: 0.446024, Accuracy: 82.42\n",
      "Train Epoch: 26 [12800/50000 (28%)]\tLoss: 0.452436, Accuracy: 82.42\n",
      "Train Epoch: 26 [14080/50000 (31%)]\tLoss: 0.431146, Accuracy: 85.16\n",
      "Train Epoch: 26 [15360/50000 (34%)]\tLoss: 0.387805, Accuracy: 86.33\n",
      "Train Epoch: 26 [16640/50000 (37%)]\tLoss: 0.386327, Accuracy: 85.94\n",
      "Train Epoch: 26 [17920/50000 (40%)]\tLoss: 0.414413, Accuracy: 86.72\n",
      "Train Epoch: 26 [19200/50000 (43%)]\tLoss: 0.291806, Accuracy: 90.23\n",
      "Train Epoch: 26 [20480/50000 (45%)]\tLoss: 0.445350, Accuracy: 82.03\n",
      "Train Epoch: 26 [21760/50000 (48%)]\tLoss: 0.320216, Accuracy: 90.62\n",
      "Train Epoch: 26 [23040/50000 (51%)]\tLoss: 0.403724, Accuracy: 85.55\n",
      "Train Epoch: 26 [24320/50000 (54%)]\tLoss: 0.434858, Accuracy: 85.55\n",
      "Train Epoch: 26 [25600/50000 (57%)]\tLoss: 0.379014, Accuracy: 85.55\n",
      "Train Epoch: 26 [26880/50000 (60%)]\tLoss: 0.480096, Accuracy: 83.59\n",
      "Train Epoch: 26 [28160/50000 (62%)]\tLoss: 0.375262, Accuracy: 87.89\n",
      "Train Epoch: 26 [29440/50000 (65%)]\tLoss: 0.358037, Accuracy: 87.50\n",
      "Train Epoch: 26 [30720/50000 (68%)]\tLoss: 0.364552, Accuracy: 87.50\n",
      "Train Epoch: 26 [32000/50000 (71%)]\tLoss: 0.473379, Accuracy: 83.59\n",
      "Train Epoch: 26 [33280/50000 (74%)]\tLoss: 0.438700, Accuracy: 87.11\n",
      "Train Epoch: 26 [34560/50000 (77%)]\tLoss: 0.440054, Accuracy: 83.20\n",
      "Train Epoch: 26 [35840/50000 (80%)]\tLoss: 0.450156, Accuracy: 85.94\n",
      "Train Epoch: 26 [37120/50000 (82%)]\tLoss: 0.364282, Accuracy: 87.89\n",
      "Train Epoch: 26 [38400/50000 (85%)]\tLoss: 0.378908, Accuracy: 89.06\n",
      "Train Epoch: 26 [39680/50000 (88%)]\tLoss: 0.391331, Accuracy: 88.67\n",
      "Train Epoch: 26 [40960/50000 (91%)]\tLoss: 0.354124, Accuracy: 87.50\n",
      "Train Epoch: 26 [42240/50000 (94%)]\tLoss: 0.460875, Accuracy: 84.38\n",
      "Train Epoch: 26 [43520/50000 (97%)]\tLoss: 0.424289, Accuracy: 84.38\n",
      "Train Epoch: 26 [35000/50000 (99%)]\tLoss: 0.416690, Accuracy: 86.00\n",
      "\n",
      "Validation set: Average loss: 0.9263, Accuracy: 3536/5000 (70.00%)\n",
      "\n",
      "the time of this epoch:[37.09123635292053 s]\n",
      "\n",
      "Test set: Average loss: 0.9253, Accuracy: 7085/10000 (70.85%)\n",
      "\n",
      "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.401728, Accuracy: 86.33\n",
      "Train Epoch: 27 [1280/50000 (3%)]\tLoss: 0.454986, Accuracy: 83.98\n",
      "Train Epoch: 27 [2560/50000 (6%)]\tLoss: 0.377595, Accuracy: 86.72\n",
      "Train Epoch: 27 [3840/50000 (9%)]\tLoss: 0.435576, Accuracy: 86.72\n",
      "Train Epoch: 27 [5120/50000 (11%)]\tLoss: 0.372614, Accuracy: 86.72\n",
      "Train Epoch: 27 [6400/50000 (14%)]\tLoss: 0.438842, Accuracy: 84.77\n",
      "Train Epoch: 27 [7680/50000 (17%)]\tLoss: 0.371906, Accuracy: 87.89\n",
      "Train Epoch: 27 [8960/50000 (20%)]\tLoss: 0.429346, Accuracy: 85.55\n",
      "Train Epoch: 27 [10240/50000 (23%)]\tLoss: 0.388322, Accuracy: 85.55\n",
      "Train Epoch: 27 [11520/50000 (26%)]\tLoss: 0.396498, Accuracy: 85.16\n",
      "Train Epoch: 27 [12800/50000 (28%)]\tLoss: 0.417012, Accuracy: 86.33\n",
      "Train Epoch: 27 [14080/50000 (31%)]\tLoss: 0.322848, Accuracy: 89.45\n",
      "Train Epoch: 27 [15360/50000 (34%)]\tLoss: 0.430562, Accuracy: 86.33\n",
      "Train Epoch: 27 [16640/50000 (37%)]\tLoss: 0.468338, Accuracy: 85.94\n",
      "Train Epoch: 27 [17920/50000 (40%)]\tLoss: 0.372029, Accuracy: 85.16\n",
      "Train Epoch: 27 [19200/50000 (43%)]\tLoss: 0.404849, Accuracy: 85.94\n",
      "Train Epoch: 27 [20480/50000 (45%)]\tLoss: 0.481477, Accuracy: 82.81\n",
      "Train Epoch: 27 [21760/50000 (48%)]\tLoss: 0.397617, Accuracy: 85.55\n",
      "Train Epoch: 27 [23040/50000 (51%)]\tLoss: 0.427095, Accuracy: 86.72\n",
      "Train Epoch: 27 [24320/50000 (54%)]\tLoss: 0.349911, Accuracy: 87.89\n",
      "Train Epoch: 27 [25600/50000 (57%)]\tLoss: 0.373313, Accuracy: 87.11\n",
      "Train Epoch: 27 [26880/50000 (60%)]\tLoss: 0.384683, Accuracy: 88.67\n",
      "Train Epoch: 27 [28160/50000 (62%)]\tLoss: 0.485335, Accuracy: 84.38\n",
      "Train Epoch: 27 [29440/50000 (65%)]\tLoss: 0.536199, Accuracy: 81.64\n",
      "Train Epoch: 27 [30720/50000 (68%)]\tLoss: 0.436618, Accuracy: 84.77\n",
      "Train Epoch: 27 [32000/50000 (71%)]\tLoss: 0.385931, Accuracy: 86.33\n",
      "Train Epoch: 27 [33280/50000 (74%)]\tLoss: 0.329299, Accuracy: 89.06\n",
      "Train Epoch: 27 [34560/50000 (77%)]\tLoss: 0.373008, Accuracy: 86.72\n",
      "Train Epoch: 27 [35840/50000 (80%)]\tLoss: 0.524956, Accuracy: 81.25\n",
      "Train Epoch: 27 [37120/50000 (82%)]\tLoss: 0.438593, Accuracy: 85.55\n",
      "Train Epoch: 27 [38400/50000 (85%)]\tLoss: 0.530457, Accuracy: 81.64\n",
      "Train Epoch: 27 [39680/50000 (88%)]\tLoss: 0.403505, Accuracy: 87.89\n",
      "Train Epoch: 27 [40960/50000 (91%)]\tLoss: 0.488569, Accuracy: 84.77\n",
      "Train Epoch: 27 [42240/50000 (94%)]\tLoss: 0.531950, Accuracy: 81.64\n",
      "Train Epoch: 27 [43520/50000 (97%)]\tLoss: 0.442050, Accuracy: 85.94\n",
      "Train Epoch: 27 [35000/50000 (99%)]\tLoss: 0.420060, Accuracy: 85.50\n",
      "\n",
      "Validation set: Average loss: 0.8323, Accuracy: 3686/5000 (73.00%)\n",
      "\n",
      "the time of this epoch:[40.310033082962036 s]\n",
      "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.403278, Accuracy: 86.72\n",
      "Train Epoch: 28 [1280/50000 (3%)]\tLoss: 0.392149, Accuracy: 85.16\n",
      "Train Epoch: 28 [2560/50000 (6%)]\tLoss: 0.395997, Accuracy: 87.11\n",
      "Train Epoch: 28 [3840/50000 (9%)]\tLoss: 0.313167, Accuracy: 91.41\n",
      "Train Epoch: 28 [5120/50000 (11%)]\tLoss: 0.437592, Accuracy: 86.72\n",
      "Train Epoch: 28 [6400/50000 (14%)]\tLoss: 0.335277, Accuracy: 88.28\n",
      "Train Epoch: 28 [7680/50000 (17%)]\tLoss: 0.431749, Accuracy: 84.77\n",
      "Train Epoch: 28 [8960/50000 (20%)]\tLoss: 0.338700, Accuracy: 88.28\n",
      "Train Epoch: 28 [10240/50000 (23%)]\tLoss: 0.441068, Accuracy: 84.38\n",
      "Train Epoch: 28 [11520/50000 (26%)]\tLoss: 0.469988, Accuracy: 83.59\n",
      "Train Epoch: 28 [12800/50000 (28%)]\tLoss: 0.408776, Accuracy: 87.11\n",
      "Train Epoch: 28 [14080/50000 (31%)]\tLoss: 0.415645, Accuracy: 86.72\n",
      "Train Epoch: 28 [15360/50000 (34%)]\tLoss: 0.388726, Accuracy: 85.55\n",
      "Train Epoch: 28 [16640/50000 (37%)]\tLoss: 0.483015, Accuracy: 83.59\n",
      "Train Epoch: 28 [17920/50000 (40%)]\tLoss: 0.477253, Accuracy: 82.42\n",
      "Train Epoch: 28 [19200/50000 (43%)]\tLoss: 0.378942, Accuracy: 86.72\n",
      "Train Epoch: 28 [20480/50000 (45%)]\tLoss: 0.343843, Accuracy: 88.28\n",
      "Train Epoch: 28 [21760/50000 (48%)]\tLoss: 0.433394, Accuracy: 84.77\n",
      "Train Epoch: 28 [23040/50000 (51%)]\tLoss: 0.410538, Accuracy: 87.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28 [24320/50000 (54%)]\tLoss: 0.446890, Accuracy: 84.38\n",
      "Train Epoch: 28 [25600/50000 (57%)]\tLoss: 0.403022, Accuracy: 85.94\n",
      "Train Epoch: 28 [26880/50000 (60%)]\tLoss: 0.415364, Accuracy: 86.72\n",
      "Train Epoch: 28 [28160/50000 (62%)]\tLoss: 0.344020, Accuracy: 87.50\n",
      "Train Epoch: 28 [29440/50000 (65%)]\tLoss: 0.361206, Accuracy: 87.50\n",
      "Train Epoch: 28 [30720/50000 (68%)]\tLoss: 0.393067, Accuracy: 86.72\n",
      "Train Epoch: 28 [32000/50000 (71%)]\tLoss: 0.351325, Accuracy: 90.23\n",
      "Train Epoch: 28 [33280/50000 (74%)]\tLoss: 0.508907, Accuracy: 85.94\n",
      "Train Epoch: 28 [34560/50000 (77%)]\tLoss: 0.443267, Accuracy: 85.94\n",
      "Train Epoch: 28 [35840/50000 (80%)]\tLoss: 0.329446, Accuracy: 90.23\n",
      "Train Epoch: 28 [37120/50000 (82%)]\tLoss: 0.377736, Accuracy: 87.11\n",
      "Train Epoch: 28 [38400/50000 (85%)]\tLoss: 0.397143, Accuracy: 87.11\n",
      "Train Epoch: 28 [39680/50000 (88%)]\tLoss: 0.450829, Accuracy: 83.20\n",
      "Train Epoch: 28 [40960/50000 (91%)]\tLoss: 0.371886, Accuracy: 88.28\n",
      "Train Epoch: 28 [42240/50000 (94%)]\tLoss: 0.477099, Accuracy: 85.55\n",
      "Train Epoch: 28 [43520/50000 (97%)]\tLoss: 0.347432, Accuracy: 87.89\n",
      "Train Epoch: 28 [35000/50000 (99%)]\tLoss: 0.358562, Accuracy: 90.00\n",
      "\n",
      "Validation set: Average loss: 0.6809, Accuracy: 3904/5000 (78.00%)\n",
      "\n",
      "the time of this epoch:[37.11703824996948 s]\n",
      "\n",
      "Test set: Average loss: 0.6997, Accuracy: 7753/10000 (77.53%)\n",
      "\n",
      "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.377607, Accuracy: 88.28\n",
      "Train Epoch: 29 [1280/50000 (3%)]\tLoss: 0.278086, Accuracy: 91.41\n",
      "Train Epoch: 29 [2560/50000 (6%)]\tLoss: 0.412095, Accuracy: 84.77\n",
      "Train Epoch: 29 [3840/50000 (9%)]\tLoss: 0.424394, Accuracy: 85.94\n",
      "Train Epoch: 29 [5120/50000 (11%)]\tLoss: 0.349772, Accuracy: 85.55\n",
      "Train Epoch: 29 [6400/50000 (14%)]\tLoss: 0.393369, Accuracy: 85.94\n",
      "Train Epoch: 29 [7680/50000 (17%)]\tLoss: 0.350314, Accuracy: 88.67\n",
      "Train Epoch: 29 [8960/50000 (20%)]\tLoss: 0.363665, Accuracy: 87.11\n",
      "Train Epoch: 29 [10240/50000 (23%)]\tLoss: 0.279684, Accuracy: 91.02\n",
      "Train Epoch: 29 [11520/50000 (26%)]\tLoss: 0.476877, Accuracy: 82.81\n",
      "Train Epoch: 29 [12800/50000 (28%)]\tLoss: 0.416613, Accuracy: 84.77\n",
      "Train Epoch: 29 [14080/50000 (31%)]\tLoss: 0.476015, Accuracy: 82.81\n",
      "Train Epoch: 29 [15360/50000 (34%)]\tLoss: 0.408827, Accuracy: 87.89\n",
      "Train Epoch: 29 [16640/50000 (37%)]\tLoss: 0.372521, Accuracy: 89.06\n",
      "Train Epoch: 29 [17920/50000 (40%)]\tLoss: 0.497613, Accuracy: 82.81\n",
      "Train Epoch: 29 [19200/50000 (43%)]\tLoss: 0.462769, Accuracy: 83.20\n",
      "Train Epoch: 29 [20480/50000 (45%)]\tLoss: 0.436689, Accuracy: 86.33\n",
      "Train Epoch: 29 [21760/50000 (48%)]\tLoss: 0.462063, Accuracy: 83.59\n",
      "Train Epoch: 29 [23040/50000 (51%)]\tLoss: 0.351425, Accuracy: 87.50\n",
      "Train Epoch: 29 [24320/50000 (54%)]\tLoss: 0.279179, Accuracy: 89.84\n",
      "Train Epoch: 29 [25600/50000 (57%)]\tLoss: 0.376587, Accuracy: 87.89\n",
      "Train Epoch: 29 [26880/50000 (60%)]\tLoss: 0.409145, Accuracy: 87.89\n",
      "Train Epoch: 29 [28160/50000 (62%)]\tLoss: 0.452543, Accuracy: 83.20\n",
      "Train Epoch: 29 [29440/50000 (65%)]\tLoss: 0.415724, Accuracy: 86.72\n",
      "Train Epoch: 29 [30720/50000 (68%)]\tLoss: 0.327418, Accuracy: 89.06\n",
      "Train Epoch: 29 [32000/50000 (71%)]\tLoss: 0.454509, Accuracy: 82.42\n",
      "Train Epoch: 29 [33280/50000 (74%)]\tLoss: 0.551077, Accuracy: 83.20\n",
      "Train Epoch: 29 [34560/50000 (77%)]\tLoss: 0.530365, Accuracy: 83.20\n",
      "Train Epoch: 29 [35840/50000 (80%)]\tLoss: 0.397254, Accuracy: 87.89\n",
      "Train Epoch: 29 [37120/50000 (82%)]\tLoss: 0.484832, Accuracy: 84.38\n",
      "Train Epoch: 29 [38400/50000 (85%)]\tLoss: 0.390068, Accuracy: 86.33\n",
      "Train Epoch: 29 [39680/50000 (88%)]\tLoss: 0.302562, Accuracy: 90.62\n",
      "Train Epoch: 29 [40960/50000 (91%)]\tLoss: 0.366647, Accuracy: 85.16\n",
      "Train Epoch: 29 [42240/50000 (94%)]\tLoss: 0.414693, Accuracy: 85.16\n",
      "Train Epoch: 29 [43520/50000 (97%)]\tLoss: 0.368242, Accuracy: 87.50\n",
      "Train Epoch: 29 [35000/50000 (99%)]\tLoss: 0.460496, Accuracy: 82.50\n",
      "\n",
      "Validation set: Average loss: 0.7158, Accuracy: 3879/5000 (77.00%)\n",
      "\n",
      "the time of this epoch:[40.30790305137634 s]\n",
      "Train Epoch: 30 [0/50000 (0%)]\tLoss: 0.458026, Accuracy: 85.16\n",
      "Train Epoch: 30 [1280/50000 (3%)]\tLoss: 0.405388, Accuracy: 87.89\n",
      "Train Epoch: 30 [2560/50000 (6%)]\tLoss: 0.343657, Accuracy: 89.06\n",
      "Train Epoch: 30 [3840/50000 (9%)]\tLoss: 0.395593, Accuracy: 88.67\n",
      "Train Epoch: 30 [5120/50000 (11%)]\tLoss: 0.478687, Accuracy: 84.77\n",
      "Train Epoch: 30 [6400/50000 (14%)]\tLoss: 0.386581, Accuracy: 86.33\n",
      "Train Epoch: 30 [7680/50000 (17%)]\tLoss: 0.276261, Accuracy: 90.62\n",
      "Train Epoch: 30 [8960/50000 (20%)]\tLoss: 0.374846, Accuracy: 88.28\n",
      "Train Epoch: 30 [10240/50000 (23%)]\tLoss: 0.334621, Accuracy: 88.67\n",
      "Train Epoch: 30 [11520/50000 (26%)]\tLoss: 0.437901, Accuracy: 85.16\n",
      "Train Epoch: 30 [12800/50000 (28%)]\tLoss: 0.419874, Accuracy: 83.59\n",
      "Train Epoch: 30 [14080/50000 (31%)]\tLoss: 0.431077, Accuracy: 85.16\n",
      "Train Epoch: 30 [15360/50000 (34%)]\tLoss: 0.413382, Accuracy: 85.94\n",
      "Train Epoch: 30 [16640/50000 (37%)]\tLoss: 0.535871, Accuracy: 82.81\n",
      "Train Epoch: 30 [17920/50000 (40%)]\tLoss: 0.311864, Accuracy: 87.89\n",
      "Train Epoch: 30 [19200/50000 (43%)]\tLoss: 0.472186, Accuracy: 84.38\n",
      "Train Epoch: 30 [20480/50000 (45%)]\tLoss: 0.353691, Accuracy: 89.84\n",
      "Train Epoch: 30 [21760/50000 (48%)]\tLoss: 0.416588, Accuracy: 87.11\n",
      "Train Epoch: 30 [23040/50000 (51%)]\tLoss: 0.365923, Accuracy: 86.33\n",
      "Train Epoch: 30 [24320/50000 (54%)]\tLoss: 0.433789, Accuracy: 85.16\n",
      "Train Epoch: 30 [25600/50000 (57%)]\tLoss: 0.307598, Accuracy: 88.67\n",
      "Train Epoch: 30 [26880/50000 (60%)]\tLoss: 0.378812, Accuracy: 86.72\n",
      "Train Epoch: 30 [28160/50000 (62%)]\tLoss: 0.391186, Accuracy: 87.11\n",
      "Train Epoch: 30 [29440/50000 (65%)]\tLoss: 0.348723, Accuracy: 87.11\n",
      "Train Epoch: 30 [30720/50000 (68%)]\tLoss: 0.450328, Accuracy: 85.55\n",
      "Train Epoch: 30 [32000/50000 (71%)]\tLoss: 0.471590, Accuracy: 82.81\n",
      "Train Epoch: 30 [33280/50000 (74%)]\tLoss: 0.464678, Accuracy: 84.38\n",
      "Train Epoch: 30 [34560/50000 (77%)]\tLoss: 0.359197, Accuracy: 86.72\n",
      "Train Epoch: 30 [35840/50000 (80%)]\tLoss: 0.319123, Accuracy: 88.67\n",
      "Train Epoch: 30 [37120/50000 (82%)]\tLoss: 0.317715, Accuracy: 87.11\n",
      "Train Epoch: 30 [38400/50000 (85%)]\tLoss: 0.396147, Accuracy: 84.38\n",
      "Train Epoch: 30 [39680/50000 (88%)]\tLoss: 0.381262, Accuracy: 87.11\n",
      "Train Epoch: 30 [40960/50000 (91%)]\tLoss: 0.426893, Accuracy: 84.38\n",
      "Train Epoch: 30 [42240/50000 (94%)]\tLoss: 0.400970, Accuracy: 86.33\n",
      "Train Epoch: 30 [43520/50000 (97%)]\tLoss: 0.389193, Accuracy: 85.94\n",
      "Train Epoch: 30 [35000/50000 (99%)]\tLoss: 0.362816, Accuracy: 88.00\n",
      "\n",
      "Validation set: Average loss: 0.5651, Accuracy: 4086/5000 (81.00%)\n",
      "\n",
      "the time of this epoch:[37.04419779777527 s]\n",
      "\n",
      "Test set: Average loss: 0.5972, Accuracy: 8092/10000 (80.92%)\n",
      "\n",
      "Train Epoch: 31 [0/50000 (0%)]\tLoss: 0.368926, Accuracy: 85.55\n",
      "Train Epoch: 31 [1280/50000 (3%)]\tLoss: 0.402388, Accuracy: 86.33\n",
      "Train Epoch: 31 [2560/50000 (6%)]\tLoss: 0.345791, Accuracy: 85.16\n",
      "Train Epoch: 31 [3840/50000 (9%)]\tLoss: 0.487316, Accuracy: 83.98\n",
      "Train Epoch: 31 [5120/50000 (11%)]\tLoss: 0.429137, Accuracy: 85.55\n",
      "Train Epoch: 31 [6400/50000 (14%)]\tLoss: 0.347632, Accuracy: 88.28\n",
      "Train Epoch: 31 [7680/50000 (17%)]\tLoss: 0.385421, Accuracy: 87.50\n",
      "Train Epoch: 31 [8960/50000 (20%)]\tLoss: 0.493636, Accuracy: 84.38\n",
      "Train Epoch: 31 [10240/50000 (23%)]\tLoss: 0.375317, Accuracy: 87.89\n",
      "Train Epoch: 31 [11520/50000 (26%)]\tLoss: 0.330072, Accuracy: 87.89\n",
      "Train Epoch: 31 [12800/50000 (28%)]\tLoss: 0.272073, Accuracy: 90.23\n",
      "Train Epoch: 31 [14080/50000 (31%)]\tLoss: 0.366598, Accuracy: 87.11\n",
      "Train Epoch: 31 [15360/50000 (34%)]\tLoss: 0.420530, Accuracy: 86.33\n",
      "Train Epoch: 31 [16640/50000 (37%)]\tLoss: 0.447698, Accuracy: 83.20\n",
      "Train Epoch: 31 [17920/50000 (40%)]\tLoss: 0.487602, Accuracy: 83.59\n",
      "Train Epoch: 31 [19200/50000 (43%)]\tLoss: 0.481064, Accuracy: 82.81\n",
      "Train Epoch: 31 [20480/50000 (45%)]\tLoss: 0.407773, Accuracy: 87.89\n",
      "Train Epoch: 31 [21760/50000 (48%)]\tLoss: 0.391272, Accuracy: 88.28\n",
      "Train Epoch: 31 [23040/50000 (51%)]\tLoss: 0.359034, Accuracy: 87.89\n",
      "Train Epoch: 31 [24320/50000 (54%)]\tLoss: 0.434583, Accuracy: 85.16\n",
      "Train Epoch: 31 [25600/50000 (57%)]\tLoss: 0.440497, Accuracy: 86.72\n",
      "Train Epoch: 31 [26880/50000 (60%)]\tLoss: 0.396532, Accuracy: 87.50\n",
      "Train Epoch: 31 [28160/50000 (62%)]\tLoss: 0.429953, Accuracy: 85.16\n",
      "Train Epoch: 31 [29440/50000 (65%)]\tLoss: 0.490609, Accuracy: 84.38\n",
      "Train Epoch: 31 [30720/50000 (68%)]\tLoss: 0.333437, Accuracy: 89.45\n",
      "Train Epoch: 31 [32000/50000 (71%)]\tLoss: 0.362649, Accuracy: 86.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 31 [33280/50000 (74%)]\tLoss: 0.498425, Accuracy: 82.81\n",
      "Train Epoch: 31 [34560/50000 (77%)]\tLoss: 0.367828, Accuracy: 87.50\n",
      "Train Epoch: 31 [35840/50000 (80%)]\tLoss: 0.450762, Accuracy: 83.98\n",
      "Train Epoch: 31 [37120/50000 (82%)]\tLoss: 0.455778, Accuracy: 85.16\n",
      "Train Epoch: 31 [38400/50000 (85%)]\tLoss: 0.478064, Accuracy: 83.59\n",
      "Train Epoch: 31 [39680/50000 (88%)]\tLoss: 0.426196, Accuracy: 85.55\n",
      "Train Epoch: 31 [40960/50000 (91%)]\tLoss: 0.342028, Accuracy: 88.67\n",
      "Train Epoch: 31 [42240/50000 (94%)]\tLoss: 0.344137, Accuracy: 87.11\n",
      "Train Epoch: 31 [43520/50000 (97%)]\tLoss: 0.366058, Accuracy: 88.67\n",
      "Train Epoch: 31 [35000/50000 (99%)]\tLoss: 0.345766, Accuracy: 88.50\n",
      "\n",
      "Validation set: Average loss: 0.5906, Accuracy: 4067/5000 (81.00%)\n",
      "\n",
      "the time of this epoch:[40.22774362564087 s]\n",
      "Train Epoch: 32 [0/50000 (0%)]\tLoss: 0.320065, Accuracy: 88.67\n",
      "Train Epoch: 32 [1280/50000 (3%)]\tLoss: 0.446030, Accuracy: 83.20\n",
      "Train Epoch: 32 [2560/50000 (6%)]\tLoss: 0.444192, Accuracy: 82.42\n",
      "Train Epoch: 32 [3840/50000 (9%)]\tLoss: 0.469478, Accuracy: 85.16\n",
      "Train Epoch: 32 [5120/50000 (11%)]\tLoss: 0.428981, Accuracy: 83.98\n",
      "Train Epoch: 32 [6400/50000 (14%)]\tLoss: 0.444268, Accuracy: 85.94\n",
      "Train Epoch: 32 [7680/50000 (17%)]\tLoss: 0.396432, Accuracy: 86.33\n",
      "Train Epoch: 32 [8960/50000 (20%)]\tLoss: 0.425398, Accuracy: 87.50\n",
      "Train Epoch: 32 [10240/50000 (23%)]\tLoss: 0.478914, Accuracy: 85.55\n",
      "Train Epoch: 32 [11520/50000 (26%)]\tLoss: 0.438538, Accuracy: 83.59\n",
      "Train Epoch: 32 [12800/50000 (28%)]\tLoss: 0.403402, Accuracy: 85.55\n",
      "Train Epoch: 32 [14080/50000 (31%)]\tLoss: 0.489284, Accuracy: 85.16\n",
      "Train Epoch: 32 [15360/50000 (34%)]\tLoss: 0.424461, Accuracy: 87.89\n",
      "Train Epoch: 32 [16640/50000 (37%)]\tLoss: 0.476515, Accuracy: 82.81\n",
      "Train Epoch: 32 [17920/50000 (40%)]\tLoss: 0.345225, Accuracy: 88.67\n",
      "Train Epoch: 32 [19200/50000 (43%)]\tLoss: 0.413384, Accuracy: 86.33\n",
      "Train Epoch: 32 [20480/50000 (45%)]\tLoss: 0.318066, Accuracy: 89.84\n",
      "Train Epoch: 32 [21760/50000 (48%)]\tLoss: 0.395819, Accuracy: 86.33\n",
      "Train Epoch: 32 [23040/50000 (51%)]\tLoss: 0.426232, Accuracy: 85.16\n",
      "Train Epoch: 32 [24320/50000 (54%)]\tLoss: 0.338765, Accuracy: 89.06\n",
      "Train Epoch: 32 [25600/50000 (57%)]\tLoss: 0.445514, Accuracy: 85.55\n",
      "Train Epoch: 32 [26880/50000 (60%)]\tLoss: 0.508292, Accuracy: 83.59\n",
      "Train Epoch: 32 [28160/50000 (62%)]\tLoss: 0.546090, Accuracy: 79.69\n",
      "Train Epoch: 32 [29440/50000 (65%)]\tLoss: 0.407448, Accuracy: 85.94\n",
      "Train Epoch: 32 [30720/50000 (68%)]\tLoss: 0.438614, Accuracy: 83.98\n",
      "Train Epoch: 32 [32000/50000 (71%)]\tLoss: 0.355199, Accuracy: 88.28\n",
      "Train Epoch: 32 [33280/50000 (74%)]\tLoss: 0.358220, Accuracy: 86.33\n",
      "Train Epoch: 32 [34560/50000 (77%)]\tLoss: 0.342437, Accuracy: 89.06\n",
      "Train Epoch: 32 [35840/50000 (80%)]\tLoss: 0.425722, Accuracy: 85.16\n",
      "Train Epoch: 32 [37120/50000 (82%)]\tLoss: 0.524740, Accuracy: 83.59\n",
      "Train Epoch: 32 [38400/50000 (85%)]\tLoss: 0.375085, Accuracy: 85.16\n",
      "Train Epoch: 32 [39680/50000 (88%)]\tLoss: 0.336328, Accuracy: 88.67\n",
      "Train Epoch: 32 [40960/50000 (91%)]\tLoss: 0.361359, Accuracy: 87.89\n",
      "Train Epoch: 32 [42240/50000 (94%)]\tLoss: 0.462863, Accuracy: 85.55\n",
      "Train Epoch: 32 [43520/50000 (97%)]\tLoss: 0.361827, Accuracy: 88.67\n",
      "Train Epoch: 32 [35000/50000 (99%)]\tLoss: 0.327234, Accuracy: 88.50\n",
      "\n",
      "Validation set: Average loss: 0.5514, Accuracy: 4046/5000 (80.00%)\n",
      "\n",
      "the time of this epoch:[37.07319641113281 s]\n",
      "\n",
      "Test set: Average loss: 0.5566, Accuracy: 8139/10000 (81.39%)\n",
      "\n",
      "Train Epoch: 33 [0/50000 (0%)]\tLoss: 0.410521, Accuracy: 86.72\n",
      "Train Epoch: 33 [1280/50000 (3%)]\tLoss: 0.447813, Accuracy: 82.42\n",
      "Train Epoch: 33 [2560/50000 (6%)]\tLoss: 0.350360, Accuracy: 89.06\n",
      "Train Epoch: 33 [3840/50000 (9%)]\tLoss: 0.410982, Accuracy: 87.89\n",
      "Train Epoch: 33 [5120/50000 (11%)]\tLoss: 0.374352, Accuracy: 87.11\n",
      "Train Epoch: 33 [6400/50000 (14%)]\tLoss: 0.298563, Accuracy: 91.02\n",
      "Train Epoch: 33 [7680/50000 (17%)]\tLoss: 0.365847, Accuracy: 87.11\n",
      "Train Epoch: 33 [8960/50000 (20%)]\tLoss: 0.383778, Accuracy: 86.72\n",
      "Train Epoch: 33 [10240/50000 (23%)]\tLoss: 0.387830, Accuracy: 87.89\n",
      "Train Epoch: 33 [11520/50000 (26%)]\tLoss: 0.419928, Accuracy: 84.38\n",
      "Train Epoch: 33 [12800/50000 (28%)]\tLoss: 0.396131, Accuracy: 87.11\n",
      "Train Epoch: 33 [14080/50000 (31%)]\tLoss: 0.410644, Accuracy: 87.11\n",
      "Train Epoch: 33 [15360/50000 (34%)]\tLoss: 0.443276, Accuracy: 83.98\n",
      "Train Epoch: 33 [16640/50000 (37%)]\tLoss: 0.569990, Accuracy: 82.03\n",
      "Train Epoch: 33 [17920/50000 (40%)]\tLoss: 0.414910, Accuracy: 85.55\n",
      "Train Epoch: 33 [19200/50000 (43%)]\tLoss: 0.393456, Accuracy: 86.72\n",
      "Train Epoch: 33 [20480/50000 (45%)]\tLoss: 0.427313, Accuracy: 84.77\n",
      "Train Epoch: 33 [21760/50000 (48%)]\tLoss: 0.349704, Accuracy: 89.45\n",
      "Train Epoch: 33 [23040/50000 (51%)]\tLoss: 0.466282, Accuracy: 85.16\n",
      "Train Epoch: 33 [24320/50000 (54%)]\tLoss: 0.459264, Accuracy: 85.55\n",
      "Train Epoch: 33 [25600/50000 (57%)]\tLoss: 0.381595, Accuracy: 88.28\n",
      "Train Epoch: 33 [26880/50000 (60%)]\tLoss: 0.456100, Accuracy: 83.98\n",
      "Train Epoch: 33 [28160/50000 (62%)]\tLoss: 0.337097, Accuracy: 88.67\n",
      "Train Epoch: 33 [29440/50000 (65%)]\tLoss: 0.460512, Accuracy: 85.16\n",
      "Train Epoch: 33 [30720/50000 (68%)]\tLoss: 0.408135, Accuracy: 85.55\n",
      "Train Epoch: 33 [32000/50000 (71%)]\tLoss: 0.342433, Accuracy: 88.28\n",
      "Train Epoch: 33 [33280/50000 (74%)]\tLoss: 0.394222, Accuracy: 87.11\n",
      "Train Epoch: 33 [34560/50000 (77%)]\tLoss: 0.507402, Accuracy: 80.86\n",
      "Train Epoch: 33 [35840/50000 (80%)]\tLoss: 0.360470, Accuracy: 87.50\n",
      "Train Epoch: 33 [37120/50000 (82%)]\tLoss: 0.370138, Accuracy: 87.89\n",
      "Train Epoch: 33 [38400/50000 (85%)]\tLoss: 0.409853, Accuracy: 84.77\n",
      "Train Epoch: 33 [39680/50000 (88%)]\tLoss: 0.476167, Accuracy: 83.98\n",
      "Train Epoch: 33 [40960/50000 (91%)]\tLoss: 0.384423, Accuracy: 86.72\n",
      "Train Epoch: 33 [42240/50000 (94%)]\tLoss: 0.331953, Accuracy: 88.28\n",
      "Train Epoch: 33 [43520/50000 (97%)]\tLoss: 0.434498, Accuracy: 83.98\n",
      "Train Epoch: 33 [35000/50000 (99%)]\tLoss: 0.508153, Accuracy: 85.00\n",
      "\n",
      "Validation set: Average loss: 0.5685, Accuracy: 4065/5000 (81.00%)\n",
      "\n",
      "the time of this epoch:[40.27944302558899 s]\n",
      "Train Epoch: 34 [0/50000 (0%)]\tLoss: 0.369515, Accuracy: 87.50\n",
      "Train Epoch: 34 [1280/50000 (3%)]\tLoss: 0.399139, Accuracy: 87.89\n",
      "Train Epoch: 34 [2560/50000 (6%)]\tLoss: 0.418003, Accuracy: 85.94\n",
      "Train Epoch: 34 [3840/50000 (9%)]\tLoss: 0.373967, Accuracy: 87.50\n",
      "Train Epoch: 34 [5120/50000 (11%)]\tLoss: 0.335470, Accuracy: 86.33\n",
      "Train Epoch: 34 [6400/50000 (14%)]\tLoss: 0.356199, Accuracy: 89.45\n",
      "Train Epoch: 34 [7680/50000 (17%)]\tLoss: 0.328304, Accuracy: 87.50\n",
      "Train Epoch: 34 [8960/50000 (20%)]\tLoss: 0.395235, Accuracy: 85.16\n",
      "Train Epoch: 34 [10240/50000 (23%)]\tLoss: 0.300502, Accuracy: 90.62\n",
      "Train Epoch: 34 [11520/50000 (26%)]\tLoss: 0.371161, Accuracy: 88.28\n",
      "Train Epoch: 34 [12800/50000 (28%)]\tLoss: 0.439013, Accuracy: 83.98\n",
      "Train Epoch: 34 [14080/50000 (31%)]\tLoss: 0.455687, Accuracy: 84.38\n",
      "Train Epoch: 34 [15360/50000 (34%)]\tLoss: 0.366048, Accuracy: 89.84\n",
      "Train Epoch: 34 [16640/50000 (37%)]\tLoss: 0.358567, Accuracy: 88.67\n",
      "Train Epoch: 34 [17920/50000 (40%)]\tLoss: 0.399204, Accuracy: 88.67\n",
      "Train Epoch: 34 [19200/50000 (43%)]\tLoss: 0.315226, Accuracy: 88.67\n",
      "Train Epoch: 34 [20480/50000 (45%)]\tLoss: 0.368741, Accuracy: 85.94\n",
      "Train Epoch: 34 [21760/50000 (48%)]\tLoss: 0.401562, Accuracy: 86.33\n",
      "Train Epoch: 34 [23040/50000 (51%)]\tLoss: 0.432844, Accuracy: 83.59\n",
      "Train Epoch: 34 [24320/50000 (54%)]\tLoss: 0.404134, Accuracy: 83.98\n",
      "Train Epoch: 34 [25600/50000 (57%)]\tLoss: 0.401994, Accuracy: 86.72\n",
      "Train Epoch: 34 [26880/50000 (60%)]\tLoss: 0.307997, Accuracy: 90.62\n",
      "Train Epoch: 34 [28160/50000 (62%)]\tLoss: 0.617749, Accuracy: 80.47\n",
      "Train Epoch: 34 [29440/50000 (65%)]\tLoss: 0.493366, Accuracy: 83.59\n",
      "Train Epoch: 34 [30720/50000 (68%)]\tLoss: 0.471085, Accuracy: 84.38\n",
      "Train Epoch: 34 [32000/50000 (71%)]\tLoss: 0.465291, Accuracy: 85.55\n",
      "Train Epoch: 34 [33280/50000 (74%)]\tLoss: 0.415300, Accuracy: 85.55\n",
      "Train Epoch: 34 [34560/50000 (77%)]\tLoss: 0.512444, Accuracy: 83.98\n",
      "Train Epoch: 34 [35840/50000 (80%)]\tLoss: 0.341475, Accuracy: 87.50\n",
      "Train Epoch: 34 [37120/50000 (82%)]\tLoss: 0.388298, Accuracy: 86.33\n",
      "Train Epoch: 34 [38400/50000 (85%)]\tLoss: 0.509383, Accuracy: 84.77\n",
      "Train Epoch: 34 [39680/50000 (88%)]\tLoss: 0.348593, Accuracy: 88.67\n",
      "Train Epoch: 34 [40960/50000 (91%)]\tLoss: 0.560977, Accuracy: 81.25\n",
      "Train Epoch: 34 [42240/50000 (94%)]\tLoss: 0.420279, Accuracy: 85.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 34 [43520/50000 (97%)]\tLoss: 0.351843, Accuracy: 87.50\n",
      "Train Epoch: 34 [35000/50000 (99%)]\tLoss: 0.379462, Accuracy: 85.50\n",
      "\n",
      "Validation set: Average loss: 0.6128, Accuracy: 3963/5000 (79.00%)\n",
      "\n",
      "the time of this epoch:[37.006678104400635 s]\n",
      "\n",
      "Test set: Average loss: 0.6312, Accuracy: 7853/10000 (78.53%)\n",
      "\n",
      "Train Epoch: 35 [0/50000 (0%)]\tLoss: 0.364511, Accuracy: 88.67\n",
      "Train Epoch: 35 [1280/50000 (3%)]\tLoss: 0.373863, Accuracy: 87.11\n",
      "Train Epoch: 35 [2560/50000 (6%)]\tLoss: 0.388420, Accuracy: 86.33\n",
      "Train Epoch: 35 [3840/50000 (9%)]\tLoss: 0.442329, Accuracy: 84.38\n",
      "torch.Size([512, 1, 1])\n",
      "tensor([[[-0.1342]],\n",
      "\n",
      "        [[ 0.8539]],\n",
      "\n",
      "        [[-0.0611]],\n",
      "\n",
      "        [[ 0.2933]],\n",
      "\n",
      "        [[-0.0674]],\n",
      "\n",
      "        [[-1.1247]],\n",
      "\n",
      "        [[-0.0588]],\n",
      "\n",
      "        [[ 1.8172]],\n",
      "\n",
      "        [[ 0.7915]],\n",
      "\n",
      "        [[-1.0217]],\n",
      "\n",
      "        [[ 2.1730]],\n",
      "\n",
      "        [[ 0.6556]],\n",
      "\n",
      "        [[-1.3892]],\n",
      "\n",
      "        [[ 0.1491]],\n",
      "\n",
      "        [[ 0.0247]],\n",
      "\n",
      "        [[-0.0599]],\n",
      "\n",
      "        [[ 1.3984]],\n",
      "\n",
      "        [[ 0.6345]],\n",
      "\n",
      "        [[-0.6508]],\n",
      "\n",
      "        [[-0.1262]],\n",
      "\n",
      "        [[-0.4773]],\n",
      "\n",
      "        [[ 0.9106]],\n",
      "\n",
      "        [[ 0.2962]],\n",
      "\n",
      "        [[ 0.4962]],\n",
      "\n",
      "        [[ 0.1984]],\n",
      "\n",
      "        [[-0.0870]],\n",
      "\n",
      "        [[-0.1820]],\n",
      "\n",
      "        [[ 1.0527]],\n",
      "\n",
      "        [[ 0.7573]],\n",
      "\n",
      "        [[-0.0149]],\n",
      "\n",
      "        [[-0.1114]],\n",
      "\n",
      "        [[ 0.1625]],\n",
      "\n",
      "        [[-1.0303]],\n",
      "\n",
      "        [[ 0.7099]],\n",
      "\n",
      "        [[ 1.1998]],\n",
      "\n",
      "        [[ 1.0208]],\n",
      "\n",
      "        [[-0.0624]],\n",
      "\n",
      "        [[ 1.2154]],\n",
      "\n",
      "        [[ 2.1565]],\n",
      "\n",
      "        [[-0.8308]],\n",
      "\n",
      "        [[-0.4871]],\n",
      "\n",
      "        [[ 0.7698]],\n",
      "\n",
      "        [[ 1.0635]],\n",
      "\n",
      "        [[ 0.0727]],\n",
      "\n",
      "        [[-0.2937]],\n",
      "\n",
      "        [[-0.3434]],\n",
      "\n",
      "        [[ 0.8322]],\n",
      "\n",
      "        [[-0.7636]],\n",
      "\n",
      "        [[-1.5084]],\n",
      "\n",
      "        [[ 1.5864]],\n",
      "\n",
      "        [[-0.3595]],\n",
      "\n",
      "        [[ 0.7929]],\n",
      "\n",
      "        [[-0.5605]],\n",
      "\n",
      "        [[ 0.5253]],\n",
      "\n",
      "        [[ 0.8752]],\n",
      "\n",
      "        [[ 0.5103]],\n",
      "\n",
      "        [[ 0.2659]],\n",
      "\n",
      "        [[ 1.0030]],\n",
      "\n",
      "        [[-0.5967]],\n",
      "\n",
      "        [[ 1.3051]],\n",
      "\n",
      "        [[-0.1983]],\n",
      "\n",
      "        [[-0.0281]],\n",
      "\n",
      "        [[-2.1790]],\n",
      "\n",
      "        [[ 0.8799]],\n",
      "\n",
      "        [[-0.2430]],\n",
      "\n",
      "        [[-1.6100]],\n",
      "\n",
      "        [[ 1.5917]],\n",
      "\n",
      "        [[ 0.8884]],\n",
      "\n",
      "        [[ 0.4586]],\n",
      "\n",
      "        [[ 1.0243]],\n",
      "\n",
      "        [[-0.3666]],\n",
      "\n",
      "        [[ 0.4112]],\n",
      "\n",
      "        [[ 0.2421]],\n",
      "\n",
      "        [[-0.7912]],\n",
      "\n",
      "        [[-0.7548]],\n",
      "\n",
      "        [[-0.2929]],\n",
      "\n",
      "        [[-0.5741]],\n",
      "\n",
      "        [[-0.8223]],\n",
      "\n",
      "        [[ 0.0139]],\n",
      "\n",
      "        [[-1.4690]],\n",
      "\n",
      "        [[-2.4388]],\n",
      "\n",
      "        [[ 0.2159]],\n",
      "\n",
      "        [[ 0.0883]],\n",
      "\n",
      "        [[ 0.7853]],\n",
      "\n",
      "        [[ 0.2779]],\n",
      "\n",
      "        [[-1.4196]],\n",
      "\n",
      "        [[ 1.4910]],\n",
      "\n",
      "        [[-0.2959]],\n",
      "\n",
      "        [[-1.4303]],\n",
      "\n",
      "        [[-0.8920]],\n",
      "\n",
      "        [[-0.9468]],\n",
      "\n",
      "        [[ 1.1101]],\n",
      "\n",
      "        [[ 0.0591]],\n",
      "\n",
      "        [[-1.2367]],\n",
      "\n",
      "        [[-1.0516]],\n",
      "\n",
      "        [[ 2.4801]],\n",
      "\n",
      "        [[-0.3024]],\n",
      "\n",
      "        [[-0.1603]],\n",
      "\n",
      "        [[ 0.8313]],\n",
      "\n",
      "        [[-0.6184]],\n",
      "\n",
      "        [[ 1.0078]],\n",
      "\n",
      "        [[ 0.1199]],\n",
      "\n",
      "        [[ 0.7155]],\n",
      "\n",
      "        [[ 0.6955]],\n",
      "\n",
      "        [[ 0.5611]],\n",
      "\n",
      "        [[-0.3555]],\n",
      "\n",
      "        [[ 1.4453]],\n",
      "\n",
      "        [[-0.3563]],\n",
      "\n",
      "        [[ 0.2510]],\n",
      "\n",
      "        [[-0.0028]],\n",
      "\n",
      "        [[ 0.4613]],\n",
      "\n",
      "        [[ 0.3797]],\n",
      "\n",
      "        [[ 0.8755]],\n",
      "\n",
      "        [[-0.2232]],\n",
      "\n",
      "        [[-1.4510]],\n",
      "\n",
      "        [[ 0.3122]],\n",
      "\n",
      "        [[ 0.4835]],\n",
      "\n",
      "        [[-0.0153]],\n",
      "\n",
      "        [[-0.3565]],\n",
      "\n",
      "        [[-1.1657]],\n",
      "\n",
      "        [[-0.7910]],\n",
      "\n",
      "        [[-1.7687]],\n",
      "\n",
      "        [[-0.9633]],\n",
      "\n",
      "        [[-0.1004]],\n",
      "\n",
      "        [[ 0.4641]],\n",
      "\n",
      "        [[ 0.3931]],\n",
      "\n",
      "        [[-1.0668]],\n",
      "\n",
      "        [[ 1.1571]],\n",
      "\n",
      "        [[-0.6488]],\n",
      "\n",
      "        [[-0.2381]],\n",
      "\n",
      "        [[-1.7472]],\n",
      "\n",
      "        [[ 0.0340]],\n",
      "\n",
      "        [[-1.0108]],\n",
      "\n",
      "        [[-2.2960]],\n",
      "\n",
      "        [[-0.0908]],\n",
      "\n",
      "        [[-1.4920]],\n",
      "\n",
      "        [[-0.7595]],\n",
      "\n",
      "        [[-0.8786]],\n",
      "\n",
      "        [[-1.1841]],\n",
      "\n",
      "        [[-1.0631]],\n",
      "\n",
      "        [[-1.5736]],\n",
      "\n",
      "        [[ 0.1729]],\n",
      "\n",
      "        [[ 1.9823]],\n",
      "\n",
      "        [[-1.1978]],\n",
      "\n",
      "        [[ 1.2751]],\n",
      "\n",
      "        [[ 1.1414]],\n",
      "\n",
      "        [[ 1.7164]],\n",
      "\n",
      "        [[ 0.9587]],\n",
      "\n",
      "        [[-0.3283]],\n",
      "\n",
      "        [[-0.8570]],\n",
      "\n",
      "        [[ 0.8099]],\n",
      "\n",
      "        [[ 0.5381]],\n",
      "\n",
      "        [[-0.7469]],\n",
      "\n",
      "        [[ 1.5074]],\n",
      "\n",
      "        [[-0.8294]],\n",
      "\n",
      "        [[-1.0444]],\n",
      "\n",
      "        [[ 0.6473]],\n",
      "\n",
      "        [[ 0.0286]],\n",
      "\n",
      "        [[-0.6588]],\n",
      "\n",
      "        [[ 0.1412]],\n",
      "\n",
      "        [[-0.6132]],\n",
      "\n",
      "        [[ 1.9236]],\n",
      "\n",
      "        [[-0.1076]],\n",
      "\n",
      "        [[-0.3102]],\n",
      "\n",
      "        [[-0.9991]],\n",
      "\n",
      "        [[-1.4152]],\n",
      "\n",
      "        [[ 0.2337]],\n",
      "\n",
      "        [[ 1.5928]],\n",
      "\n",
      "        [[-0.4764]],\n",
      "\n",
      "        [[ 0.9881]],\n",
      "\n",
      "        [[ 0.5229]],\n",
      "\n",
      "        [[ 0.0455]],\n",
      "\n",
      "        [[ 0.4589]],\n",
      "\n",
      "        [[-0.0384]],\n",
      "\n",
      "        [[ 0.1732]],\n",
      "\n",
      "        [[-0.7089]],\n",
      "\n",
      "        [[ 1.1644]],\n",
      "\n",
      "        [[-1.1613]],\n",
      "\n",
      "        [[ 0.6927]],\n",
      "\n",
      "        [[ 1.0691]],\n",
      "\n",
      "        [[-0.9306]],\n",
      "\n",
      "        [[ 0.0087]],\n",
      "\n",
      "        [[-0.5286]],\n",
      "\n",
      "        [[ 0.8627]],\n",
      "\n",
      "        [[-0.8672]],\n",
      "\n",
      "        [[ 0.5647]],\n",
      "\n",
      "        [[ 0.9072]],\n",
      "\n",
      "        [[-0.9209]],\n",
      "\n",
      "        [[-1.4269]],\n",
      "\n",
      "        [[ 0.5853]],\n",
      "\n",
      "        [[ 0.0988]],\n",
      "\n",
      "        [[ 0.0563]],\n",
      "\n",
      "        [[-1.0398]],\n",
      "\n",
      "        [[-0.3007]],\n",
      "\n",
      "        [[ 1.9541]],\n",
      "\n",
      "        [[-0.0452]],\n",
      "\n",
      "        [[-0.1716]],\n",
      "\n",
      "        [[-0.7224]],\n",
      "\n",
      "        [[-0.2062]],\n",
      "\n",
      "        [[ 1.3376]],\n",
      "\n",
      "        [[ 0.5257]],\n",
      "\n",
      "        [[ 0.4269]],\n",
      "\n",
      "        [[-1.1650]],\n",
      "\n",
      "        [[-0.6577]],\n",
      "\n",
      "        [[ 0.0537]],\n",
      "\n",
      "        [[-0.3903]],\n",
      "\n",
      "        [[ 0.1123]],\n",
      "\n",
      "        [[-0.8781]],\n",
      "\n",
      "        [[-0.0800]],\n",
      "\n",
      "        [[ 2.1696]],\n",
      "\n",
      "        [[-2.0711]],\n",
      "\n",
      "        [[ 1.5853]],\n",
      "\n",
      "        [[ 1.5060]],\n",
      "\n",
      "        [[ 0.1738]],\n",
      "\n",
      "        [[ 2.6993]],\n",
      "\n",
      "        [[-0.8748]],\n",
      "\n",
      "        [[-0.9647]],\n",
      "\n",
      "        [[-0.9044]],\n",
      "\n",
      "        [[ 0.3902]],\n",
      "\n",
      "        [[-0.9290]],\n",
      "\n",
      "        [[ 0.1476]],\n",
      "\n",
      "        [[ 1.4134]],\n",
      "\n",
      "        [[ 0.2992]],\n",
      "\n",
      "        [[-0.4131]],\n",
      "\n",
      "        [[ 0.0557]],\n",
      "\n",
      "        [[-2.3148]],\n",
      "\n",
      "        [[ 0.8214]],\n",
      "\n",
      "        [[ 0.0018]],\n",
      "\n",
      "        [[-0.8075]],\n",
      "\n",
      "        [[ 1.0455]],\n",
      "\n",
      "        [[ 0.1743]],\n",
      "\n",
      "        [[ 0.3128]],\n",
      "\n",
      "        [[ 2.4212]],\n",
      "\n",
      "        [[-0.1813]],\n",
      "\n",
      "        [[ 1.0338]],\n",
      "\n",
      "        [[-0.6211]],\n",
      "\n",
      "        [[-0.5848]],\n",
      "\n",
      "        [[ 1.0579]],\n",
      "\n",
      "        [[ 0.3438]],\n",
      "\n",
      "        [[ 0.4167]],\n",
      "\n",
      "        [[-0.1537]],\n",
      "\n",
      "        [[-0.8139]],\n",
      "\n",
      "        [[ 1.0944]],\n",
      "\n",
      "        [[ 0.7702]],\n",
      "\n",
      "        [[-0.8342]],\n",
      "\n",
      "        [[ 0.9402]],\n",
      "\n",
      "        [[-0.3867]],\n",
      "\n",
      "        [[-2.8166]],\n",
      "\n",
      "        [[-0.8283]],\n",
      "\n",
      "        [[ 0.4593]],\n",
      "\n",
      "        [[ 0.8797]],\n",
      "\n",
      "        [[-0.5998]],\n",
      "\n",
      "        [[ 1.1287]],\n",
      "\n",
      "        [[-0.3587]],\n",
      "\n",
      "        [[ 1.0032]],\n",
      "\n",
      "        [[ 1.2224]],\n",
      "\n",
      "        [[-0.0016]],\n",
      "\n",
      "        [[-0.1998]],\n",
      "\n",
      "        [[ 0.8898]],\n",
      "\n",
      "        [[ 0.6810]],\n",
      "\n",
      "        [[ 0.2498]],\n",
      "\n",
      "        [[-1.0189]],\n",
      "\n",
      "        [[-1.8048]],\n",
      "\n",
      "        [[ 0.2604]],\n",
      "\n",
      "        [[ 2.0090]],\n",
      "\n",
      "        [[-0.4685]],\n",
      "\n",
      "        [[-0.7572]],\n",
      "\n",
      "        [[ 0.6850]],\n",
      "\n",
      "        [[-1.2289]],\n",
      "\n",
      "        [[ 0.0728]],\n",
      "\n",
      "        [[-1.9032]],\n",
      "\n",
      "        [[-0.8110]],\n",
      "\n",
      "        [[ 0.2685]],\n",
      "\n",
      "        [[ 0.7286]],\n",
      "\n",
      "        [[ 0.5378]],\n",
      "\n",
      "        [[ 0.1506]],\n",
      "\n",
      "        [[-0.7232]],\n",
      "\n",
      "        [[ 1.2554]],\n",
      "\n",
      "        [[ 0.0218]],\n",
      "\n",
      "        [[-0.2378]],\n",
      "\n",
      "        [[-0.6992]],\n",
      "\n",
      "        [[-0.7192]],\n",
      "\n",
      "        [[ 0.9265]],\n",
      "\n",
      "        [[-0.7199]],\n",
      "\n",
      "        [[ 2.0194]],\n",
      "\n",
      "        [[-0.7177]],\n",
      "\n",
      "        [[-0.3743]],\n",
      "\n",
      "        [[-0.1755]],\n",
      "\n",
      "        [[ 0.9097]],\n",
      "\n",
      "        [[-0.1273]],\n",
      "\n",
      "        [[ 0.2324]],\n",
      "\n",
      "        [[ 1.7760]],\n",
      "\n",
      "        [[-1.0741]],\n",
      "\n",
      "        [[ 1.4316]],\n",
      "\n",
      "        [[ 0.1721]],\n",
      "\n",
      "        [[-0.6959]],\n",
      "\n",
      "        [[ 1.5678]],\n",
      "\n",
      "        [[-0.8887]],\n",
      "\n",
      "        [[ 1.5288]],\n",
      "\n",
      "        [[-0.4130]],\n",
      "\n",
      "        [[ 0.2952]],\n",
      "\n",
      "        [[-0.4254]],\n",
      "\n",
      "        [[ 0.1067]],\n",
      "\n",
      "        [[-1.8510]],\n",
      "\n",
      "        [[ 1.2912]],\n",
      "\n",
      "        [[ 1.6361]],\n",
      "\n",
      "        [[ 0.4737]],\n",
      "\n",
      "        [[-1.4003]],\n",
      "\n",
      "        [[-0.9540]],\n",
      "\n",
      "        [[ 0.5597]],\n",
      "\n",
      "        [[-0.7985]],\n",
      "\n",
      "        [[ 0.8816]],\n",
      "\n",
      "        [[ 1.3440]],\n",
      "\n",
      "        [[-0.0492]],\n",
      "\n",
      "        [[ 0.4768]],\n",
      "\n",
      "        [[-0.1215]],\n",
      "\n",
      "        [[ 0.9223]],\n",
      "\n",
      "        [[-1.2918]],\n",
      "\n",
      "        [[-0.1116]],\n",
      "\n",
      "        [[ 1.6548]],\n",
      "\n",
      "        [[ 0.7423]],\n",
      "\n",
      "        [[ 1.3792]],\n",
      "\n",
      "        [[ 1.6240]],\n",
      "\n",
      "        [[ 1.4105]],\n",
      "\n",
      "        [[-0.9088]],\n",
      "\n",
      "        [[-0.6527]],\n",
      "\n",
      "        [[-0.3691]],\n",
      "\n",
      "        [[ 0.0748]],\n",
      "\n",
      "        [[-0.3692]],\n",
      "\n",
      "        [[ 3.0605]],\n",
      "\n",
      "        [[-1.0686]],\n",
      "\n",
      "        [[ 0.5223]],\n",
      "\n",
      "        [[ 0.9284]],\n",
      "\n",
      "        [[-1.4849]],\n",
      "\n",
      "        [[ 0.3561]],\n",
      "\n",
      "        [[ 2.0936]],\n",
      "\n",
      "        [[ 1.7724]],\n",
      "\n",
      "        [[ 1.2693]],\n",
      "\n",
      "        [[-0.2226]],\n",
      "\n",
      "        [[ 0.7446]],\n",
      "\n",
      "        [[ 0.5624]],\n",
      "\n",
      "        [[-0.0374]],\n",
      "\n",
      "        [[-1.0492]],\n",
      "\n",
      "        [[-0.8339]],\n",
      "\n",
      "        [[ 1.5765]],\n",
      "\n",
      "        [[ 0.8593]],\n",
      "\n",
      "        [[ 0.5912]],\n",
      "\n",
      "        [[-0.3877]],\n",
      "\n",
      "        [[ 0.3582]],\n",
      "\n",
      "        [[-0.2057]],\n",
      "\n",
      "        [[-0.7887]],\n",
      "\n",
      "        [[-0.3801]],\n",
      "\n",
      "        [[ 0.6776]],\n",
      "\n",
      "        [[ 0.8332]],\n",
      "\n",
      "        [[ 1.1374]],\n",
      "\n",
      "        [[ 1.2217]],\n",
      "\n",
      "        [[-0.2363]],\n",
      "\n",
      "        [[ 1.1702]],\n",
      "\n",
      "        [[ 1.7362]],\n",
      "\n",
      "        [[ 0.3841]],\n",
      "\n",
      "        [[ 0.0288]],\n",
      "\n",
      "        [[ 0.1364]],\n",
      "\n",
      "        [[-0.0692]],\n",
      "\n",
      "        [[ 1.0188]],\n",
      "\n",
      "        [[ 1.7504]],\n",
      "\n",
      "        [[-0.0089]],\n",
      "\n",
      "        [[ 1.8674]],\n",
      "\n",
      "        [[-1.3809]],\n",
      "\n",
      "        [[-0.0575]],\n",
      "\n",
      "        [[ 1.6427]],\n",
      "\n",
      "        [[-0.1872]],\n",
      "\n",
      "        [[-0.6620]],\n",
      "\n",
      "        [[-0.9233]],\n",
      "\n",
      "        [[-0.3971]],\n",
      "\n",
      "        [[ 0.9753]],\n",
      "\n",
      "        [[-0.2528]],\n",
      "\n",
      "        [[-1.1520]],\n",
      "\n",
      "        [[ 1.1130]],\n",
      "\n",
      "        [[ 1.9569]],\n",
      "\n",
      "        [[ 1.1769]],\n",
      "\n",
      "        [[ 1.3430]],\n",
      "\n",
      "        [[ 0.0683]],\n",
      "\n",
      "        [[-0.2279]],\n",
      "\n",
      "        [[ 2.4491]],\n",
      "\n",
      "        [[-0.7163]],\n",
      "\n",
      "        [[-0.9140]],\n",
      "\n",
      "        [[ 0.2277]],\n",
      "\n",
      "        [[-0.2991]],\n",
      "\n",
      "        [[ 0.9572]],\n",
      "\n",
      "        [[ 0.3069]],\n",
      "\n",
      "        [[-0.5665]],\n",
      "\n",
      "        [[ 0.0075]],\n",
      "\n",
      "        [[ 0.3095]],\n",
      "\n",
      "        [[ 0.0435]],\n",
      "\n",
      "        [[ 1.5311]],\n",
      "\n",
      "        [[ 1.4457]],\n",
      "\n",
      "        [[-0.1882]],\n",
      "\n",
      "        [[-0.3049]],\n",
      "\n",
      "        [[-1.3377]],\n",
      "\n",
      "        [[ 0.6586]],\n",
      "\n",
      "        [[ 0.3605]],\n",
      "\n",
      "        [[ 1.6113]],\n",
      "\n",
      "        [[ 2.4964]],\n",
      "\n",
      "        [[ 0.4188]],\n",
      "\n",
      "        [[-0.9981]],\n",
      "\n",
      "        [[ 0.1298]],\n",
      "\n",
      "        [[-0.0029]],\n",
      "\n",
      "        [[-1.7701]],\n",
      "\n",
      "        [[ 0.7384]],\n",
      "\n",
      "        [[ 1.3409]],\n",
      "\n",
      "        [[ 0.0475]],\n",
      "\n",
      "        [[ 0.3206]],\n",
      "\n",
      "        [[ 0.5032]],\n",
      "\n",
      "        [[-0.0973]],\n",
      "\n",
      "        [[ 0.4461]],\n",
      "\n",
      "        [[-1.0206]],\n",
      "\n",
      "        [[ 0.4658]],\n",
      "\n",
      "        [[ 0.2166]],\n",
      "\n",
      "        [[ 0.3385]],\n",
      "\n",
      "        [[-1.4097]],\n",
      "\n",
      "        [[-0.2320]],\n",
      "\n",
      "        [[ 0.9616]],\n",
      "\n",
      "        [[-0.1814]],\n",
      "\n",
      "        [[-0.0885]],\n",
      "\n",
      "        [[ 0.7390]],\n",
      "\n",
      "        [[ 0.1087]],\n",
      "\n",
      "        [[-0.0460]],\n",
      "\n",
      "        [[ 0.1853]],\n",
      "\n",
      "        [[ 0.5104]],\n",
      "\n",
      "        [[ 1.6039]],\n",
      "\n",
      "        [[ 1.6904]],\n",
      "\n",
      "        [[ 0.1019]],\n",
      "\n",
      "        [[-0.3540]],\n",
      "\n",
      "        [[-0.7973]],\n",
      "\n",
      "        [[ 0.1163]],\n",
      "\n",
      "        [[-0.2867]],\n",
      "\n",
      "        [[-1.3492]],\n",
      "\n",
      "        [[-0.6493]],\n",
      "\n",
      "        [[-0.1001]],\n",
      "\n",
      "        [[ 1.1374]],\n",
      "\n",
      "        [[ 0.7418]],\n",
      "\n",
      "        [[ 0.3013]],\n",
      "\n",
      "        [[-0.7153]],\n",
      "\n",
      "        [[-1.5146]],\n",
      "\n",
      "        [[-1.4846]],\n",
      "\n",
      "        [[ 0.3411]],\n",
      "\n",
      "        [[-0.9525]],\n",
      "\n",
      "        [[-0.1981]],\n",
      "\n",
      "        [[-0.2741]],\n",
      "\n",
      "        [[-0.3610]],\n",
      "\n",
      "        [[ 0.4899]],\n",
      "\n",
      "        [[-0.6922]],\n",
      "\n",
      "        [[-0.8778]],\n",
      "\n",
      "        [[ 0.5674]],\n",
      "\n",
      "        [[-0.7877]],\n",
      "\n",
      "        [[-1.5094]],\n",
      "\n",
      "        [[ 0.8161]],\n",
      "\n",
      "        [[-0.9975]],\n",
      "\n",
      "        [[-1.0672]],\n",
      "\n",
      "        [[ 1.0181]],\n",
      "\n",
      "        [[-0.6184]],\n",
      "\n",
      "        [[ 0.8219]],\n",
      "\n",
      "        [[-0.2751]],\n",
      "\n",
      "        [[ 0.3473]],\n",
      "\n",
      "        [[ 0.1216]],\n",
      "\n",
      "        [[ 0.0308]],\n",
      "\n",
      "        [[-1.2354]],\n",
      "\n",
      "        [[ 1.3263]],\n",
      "\n",
      "        [[-0.4280]],\n",
      "\n",
      "        [[ 0.2055]],\n",
      "\n",
      "        [[-0.4408]],\n",
      "\n",
      "        [[-1.3608]],\n",
      "\n",
      "        [[ 0.3627]],\n",
      "\n",
      "        [[ 0.5874]],\n",
      "\n",
      "        [[ 0.3991]],\n",
      "\n",
      "        [[ 0.2820]],\n",
      "\n",
      "        [[-0.4034]],\n",
      "\n",
      "        [[ 0.2083]],\n",
      "\n",
      "        [[ 1.2111]],\n",
      "\n",
      "        [[-0.0392]],\n",
      "\n",
      "        [[ 0.2345]],\n",
      "\n",
      "        [[ 0.8183]],\n",
      "\n",
      "        [[ 0.7374]],\n",
      "\n",
      "        [[ 0.9408]],\n",
      "\n",
      "        [[-0.0593]],\n",
      "\n",
      "        [[ 1.4768]],\n",
      "\n",
      "        [[ 0.1132]],\n",
      "\n",
      "        [[ 0.0525]],\n",
      "\n",
      "        [[ 1.4869]],\n",
      "\n",
      "        [[-0.3111]],\n",
      "\n",
      "        [[ 1.6412]],\n",
      "\n",
      "        [[ 0.1293]],\n",
      "\n",
      "        [[-0.3500]],\n",
      "\n",
      "        [[ 0.2648]],\n",
      "\n",
      "        [[-1.3573]],\n",
      "\n",
      "        [[-0.5149]],\n",
      "\n",
      "        [[-1.2850]],\n",
      "\n",
      "        [[-1.4014]],\n",
      "\n",
      "        [[ 0.7866]],\n",
      "\n",
      "        [[-0.3042]],\n",
      "\n",
      "        [[ 0.1916]],\n",
      "\n",
      "        [[-0.0487]],\n",
      "\n",
      "        [[-0.4335]],\n",
      "\n",
      "        [[-0.0303]],\n",
      "\n",
      "        [[ 0.0512]],\n",
      "\n",
      "        [[-0.3151]],\n",
      "\n",
      "        [[ 0.1835]],\n",
      "\n",
      "        [[ 2.2304]],\n",
      "\n",
      "        [[-0.2199]],\n",
      "\n",
      "        [[-0.5637]],\n",
      "\n",
      "        [[ 0.2237]],\n",
      "\n",
      "        [[-0.4820]]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor(1.00000e-02 *\n",
      "       [[[-4.0546]]], device='cuda:0')\n",
      "torch.Size([1, 448, 512])\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 1.9508,  1.9533,  1.9528,  ...,  1.9524,  1.9518,  1.9550],\n",
      "         [ 1.9511,  1.9489,  1.9510,  ...,  1.9492,  1.9502,  1.9503],\n",
      "         [ 1.9520,  1.9551,  1.9512,  ...,  1.9533,  1.9564,  1.9569],\n",
      "         ...,\n",
      "         [ 1.9521,  1.9543,  1.9508,  ...,  1.9539,  1.9542,  1.9517],\n",
      "         [ 1.9576,  1.9563,  1.9548,  ...,  1.9513,  1.9503,  1.9516],\n",
      "         [ 1.9530,  1.9547,  1.9550,  ...,  1.9520,  1.9526,  1.9513]]], device='cuda:0')\n",
      "Train Epoch: 35 [5120/50000 (11%)]\tLoss: 0.426957, Accuracy: 84.77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 35 [6400/50000 (14%)]\tLoss: 0.371240, Accuracy: 87.11\n",
      "Train Epoch: 35 [7680/50000 (17%)]\tLoss: 0.352777, Accuracy: 88.28\n",
      "Train Epoch: 35 [8960/50000 (20%)]\tLoss: 0.419974, Accuracy: 87.89\n",
      "Train Epoch: 35 [10240/50000 (23%)]\tLoss: 0.476507, Accuracy: 82.81\n",
      "Train Epoch: 35 [11520/50000 (26%)]\tLoss: 0.389522, Accuracy: 86.72\n",
      "Train Epoch: 35 [12800/50000 (28%)]\tLoss: 0.434777, Accuracy: 86.33\n",
      "Train Epoch: 35 [14080/50000 (31%)]\tLoss: 0.422669, Accuracy: 85.94\n",
      "Train Epoch: 35 [15360/50000 (34%)]\tLoss: 0.427802, Accuracy: 85.55\n",
      "Train Epoch: 35 [16640/50000 (37%)]\tLoss: 0.334970, Accuracy: 87.89\n",
      "Train Epoch: 35 [17920/50000 (40%)]\tLoss: 0.404548, Accuracy: 85.94\n",
      "Train Epoch: 35 [19200/50000 (43%)]\tLoss: 0.350750, Accuracy: 86.72\n",
      "Train Epoch: 35 [20480/50000 (45%)]\tLoss: 0.310157, Accuracy: 90.62\n",
      "Train Epoch: 35 [21760/50000 (48%)]\tLoss: 0.391348, Accuracy: 88.28\n",
      "torch.Size([512, 1, 1])\n",
      "tensor([[[-1.1422]],\n",
      "\n",
      "        [[-0.5346]],\n",
      "\n",
      "        [[-0.3078]],\n",
      "\n",
      "        [[ 0.2535]],\n",
      "\n",
      "        [[ 0.9166]],\n",
      "\n",
      "        [[-0.5656]],\n",
      "\n",
      "        [[-1.8059]],\n",
      "\n",
      "        [[-0.9363]],\n",
      "\n",
      "        [[-1.0666]],\n",
      "\n",
      "        [[ 0.1119]],\n",
      "\n",
      "        [[-0.0817]],\n",
      "\n",
      "        [[-1.0197]],\n",
      "\n",
      "        [[-1.1784]],\n",
      "\n",
      "        [[-0.2739]],\n",
      "\n",
      "        [[ 0.9402]],\n",
      "\n",
      "        [[ 1.0116]],\n",
      "\n",
      "        [[-0.7719]],\n",
      "\n",
      "        [[ 0.7508]],\n",
      "\n",
      "        [[-1.2299]],\n",
      "\n",
      "        [[ 0.9217]],\n",
      "\n",
      "        [[-0.7362]],\n",
      "\n",
      "        [[-1.9108]],\n",
      "\n",
      "        [[ 0.2936]],\n",
      "\n",
      "        [[ 0.3932]],\n",
      "\n",
      "        [[ 0.6936]],\n",
      "\n",
      "        [[ 2.3162]],\n",
      "\n",
      "        [[-1.8789]],\n",
      "\n",
      "        [[ 0.0134]],\n",
      "\n",
      "        [[-0.4541]],\n",
      "\n",
      "        [[ 0.4820]],\n",
      "\n",
      "        [[-1.4737]],\n",
      "\n",
      "        [[ 1.8783]],\n",
      "\n",
      "        [[ 0.9826]],\n",
      "\n",
      "        [[-0.5980]],\n",
      "\n",
      "        [[ 0.9936]],\n",
      "\n",
      "        [[-0.9569]],\n",
      "\n",
      "        [[-0.4773]],\n",
      "\n",
      "        [[ 0.9163]],\n",
      "\n",
      "        [[ 1.5700]],\n",
      "\n",
      "        [[ 0.4466]],\n",
      "\n",
      "        [[ 0.1917]],\n",
      "\n",
      "        [[ 0.9945]],\n",
      "\n",
      "        [[ 0.6555]],\n",
      "\n",
      "        [[ 2.7473]],\n",
      "\n",
      "        [[-0.1783]],\n",
      "\n",
      "        [[ 0.6471]],\n",
      "\n",
      "        [[ 1.0732]],\n",
      "\n",
      "        [[-0.9886]],\n",
      "\n",
      "        [[-0.7691]],\n",
      "\n",
      "        [[ 0.9392]],\n",
      "\n",
      "        [[-1.3717]],\n",
      "\n",
      "        [[ 1.3692]],\n",
      "\n",
      "        [[-0.4145]],\n",
      "\n",
      "        [[ 0.2098]],\n",
      "\n",
      "        [[-0.7384]],\n",
      "\n",
      "        [[ 0.6631]],\n",
      "\n",
      "        [[-0.0574]],\n",
      "\n",
      "        [[-0.9371]],\n",
      "\n",
      "        [[-0.3692]],\n",
      "\n",
      "        [[ 1.2178]],\n",
      "\n",
      "        [[ 0.4173]],\n",
      "\n",
      "        [[-0.6699]],\n",
      "\n",
      "        [[-0.0837]],\n",
      "\n",
      "        [[ 0.9746]],\n",
      "\n",
      "        [[-0.1187]],\n",
      "\n",
      "        [[ 1.1184]],\n",
      "\n",
      "        [[ 1.1267]],\n",
      "\n",
      "        [[ 1.8431]],\n",
      "\n",
      "        [[-0.3794]],\n",
      "\n",
      "        [[-0.2730]],\n",
      "\n",
      "        [[-0.7050]],\n",
      "\n",
      "        [[ 0.7728]],\n",
      "\n",
      "        [[ 0.5468]],\n",
      "\n",
      "        [[-0.0989]],\n",
      "\n",
      "        [[ 1.2822]],\n",
      "\n",
      "        [[ 0.6028]],\n",
      "\n",
      "        [[-1.0394]],\n",
      "\n",
      "        [[-0.2561]],\n",
      "\n",
      "        [[-2.1970]],\n",
      "\n",
      "        [[ 0.1855]],\n",
      "\n",
      "        [[ 1.7922]],\n",
      "\n",
      "        [[ 0.9322]],\n",
      "\n",
      "        [[ 0.0952]],\n",
      "\n",
      "        [[-0.0144]],\n",
      "\n",
      "        [[-2.5527]],\n",
      "\n",
      "        [[-0.9152]],\n",
      "\n",
      "        [[-0.7924]],\n",
      "\n",
      "        [[ 0.7551]],\n",
      "\n",
      "        [[ 0.6925]],\n",
      "\n",
      "        [[ 0.5080]],\n",
      "\n",
      "        [[ 0.5955]],\n",
      "\n",
      "        [[ 0.6985]],\n",
      "\n",
      "        [[ 1.6253]],\n",
      "\n",
      "        [[ 1.0809]],\n",
      "\n",
      "        [[-0.8525]],\n",
      "\n",
      "        [[-0.5308]],\n",
      "\n",
      "        [[-1.5986]],\n",
      "\n",
      "        [[ 2.7703]],\n",
      "\n",
      "        [[ 0.0600]],\n",
      "\n",
      "        [[ 1.4928]],\n",
      "\n",
      "        [[-0.1205]],\n",
      "\n",
      "        [[-0.9350]],\n",
      "\n",
      "        [[-1.1598]],\n",
      "\n",
      "        [[-0.0845]],\n",
      "\n",
      "        [[-0.6596]],\n",
      "\n",
      "        [[ 0.8539]],\n",
      "\n",
      "        [[ 0.7910]],\n",
      "\n",
      "        [[ 2.5217]],\n",
      "\n",
      "        [[ 0.7258]],\n",
      "\n",
      "        [[ 1.8447]],\n",
      "\n",
      "        [[ 1.3386]],\n",
      "\n",
      "        [[ 0.2648]],\n",
      "\n",
      "        [[-0.3108]],\n",
      "\n",
      "        [[ 0.2884]],\n",
      "\n",
      "        [[-0.3610]],\n",
      "\n",
      "        [[ 0.7599]],\n",
      "\n",
      "        [[ 0.8487]],\n",
      "\n",
      "        [[ 2.1816]],\n",
      "\n",
      "        [[ 1.2587]],\n",
      "\n",
      "        [[-0.8096]],\n",
      "\n",
      "        [[ 0.6356]],\n",
      "\n",
      "        [[-0.0407]],\n",
      "\n",
      "        [[ 0.4756]],\n",
      "\n",
      "        [[ 0.7901]],\n",
      "\n",
      "        [[-1.6572]],\n",
      "\n",
      "        [[ 0.5599]],\n",
      "\n",
      "        [[-0.3395]],\n",
      "\n",
      "        [[ 1.4319]],\n",
      "\n",
      "        [[ 0.4386]],\n",
      "\n",
      "        [[ 1.3403]],\n",
      "\n",
      "        [[ 1.3425]],\n",
      "\n",
      "        [[-0.4703]],\n",
      "\n",
      "        [[-0.1498]],\n",
      "\n",
      "        [[ 0.2092]],\n",
      "\n",
      "        [[-1.8106]],\n",
      "\n",
      "        [[-1.1830]],\n",
      "\n",
      "        [[-0.4082]],\n",
      "\n",
      "        [[ 0.8706]],\n",
      "\n",
      "        [[ 0.2873]],\n",
      "\n",
      "        [[ 0.8765]],\n",
      "\n",
      "        [[ 0.9149]],\n",
      "\n",
      "        [[ 0.5074]],\n",
      "\n",
      "        [[-0.0161]],\n",
      "\n",
      "        [[-0.1168]],\n",
      "\n",
      "        [[-0.5067]],\n",
      "\n",
      "        [[ 0.8058]],\n",
      "\n",
      "        [[ 0.1280]],\n",
      "\n",
      "        [[-0.3088]],\n",
      "\n",
      "        [[ 0.6640]],\n",
      "\n",
      "        [[-0.5722]],\n",
      "\n",
      "        [[ 1.3109]],\n",
      "\n",
      "        [[ 0.1017]],\n",
      "\n",
      "        [[ 0.7968]],\n",
      "\n",
      "        [[-1.3943]],\n",
      "\n",
      "        [[ 0.4412]],\n",
      "\n",
      "        [[-0.1077]],\n",
      "\n",
      "        [[ 0.1446]],\n",
      "\n",
      "        [[ 0.1765]],\n",
      "\n",
      "        [[ 0.3404]],\n",
      "\n",
      "        [[ 0.7136]],\n",
      "\n",
      "        [[-0.6216]],\n",
      "\n",
      "        [[-0.0602]],\n",
      "\n",
      "        [[ 0.6425]],\n",
      "\n",
      "        [[ 0.7340]],\n",
      "\n",
      "        [[-1.0313]],\n",
      "\n",
      "        [[-0.3445]],\n",
      "\n",
      "        [[-1.3170]],\n",
      "\n",
      "        [[-0.9696]],\n",
      "\n",
      "        [[ 0.8592]],\n",
      "\n",
      "        [[-1.9292]],\n",
      "\n",
      "        [[-0.2074]],\n",
      "\n",
      "        [[-0.7311]],\n",
      "\n",
      "        [[ 0.7594]],\n",
      "\n",
      "        [[-2.1729]],\n",
      "\n",
      "        [[ 0.6151]],\n",
      "\n",
      "        [[-1.3036]],\n",
      "\n",
      "        [[ 1.9034]],\n",
      "\n",
      "        [[-2.1673]],\n",
      "\n",
      "        [[-0.1674]],\n",
      "\n",
      "        [[ 1.8450]],\n",
      "\n",
      "        [[ 1.2720]],\n",
      "\n",
      "        [[-0.2937]],\n",
      "\n",
      "        [[ 0.1532]],\n",
      "\n",
      "        [[ 0.9382]],\n",
      "\n",
      "        [[-1.2561]],\n",
      "\n",
      "        [[-0.4730]],\n",
      "\n",
      "        [[-0.6347]],\n",
      "\n",
      "        [[ 1.3392]],\n",
      "\n",
      "        [[ 0.3006]],\n",
      "\n",
      "        [[-0.1779]],\n",
      "\n",
      "        [[ 0.1590]],\n",
      "\n",
      "        [[ 1.1634]],\n",
      "\n",
      "        [[-1.9464]],\n",
      "\n",
      "        [[-0.0527]],\n",
      "\n",
      "        [[ 0.8229]],\n",
      "\n",
      "        [[ 0.4118]],\n",
      "\n",
      "        [[ 0.7438]],\n",
      "\n",
      "        [[ 0.0486]],\n",
      "\n",
      "        [[ 0.1160]],\n",
      "\n",
      "        [[ 0.7462]],\n",
      "\n",
      "        [[ 0.8266]],\n",
      "\n",
      "        [[ 0.9215]],\n",
      "\n",
      "        [[ 2.4368]],\n",
      "\n",
      "        [[-1.2664]],\n",
      "\n",
      "        [[ 1.8561]],\n",
      "\n",
      "        [[ 0.1112]],\n",
      "\n",
      "        [[ 0.5330]],\n",
      "\n",
      "        [[ 0.3252]],\n",
      "\n",
      "        [[-1.9468]],\n",
      "\n",
      "        [[ 0.3895]],\n",
      "\n",
      "        [[-0.2858]],\n",
      "\n",
      "        [[-1.1144]],\n",
      "\n",
      "        [[ 0.1797]],\n",
      "\n",
      "        [[ 0.6866]],\n",
      "\n",
      "        [[-0.5690]],\n",
      "\n",
      "        [[-0.9300]],\n",
      "\n",
      "        [[ 0.3347]],\n",
      "\n",
      "        [[ 1.2963]],\n",
      "\n",
      "        [[ 0.8041]],\n",
      "\n",
      "        [[-0.8831]],\n",
      "\n",
      "        [[ 0.5658]],\n",
      "\n",
      "        [[-1.2429]],\n",
      "\n",
      "        [[-0.3127]],\n",
      "\n",
      "        [[ 1.1729]],\n",
      "\n",
      "        [[ 0.9569]],\n",
      "\n",
      "        [[-1.2469]],\n",
      "\n",
      "        [[ 0.7710]],\n",
      "\n",
      "        [[-2.3422]],\n",
      "\n",
      "        [[-0.7826]],\n",
      "\n",
      "        [[-0.3251]],\n",
      "\n",
      "        [[ 0.6982]],\n",
      "\n",
      "        [[ 0.3613]],\n",
      "\n",
      "        [[ 0.2573]],\n",
      "\n",
      "        [[-0.2912]],\n",
      "\n",
      "        [[ 0.2241]],\n",
      "\n",
      "        [[-0.8331]],\n",
      "\n",
      "        [[-0.5975]],\n",
      "\n",
      "        [[-0.8234]],\n",
      "\n",
      "        [[-0.2005]],\n",
      "\n",
      "        [[ 0.7580]],\n",
      "\n",
      "        [[ 1.2696]],\n",
      "\n",
      "        [[ 1.1354]],\n",
      "\n",
      "        [[ 0.9997]],\n",
      "\n",
      "        [[-0.6392]],\n",
      "\n",
      "        [[ 0.5562]],\n",
      "\n",
      "        [[-0.5702]],\n",
      "\n",
      "        [[ 0.0892]],\n",
      "\n",
      "        [[ 0.0978]],\n",
      "\n",
      "        [[-0.2606]],\n",
      "\n",
      "        [[ 0.2165]],\n",
      "\n",
      "        [[-0.1403]],\n",
      "\n",
      "        [[ 0.0825]],\n",
      "\n",
      "        [[-1.0894]],\n",
      "\n",
      "        [[-1.7330]],\n",
      "\n",
      "        [[-0.9808]],\n",
      "\n",
      "        [[-1.6587]],\n",
      "\n",
      "        [[-0.1963]],\n",
      "\n",
      "        [[ 0.5576]],\n",
      "\n",
      "        [[-2.4474]],\n",
      "\n",
      "        [[ 0.4483]],\n",
      "\n",
      "        [[-0.9866]],\n",
      "\n",
      "        [[-0.0019]],\n",
      "\n",
      "        [[-0.9639]],\n",
      "\n",
      "        [[-0.8004]],\n",
      "\n",
      "        [[ 0.2049]],\n",
      "\n",
      "        [[-0.3186]],\n",
      "\n",
      "        [[ 0.0389]],\n",
      "\n",
      "        [[-0.3733]],\n",
      "\n",
      "        [[-0.7181]],\n",
      "\n",
      "        [[-1.2329]],\n",
      "\n",
      "        [[-0.7915]],\n",
      "\n",
      "        [[ 1.3798]],\n",
      "\n",
      "        [[-1.1449]],\n",
      "\n",
      "        [[ 1.0307]],\n",
      "\n",
      "        [[-0.2686]],\n",
      "\n",
      "        [[-0.7918]],\n",
      "\n",
      "        [[ 0.7608]],\n",
      "\n",
      "        [[-0.5568]],\n",
      "\n",
      "        [[ 0.6403]],\n",
      "\n",
      "        [[-0.3581]],\n",
      "\n",
      "        [[ 0.4903]],\n",
      "\n",
      "        [[ 0.2432]],\n",
      "\n",
      "        [[ 0.7458]],\n",
      "\n",
      "        [[-0.3688]],\n",
      "\n",
      "        [[ 0.4737]],\n",
      "\n",
      "        [[ 0.1887]],\n",
      "\n",
      "        [[-0.9664]],\n",
      "\n",
      "        [[-0.5780]],\n",
      "\n",
      "        [[-0.0846]],\n",
      "\n",
      "        [[ 0.0179]],\n",
      "\n",
      "        [[-0.5678]],\n",
      "\n",
      "        [[-0.5801]],\n",
      "\n",
      "        [[-0.6204]],\n",
      "\n",
      "        [[ 1.8705]],\n",
      "\n",
      "        [[-1.5270]],\n",
      "\n",
      "        [[-1.0698]],\n",
      "\n",
      "        [[ 1.3007]],\n",
      "\n",
      "        [[-1.3418]],\n",
      "\n",
      "        [[ 0.9675]],\n",
      "\n",
      "        [[-0.8120]],\n",
      "\n",
      "        [[ 0.2616]],\n",
      "\n",
      "        [[ 0.2765]],\n",
      "\n",
      "        [[ 0.7698]],\n",
      "\n",
      "        [[ 0.7239]],\n",
      "\n",
      "        [[-1.6109]],\n",
      "\n",
      "        [[-0.9432]],\n",
      "\n",
      "        [[ 2.2496]],\n",
      "\n",
      "        [[-0.5592]],\n",
      "\n",
      "        [[ 0.2743]],\n",
      "\n",
      "        [[ 0.5206]],\n",
      "\n",
      "        [[ 1.5426]],\n",
      "\n",
      "        [[-0.7240]],\n",
      "\n",
      "        [[ 0.9356]],\n",
      "\n",
      "        [[-1.8243]],\n",
      "\n",
      "        [[-1.8665]],\n",
      "\n",
      "        [[-1.1141]],\n",
      "\n",
      "        [[-0.9480]],\n",
      "\n",
      "        [[-0.7788]],\n",
      "\n",
      "        [[-1.3914]],\n",
      "\n",
      "        [[ 0.7282]],\n",
      "\n",
      "        [[ 1.0170]],\n",
      "\n",
      "        [[-0.7797]],\n",
      "\n",
      "        [[ 1.8166]],\n",
      "\n",
      "        [[-0.7950]],\n",
      "\n",
      "        [[ 0.7091]],\n",
      "\n",
      "        [[ 0.7738]],\n",
      "\n",
      "        [[-0.1404]],\n",
      "\n",
      "        [[-1.4810]],\n",
      "\n",
      "        [[-0.8761]],\n",
      "\n",
      "        [[-0.2911]],\n",
      "\n",
      "        [[-0.6699]],\n",
      "\n",
      "        [[-0.7515]],\n",
      "\n",
      "        [[ 0.6878]],\n",
      "\n",
      "        [[-0.0334]],\n",
      "\n",
      "        [[ 0.1377]],\n",
      "\n",
      "        [[-0.9423]],\n",
      "\n",
      "        [[ 0.4224]],\n",
      "\n",
      "        [[-0.9460]],\n",
      "\n",
      "        [[ 1.2314]],\n",
      "\n",
      "        [[ 0.2633]],\n",
      "\n",
      "        [[ 0.6836]],\n",
      "\n",
      "        [[ 0.2197]],\n",
      "\n",
      "        [[-0.2464]],\n",
      "\n",
      "        [[ 0.1338]],\n",
      "\n",
      "        [[-0.1091]],\n",
      "\n",
      "        [[-1.1521]],\n",
      "\n",
      "        [[ 0.8882]],\n",
      "\n",
      "        [[ 0.1579]],\n",
      "\n",
      "        [[ 0.0259]],\n",
      "\n",
      "        [[ 1.8913]],\n",
      "\n",
      "        [[ 0.7763]],\n",
      "\n",
      "        [[-0.7456]],\n",
      "\n",
      "        [[-1.2671]],\n",
      "\n",
      "        [[-0.7052]],\n",
      "\n",
      "        [[ 0.0596]],\n",
      "\n",
      "        [[ 0.6175]],\n",
      "\n",
      "        [[ 0.6726]],\n",
      "\n",
      "        [[ 1.1417]],\n",
      "\n",
      "        [[-1.0090]],\n",
      "\n",
      "        [[-2.1894]],\n",
      "\n",
      "        [[ 1.8991]],\n",
      "\n",
      "        [[ 0.9105]],\n",
      "\n",
      "        [[-1.0083]],\n",
      "\n",
      "        [[-0.3877]],\n",
      "\n",
      "        [[-3.3848]],\n",
      "\n",
      "        [[ 0.0115]],\n",
      "\n",
      "        [[-1.0012]],\n",
      "\n",
      "        [[-0.3423]],\n",
      "\n",
      "        [[ 2.6702]],\n",
      "\n",
      "        [[ 0.8160]],\n",
      "\n",
      "        [[-0.6967]],\n",
      "\n",
      "        [[ 0.6278]],\n",
      "\n",
      "        [[ 0.6972]],\n",
      "\n",
      "        [[ 1.4880]],\n",
      "\n",
      "        [[-0.0831]],\n",
      "\n",
      "        [[ 1.4766]],\n",
      "\n",
      "        [[ 1.5528]],\n",
      "\n",
      "        [[ 0.0632]],\n",
      "\n",
      "        [[-0.2242]],\n",
      "\n",
      "        [[ 0.9174]],\n",
      "\n",
      "        [[ 0.5668]],\n",
      "\n",
      "        [[-0.0727]],\n",
      "\n",
      "        [[-1.9793]],\n",
      "\n",
      "        [[ 0.0562]],\n",
      "\n",
      "        [[ 0.1242]],\n",
      "\n",
      "        [[-0.0834]],\n",
      "\n",
      "        [[ 0.5478]],\n",
      "\n",
      "        [[-1.3828]],\n",
      "\n",
      "        [[ 1.3771]],\n",
      "\n",
      "        [[ 1.4598]],\n",
      "\n",
      "        [[ 0.5097]],\n",
      "\n",
      "        [[-1.1120]],\n",
      "\n",
      "        [[-0.0786]],\n",
      "\n",
      "        [[ 0.5454]],\n",
      "\n",
      "        [[-0.2351]],\n",
      "\n",
      "        [[ 0.9357]],\n",
      "\n",
      "        [[ 0.1108]],\n",
      "\n",
      "        [[-0.5509]],\n",
      "\n",
      "        [[-0.3202]],\n",
      "\n",
      "        [[ 0.7593]],\n",
      "\n",
      "        [[ 1.3620]],\n",
      "\n",
      "        [[ 0.5376]],\n",
      "\n",
      "        [[-1.0997]],\n",
      "\n",
      "        [[ 0.1352]],\n",
      "\n",
      "        [[ 2.0734]],\n",
      "\n",
      "        [[-0.4281]],\n",
      "\n",
      "        [[ 1.0674]],\n",
      "\n",
      "        [[ 0.6887]],\n",
      "\n",
      "        [[ 0.2739]],\n",
      "\n",
      "        [[-1.7583]],\n",
      "\n",
      "        [[ 0.6825]],\n",
      "\n",
      "        [[-1.0649]],\n",
      "\n",
      "        [[ 0.0605]],\n",
      "\n",
      "        [[ 0.0994]],\n",
      "\n",
      "        [[-1.6238]],\n",
      "\n",
      "        [[ 0.7329]],\n",
      "\n",
      "        [[ 0.4614]],\n",
      "\n",
      "        [[-0.0798]],\n",
      "\n",
      "        [[-0.6822]],\n",
      "\n",
      "        [[ 0.1594]],\n",
      "\n",
      "        [[ 0.8827]],\n",
      "\n",
      "        [[-2.5945]],\n",
      "\n",
      "        [[-1.0220]],\n",
      "\n",
      "        [[-0.0561]],\n",
      "\n",
      "        [[-0.5285]],\n",
      "\n",
      "        [[-0.0206]],\n",
      "\n",
      "        [[-0.1235]],\n",
      "\n",
      "        [[-0.4389]],\n",
      "\n",
      "        [[-1.5379]],\n",
      "\n",
      "        [[ 1.0301]],\n",
      "\n",
      "        [[ 0.4195]],\n",
      "\n",
      "        [[-0.5399]],\n",
      "\n",
      "        [[ 1.0600]],\n",
      "\n",
      "        [[ 1.3249]],\n",
      "\n",
      "        [[ 0.0764]],\n",
      "\n",
      "        [[ 1.0385]],\n",
      "\n",
      "        [[ 1.5485]],\n",
      "\n",
      "        [[ 0.7111]],\n",
      "\n",
      "        [[-0.2814]],\n",
      "\n",
      "        [[ 0.4090]],\n",
      "\n",
      "        [[-0.0086]],\n",
      "\n",
      "        [[ 1.5976]],\n",
      "\n",
      "        [[ 0.5750]],\n",
      "\n",
      "        [[-0.0050]],\n",
      "\n",
      "        [[-0.7513]],\n",
      "\n",
      "        [[ 0.5994]],\n",
      "\n",
      "        [[ 0.0312]],\n",
      "\n",
      "        [[-0.5653]],\n",
      "\n",
      "        [[ 0.2416]],\n",
      "\n",
      "        [[ 1.9772]],\n",
      "\n",
      "        [[ 1.4969]],\n",
      "\n",
      "        [[ 1.2378]],\n",
      "\n",
      "        [[-0.4330]],\n",
      "\n",
      "        [[ 0.2634]],\n",
      "\n",
      "        [[-0.0133]],\n",
      "\n",
      "        [[-1.2806]],\n",
      "\n",
      "        [[-1.2882]],\n",
      "\n",
      "        [[-0.1738]],\n",
      "\n",
      "        [[ 0.8204]],\n",
      "\n",
      "        [[-1.6919]],\n",
      "\n",
      "        [[ 0.7022]],\n",
      "\n",
      "        [[ 0.4595]],\n",
      "\n",
      "        [[-0.2832]],\n",
      "\n",
      "        [[ 0.7535]],\n",
      "\n",
      "        [[ 0.0649]],\n",
      "\n",
      "        [[ 0.4327]],\n",
      "\n",
      "        [[-0.6170]],\n",
      "\n",
      "        [[ 1.1359]],\n",
      "\n",
      "        [[ 1.2573]],\n",
      "\n",
      "        [[ 1.6663]],\n",
      "\n",
      "        [[ 0.6819]],\n",
      "\n",
      "        [[-1.4114]],\n",
      "\n",
      "        [[-1.0762]],\n",
      "\n",
      "        [[-0.2076]],\n",
      "\n",
      "        [[-0.2797]],\n",
      "\n",
      "        [[ 0.5277]],\n",
      "\n",
      "        [[-0.3160]],\n",
      "\n",
      "        [[-0.6764]],\n",
      "\n",
      "        [[-0.8139]],\n",
      "\n",
      "        [[ 0.2374]],\n",
      "\n",
      "        [[-3.2301]],\n",
      "\n",
      "        [[-1.2977]],\n",
      "\n",
      "        [[-0.7671]],\n",
      "\n",
      "        [[-0.5584]],\n",
      "\n",
      "        [[ 1.2670]],\n",
      "\n",
      "        [[ 0.4153]],\n",
      "\n",
      "        [[-1.7737]],\n",
      "\n",
      "        [[-0.2854]],\n",
      "\n",
      "        [[-0.3761]],\n",
      "\n",
      "        [[-1.5187]],\n",
      "\n",
      "        [[ 0.2329]],\n",
      "\n",
      "        [[-1.4992]],\n",
      "\n",
      "        [[ 0.2801]],\n",
      "\n",
      "        [[-0.7290]],\n",
      "\n",
      "        [[ 1.1702]],\n",
      "\n",
      "        [[-0.2639]],\n",
      "\n",
      "        [[ 1.9589]],\n",
      "\n",
      "        [[-1.0180]],\n",
      "\n",
      "        [[-0.3173]],\n",
      "\n",
      "        [[-0.9435]],\n",
      "\n",
      "        [[-0.5232]],\n",
      "\n",
      "        [[ 0.1958]],\n",
      "\n",
      "        [[-0.3150]],\n",
      "\n",
      "        [[-0.2893]],\n",
      "\n",
      "        [[-1.4091]],\n",
      "\n",
      "        [[-1.0279]],\n",
      "\n",
      "        [[-1.4756]],\n",
      "\n",
      "        [[-1.3730]],\n",
      "\n",
      "        [[-0.1224]],\n",
      "\n",
      "        [[-0.2727]],\n",
      "\n",
      "        [[ 1.4685]],\n",
      "\n",
      "        [[-0.8693]]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor(1.00000e-04 *\n",
      "       [[[-7.3572]]], device='cuda:0')\n",
      "torch.Size([1, 448, 512])\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 1.9542,  1.9539,  1.9538,  ...,  1.9550,  1.9555,  1.9548],\n",
      "         [ 1.9516,  1.9516,  1.9519,  ...,  1.9534,  1.9536,  1.9534],\n",
      "         [ 1.9536,  1.9534,  1.9530,  ...,  1.9537,  1.9539,  1.9541],\n",
      "         ...,\n",
      "         [ 1.9541,  1.9540,  1.9540,  ...,  1.9529,  1.9533,  1.9539],\n",
      "         [ 1.9529,  1.9524,  1.9524,  ...,  1.9536,  1.9542,  1.9545],\n",
      "         [ 1.9531,  1.9533,  1.9528,  ...,  1.9523,  1.9525,  1.9527]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 35 [23040/50000 (51%)]\tLoss: 0.286576, Accuracy: 89.84\n",
      "Train Epoch: 35 [24320/50000 (54%)]\tLoss: 0.502175, Accuracy: 82.42\n",
      "Train Epoch: 35 [25600/50000 (57%)]\tLoss: 0.348054, Accuracy: 90.62\n",
      "Train Epoch: 35 [26880/50000 (60%)]\tLoss: 0.365172, Accuracy: 87.50\n",
      "Train Epoch: 35 [28160/50000 (62%)]\tLoss: 0.502846, Accuracy: 83.59\n",
      "Train Epoch: 35 [29440/50000 (65%)]\tLoss: 0.394236, Accuracy: 88.28\n",
      "Train Epoch: 35 [30720/50000 (68%)]\tLoss: 0.325435, Accuracy: 87.11\n",
      "Train Epoch: 35 [32000/50000 (71%)]\tLoss: 0.396677, Accuracy: 87.11\n",
      "Train Epoch: 35 [33280/50000 (74%)]\tLoss: 0.402783, Accuracy: 85.16\n",
      "Train Epoch: 35 [34560/50000 (77%)]\tLoss: 0.487055, Accuracy: 83.98\n",
      "Train Epoch: 35 [35840/50000 (80%)]\tLoss: 0.453306, Accuracy: 82.42\n",
      "Train Epoch: 35 [37120/50000 (82%)]\tLoss: 0.476775, Accuracy: 82.81\n",
      "Train Epoch: 35 [38400/50000 (85%)]\tLoss: 0.362914, Accuracy: 86.72\n",
      "Train Epoch: 35 [39680/50000 (88%)]\tLoss: 0.389281, Accuracy: 86.33\n",
      "Train Epoch: 35 [40960/50000 (91%)]\tLoss: 0.325214, Accuracy: 88.67\n",
      "Train Epoch: 35 [42240/50000 (94%)]\tLoss: 0.334036, Accuracy: 89.45\n",
      "Train Epoch: 35 [43520/50000 (97%)]\tLoss: 0.488739, Accuracy: 83.98\n",
      "Train Epoch: 35 [35000/50000 (99%)]\tLoss: 0.488880, Accuracy: 83.50\n",
      "\n",
      "Validation set: Average loss: 0.6438, Accuracy: 3898/5000 (77.00%)\n",
      "\n",
      "the time of this epoch:[40.28305697441101 s]\n",
      "Train Epoch: 36 [0/50000 (0%)]\tLoss: 0.404328, Accuracy: 86.33\n",
      "Train Epoch: 36 [1280/50000 (3%)]\tLoss: 0.383202, Accuracy: 86.72\n",
      "Train Epoch: 36 [2560/50000 (6%)]\tLoss: 0.281223, Accuracy: 91.80\n",
      "Train Epoch: 36 [3840/50000 (9%)]\tLoss: 0.354403, Accuracy: 88.67\n",
      "Train Epoch: 36 [5120/50000 (11%)]\tLoss: 0.336491, Accuracy: 89.84\n",
      "Train Epoch: 36 [6400/50000 (14%)]\tLoss: 0.395531, Accuracy: 87.11\n",
      "Train Epoch: 36 [7680/50000 (17%)]\tLoss: 0.336907, Accuracy: 87.89\n",
      "Train Epoch: 36 [8960/50000 (20%)]\tLoss: 0.332675, Accuracy: 88.28\n",
      "Train Epoch: 36 [10240/50000 (23%)]\tLoss: 0.383386, Accuracy: 85.16\n",
      "Train Epoch: 36 [11520/50000 (26%)]\tLoss: 0.491718, Accuracy: 83.20\n",
      "Train Epoch: 36 [12800/50000 (28%)]\tLoss: 0.356625, Accuracy: 85.16\n",
      "Train Epoch: 36 [14080/50000 (31%)]\tLoss: 0.385173, Accuracy: 88.67\n",
      "Train Epoch: 36 [15360/50000 (34%)]\tLoss: 0.336297, Accuracy: 86.72\n",
      "Train Epoch: 36 [16640/50000 (37%)]\tLoss: 0.487458, Accuracy: 84.38\n",
      "Train Epoch: 36 [17920/50000 (40%)]\tLoss: 0.410756, Accuracy: 87.89\n",
      "Train Epoch: 36 [19200/50000 (43%)]\tLoss: 0.390833, Accuracy: 88.67\n",
      "Train Epoch: 36 [20480/50000 (45%)]\tLoss: 0.355560, Accuracy: 89.84\n",
      "Train Epoch: 36 [21760/50000 (48%)]\tLoss: 0.316720, Accuracy: 89.06\n",
      "Train Epoch: 36 [23040/50000 (51%)]\tLoss: 0.354309, Accuracy: 85.94\n",
      "Train Epoch: 36 [24320/50000 (54%)]\tLoss: 0.323129, Accuracy: 88.28\n",
      "Train Epoch: 36 [25600/50000 (57%)]\tLoss: 0.324435, Accuracy: 88.67\n",
      "Train Epoch: 36 [26880/50000 (60%)]\tLoss: 0.357266, Accuracy: 86.33\n",
      "Train Epoch: 36 [28160/50000 (62%)]\tLoss: 0.316034, Accuracy: 89.06\n",
      "Train Epoch: 36 [29440/50000 (65%)]\tLoss: 0.409812, Accuracy: 86.72\n",
      "Train Epoch: 36 [30720/50000 (68%)]\tLoss: 0.374721, Accuracy: 86.72\n",
      "Train Epoch: 36 [32000/50000 (71%)]\tLoss: 0.384355, Accuracy: 88.28\n",
      "Train Epoch: 36 [33280/50000 (74%)]\tLoss: 0.323526, Accuracy: 87.89\n",
      "Train Epoch: 36 [34560/50000 (77%)]\tLoss: 0.342927, Accuracy: 88.28\n",
      "Train Epoch: 36 [35840/50000 (80%)]\tLoss: 0.392255, Accuracy: 84.77\n",
      "Train Epoch: 36 [37120/50000 (82%)]\tLoss: 0.390203, Accuracy: 88.28\n",
      "Train Epoch: 36 [38400/50000 (85%)]\tLoss: 0.367718, Accuracy: 88.67\n",
      "Train Epoch: 36 [39680/50000 (88%)]\tLoss: 0.412269, Accuracy: 86.33\n",
      "Train Epoch: 36 [40960/50000 (91%)]\tLoss: 0.418396, Accuracy: 85.16\n",
      "Train Epoch: 36 [42240/50000 (94%)]\tLoss: 0.421430, Accuracy: 85.55\n",
      "Train Epoch: 36 [43520/50000 (97%)]\tLoss: 0.339768, Accuracy: 89.84\n",
      "Train Epoch: 36 [35000/50000 (99%)]\tLoss: 0.394103, Accuracy: 86.50\n",
      "\n",
      "Validation set: Average loss: 0.5506, Accuracy: 4112/5000 (82.00%)\n",
      "\n",
      "the time of this epoch:[37.01694846153259 s]\n",
      "\n",
      "Test set: Average loss: 0.5809, Accuracy: 8176/10000 (81.76%)\n",
      "\n",
      "Train Epoch: 37 [0/50000 (0%)]\tLoss: 0.344696, Accuracy: 88.67\n",
      "Train Epoch: 37 [1280/50000 (3%)]\tLoss: 0.364028, Accuracy: 87.89\n",
      "Train Epoch: 37 [2560/50000 (6%)]\tLoss: 0.304265, Accuracy: 89.45\n",
      "Train Epoch: 37 [3840/50000 (9%)]\tLoss: 0.368720, Accuracy: 87.11\n",
      "Train Epoch: 37 [5120/50000 (11%)]\tLoss: 0.451370, Accuracy: 83.98\n",
      "Train Epoch: 37 [6400/50000 (14%)]\tLoss: 0.400546, Accuracy: 85.55\n",
      "Train Epoch: 37 [7680/50000 (17%)]\tLoss: 0.279659, Accuracy: 89.45\n",
      "Train Epoch: 37 [8960/50000 (20%)]\tLoss: 0.252993, Accuracy: 90.62\n",
      "Train Epoch: 37 [10240/50000 (23%)]\tLoss: 0.404605, Accuracy: 87.50\n",
      "Train Epoch: 37 [11520/50000 (26%)]\tLoss: 0.361394, Accuracy: 88.67\n",
      "Train Epoch: 37 [12800/50000 (28%)]\tLoss: 0.383633, Accuracy: 84.77\n",
      "Train Epoch: 37 [14080/50000 (31%)]\tLoss: 0.440282, Accuracy: 87.50\n",
      "Train Epoch: 37 [15360/50000 (34%)]\tLoss: 0.416177, Accuracy: 85.16\n",
      "Train Epoch: 37 [16640/50000 (37%)]\tLoss: 0.409238, Accuracy: 83.98\n",
      "Train Epoch: 37 [17920/50000 (40%)]\tLoss: 0.315745, Accuracy: 90.23\n",
      "Train Epoch: 37 [19200/50000 (43%)]\tLoss: 0.354186, Accuracy: 87.50\n",
      "Train Epoch: 37 [20480/50000 (45%)]\tLoss: 0.389773, Accuracy: 86.33\n",
      "Train Epoch: 37 [21760/50000 (48%)]\tLoss: 0.448213, Accuracy: 85.16\n",
      "Train Epoch: 37 [23040/50000 (51%)]\tLoss: 0.400569, Accuracy: 87.11\n",
      "Train Epoch: 37 [24320/50000 (54%)]\tLoss: 0.405916, Accuracy: 85.94\n",
      "Train Epoch: 37 [25600/50000 (57%)]\tLoss: 0.396451, Accuracy: 83.59\n",
      "Train Epoch: 37 [26880/50000 (60%)]\tLoss: 0.347179, Accuracy: 89.06\n",
      "Train Epoch: 37 [28160/50000 (62%)]\tLoss: 0.354635, Accuracy: 87.50\n",
      "Train Epoch: 37 [29440/50000 (65%)]\tLoss: 0.395375, Accuracy: 85.55\n",
      "Train Epoch: 37 [30720/50000 (68%)]\tLoss: 0.379431, Accuracy: 84.77\n",
      "Train Epoch: 37 [32000/50000 (71%)]\tLoss: 0.400328, Accuracy: 83.59\n",
      "Train Epoch: 37 [33280/50000 (74%)]\tLoss: 0.435816, Accuracy: 85.94\n",
      "Train Epoch: 37 [34560/50000 (77%)]\tLoss: 0.424338, Accuracy: 86.72\n",
      "Train Epoch: 37 [35840/50000 (80%)]\tLoss: 0.389739, Accuracy: 85.55\n",
      "Train Epoch: 37 [37120/50000 (82%)]\tLoss: 0.428830, Accuracy: 84.77\n",
      "Train Epoch: 37 [38400/50000 (85%)]\tLoss: 0.456466, Accuracy: 84.38\n",
      "Train Epoch: 37 [39680/50000 (88%)]\tLoss: 0.334534, Accuracy: 89.84\n",
      "Train Epoch: 37 [40960/50000 (91%)]\tLoss: 0.341974, Accuracy: 87.11\n",
      "Train Epoch: 37 [42240/50000 (94%)]\tLoss: 0.380289, Accuracy: 87.89\n",
      "Train Epoch: 37 [43520/50000 (97%)]\tLoss: 0.324559, Accuracy: 88.67\n",
      "Train Epoch: 37 [35000/50000 (99%)]\tLoss: 0.399986, Accuracy: 88.00\n",
      "\n",
      "Validation set: Average loss: 0.5749, Accuracy: 4045/5000 (80.00%)\n",
      "\n",
      "the time of this epoch:[40.26620078086853 s]\n",
      "Train Epoch: 38 [0/50000 (0%)]\tLoss: 0.417182, Accuracy: 85.16\n",
      "Train Epoch: 38 [1280/50000 (3%)]\tLoss: 0.294770, Accuracy: 89.84\n",
      "Train Epoch: 38 [2560/50000 (6%)]\tLoss: 0.352162, Accuracy: 86.33\n",
      "Train Epoch: 38 [3840/50000 (9%)]\tLoss: 0.324504, Accuracy: 87.50\n",
      "Train Epoch: 38 [5120/50000 (11%)]\tLoss: 0.355280, Accuracy: 85.94\n",
      "Train Epoch: 38 [6400/50000 (14%)]\tLoss: 0.407814, Accuracy: 85.55\n",
      "Train Epoch: 38 [7680/50000 (17%)]\tLoss: 0.362726, Accuracy: 89.45\n",
      "Train Epoch: 38 [8960/50000 (20%)]\tLoss: 0.373406, Accuracy: 87.50\n",
      "Train Epoch: 38 [10240/50000 (23%)]\tLoss: 0.410710, Accuracy: 85.55\n",
      "Train Epoch: 38 [11520/50000 (26%)]\tLoss: 0.355167, Accuracy: 88.28\n",
      "Train Epoch: 38 [12800/50000 (28%)]\tLoss: 0.396891, Accuracy: 86.72\n",
      "Train Epoch: 38 [14080/50000 (31%)]\tLoss: 0.353724, Accuracy: 86.72\n",
      "torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.5031]],\n",
      "\n",
      "        [[ 0.1255]],\n",
      "\n",
      "        [[ 0.1536]],\n",
      "\n",
      "        [[ 1.4467]],\n",
      "\n",
      "        [[ 0.4381]],\n",
      "\n",
      "        [[-1.2615]],\n",
      "\n",
      "        [[-1.0709]],\n",
      "\n",
      "        [[ 0.2111]],\n",
      "\n",
      "        [[ 0.0837]],\n",
      "\n",
      "        [[ 0.4583]],\n",
      "\n",
      "        [[-0.2822]],\n",
      "\n",
      "        [[ 0.9547]],\n",
      "\n",
      "        [[-1.9192]],\n",
      "\n",
      "        [[ 0.4845]],\n",
      "\n",
      "        [[ 0.4443]],\n",
      "\n",
      "        [[ 1.1046]],\n",
      "\n",
      "        [[ 0.6398]],\n",
      "\n",
      "        [[-2.1451]],\n",
      "\n",
      "        [[-0.5453]],\n",
      "\n",
      "        [[ 0.0094]],\n",
      "\n",
      "        [[-1.0230]],\n",
      "\n",
      "        [[-0.5365]],\n",
      "\n",
      "        [[ 0.6674]],\n",
      "\n",
      "        [[ 0.2944]],\n",
      "\n",
      "        [[ 0.4329]],\n",
      "\n",
      "        [[-0.1710]],\n",
      "\n",
      "        [[ 0.8839]],\n",
      "\n",
      "        [[ 0.2358]],\n",
      "\n",
      "        [[-0.2046]],\n",
      "\n",
      "        [[ 1.3606]],\n",
      "\n",
      "        [[-1.2522]],\n",
      "\n",
      "        [[ 0.2397]],\n",
      "\n",
      "        [[ 0.6571]],\n",
      "\n",
      "        [[-0.7216]],\n",
      "\n",
      "        [[-0.4897]],\n",
      "\n",
      "        [[-1.9818]],\n",
      "\n",
      "        [[ 0.9263]],\n",
      "\n",
      "        [[ 1.5932]],\n",
      "\n",
      "        [[-1.0472]],\n",
      "\n",
      "        [[ 0.9154]],\n",
      "\n",
      "        [[ 0.6126]],\n",
      "\n",
      "        [[ 1.6072]],\n",
      "\n",
      "        [[-0.7085]],\n",
      "\n",
      "        [[ 0.1274]],\n",
      "\n",
      "        [[-0.6224]],\n",
      "\n",
      "        [[-0.4889]],\n",
      "\n",
      "        [[ 0.4907]],\n",
      "\n",
      "        [[-0.2224]],\n",
      "\n",
      "        [[ 1.2257]],\n",
      "\n",
      "        [[ 1.5665]],\n",
      "\n",
      "        [[ 2.0601]],\n",
      "\n",
      "        [[ 0.9495]],\n",
      "\n",
      "        [[-0.8474]],\n",
      "\n",
      "        [[-0.7614]],\n",
      "\n",
      "        [[ 0.2376]],\n",
      "\n",
      "        [[ 1.7499]],\n",
      "\n",
      "        [[-1.6514]],\n",
      "\n",
      "        [[-0.3127]],\n",
      "\n",
      "        [[-1.1338]],\n",
      "\n",
      "        [[-0.6008]],\n",
      "\n",
      "        [[ 0.6114]],\n",
      "\n",
      "        [[ 2.2277]],\n",
      "\n",
      "        [[-1.7055]],\n",
      "\n",
      "        [[-1.4026]],\n",
      "\n",
      "        [[ 0.0185]],\n",
      "\n",
      "        [[-0.7524]],\n",
      "\n",
      "        [[-0.6956]],\n",
      "\n",
      "        [[ 0.6219]],\n",
      "\n",
      "        [[-1.7624]],\n",
      "\n",
      "        [[-0.8163]],\n",
      "\n",
      "        [[ 0.4480]],\n",
      "\n",
      "        [[ 1.5055]],\n",
      "\n",
      "        [[-0.3165]],\n",
      "\n",
      "        [[ 0.2518]],\n",
      "\n",
      "        [[ 0.8037]],\n",
      "\n",
      "        [[ 0.3191]],\n",
      "\n",
      "        [[-1.5460]],\n",
      "\n",
      "        [[-1.2517]],\n",
      "\n",
      "        [[ 1.0092]],\n",
      "\n",
      "        [[ 0.3229]],\n",
      "\n",
      "        [[-0.3594]],\n",
      "\n",
      "        [[ 0.2379]],\n",
      "\n",
      "        [[ 1.2778]],\n",
      "\n",
      "        [[ 0.5335]],\n",
      "\n",
      "        [[-0.5969]],\n",
      "\n",
      "        [[ 0.4616]],\n",
      "\n",
      "        [[-0.2003]],\n",
      "\n",
      "        [[-0.7698]],\n",
      "\n",
      "        [[-1.3545]],\n",
      "\n",
      "        [[-0.4452]],\n",
      "\n",
      "        [[-0.3713]],\n",
      "\n",
      "        [[-1.7619]],\n",
      "\n",
      "        [[ 0.0932]],\n",
      "\n",
      "        [[ 0.7515]],\n",
      "\n",
      "        [[-1.6667]],\n",
      "\n",
      "        [[-1.2098]],\n",
      "\n",
      "        [[ 0.1939]],\n",
      "\n",
      "        [[ 0.3250]],\n",
      "\n",
      "        [[-2.2033]],\n",
      "\n",
      "        [[ 1.5531]],\n",
      "\n",
      "        [[-0.1815]],\n",
      "\n",
      "        [[-1.5735]],\n",
      "\n",
      "        [[-0.7337]],\n",
      "\n",
      "        [[-1.3805]],\n",
      "\n",
      "        [[-0.3328]],\n",
      "\n",
      "        [[-0.0940]],\n",
      "\n",
      "        [[-0.8876]],\n",
      "\n",
      "        [[-0.8417]],\n",
      "\n",
      "        [[ 2.6364]],\n",
      "\n",
      "        [[ 1.3060]],\n",
      "\n",
      "        [[-0.2005]],\n",
      "\n",
      "        [[-1.4741]],\n",
      "\n",
      "        [[ 0.7236]],\n",
      "\n",
      "        [[ 0.0142]],\n",
      "\n",
      "        [[ 1.6937]],\n",
      "\n",
      "        [[ 0.4971]],\n",
      "\n",
      "        [[-1.2797]],\n",
      "\n",
      "        [[ 0.0520]],\n",
      "\n",
      "        [[ 0.0264]],\n",
      "\n",
      "        [[-0.1652]],\n",
      "\n",
      "        [[-0.3781]],\n",
      "\n",
      "        [[ 0.2054]],\n",
      "\n",
      "        [[-2.3216]],\n",
      "\n",
      "        [[-1.9832]],\n",
      "\n",
      "        [[-0.8976]],\n",
      "\n",
      "        [[-1.1334]],\n",
      "\n",
      "        [[ 0.1181]],\n",
      "\n",
      "        [[ 1.6229]],\n",
      "\n",
      "        [[-1.1514]],\n",
      "\n",
      "        [[ 0.2163]],\n",
      "\n",
      "        [[ 0.6188]],\n",
      "\n",
      "        [[-0.6999]],\n",
      "\n",
      "        [[-0.5198]],\n",
      "\n",
      "        [[-1.4598]],\n",
      "\n",
      "        [[ 1.2857]],\n",
      "\n",
      "        [[ 1.0962]],\n",
      "\n",
      "        [[ 0.7540]],\n",
      "\n",
      "        [[ 0.7002]],\n",
      "\n",
      "        [[-0.3033]],\n",
      "\n",
      "        [[ 0.2921]],\n",
      "\n",
      "        [[ 0.9776]],\n",
      "\n",
      "        [[ 0.0758]],\n",
      "\n",
      "        [[ 1.7990]],\n",
      "\n",
      "        [[-0.2959]],\n",
      "\n",
      "        [[-0.1052]],\n",
      "\n",
      "        [[-0.2100]],\n",
      "\n",
      "        [[-1.6036]],\n",
      "\n",
      "        [[-0.5629]],\n",
      "\n",
      "        [[-1.3349]],\n",
      "\n",
      "        [[ 0.7359]],\n",
      "\n",
      "        [[-0.2326]],\n",
      "\n",
      "        [[ 1.3345]],\n",
      "\n",
      "        [[ 1.7080]],\n",
      "\n",
      "        [[-0.6872]],\n",
      "\n",
      "        [[ 0.0186]],\n",
      "\n",
      "        [[ 0.1660]],\n",
      "\n",
      "        [[ 1.5840]],\n",
      "\n",
      "        [[-0.4287]],\n",
      "\n",
      "        [[-0.2298]],\n",
      "\n",
      "        [[ 0.1819]],\n",
      "\n",
      "        [[-0.2580]],\n",
      "\n",
      "        [[-0.4865]],\n",
      "\n",
      "        [[ 1.5594]],\n",
      "\n",
      "        [[-0.5116]],\n",
      "\n",
      "        [[ 0.5536]],\n",
      "\n",
      "        [[-0.0051]],\n",
      "\n",
      "        [[ 0.8517]],\n",
      "\n",
      "        [[-0.3547]],\n",
      "\n",
      "        [[-0.6509]],\n",
      "\n",
      "        [[-2.6288]],\n",
      "\n",
      "        [[-0.5914]],\n",
      "\n",
      "        [[ 1.2170]],\n",
      "\n",
      "        [[ 0.6985]],\n",
      "\n",
      "        [[ 0.3630]],\n",
      "\n",
      "        [[-0.4393]],\n",
      "\n",
      "        [[-0.0571]],\n",
      "\n",
      "        [[-1.1135]],\n",
      "\n",
      "        [[-1.5669]],\n",
      "\n",
      "        [[-1.5322]],\n",
      "\n",
      "        [[ 0.5713]],\n",
      "\n",
      "        [[-0.7689]],\n",
      "\n",
      "        [[-0.6590]],\n",
      "\n",
      "        [[ 0.9341]],\n",
      "\n",
      "        [[ 1.1871]],\n",
      "\n",
      "        [[ 1.3158]],\n",
      "\n",
      "        [[-1.5033]],\n",
      "\n",
      "        [[ 1.1887]],\n",
      "\n",
      "        [[ 1.5185]],\n",
      "\n",
      "        [[ 1.4113]],\n",
      "\n",
      "        [[ 0.5345]],\n",
      "\n",
      "        [[ 0.0212]],\n",
      "\n",
      "        [[ 0.1816]],\n",
      "\n",
      "        [[-1.5095]],\n",
      "\n",
      "        [[-0.4042]],\n",
      "\n",
      "        [[ 0.3966]],\n",
      "\n",
      "        [[-1.8465]],\n",
      "\n",
      "        [[ 0.7064]],\n",
      "\n",
      "        [[ 0.2451]],\n",
      "\n",
      "        [[ 0.0621]],\n",
      "\n",
      "        [[ 0.1996]],\n",
      "\n",
      "        [[-0.8088]],\n",
      "\n",
      "        [[-0.5917]],\n",
      "\n",
      "        [[-0.3042]],\n",
      "\n",
      "        [[-0.4866]],\n",
      "\n",
      "        [[-0.2997]],\n",
      "\n",
      "        [[ 0.0198]],\n",
      "\n",
      "        [[ 0.8174]],\n",
      "\n",
      "        [[-0.2238]],\n",
      "\n",
      "        [[ 1.5530]],\n",
      "\n",
      "        [[ 1.6778]],\n",
      "\n",
      "        [[ 1.0482]],\n",
      "\n",
      "        [[ 1.3205]],\n",
      "\n",
      "        [[-0.6572]],\n",
      "\n",
      "        [[-1.4027]],\n",
      "\n",
      "        [[ 1.6220]],\n",
      "\n",
      "        [[ 0.2111]],\n",
      "\n",
      "        [[ 0.0078]],\n",
      "\n",
      "        [[ 0.6696]],\n",
      "\n",
      "        [[-1.0882]],\n",
      "\n",
      "        [[-1.2887]],\n",
      "\n",
      "        [[ 0.0704]],\n",
      "\n",
      "        [[-0.4358]],\n",
      "\n",
      "        [[ 2.5019]],\n",
      "\n",
      "        [[-0.1412]],\n",
      "\n",
      "        [[ 0.1793]],\n",
      "\n",
      "        [[-1.8690]],\n",
      "\n",
      "        [[ 0.8286]],\n",
      "\n",
      "        [[ 1.1068]],\n",
      "\n",
      "        [[-0.3233]],\n",
      "\n",
      "        [[ 0.8120]],\n",
      "\n",
      "        [[ 1.4757]],\n",
      "\n",
      "        [[-0.5912]],\n",
      "\n",
      "        [[ 1.0788]],\n",
      "\n",
      "        [[ 0.7217]],\n",
      "\n",
      "        [[-2.1902]],\n",
      "\n",
      "        [[-0.7851]],\n",
      "\n",
      "        [[-0.3851]],\n",
      "\n",
      "        [[-1.3317]],\n",
      "\n",
      "        [[ 1.3288]],\n",
      "\n",
      "        [[-2.2194]],\n",
      "\n",
      "        [[ 0.4254]],\n",
      "\n",
      "        [[ 1.2793]],\n",
      "\n",
      "        [[-1.4900]],\n",
      "\n",
      "        [[-1.1831]],\n",
      "\n",
      "        [[-0.3437]],\n",
      "\n",
      "        [[ 1.3168]],\n",
      "\n",
      "        [[ 0.2570]],\n",
      "\n",
      "        [[ 0.1106]],\n",
      "\n",
      "        [[-1.0518]],\n",
      "\n",
      "        [[ 0.3719]],\n",
      "\n",
      "        [[ 1.5187]],\n",
      "\n",
      "        [[ 0.9913]],\n",
      "\n",
      "        [[-2.4803]],\n",
      "\n",
      "        [[ 2.0379]],\n",
      "\n",
      "        [[-0.1771]],\n",
      "\n",
      "        [[-1.6740]],\n",
      "\n",
      "        [[-1.4847]],\n",
      "\n",
      "        [[ 0.3925]],\n",
      "\n",
      "        [[-0.3433]],\n",
      "\n",
      "        [[ 0.6219]],\n",
      "\n",
      "        [[ 1.3922]],\n",
      "\n",
      "        [[ 1.7560]],\n",
      "\n",
      "        [[ 1.2735]],\n",
      "\n",
      "        [[ 1.0372]],\n",
      "\n",
      "        [[ 0.4905]],\n",
      "\n",
      "        [[-0.4757]],\n",
      "\n",
      "        [[ 0.1036]],\n",
      "\n",
      "        [[-1.8871]],\n",
      "\n",
      "        [[ 0.0189]],\n",
      "\n",
      "        [[ 0.8629]],\n",
      "\n",
      "        [[ 0.7554]],\n",
      "\n",
      "        [[ 2.4111]],\n",
      "\n",
      "        [[-0.0565]],\n",
      "\n",
      "        [[-1.0976]],\n",
      "\n",
      "        [[-0.0906]],\n",
      "\n",
      "        [[-0.1941]],\n",
      "\n",
      "        [[ 0.4701]],\n",
      "\n",
      "        [[ 0.2386]],\n",
      "\n",
      "        [[ 1.0222]],\n",
      "\n",
      "        [[-1.7583]],\n",
      "\n",
      "        [[-1.3003]],\n",
      "\n",
      "        [[ 0.0267]],\n",
      "\n",
      "        [[ 0.5526]],\n",
      "\n",
      "        [[ 0.7016]],\n",
      "\n",
      "        [[-0.8410]],\n",
      "\n",
      "        [[ 0.0815]],\n",
      "\n",
      "        [[ 1.2042]],\n",
      "\n",
      "        [[ 0.0473]],\n",
      "\n",
      "        [[-0.5388]],\n",
      "\n",
      "        [[-0.2913]],\n",
      "\n",
      "        [[-0.8281]],\n",
      "\n",
      "        [[ 0.0009]],\n",
      "\n",
      "        [[-0.0139]],\n",
      "\n",
      "        [[-1.0039]],\n",
      "\n",
      "        [[ 2.1466]],\n",
      "\n",
      "        [[-0.0578]],\n",
      "\n",
      "        [[ 2.6365]],\n",
      "\n",
      "        [[-0.3928]],\n",
      "\n",
      "        [[ 1.6341]],\n",
      "\n",
      "        [[-1.1755]],\n",
      "\n",
      "        [[ 1.3263]],\n",
      "\n",
      "        [[ 0.8848]],\n",
      "\n",
      "        [[ 0.4171]],\n",
      "\n",
      "        [[ 0.6485]],\n",
      "\n",
      "        [[-0.4018]],\n",
      "\n",
      "        [[-0.0013]],\n",
      "\n",
      "        [[ 0.5426]],\n",
      "\n",
      "        [[-1.9650]],\n",
      "\n",
      "        [[-0.6488]],\n",
      "\n",
      "        [[ 0.4588]],\n",
      "\n",
      "        [[-0.4180]],\n",
      "\n",
      "        [[-1.3158]],\n",
      "\n",
      "        [[-0.7499]],\n",
      "\n",
      "        [[-0.0626]],\n",
      "\n",
      "        [[-0.1548]],\n",
      "\n",
      "        [[-0.2788]],\n",
      "\n",
      "        [[-0.3139]],\n",
      "\n",
      "        [[ 0.5410]],\n",
      "\n",
      "        [[-1.3108]],\n",
      "\n",
      "        [[ 0.5132]],\n",
      "\n",
      "        [[-0.8678]],\n",
      "\n",
      "        [[ 1.1439]],\n",
      "\n",
      "        [[-0.1057]],\n",
      "\n",
      "        [[ 0.3369]],\n",
      "\n",
      "        [[ 0.5061]],\n",
      "\n",
      "        [[-1.3969]],\n",
      "\n",
      "        [[-2.2556]],\n",
      "\n",
      "        [[-0.6568]],\n",
      "\n",
      "        [[ 0.4626]],\n",
      "\n",
      "        [[-1.4258]],\n",
      "\n",
      "        [[-2.0163]],\n",
      "\n",
      "        [[-3.7100]],\n",
      "\n",
      "        [[-0.4363]],\n",
      "\n",
      "        [[ 0.6534]],\n",
      "\n",
      "        [[ 0.5107]],\n",
      "\n",
      "        [[ 0.9080]],\n",
      "\n",
      "        [[-0.6581]],\n",
      "\n",
      "        [[ 0.1894]],\n",
      "\n",
      "        [[ 0.0415]],\n",
      "\n",
      "        [[ 0.8296]],\n",
      "\n",
      "        [[ 0.5171]],\n",
      "\n",
      "        [[ 1.5347]],\n",
      "\n",
      "        [[ 1.3053]],\n",
      "\n",
      "        [[-0.4989]],\n",
      "\n",
      "        [[-0.2008]],\n",
      "\n",
      "        [[ 0.6411]],\n",
      "\n",
      "        [[ 0.2256]],\n",
      "\n",
      "        [[ 1.0616]],\n",
      "\n",
      "        [[-0.8984]],\n",
      "\n",
      "        [[-0.9727]],\n",
      "\n",
      "        [[-0.6413]],\n",
      "\n",
      "        [[-1.3988]],\n",
      "\n",
      "        [[-0.6552]],\n",
      "\n",
      "        [[ 1.2199]],\n",
      "\n",
      "        [[ 0.3824]],\n",
      "\n",
      "        [[ 1.1902]],\n",
      "\n",
      "        [[-0.1408]],\n",
      "\n",
      "        [[ 1.4650]],\n",
      "\n",
      "        [[ 1.2208]],\n",
      "\n",
      "        [[-0.6993]],\n",
      "\n",
      "        [[-0.4180]],\n",
      "\n",
      "        [[-2.4267]],\n",
      "\n",
      "        [[-1.8242]],\n",
      "\n",
      "        [[ 0.0830]],\n",
      "\n",
      "        [[ 0.1651]],\n",
      "\n",
      "        [[-0.4175]],\n",
      "\n",
      "        [[ 1.0557]],\n",
      "\n",
      "        [[ 0.0834]],\n",
      "\n",
      "        [[ 0.4138]],\n",
      "\n",
      "        [[ 0.4692]],\n",
      "\n",
      "        [[ 0.7759]],\n",
      "\n",
      "        [[-1.2109]],\n",
      "\n",
      "        [[-0.8340]],\n",
      "\n",
      "        [[ 0.8589]],\n",
      "\n",
      "        [[-1.0731]],\n",
      "\n",
      "        [[-1.0397]],\n",
      "\n",
      "        [[ 1.2394]],\n",
      "\n",
      "        [[-0.3788]],\n",
      "\n",
      "        [[-0.8228]],\n",
      "\n",
      "        [[-0.4047]],\n",
      "\n",
      "        [[ 1.6454]],\n",
      "\n",
      "        [[-0.3096]],\n",
      "\n",
      "        [[-0.9413]],\n",
      "\n",
      "        [[-0.4080]],\n",
      "\n",
      "        [[ 0.1169]],\n",
      "\n",
      "        [[-1.4650]],\n",
      "\n",
      "        [[-0.0735]],\n",
      "\n",
      "        [[-0.7273]],\n",
      "\n",
      "        [[ 0.0546]],\n",
      "\n",
      "        [[ 0.2711]],\n",
      "\n",
      "        [[-1.4656]],\n",
      "\n",
      "        [[-0.2960]],\n",
      "\n",
      "        [[-0.0588]],\n",
      "\n",
      "        [[-0.0106]],\n",
      "\n",
      "        [[ 0.0903]],\n",
      "\n",
      "        [[ 1.0208]],\n",
      "\n",
      "        [[-1.5011]],\n",
      "\n",
      "        [[ 2.2331]],\n",
      "\n",
      "        [[ 0.0069]],\n",
      "\n",
      "        [[ 1.0108]],\n",
      "\n",
      "        [[ 1.0665]],\n",
      "\n",
      "        [[ 0.2609]],\n",
      "\n",
      "        [[ 0.1694]],\n",
      "\n",
      "        [[-0.1056]],\n",
      "\n",
      "        [[-2.6677]],\n",
      "\n",
      "        [[ 0.0574]],\n",
      "\n",
      "        [[ 0.4230]],\n",
      "\n",
      "        [[-1.1236]],\n",
      "\n",
      "        [[-0.3061]],\n",
      "\n",
      "        [[ 0.1569]],\n",
      "\n",
      "        [[-0.8443]],\n",
      "\n",
      "        [[ 0.8927]],\n",
      "\n",
      "        [[-0.6192]],\n",
      "\n",
      "        [[ 1.2191]],\n",
      "\n",
      "        [[-0.5370]],\n",
      "\n",
      "        [[ 0.4216]],\n",
      "\n",
      "        [[-0.1213]],\n",
      "\n",
      "        [[ 0.6571]],\n",
      "\n",
      "        [[ 0.5159]],\n",
      "\n",
      "        [[ 0.5098]],\n",
      "\n",
      "        [[ 0.8663]],\n",
      "\n",
      "        [[-2.1252]],\n",
      "\n",
      "        [[-0.1149]],\n",
      "\n",
      "        [[-2.0216]],\n",
      "\n",
      "        [[-0.1578]],\n",
      "\n",
      "        [[-0.0871]],\n",
      "\n",
      "        [[ 0.4058]],\n",
      "\n",
      "        [[-0.4270]],\n",
      "\n",
      "        [[-1.4462]],\n",
      "\n",
      "        [[ 0.5377]],\n",
      "\n",
      "        [[-0.3766]],\n",
      "\n",
      "        [[ 0.5061]],\n",
      "\n",
      "        [[-0.6686]],\n",
      "\n",
      "        [[ 0.8095]],\n",
      "\n",
      "        [[-0.5849]],\n",
      "\n",
      "        [[-0.0433]],\n",
      "\n",
      "        [[ 2.9841]],\n",
      "\n",
      "        [[ 0.4275]],\n",
      "\n",
      "        [[-1.6626]],\n",
      "\n",
      "        [[ 0.4290]],\n",
      "\n",
      "        [[ 0.4614]],\n",
      "\n",
      "        [[-0.0323]],\n",
      "\n",
      "        [[-0.5052]],\n",
      "\n",
      "        [[-0.5080]],\n",
      "\n",
      "        [[ 0.0696]],\n",
      "\n",
      "        [[ 0.3753]],\n",
      "\n",
      "        [[-1.3442]],\n",
      "\n",
      "        [[-0.6522]],\n",
      "\n",
      "        [[ 0.3723]],\n",
      "\n",
      "        [[ 0.5598]],\n",
      "\n",
      "        [[-0.1380]],\n",
      "\n",
      "        [[-0.1334]],\n",
      "\n",
      "        [[-1.2957]],\n",
      "\n",
      "        [[-0.5944]],\n",
      "\n",
      "        [[ 0.0880]],\n",
      "\n",
      "        [[ 1.2019]],\n",
      "\n",
      "        [[ 0.6991]],\n",
      "\n",
      "        [[-2.6660]],\n",
      "\n",
      "        [[ 0.9983]],\n",
      "\n",
      "        [[ 1.1068]],\n",
      "\n",
      "        [[ 0.6954]],\n",
      "\n",
      "        [[-0.9449]],\n",
      "\n",
      "        [[ 0.8874]],\n",
      "\n",
      "        [[ 0.9622]],\n",
      "\n",
      "        [[ 0.1112]],\n",
      "\n",
      "        [[-1.7064]],\n",
      "\n",
      "        [[ 0.4556]],\n",
      "\n",
      "        [[-0.5691]],\n",
      "\n",
      "        [[-1.1606]],\n",
      "\n",
      "        [[-0.6134]],\n",
      "\n",
      "        [[-0.8936]],\n",
      "\n",
      "        [[ 0.5473]],\n",
      "\n",
      "        [[-1.3414]],\n",
      "\n",
      "        [[-0.1189]],\n",
      "\n",
      "        [[ 1.4946]],\n",
      "\n",
      "        [[-0.6226]],\n",
      "\n",
      "        [[-1.2663]],\n",
      "\n",
      "        [[ 2.3198]],\n",
      "\n",
      "        [[ 2.0163]],\n",
      "\n",
      "        [[-0.5684]],\n",
      "\n",
      "        [[-1.0632]],\n",
      "\n",
      "        [[-0.8022]],\n",
      "\n",
      "        [[-0.0262]],\n",
      "\n",
      "        [[-1.0737]],\n",
      "\n",
      "        [[ 0.9271]],\n",
      "\n",
      "        [[ 0.1882]],\n",
      "\n",
      "        [[-1.0476]],\n",
      "\n",
      "        [[ 0.0759]],\n",
      "\n",
      "        [[ 1.6069]],\n",
      "\n",
      "        [[ 0.0209]],\n",
      "\n",
      "        [[ 1.9198]],\n",
      "\n",
      "        [[-0.5651]],\n",
      "\n",
      "        [[-0.0273]],\n",
      "\n",
      "        [[-0.6824]],\n",
      "\n",
      "        [[-0.7126]],\n",
      "\n",
      "        [[-1.0701]],\n",
      "\n",
      "        [[ 1.5919]],\n",
      "\n",
      "        [[ 0.6920]],\n",
      "\n",
      "        [[-0.4421]],\n",
      "\n",
      "        [[-0.7555]],\n",
      "\n",
      "        [[ 0.2551]],\n",
      "\n",
      "        [[-1.0037]],\n",
      "\n",
      "        [[-1.6364]],\n",
      "\n",
      "        [[ 1.0636]],\n",
      "\n",
      "        [[ 0.4107]],\n",
      "\n",
      "        [[-0.7147]],\n",
      "\n",
      "        [[ 0.2282]],\n",
      "\n",
      "        [[-0.4876]],\n",
      "\n",
      "        [[-0.6122]],\n",
      "\n",
      "        [[-0.0766]],\n",
      "\n",
      "        [[ 0.7668]],\n",
      "\n",
      "        [[-0.1225]]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor(1.00000e-04 *\n",
      "       [[[-6.4397]]], device='cuda:0')\n",
      "torch.Size([1, 448, 512])\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 1.9538,  1.9536,  1.9535,  ...,  1.9542,  1.9545,  1.9541],\n",
      "         [ 1.9522,  1.9522,  1.9524,  ...,  1.9533,  1.9534,  1.9533],\n",
      "         [ 1.9534,  1.9532,  1.9530,  ...,  1.9535,  1.9536,  1.9537],\n",
      "         ...,\n",
      "         [ 1.9537,  1.9536,  1.9537,  ...,  1.9530,  1.9532,  1.9536],\n",
      "         [ 1.9530,  1.9527,  1.9527,  ...,  1.9534,  1.9538,  1.9540],\n",
      "         [ 1.9532,  1.9532,  1.9529,  ...,  1.9526,  1.9528,  1.9529]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 38 [15360/50000 (34%)]\tLoss: 0.365169, Accuracy: 86.72\n",
      "Train Epoch: 38 [16640/50000 (37%)]\tLoss: 0.323031, Accuracy: 89.06\n",
      "Train Epoch: 38 [17920/50000 (40%)]\tLoss: 0.385659, Accuracy: 87.11\n",
      "Train Epoch: 38 [19200/50000 (43%)]\tLoss: 0.333153, Accuracy: 88.28\n",
      "Train Epoch: 38 [20480/50000 (45%)]\tLoss: 0.515478, Accuracy: 82.03\n",
      "Train Epoch: 38 [21760/50000 (48%)]\tLoss: 0.334071, Accuracy: 88.67\n",
      "Train Epoch: 38 [23040/50000 (51%)]\tLoss: 0.444122, Accuracy: 85.16\n",
      "Train Epoch: 38 [24320/50000 (54%)]\tLoss: 0.425883, Accuracy: 87.50\n",
      "Train Epoch: 38 [25600/50000 (57%)]\tLoss: 0.336438, Accuracy: 85.94\n",
      "Train Epoch: 38 [26880/50000 (60%)]\tLoss: 0.356445, Accuracy: 87.50\n",
      "Train Epoch: 38 [28160/50000 (62%)]\tLoss: 0.347666, Accuracy: 87.50\n",
      "Train Epoch: 38 [29440/50000 (65%)]\tLoss: 0.397734, Accuracy: 86.33\n",
      "Train Epoch: 38 [30720/50000 (68%)]\tLoss: 0.471633, Accuracy: 83.59\n",
      "Train Epoch: 38 [32000/50000 (71%)]\tLoss: 0.344529, Accuracy: 89.45\n",
      "Train Epoch: 38 [33280/50000 (74%)]\tLoss: 0.421205, Accuracy: 83.20\n",
      "Train Epoch: 38 [34560/50000 (77%)]\tLoss: 0.517265, Accuracy: 82.03\n",
      "Train Epoch: 38 [35840/50000 (80%)]\tLoss: 0.445602, Accuracy: 85.16\n",
      "Train Epoch: 38 [37120/50000 (82%)]\tLoss: 0.365648, Accuracy: 86.72\n",
      "Train Epoch: 38 [38400/50000 (85%)]\tLoss: 0.347605, Accuracy: 91.41\n",
      "Train Epoch: 38 [39680/50000 (88%)]\tLoss: 0.307843, Accuracy: 91.02\n",
      "Train Epoch: 38 [40960/50000 (91%)]\tLoss: 0.440195, Accuracy: 84.38\n",
      "Train Epoch: 38 [42240/50000 (94%)]\tLoss: 0.402733, Accuracy: 84.38\n",
      "Train Epoch: 38 [43520/50000 (97%)]\tLoss: 0.263539, Accuracy: 92.97\n",
      "Train Epoch: 38 [35000/50000 (99%)]\tLoss: 0.443705, Accuracy: 86.50\n",
      "\n",
      "Validation set: Average loss: 0.6493, Accuracy: 3930/5000 (78.00%)\n",
      "\n",
      "the time of this epoch:[37.4273157119751 s]\n",
      "\n",
      "Test set: Average loss: 0.6916, Accuracy: 7804/10000 (78.04%)\n",
      "\n",
      "Train Epoch: 39 [0/50000 (0%)]\tLoss: 0.341756, Accuracy: 88.67\n",
      "Train Epoch: 39 [1280/50000 (3%)]\tLoss: 0.281392, Accuracy: 90.62\n",
      "Train Epoch: 39 [2560/50000 (6%)]\tLoss: 0.409345, Accuracy: 87.89\n",
      "Train Epoch: 39 [3840/50000 (9%)]\tLoss: 0.370839, Accuracy: 86.33\n",
      "Train Epoch: 39 [5120/50000 (11%)]\tLoss: 0.278225, Accuracy: 89.45\n",
      "Train Epoch: 39 [6400/50000 (14%)]\tLoss: 0.359957, Accuracy: 87.89\n",
      "Train Epoch: 39 [7680/50000 (17%)]\tLoss: 0.413183, Accuracy: 85.16\n",
      "Train Epoch: 39 [8960/50000 (20%)]\tLoss: 0.244676, Accuracy: 91.41\n",
      "Train Epoch: 39 [10240/50000 (23%)]\tLoss: 0.467220, Accuracy: 84.77\n",
      "Train Epoch: 39 [11520/50000 (26%)]\tLoss: 0.405461, Accuracy: 87.50\n",
      "Train Epoch: 39 [12800/50000 (28%)]\tLoss: 0.376958, Accuracy: 88.28\n",
      "Train Epoch: 39 [14080/50000 (31%)]\tLoss: 0.495023, Accuracy: 83.59\n",
      "Train Epoch: 39 [15360/50000 (34%)]\tLoss: 0.358366, Accuracy: 87.89\n",
      "Train Epoch: 39 [16640/50000 (37%)]\tLoss: 0.337197, Accuracy: 87.50\n",
      "Train Epoch: 39 [17920/50000 (40%)]\tLoss: 0.410727, Accuracy: 83.20\n",
      "Train Epoch: 39 [19200/50000 (43%)]\tLoss: 0.417189, Accuracy: 87.11\n",
      "Train Epoch: 39 [20480/50000 (45%)]\tLoss: 0.373321, Accuracy: 86.72\n",
      "Train Epoch: 39 [21760/50000 (48%)]\tLoss: 0.408780, Accuracy: 87.11\n",
      "Train Epoch: 39 [23040/50000 (51%)]\tLoss: 0.345017, Accuracy: 90.23\n",
      "Train Epoch: 39 [24320/50000 (54%)]\tLoss: 0.449446, Accuracy: 85.94\n",
      "Train Epoch: 39 [25600/50000 (57%)]\tLoss: 0.425089, Accuracy: 86.72\n",
      "Train Epoch: 39 [26880/50000 (60%)]\tLoss: 0.378381, Accuracy: 85.55\n",
      "Train Epoch: 39 [28160/50000 (62%)]\tLoss: 0.468585, Accuracy: 83.59\n",
      "Train Epoch: 39 [29440/50000 (65%)]\tLoss: 0.420807, Accuracy: 85.55\n",
      "Train Epoch: 39 [30720/50000 (68%)]\tLoss: 0.374645, Accuracy: 88.28\n",
      "Train Epoch: 39 [32000/50000 (71%)]\tLoss: 0.529498, Accuracy: 82.42\n",
      "Train Epoch: 39 [33280/50000 (74%)]\tLoss: 0.335031, Accuracy: 88.67\n",
      "Train Epoch: 39 [34560/50000 (77%)]\tLoss: 0.365623, Accuracy: 87.50\n",
      "Train Epoch: 39 [35840/50000 (80%)]\tLoss: 0.366858, Accuracy: 85.94\n",
      "Train Epoch: 39 [37120/50000 (82%)]\tLoss: 0.372479, Accuracy: 87.11\n",
      "Train Epoch: 39 [38400/50000 (85%)]\tLoss: 0.327303, Accuracy: 88.67\n",
      "Train Epoch: 39 [39680/50000 (88%)]\tLoss: 0.361041, Accuracy: 88.67\n",
      "Train Epoch: 39 [40960/50000 (91%)]\tLoss: 0.484030, Accuracy: 82.42\n",
      "Train Epoch: 39 [42240/50000 (94%)]\tLoss: 0.400772, Accuracy: 85.55\n",
      "Train Epoch: 39 [43520/50000 (97%)]\tLoss: 0.464392, Accuracy: 85.16\n",
      "Train Epoch: 39 [35000/50000 (99%)]\tLoss: 0.420715, Accuracy: 88.00\n",
      "\n",
      "Validation set: Average loss: 0.6803, Accuracy: 3892/5000 (77.00%)\n",
      "\n",
      "the time of this epoch:[40.72255301475525 s]\n",
      "Train Epoch: 40 [0/50000 (0%)]\tLoss: 0.373114, Accuracy: 87.11\n",
      "Train Epoch: 40 [1280/50000 (3%)]\tLoss: 0.282827, Accuracy: 90.23\n",
      "Train Epoch: 40 [2560/50000 (6%)]\tLoss: 0.300606, Accuracy: 89.84\n",
      "Train Epoch: 40 [3840/50000 (9%)]\tLoss: 0.376620, Accuracy: 87.11\n",
      "Train Epoch: 40 [5120/50000 (11%)]\tLoss: 0.458905, Accuracy: 83.98\n",
      "Train Epoch: 40 [6400/50000 (14%)]\tLoss: 0.347642, Accuracy: 89.45\n",
      "Train Epoch: 40 [7680/50000 (17%)]\tLoss: 0.423194, Accuracy: 85.94\n",
      "Train Epoch: 40 [8960/50000 (20%)]\tLoss: 0.350420, Accuracy: 86.33\n",
      "Train Epoch: 40 [10240/50000 (23%)]\tLoss: 0.290155, Accuracy: 91.02\n",
      "Train Epoch: 40 [11520/50000 (26%)]\tLoss: 0.386126, Accuracy: 87.11\n",
      "Train Epoch: 40 [12800/50000 (28%)]\tLoss: 0.404525, Accuracy: 87.89\n",
      "Train Epoch: 40 [14080/50000 (31%)]\tLoss: 0.398261, Accuracy: 86.72\n",
      "Train Epoch: 40 [15360/50000 (34%)]\tLoss: 0.357288, Accuracy: 87.50\n",
      "Train Epoch: 40 [16640/50000 (37%)]\tLoss: 0.371834, Accuracy: 87.89\n",
      "Train Epoch: 40 [17920/50000 (40%)]\tLoss: 0.377032, Accuracy: 87.11\n",
      "Train Epoch: 40 [19200/50000 (43%)]\tLoss: 0.370662, Accuracy: 86.33\n",
      "Train Epoch: 40 [20480/50000 (45%)]\tLoss: 0.295092, Accuracy: 91.41\n",
      "Train Epoch: 40 [21760/50000 (48%)]\tLoss: 0.417044, Accuracy: 85.55\n",
      "Train Epoch: 40 [23040/50000 (51%)]\tLoss: 0.351013, Accuracy: 87.89\n",
      "Train Epoch: 40 [24320/50000 (54%)]\tLoss: 0.510549, Accuracy: 83.98\n",
      "Train Epoch: 40 [25600/50000 (57%)]\tLoss: 0.448581, Accuracy: 83.59\n",
      "Train Epoch: 40 [26880/50000 (60%)]\tLoss: 0.343383, Accuracy: 88.28\n",
      "Train Epoch: 40 [28160/50000 (62%)]\tLoss: 0.372907, Accuracy: 87.50\n",
      "Train Epoch: 40 [29440/50000 (65%)]\tLoss: 0.446540, Accuracy: 84.77\n",
      "Train Epoch: 40 [30720/50000 (68%)]\tLoss: 0.406976, Accuracy: 87.50\n",
      "Train Epoch: 40 [32000/50000 (71%)]\tLoss: 0.443434, Accuracy: 85.55\n",
      "Train Epoch: 40 [33280/50000 (74%)]\tLoss: 0.370316, Accuracy: 85.16\n",
      "Train Epoch: 40 [34560/50000 (77%)]\tLoss: 0.395160, Accuracy: 89.06\n",
      "Train Epoch: 40 [35840/50000 (80%)]\tLoss: 0.449867, Accuracy: 83.98\n",
      "Train Epoch: 40 [37120/50000 (82%)]\tLoss: 0.431988, Accuracy: 85.94\n",
      "Train Epoch: 40 [38400/50000 (85%)]\tLoss: 0.487161, Accuracy: 84.38\n",
      "Train Epoch: 40 [39680/50000 (88%)]\tLoss: 0.422840, Accuracy: 83.98\n",
      "Train Epoch: 40 [40960/50000 (91%)]\tLoss: 0.341561, Accuracy: 91.02\n",
      "Train Epoch: 40 [42240/50000 (94%)]\tLoss: 0.353350, Accuracy: 86.72\n",
      "Train Epoch: 40 [43520/50000 (97%)]\tLoss: 0.548479, Accuracy: 82.81\n",
      "Train Epoch: 40 [35000/50000 (99%)]\tLoss: 0.496537, Accuracy: 82.00\n",
      "\n",
      "Validation set: Average loss: 0.7748, Accuracy: 3754/5000 (75.00%)\n",
      "\n",
      "the time of this epoch:[37.594858169555664 s]\n",
      "\n",
      "Test set: Average loss: 0.7948, Accuracy: 7466/10000 (74.66%)\n",
      "\n",
      "Train Epoch: 41 [0/50000 (0%)]\tLoss: 0.381499, Accuracy: 86.72\n",
      "Train Epoch: 41 [1280/50000 (3%)]\tLoss: 0.362645, Accuracy: 87.50\n",
      "Train Epoch: 41 [2560/50000 (6%)]\tLoss: 0.320222, Accuracy: 89.45\n",
      "Train Epoch: 41 [3840/50000 (9%)]\tLoss: 0.404121, Accuracy: 87.50\n",
      "Train Epoch: 41 [5120/50000 (11%)]\tLoss: 0.458790, Accuracy: 85.16\n",
      "Train Epoch: 41 [6400/50000 (14%)]\tLoss: 0.458105, Accuracy: 83.20\n",
      "Train Epoch: 41 [7680/50000 (17%)]\tLoss: 0.422817, Accuracy: 85.94\n",
      "Train Epoch: 41 [8960/50000 (20%)]\tLoss: 0.377944, Accuracy: 88.67\n",
      "Train Epoch: 41 [10240/50000 (23%)]\tLoss: 0.381448, Accuracy: 90.23\n",
      "Train Epoch: 41 [11520/50000 (26%)]\tLoss: 0.344434, Accuracy: 89.84\n",
      "Train Epoch: 41 [12800/50000 (28%)]\tLoss: 0.265472, Accuracy: 91.80\n",
      "Train Epoch: 41 [14080/50000 (31%)]\tLoss: 0.332093, Accuracy: 87.50\n",
      "Train Epoch: 41 [15360/50000 (34%)]\tLoss: 0.484335, Accuracy: 82.42\n",
      "Train Epoch: 41 [16640/50000 (37%)]\tLoss: 0.305660, Accuracy: 91.41\n",
      "Train Epoch: 41 [17920/50000 (40%)]\tLoss: 0.446363, Accuracy: 83.98\n",
      "Train Epoch: 41 [19200/50000 (43%)]\tLoss: 0.392952, Accuracy: 86.33\n",
      "Train Epoch: 41 [20480/50000 (45%)]\tLoss: 0.437158, Accuracy: 86.33\n",
      "Train Epoch: 41 [21760/50000 (48%)]\tLoss: 0.368631, Accuracy: 86.72\n",
      "Train Epoch: 41 [23040/50000 (51%)]\tLoss: 0.349123, Accuracy: 89.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 41 [24320/50000 (54%)]\tLoss: 0.392797, Accuracy: 87.11\n",
      "Train Epoch: 41 [25600/50000 (57%)]\tLoss: 0.387998, Accuracy: 85.94\n",
      "Train Epoch: 41 [26880/50000 (60%)]\tLoss: 0.472315, Accuracy: 82.81\n",
      "Train Epoch: 41 [28160/50000 (62%)]\tLoss: 0.375542, Accuracy: 88.28\n",
      "Train Epoch: 41 [29440/50000 (65%)]\tLoss: 0.392399, Accuracy: 87.50\n",
      "Train Epoch: 41 [30720/50000 (68%)]\tLoss: 0.302771, Accuracy: 89.45\n",
      "Train Epoch: 41 [32000/50000 (71%)]\tLoss: 0.322332, Accuracy: 88.28\n",
      "Train Epoch: 41 [33280/50000 (74%)]\tLoss: 0.463185, Accuracy: 83.98\n",
      "Train Epoch: 41 [34560/50000 (77%)]\tLoss: 0.438015, Accuracy: 83.59\n",
      "Train Epoch: 41 [35840/50000 (80%)]\tLoss: 0.394861, Accuracy: 86.33\n",
      "Train Epoch: 41 [37120/50000 (82%)]\tLoss: 0.397853, Accuracy: 85.55\n",
      "Train Epoch: 41 [38400/50000 (85%)]\tLoss: 0.354380, Accuracy: 87.50\n",
      "Train Epoch: 41 [39680/50000 (88%)]\tLoss: 0.447853, Accuracy: 84.38\n",
      "Train Epoch: 41 [40960/50000 (91%)]\tLoss: 0.471464, Accuracy: 83.98\n",
      "Train Epoch: 41 [42240/50000 (94%)]\tLoss: 0.356323, Accuracy: 84.77\n",
      "Train Epoch: 41 [43520/50000 (97%)]\tLoss: 0.446596, Accuracy: 85.55\n",
      "Train Epoch: 41 [35000/50000 (99%)]\tLoss: 0.387173, Accuracy: 86.00\n",
      "\n",
      "Validation set: Average loss: 0.5855, Accuracy: 4040/5000 (80.00%)\n",
      "\n",
      "the time of this epoch:[41.35384488105774 s]\n",
      "Train Epoch: 42 [0/50000 (0%)]\tLoss: 0.434732, Accuracy: 84.38\n",
      "Train Epoch: 42 [1280/50000 (3%)]\tLoss: 0.431500, Accuracy: 83.98\n",
      "Train Epoch: 42 [2560/50000 (6%)]\tLoss: 0.489313, Accuracy: 84.77\n",
      "Train Epoch: 42 [3840/50000 (9%)]\tLoss: 0.531817, Accuracy: 82.42\n",
      "Train Epoch: 42 [5120/50000 (11%)]\tLoss: 0.385437, Accuracy: 86.33\n",
      "Train Epoch: 42 [6400/50000 (14%)]\tLoss: 0.333121, Accuracy: 90.62\n",
      "Train Epoch: 42 [7680/50000 (17%)]\tLoss: 0.323241, Accuracy: 88.28\n",
      "Train Epoch: 42 [8960/50000 (20%)]\tLoss: 0.363749, Accuracy: 86.72\n",
      "Train Epoch: 42 [10240/50000 (23%)]\tLoss: 0.403907, Accuracy: 87.11\n",
      "Train Epoch: 42 [11520/50000 (26%)]\tLoss: 0.351564, Accuracy: 88.67\n",
      "Train Epoch: 42 [12800/50000 (28%)]\tLoss: 0.398674, Accuracy: 86.72\n",
      "Train Epoch: 42 [14080/50000 (31%)]\tLoss: 0.320012, Accuracy: 87.11\n",
      "Train Epoch: 42 [15360/50000 (34%)]\tLoss: 0.307687, Accuracy: 89.06\n",
      "Train Epoch: 42 [16640/50000 (37%)]\tLoss: 0.357645, Accuracy: 86.33\n",
      "Train Epoch: 42 [17920/50000 (40%)]\tLoss: 0.384034, Accuracy: 87.50\n",
      "Train Epoch: 42 [19200/50000 (43%)]\tLoss: 0.400496, Accuracy: 88.67\n",
      "Train Epoch: 42 [20480/50000 (45%)]\tLoss: 0.310612, Accuracy: 89.06\n",
      "Train Epoch: 42 [21760/50000 (48%)]\tLoss: 0.397271, Accuracy: 86.72\n",
      "Train Epoch: 42 [23040/50000 (51%)]\tLoss: 0.420906, Accuracy: 83.59\n",
      "Train Epoch: 42 [24320/50000 (54%)]\tLoss: 0.301505, Accuracy: 89.45\n",
      "Train Epoch: 42 [25600/50000 (57%)]\tLoss: 0.405369, Accuracy: 85.55\n",
      "Train Epoch: 42 [26880/50000 (60%)]\tLoss: 0.316273, Accuracy: 90.23\n",
      "Train Epoch: 42 [28160/50000 (62%)]\tLoss: 0.482759, Accuracy: 82.81\n",
      "Train Epoch: 42 [29440/50000 (65%)]\tLoss: 0.349116, Accuracy: 88.67\n",
      "Train Epoch: 42 [30720/50000 (68%)]\tLoss: 0.416845, Accuracy: 84.77\n",
      "Train Epoch: 42 [32000/50000 (71%)]\tLoss: 0.324761, Accuracy: 88.67\n",
      "torch.Size([512, 1, 1])\n",
      "tensor([[[-1.1856e+00]],\n",
      "\n",
      "        [[-1.8272e+00]],\n",
      "\n",
      "        [[ 1.3476e-02]],\n",
      "\n",
      "        [[ 1.8825e+00]],\n",
      "\n",
      "        [[-1.4828e-01]],\n",
      "\n",
      "        [[-7.1419e-01]],\n",
      "\n",
      "        [[ 9.4087e-01]],\n",
      "\n",
      "        [[ 7.1082e-01]],\n",
      "\n",
      "        [[-3.6975e-01]],\n",
      "\n",
      "        [[ 3.8887e-01]],\n",
      "\n",
      "        [[ 3.8349e-01]],\n",
      "\n",
      "        [[-1.4266e-01]],\n",
      "\n",
      "        [[ 6.9832e-01]],\n",
      "\n",
      "        [[ 9.1665e-01]],\n",
      "\n",
      "        [[-3.7954e-01]],\n",
      "\n",
      "        [[ 1.1742e+00]],\n",
      "\n",
      "        [[ 1.0241e+00]],\n",
      "\n",
      "        [[-1.0097e-01]],\n",
      "\n",
      "        [[ 1.0928e+00]],\n",
      "\n",
      "        [[-4.2899e-01]],\n",
      "\n",
      "        [[-6.6350e-01]],\n",
      "\n",
      "        [[ 3.2021e-01]],\n",
      "\n",
      "        [[-9.6252e-01]],\n",
      "\n",
      "        [[ 4.2408e-02]],\n",
      "\n",
      "        [[-7.9129e-01]],\n",
      "\n",
      "        [[-4.2713e-01]],\n",
      "\n",
      "        [[ 2.7273e-01]],\n",
      "\n",
      "        [[-7.3710e-01]],\n",
      "\n",
      "        [[-1.8059e+00]],\n",
      "\n",
      "        [[ 1.0327e+00]],\n",
      "\n",
      "        [[-5.9490e-01]],\n",
      "\n",
      "        [[ 9.7590e-02]],\n",
      "\n",
      "        [[-4.8967e-01]],\n",
      "\n",
      "        [[ 5.7974e-01]],\n",
      "\n",
      "        [[-5.9956e-01]],\n",
      "\n",
      "        [[-7.3772e-02]],\n",
      "\n",
      "        [[ 2.3218e-01]],\n",
      "\n",
      "        [[ 9.9326e-01]],\n",
      "\n",
      "        [[ 9.1838e-01]],\n",
      "\n",
      "        [[-9.8265e-01]],\n",
      "\n",
      "        [[-1.0981e+00]],\n",
      "\n",
      "        [[-8.1470e-01]],\n",
      "\n",
      "        [[-6.6107e-01]],\n",
      "\n",
      "        [[-5.0435e-01]],\n",
      "\n",
      "        [[ 1.3510e+00]],\n",
      "\n",
      "        [[ 1.2891e+00]],\n",
      "\n",
      "        [[ 2.7575e-01]],\n",
      "\n",
      "        [[-1.2003e+00]],\n",
      "\n",
      "        [[ 7.4416e-01]],\n",
      "\n",
      "        [[ 2.3861e-01]],\n",
      "\n",
      "        [[ 6.2588e-01]],\n",
      "\n",
      "        [[-1.1248e+00]],\n",
      "\n",
      "        [[-9.2617e-01]],\n",
      "\n",
      "        [[-1.0794e-01]],\n",
      "\n",
      "        [[-1.4510e+00]],\n",
      "\n",
      "        [[ 8.0592e-01]],\n",
      "\n",
      "        [[ 1.2916e-01]],\n",
      "\n",
      "        [[-6.7261e-01]],\n",
      "\n",
      "        [[ 1.4205e+00]],\n",
      "\n",
      "        [[ 1.6794e+00]],\n",
      "\n",
      "        [[-1.1625e-01]],\n",
      "\n",
      "        [[ 1.6191e+00]],\n",
      "\n",
      "        [[-1.3596e-01]],\n",
      "\n",
      "        [[-1.7912e+00]],\n",
      "\n",
      "        [[ 2.0496e-02]],\n",
      "\n",
      "        [[-1.1658e+00]],\n",
      "\n",
      "        [[-5.3737e-01]],\n",
      "\n",
      "        [[ 2.2837e-01]],\n",
      "\n",
      "        [[ 1.5193e+00]],\n",
      "\n",
      "        [[ 3.9111e-02]],\n",
      "\n",
      "        [[ 1.9789e-01]],\n",
      "\n",
      "        [[-2.0368e+00]],\n",
      "\n",
      "        [[-1.1739e+00]],\n",
      "\n",
      "        [[ 9.0710e-01]],\n",
      "\n",
      "        [[ 1.0137e+00]],\n",
      "\n",
      "        [[-1.2794e+00]],\n",
      "\n",
      "        [[-9.7217e-01]],\n",
      "\n",
      "        [[-1.4173e+00]],\n",
      "\n",
      "        [[ 1.1672e+00]],\n",
      "\n",
      "        [[ 1.7864e-01]],\n",
      "\n",
      "        [[ 1.8591e-01]],\n",
      "\n",
      "        [[-5.1643e-05]],\n",
      "\n",
      "        [[-2.8730e-01]],\n",
      "\n",
      "        [[-1.1593e+00]],\n",
      "\n",
      "        [[-6.8936e-01]],\n",
      "\n",
      "        [[-8.2337e-01]],\n",
      "\n",
      "        [[-6.3303e-01]],\n",
      "\n",
      "        [[-3.3678e-01]],\n",
      "\n",
      "        [[ 1.9565e+00]],\n",
      "\n",
      "        [[ 5.2807e-01]],\n",
      "\n",
      "        [[-3.0887e-01]],\n",
      "\n",
      "        [[-1.1308e+00]],\n",
      "\n",
      "        [[-4.6102e-01]],\n",
      "\n",
      "        [[-1.1669e+00]],\n",
      "\n",
      "        [[-2.1981e-01]],\n",
      "\n",
      "        [[-6.2622e-01]],\n",
      "\n",
      "        [[ 1.8908e-01]],\n",
      "\n",
      "        [[-4.4069e-01]],\n",
      "\n",
      "        [[ 1.6110e-02]],\n",
      "\n",
      "        [[-3.6990e-01]],\n",
      "\n",
      "        [[ 7.3289e-01]],\n",
      "\n",
      "        [[ 1.6786e+00]],\n",
      "\n",
      "        [[ 6.4951e-01]],\n",
      "\n",
      "        [[ 2.5706e+00]],\n",
      "\n",
      "        [[-2.4020e-01]],\n",
      "\n",
      "        [[-8.8556e-01]],\n",
      "\n",
      "        [[ 8.2957e-01]],\n",
      "\n",
      "        [[ 6.5639e-01]],\n",
      "\n",
      "        [[ 2.2917e+00]],\n",
      "\n",
      "        [[-3.8075e-01]],\n",
      "\n",
      "        [[-4.1250e-01]],\n",
      "\n",
      "        [[-1.7318e-01]],\n",
      "\n",
      "        [[ 6.1335e-01]],\n",
      "\n",
      "        [[-8.4947e-01]],\n",
      "\n",
      "        [[-3.4281e-01]],\n",
      "\n",
      "        [[-1.6429e-01]],\n",
      "\n",
      "        [[-1.7441e+00]],\n",
      "\n",
      "        [[-8.4408e-02]],\n",
      "\n",
      "        [[ 7.3270e-02]],\n",
      "\n",
      "        [[ 3.3863e-01]],\n",
      "\n",
      "        [[-3.2370e-01]],\n",
      "\n",
      "        [[ 3.6117e-01]],\n",
      "\n",
      "        [[-8.0460e-01]],\n",
      "\n",
      "        [[ 2.7390e-01]],\n",
      "\n",
      "        [[ 1.1968e-01]],\n",
      "\n",
      "        [[ 9.1617e-01]],\n",
      "\n",
      "        [[ 3.1550e-01]],\n",
      "\n",
      "        [[ 1.7030e-01]],\n",
      "\n",
      "        [[-4.1834e-01]],\n",
      "\n",
      "        [[-9.3108e-01]],\n",
      "\n",
      "        [[ 1.5097e+00]],\n",
      "\n",
      "        [[ 8.5898e-01]],\n",
      "\n",
      "        [[-1.4127e+00]],\n",
      "\n",
      "        [[-9.4811e-01]],\n",
      "\n",
      "        [[ 1.7523e+00]],\n",
      "\n",
      "        [[-2.0209e+00]],\n",
      "\n",
      "        [[-1.5683e+00]],\n",
      "\n",
      "        [[ 2.0594e+00]],\n",
      "\n",
      "        [[ 1.7533e+00]],\n",
      "\n",
      "        [[-2.6393e+00]],\n",
      "\n",
      "        [[ 1.1497e+00]],\n",
      "\n",
      "        [[ 1.1346e+00]],\n",
      "\n",
      "        [[ 2.0779e+00]],\n",
      "\n",
      "        [[ 1.7681e+00]],\n",
      "\n",
      "        [[ 1.9037e+00]],\n",
      "\n",
      "        [[ 1.2035e+00]],\n",
      "\n",
      "        [[-1.7555e+00]],\n",
      "\n",
      "        [[ 9.8618e-01]],\n",
      "\n",
      "        [[-2.0207e-01]],\n",
      "\n",
      "        [[-3.7386e-01]],\n",
      "\n",
      "        [[ 2.8526e+00]],\n",
      "\n",
      "        [[ 6.2980e-01]],\n",
      "\n",
      "        [[ 1.2280e+00]],\n",
      "\n",
      "        [[ 4.9493e-01]],\n",
      "\n",
      "        [[-5.5299e-01]],\n",
      "\n",
      "        [[-4.1747e-01]],\n",
      "\n",
      "        [[-4.2368e-01]],\n",
      "\n",
      "        [[-5.9529e-01]],\n",
      "\n",
      "        [[ 5.4799e-01]],\n",
      "\n",
      "        [[ 3.7276e-02]],\n",
      "\n",
      "        [[ 1.2190e+00]],\n",
      "\n",
      "        [[ 2.1547e+00]],\n",
      "\n",
      "        [[-1.3546e+00]],\n",
      "\n",
      "        [[-1.5563e+00]],\n",
      "\n",
      "        [[ 2.2062e+00]],\n",
      "\n",
      "        [[ 1.3016e+00]],\n",
      "\n",
      "        [[ 9.6836e-01]],\n",
      "\n",
      "        [[-4.9857e-02]],\n",
      "\n",
      "        [[ 6.3625e-01]],\n",
      "\n",
      "        [[ 2.3553e-01]],\n",
      "\n",
      "        [[ 7.2854e-01]],\n",
      "\n",
      "        [[ 1.8056e-01]],\n",
      "\n",
      "        [[ 1.3547e+00]],\n",
      "\n",
      "        [[-2.1764e+00]],\n",
      "\n",
      "        [[ 4.8203e-01]],\n",
      "\n",
      "        [[-3.5286e-01]],\n",
      "\n",
      "        [[ 8.9573e-01]],\n",
      "\n",
      "        [[ 1.3694e+00]],\n",
      "\n",
      "        [[-6.9217e-01]],\n",
      "\n",
      "        [[ 5.1878e-01]],\n",
      "\n",
      "        [[ 1.6450e+00]],\n",
      "\n",
      "        [[-8.6609e-01]],\n",
      "\n",
      "        [[ 2.1201e+00]],\n",
      "\n",
      "        [[-2.0930e+00]],\n",
      "\n",
      "        [[ 1.0374e+00]],\n",
      "\n",
      "        [[ 9.8151e-01]],\n",
      "\n",
      "        [[-1.6579e-01]],\n",
      "\n",
      "        [[-1.4569e+00]],\n",
      "\n",
      "        [[-1.6518e+00]],\n",
      "\n",
      "        [[ 7.8310e-01]],\n",
      "\n",
      "        [[-2.9233e-01]],\n",
      "\n",
      "        [[ 4.4577e-01]],\n",
      "\n",
      "        [[ 2.9542e-01]],\n",
      "\n",
      "        [[ 8.6812e-01]],\n",
      "\n",
      "        [[-4.4406e-01]],\n",
      "\n",
      "        [[-1.5092e+00]],\n",
      "\n",
      "        [[-3.3272e-03]],\n",
      "\n",
      "        [[ 1.3507e-01]],\n",
      "\n",
      "        [[-7.1392e-01]],\n",
      "\n",
      "        [[-1.3656e+00]],\n",
      "\n",
      "        [[ 7.1509e-01]],\n",
      "\n",
      "        [[-1.4613e-02]],\n",
      "\n",
      "        [[-5.0189e-02]],\n",
      "\n",
      "        [[-5.6278e-01]],\n",
      "\n",
      "        [[ 1.0028e-01]],\n",
      "\n",
      "        [[-8.6180e-02]],\n",
      "\n",
      "        [[ 1.3720e+00]],\n",
      "\n",
      "        [[-2.8687e-01]],\n",
      "\n",
      "        [[ 1.3738e+00]],\n",
      "\n",
      "        [[-4.5268e-01]],\n",
      "\n",
      "        [[-4.4539e-02]],\n",
      "\n",
      "        [[ 4.3172e-01]],\n",
      "\n",
      "        [[-5.4024e-01]],\n",
      "\n",
      "        [[-2.7283e-01]],\n",
      "\n",
      "        [[-8.4136e-01]],\n",
      "\n",
      "        [[ 3.8500e-01]],\n",
      "\n",
      "        [[-1.8813e-01]],\n",
      "\n",
      "        [[ 2.7408e-01]],\n",
      "\n",
      "        [[ 3.4913e-01]],\n",
      "\n",
      "        [[-7.8480e-01]],\n",
      "\n",
      "        [[-1.4806e-01]],\n",
      "\n",
      "        [[-2.2410e-01]],\n",
      "\n",
      "        [[-6.8932e-01]],\n",
      "\n",
      "        [[ 5.0301e-01]],\n",
      "\n",
      "        [[-1.1376e+00]],\n",
      "\n",
      "        [[-1.0391e+00]],\n",
      "\n",
      "        [[-4.6944e-01]],\n",
      "\n",
      "        [[ 7.9743e-01]],\n",
      "\n",
      "        [[ 5.5224e-01]],\n",
      "\n",
      "        [[-8.4492e-02]],\n",
      "\n",
      "        [[-3.0009e-01]],\n",
      "\n",
      "        [[ 3.0139e-01]],\n",
      "\n",
      "        [[ 1.7015e+00]],\n",
      "\n",
      "        [[ 4.3826e-02]],\n",
      "\n",
      "        [[ 5.4731e-01]],\n",
      "\n",
      "        [[-1.9790e+00]],\n",
      "\n",
      "        [[ 1.3182e+00]],\n",
      "\n",
      "        [[-1.2623e-01]],\n",
      "\n",
      "        [[-9.6238e-01]],\n",
      "\n",
      "        [[-4.9898e-01]],\n",
      "\n",
      "        [[-8.4693e-01]],\n",
      "\n",
      "        [[ 6.9427e-01]],\n",
      "\n",
      "        [[-6.4702e-01]],\n",
      "\n",
      "        [[ 2.0129e+00]],\n",
      "\n",
      "        [[ 1.2125e+00]],\n",
      "\n",
      "        [[-1.0148e+00]],\n",
      "\n",
      "        [[-2.7845e-01]],\n",
      "\n",
      "        [[-3.5463e-01]],\n",
      "\n",
      "        [[ 3.2989e-01]],\n",
      "\n",
      "        [[ 7.8747e-02]],\n",
      "\n",
      "        [[-1.9115e-01]],\n",
      "\n",
      "        [[-1.7279e+00]],\n",
      "\n",
      "        [[ 1.4529e+00]],\n",
      "\n",
      "        [[ 7.4900e-01]],\n",
      "\n",
      "        [[-1.0160e+00]],\n",
      "\n",
      "        [[-1.4506e-01]],\n",
      "\n",
      "        [[ 3.3110e-01]],\n",
      "\n",
      "        [[ 1.7536e-02]],\n",
      "\n",
      "        [[ 1.0759e+00]],\n",
      "\n",
      "        [[ 1.7389e+00]],\n",
      "\n",
      "        [[ 1.9419e-01]],\n",
      "\n",
      "        [[-7.7455e-01]],\n",
      "\n",
      "        [[ 1.1881e-01]],\n",
      "\n",
      "        [[-4.1501e-01]],\n",
      "\n",
      "        [[ 8.2616e-01]],\n",
      "\n",
      "        [[ 9.6222e-01]],\n",
      "\n",
      "        [[-4.2233e-01]],\n",
      "\n",
      "        [[ 1.3777e+00]],\n",
      "\n",
      "        [[-1.6174e+00]],\n",
      "\n",
      "        [[ 1.3637e+00]],\n",
      "\n",
      "        [[ 1.7811e-01]],\n",
      "\n",
      "        [[-1.1409e-01]],\n",
      "\n",
      "        [[ 7.4517e-01]],\n",
      "\n",
      "        [[ 8.1187e-02]],\n",
      "\n",
      "        [[ 1.6993e+00]],\n",
      "\n",
      "        [[-7.7305e-01]],\n",
      "\n",
      "        [[-8.0377e-02]],\n",
      "\n",
      "        [[ 1.4282e-01]],\n",
      "\n",
      "        [[-1.1060e-01]],\n",
      "\n",
      "        [[ 2.6898e+00]],\n",
      "\n",
      "        [[ 4.6145e-01]],\n",
      "\n",
      "        [[-1.9436e+00]],\n",
      "\n",
      "        [[-1.0956e+00]],\n",
      "\n",
      "        [[-1.1086e-02]],\n",
      "\n",
      "        [[-3.9560e-01]],\n",
      "\n",
      "        [[ 3.9676e-01]],\n",
      "\n",
      "        [[-1.5368e+00]],\n",
      "\n",
      "        [[-2.8679e-01]],\n",
      "\n",
      "        [[ 3.8285e-01]],\n",
      "\n",
      "        [[-4.3553e-01]],\n",
      "\n",
      "        [[-7.8737e-01]],\n",
      "\n",
      "        [[-1.4581e-01]],\n",
      "\n",
      "        [[-1.4314e-02]],\n",
      "\n",
      "        [[-2.9038e+00]],\n",
      "\n",
      "        [[ 3.6191e-01]],\n",
      "\n",
      "        [[ 2.9643e-01]],\n",
      "\n",
      "        [[-8.1269e-01]],\n",
      "\n",
      "        [[ 1.1041e+00]],\n",
      "\n",
      "        [[-2.4230e-01]],\n",
      "\n",
      "        [[ 5.4731e-01]],\n",
      "\n",
      "        [[ 3.3813e-01]],\n",
      "\n",
      "        [[ 3.8779e-01]],\n",
      "\n",
      "        [[-1.1467e+00]],\n",
      "\n",
      "        [[ 1.6945e-01]],\n",
      "\n",
      "        [[ 6.5040e-01]],\n",
      "\n",
      "        [[-1.4507e+00]],\n",
      "\n",
      "        [[-1.4984e+00]],\n",
      "\n",
      "        [[ 6.6858e-02]],\n",
      "\n",
      "        [[ 1.1020e+00]],\n",
      "\n",
      "        [[-1.2951e+00]],\n",
      "\n",
      "        [[ 6.5964e-01]],\n",
      "\n",
      "        [[ 7.6957e-01]],\n",
      "\n",
      "        [[-2.5571e-01]],\n",
      "\n",
      "        [[ 8.6871e-01]],\n",
      "\n",
      "        [[ 1.5310e-01]],\n",
      "\n",
      "        [[ 1.5035e+00]],\n",
      "\n",
      "        [[ 3.3245e-01]],\n",
      "\n",
      "        [[ 1.3203e+00]],\n",
      "\n",
      "        [[-1.3172e+00]],\n",
      "\n",
      "        [[-1.6016e+00]],\n",
      "\n",
      "        [[-8.1568e-01]],\n",
      "\n",
      "        [[-1.9235e-01]],\n",
      "\n",
      "        [[ 1.1177e+00]],\n",
      "\n",
      "        [[ 5.3604e-01]],\n",
      "\n",
      "        [[ 1.7999e+00]],\n",
      "\n",
      "        [[-1.1866e+00]],\n",
      "\n",
      "        [[ 1.6319e+00]],\n",
      "\n",
      "        [[-1.4799e+00]],\n",
      "\n",
      "        [[ 3.1799e-01]],\n",
      "\n",
      "        [[-2.8071e-02]],\n",
      "\n",
      "        [[ 1.2402e-01]],\n",
      "\n",
      "        [[ 2.5729e-01]],\n",
      "\n",
      "        [[ 8.5349e-02]],\n",
      "\n",
      "        [[-1.3209e+00]],\n",
      "\n",
      "        [[ 3.2263e-01]],\n",
      "\n",
      "        [[-4.3161e-01]],\n",
      "\n",
      "        [[ 1.4558e+00]],\n",
      "\n",
      "        [[-5.7744e-01]],\n",
      "\n",
      "        [[-7.2244e-01]],\n",
      "\n",
      "        [[ 8.6926e-01]],\n",
      "\n",
      "        [[-5.7685e-01]],\n",
      "\n",
      "        [[ 5.4093e-01]],\n",
      "\n",
      "        [[ 8.7935e-01]],\n",
      "\n",
      "        [[-6.0665e-01]],\n",
      "\n",
      "        [[ 5.1927e-01]],\n",
      "\n",
      "        [[-8.5701e-01]],\n",
      "\n",
      "        [[-1.8160e+00]],\n",
      "\n",
      "        [[-1.4013e+00]],\n",
      "\n",
      "        [[-9.8904e-01]],\n",
      "\n",
      "        [[-3.7872e-01]],\n",
      "\n",
      "        [[-2.8746e-01]],\n",
      "\n",
      "        [[ 5.0741e-01]],\n",
      "\n",
      "        [[ 7.8065e-01]],\n",
      "\n",
      "        [[-1.4057e+00]],\n",
      "\n",
      "        [[ 5.2351e-01]],\n",
      "\n",
      "        [[-1.0082e+00]],\n",
      "\n",
      "        [[-1.0688e+00]],\n",
      "\n",
      "        [[ 1.2425e+00]],\n",
      "\n",
      "        [[ 1.5452e+00]],\n",
      "\n",
      "        [[ 5.6585e-01]],\n",
      "\n",
      "        [[ 2.8549e+00]],\n",
      "\n",
      "        [[-5.9123e-01]],\n",
      "\n",
      "        [[ 1.3919e+00]],\n",
      "\n",
      "        [[ 7.3314e-01]],\n",
      "\n",
      "        [[-6.9269e-01]],\n",
      "\n",
      "        [[ 3.9668e-01]],\n",
      "\n",
      "        [[-1.0559e+00]],\n",
      "\n",
      "        [[ 1.0370e+00]],\n",
      "\n",
      "        [[-1.2300e+00]],\n",
      "\n",
      "        [[-9.3166e-01]],\n",
      "\n",
      "        [[-1.8074e+00]],\n",
      "\n",
      "        [[-1.4026e+00]],\n",
      "\n",
      "        [[ 7.5690e-01]],\n",
      "\n",
      "        [[-1.6864e-01]],\n",
      "\n",
      "        [[ 3.3216e-01]],\n",
      "\n",
      "        [[ 2.5170e-02]],\n",
      "\n",
      "        [[ 6.7828e-01]],\n",
      "\n",
      "        [[ 1.0453e+00]],\n",
      "\n",
      "        [[-1.2986e+00]],\n",
      "\n",
      "        [[ 5.9922e-01]],\n",
      "\n",
      "        [[ 9.5079e-01]],\n",
      "\n",
      "        [[-1.4769e+00]],\n",
      "\n",
      "        [[-2.3869e+00]],\n",
      "\n",
      "        [[ 9.4879e-01]],\n",
      "\n",
      "        [[ 3.8697e-01]],\n",
      "\n",
      "        [[ 2.7888e-01]],\n",
      "\n",
      "        [[ 1.5806e+00]],\n",
      "\n",
      "        [[ 1.4797e+00]],\n",
      "\n",
      "        [[ 3.7676e+00]],\n",
      "\n",
      "        [[ 1.9605e+00]],\n",
      "\n",
      "        [[ 2.5176e-01]],\n",
      "\n",
      "        [[-2.9555e-01]],\n",
      "\n",
      "        [[-8.1773e-01]],\n",
      "\n",
      "        [[-1.9085e-01]],\n",
      "\n",
      "        [[-6.3772e-01]],\n",
      "\n",
      "        [[ 2.3698e+00]],\n",
      "\n",
      "        [[ 3.4213e-02]],\n",
      "\n",
      "        [[ 1.8923e+00]],\n",
      "\n",
      "        [[ 1.0637e+00]],\n",
      "\n",
      "        [[-1.9835e+00]],\n",
      "\n",
      "        [[ 1.0434e+00]],\n",
      "\n",
      "        [[-2.9080e-01]],\n",
      "\n",
      "        [[ 8.5842e-01]],\n",
      "\n",
      "        [[ 1.0169e+00]],\n",
      "\n",
      "        [[ 1.0300e+00]],\n",
      "\n",
      "        [[-6.2528e-02]],\n",
      "\n",
      "        [[ 4.9289e-01]],\n",
      "\n",
      "        [[-6.8573e-01]],\n",
      "\n",
      "        [[-1.3080e+00]],\n",
      "\n",
      "        [[ 1.4581e+00]],\n",
      "\n",
      "        [[ 2.3410e-01]],\n",
      "\n",
      "        [[-1.3891e+00]],\n",
      "\n",
      "        [[-2.4915e-01]],\n",
      "\n",
      "        [[ 1.0854e-01]],\n",
      "\n",
      "        [[-4.0619e-01]],\n",
      "\n",
      "        [[ 1.0211e+00]],\n",
      "\n",
      "        [[-4.8263e-01]],\n",
      "\n",
      "        [[ 5.5629e-01]],\n",
      "\n",
      "        [[-2.2125e-01]],\n",
      "\n",
      "        [[ 1.0278e+00]],\n",
      "\n",
      "        [[-1.6204e-02]],\n",
      "\n",
      "        [[ 1.1391e+00]],\n",
      "\n",
      "        [[ 7.1317e-01]],\n",
      "\n",
      "        [[ 1.6437e-01]],\n",
      "\n",
      "        [[-4.2232e-01]],\n",
      "\n",
      "        [[-1.0176e+00]],\n",
      "\n",
      "        [[-3.5590e-01]],\n",
      "\n",
      "        [[-4.0615e-01]],\n",
      "\n",
      "        [[ 2.0690e+00]],\n",
      "\n",
      "        [[-5.0017e-02]],\n",
      "\n",
      "        [[ 1.1958e+00]],\n",
      "\n",
      "        [[-1.1701e+00]],\n",
      "\n",
      "        [[-1.5233e+00]],\n",
      "\n",
      "        [[ 3.0466e-01]],\n",
      "\n",
      "        [[ 1.4457e+00]],\n",
      "\n",
      "        [[ 1.2679e+00]],\n",
      "\n",
      "        [[ 4.1642e-02]],\n",
      "\n",
      "        [[ 8.3113e-02]],\n",
      "\n",
      "        [[-4.2436e-01]],\n",
      "\n",
      "        [[ 3.9983e-01]],\n",
      "\n",
      "        [[-4.4054e-02]],\n",
      "\n",
      "        [[-6.5228e-01]],\n",
      "\n",
      "        [[-2.3087e+00]],\n",
      "\n",
      "        [[ 1.1579e+00]],\n",
      "\n",
      "        [[-9.5168e-01]],\n",
      "\n",
      "        [[-1.2010e-01]],\n",
      "\n",
      "        [[-7.0588e-01]],\n",
      "\n",
      "        [[-1.6843e+00]],\n",
      "\n",
      "        [[ 1.0647e-01]],\n",
      "\n",
      "        [[-2.5380e-02]],\n",
      "\n",
      "        [[-1.9876e+00]],\n",
      "\n",
      "        [[ 3.4500e-01]],\n",
      "\n",
      "        [[-4.8404e-01]],\n",
      "\n",
      "        [[-2.1893e-01]],\n",
      "\n",
      "        [[-1.2545e+00]],\n",
      "\n",
      "        [[ 1.9044e+00]],\n",
      "\n",
      "        [[ 3.5473e-01]],\n",
      "\n",
      "        [[-3.4385e-01]],\n",
      "\n",
      "        [[-6.9011e-02]],\n",
      "\n",
      "        [[-7.8473e-01]],\n",
      "\n",
      "        [[-3.1529e-01]],\n",
      "\n",
      "        [[-7.8809e-01]],\n",
      "\n",
      "        [[ 1.1200e-01]],\n",
      "\n",
      "        [[-1.3515e+00]],\n",
      "\n",
      "        [[-6.7792e-01]],\n",
      "\n",
      "        [[-6.3654e-01]],\n",
      "\n",
      "        [[ 4.7048e-01]],\n",
      "\n",
      "        [[-1.4096e+00]],\n",
      "\n",
      "        [[ 1.1599e+00]],\n",
      "\n",
      "        [[-5.4584e-01]],\n",
      "\n",
      "        [[-1.6110e+00]],\n",
      "\n",
      "        [[-1.2138e+00]],\n",
      "\n",
      "        [[ 8.3036e-01]],\n",
      "\n",
      "        [[ 1.8784e+00]],\n",
      "\n",
      "        [[-1.2138e+00]],\n",
      "\n",
      "        [[-9.2389e-01]],\n",
      "\n",
      "        [[-1.6563e+00]],\n",
      "\n",
      "        [[ 2.4242e-01]],\n",
      "\n",
      "        [[ 2.4609e-01]],\n",
      "\n",
      "        [[-1.0995e+00]],\n",
      "\n",
      "        [[ 1.8037e+00]],\n",
      "\n",
      "        [[ 1.6782e+00]],\n",
      "\n",
      "        [[-6.2915e-01]],\n",
      "\n",
      "        [[ 1.0559e+00]],\n",
      "\n",
      "        [[-9.8041e-01]],\n",
      "\n",
      "        [[-3.2338e-01]],\n",
      "\n",
      "        [[-3.3842e-01]],\n",
      "\n",
      "        [[ 7.8391e-01]],\n",
      "\n",
      "        [[ 1.5444e+00]],\n",
      "\n",
      "        [[ 2.5315e+00]],\n",
      "\n",
      "        [[ 2.7384e-01]],\n",
      "\n",
      "        [[ 4.0444e-02]],\n",
      "\n",
      "        [[-4.7085e-01]],\n",
      "\n",
      "        [[ 5.5245e-01]],\n",
      "\n",
      "        [[ 1.7448e+00]],\n",
      "\n",
      "        [[-1.0839e+00]],\n",
      "\n",
      "        [[-4.9592e-01]],\n",
      "\n",
      "        [[ 7.8463e-01]],\n",
      "\n",
      "        [[-2.6431e-01]],\n",
      "\n",
      "        [[ 1.4651e-01]],\n",
      "\n",
      "        [[ 1.4054e-01]],\n",
      "\n",
      "        [[ 5.2597e-01]],\n",
      "\n",
      "        [[-6.7322e-01]],\n",
      "\n",
      "        [[ 1.1773e+00]],\n",
      "\n",
      "        [[-4.4236e-01]],\n",
      "\n",
      "        [[ 1.1848e-01]],\n",
      "\n",
      "        [[-4.8506e-01]],\n",
      "\n",
      "        [[ 4.0877e-01]],\n",
      "\n",
      "        [[ 7.1418e-01]],\n",
      "\n",
      "        [[-7.2304e-01]],\n",
      "\n",
      "        [[-6.1218e-01]],\n",
      "\n",
      "        [[ 1.3411e-01]]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor(1.00000e-04 *\n",
      "       [[[-4.5375]]], device='cuda:0')\n",
      "torch.Size([1, 448, 512])\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 1.9534,  1.9533,  1.9533,  ...,  1.9536,  1.9538,  1.9536],\n",
      "         [ 1.9527,  1.9527,  1.9528,  ...,  1.9532,  1.9533,  1.9532],\n",
      "         [ 1.9533,  1.9532,  1.9531,  ...,  1.9533,  1.9533,  1.9534],\n",
      "         ...,\n",
      "         [ 1.9534,  1.9534,  1.9534,  ...,  1.9531,  1.9532,  1.9533],\n",
      "         [ 1.9531,  1.9529,  1.9529,  ...,  1.9533,  1.9534,  1.9535],\n",
      "         [ 1.9531,  1.9532,  1.9530,  ...,  1.9529,  1.9530,  1.9530]]], device='cuda:0')\n",
      "Train Epoch: 42 [33280/50000 (74%)]\tLoss: 0.384345, Accuracy: 87.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 42 [34560/50000 (77%)]\tLoss: 0.337263, Accuracy: 87.50\n",
      "Train Epoch: 42 [35840/50000 (80%)]\tLoss: 0.400525, Accuracy: 86.33\n",
      "Train Epoch: 42 [37120/50000 (82%)]\tLoss: 0.406021, Accuracy: 87.11\n",
      "Train Epoch: 42 [38400/50000 (85%)]\tLoss: 0.521100, Accuracy: 83.59\n",
      "Train Epoch: 42 [39680/50000 (88%)]\tLoss: 0.352841, Accuracy: 89.84\n",
      "Train Epoch: 42 [40960/50000 (91%)]\tLoss: 0.424525, Accuracy: 83.98\n",
      "Train Epoch: 42 [42240/50000 (94%)]\tLoss: 0.330234, Accuracy: 87.50\n",
      "Train Epoch: 42 [43520/50000 (97%)]\tLoss: 0.391663, Accuracy: 88.67\n",
      "Train Epoch: 42 [35000/50000 (99%)]\tLoss: 0.350804, Accuracy: 89.50\n",
      "\n",
      "Validation set: Average loss: 0.5508, Accuracy: 4068/5000 (81.00%)\n",
      "\n",
      "the time of this epoch:[37.98891997337341 s]\n",
      "\n",
      "Test set: Average loss: 0.5695, Accuracy: 8141/10000 (81.41%)\n",
      "\n",
      "Train Epoch: 43 [0/50000 (0%)]\tLoss: 0.303399, Accuracy: 89.84\n",
      "Train Epoch: 43 [1280/50000 (3%)]\tLoss: 0.319490, Accuracy: 88.28\n",
      "Train Epoch: 43 [2560/50000 (6%)]\tLoss: 0.356772, Accuracy: 88.28\n",
      "Train Epoch: 43 [3840/50000 (9%)]\tLoss: 0.325355, Accuracy: 88.28\n",
      "Train Epoch: 43 [5120/50000 (11%)]\tLoss: 0.345147, Accuracy: 88.28\n",
      "Train Epoch: 43 [6400/50000 (14%)]\tLoss: 0.333728, Accuracy: 89.45\n",
      "Train Epoch: 43 [7680/50000 (17%)]\tLoss: 0.309322, Accuracy: 88.67\n",
      "Train Epoch: 43 [8960/50000 (20%)]\tLoss: 0.457746, Accuracy: 83.98\n",
      "Train Epoch: 43 [10240/50000 (23%)]\tLoss: 0.392748, Accuracy: 88.28\n",
      "Train Epoch: 43 [11520/50000 (26%)]\tLoss: 0.398120, Accuracy: 87.11\n",
      "Train Epoch: 43 [12800/50000 (28%)]\tLoss: 0.366773, Accuracy: 88.67\n",
      "Train Epoch: 43 [14080/50000 (31%)]\tLoss: 0.543440, Accuracy: 83.20\n",
      "Train Epoch: 43 [15360/50000 (34%)]\tLoss: 0.389213, Accuracy: 85.94\n",
      "Train Epoch: 43 [16640/50000 (37%)]\tLoss: 0.372119, Accuracy: 87.89\n",
      "Train Epoch: 43 [17920/50000 (40%)]\tLoss: 0.360543, Accuracy: 86.33\n",
      "Train Epoch: 43 [19200/50000 (43%)]\tLoss: 0.421395, Accuracy: 84.77\n",
      "Train Epoch: 43 [20480/50000 (45%)]\tLoss: 0.513510, Accuracy: 83.20\n",
      "Train Epoch: 43 [21760/50000 (48%)]\tLoss: 0.318073, Accuracy: 87.11\n",
      "Train Epoch: 43 [23040/50000 (51%)]\tLoss: 0.364575, Accuracy: 87.11\n",
      "Train Epoch: 43 [24320/50000 (54%)]\tLoss: 0.414546, Accuracy: 87.89\n",
      "Train Epoch: 43 [25600/50000 (57%)]\tLoss: 0.340032, Accuracy: 87.11\n",
      "Train Epoch: 43 [26880/50000 (60%)]\tLoss: 0.448296, Accuracy: 86.33\n",
      "Train Epoch: 43 [28160/50000 (62%)]\tLoss: 0.363843, Accuracy: 90.23\n",
      "Train Epoch: 43 [29440/50000 (65%)]\tLoss: 0.573337, Accuracy: 80.86\n",
      "Train Epoch: 43 [30720/50000 (68%)]\tLoss: 0.373328, Accuracy: 87.11\n",
      "Train Epoch: 43 [32000/50000 (71%)]\tLoss: 0.390771, Accuracy: 87.11\n",
      "Train Epoch: 43 [33280/50000 (74%)]\tLoss: 0.408314, Accuracy: 86.72\n",
      "Train Epoch: 43 [34560/50000 (77%)]\tLoss: 0.394334, Accuracy: 88.67\n",
      "Train Epoch: 43 [35840/50000 (80%)]\tLoss: 0.432375, Accuracy: 85.16\n",
      "Train Epoch: 43 [37120/50000 (82%)]\tLoss: 0.408900, Accuracy: 83.98\n",
      "Train Epoch: 43 [38400/50000 (85%)]\tLoss: 0.429379, Accuracy: 84.77\n",
      "Train Epoch: 43 [39680/50000 (88%)]\tLoss: 0.388723, Accuracy: 84.77\n",
      "Train Epoch: 43 [40960/50000 (91%)]\tLoss: 0.397162, Accuracy: 86.72\n",
      "Train Epoch: 43 [42240/50000 (94%)]\tLoss: 0.366033, Accuracy: 86.33\n",
      "Train Epoch: 43 [43520/50000 (97%)]\tLoss: 0.461307, Accuracy: 84.77\n",
      "Train Epoch: 43 [35000/50000 (99%)]\tLoss: 0.318638, Accuracy: 90.00\n",
      "\n",
      "Validation set: Average loss: 0.8402, Accuracy: 3773/5000 (75.00%)\n",
      "\n",
      "the time of this epoch:[40.430447578430176 s]\n",
      "Train Epoch: 44 [0/50000 (0%)]\tLoss: 0.393113, Accuracy: 87.11\n",
      "Train Epoch: 44 [1280/50000 (3%)]\tLoss: 0.423090, Accuracy: 85.55\n",
      "Train Epoch: 44 [2560/50000 (6%)]\tLoss: 0.399054, Accuracy: 86.72\n",
      "Train Epoch: 44 [3840/50000 (9%)]\tLoss: 0.291820, Accuracy: 88.67\n",
      "Train Epoch: 44 [5120/50000 (11%)]\tLoss: 0.343332, Accuracy: 89.06\n",
      "Train Epoch: 44 [6400/50000 (14%)]\tLoss: 0.372914, Accuracy: 86.72\n",
      "Train Epoch: 44 [7680/50000 (17%)]\tLoss: 0.359354, Accuracy: 88.67\n",
      "Train Epoch: 44 [8960/50000 (20%)]\tLoss: 0.323030, Accuracy: 88.28\n",
      "Train Epoch: 44 [10240/50000 (23%)]\tLoss: 0.354378, Accuracy: 87.89\n",
      "Train Epoch: 44 [11520/50000 (26%)]\tLoss: 0.330838, Accuracy: 90.62\n",
      "Train Epoch: 44 [12800/50000 (28%)]\tLoss: 0.394954, Accuracy: 86.72\n",
      "Train Epoch: 44 [14080/50000 (31%)]\tLoss: 0.300674, Accuracy: 91.41\n",
      "Train Epoch: 44 [15360/50000 (34%)]\tLoss: 0.417496, Accuracy: 88.67\n",
      "Train Epoch: 44 [16640/50000 (37%)]\tLoss: 0.380142, Accuracy: 87.50\n",
      "Train Epoch: 44 [17920/50000 (40%)]\tLoss: 0.483924, Accuracy: 85.16\n",
      "Train Epoch: 44 [19200/50000 (43%)]\tLoss: 0.491849, Accuracy: 85.16\n",
      "Train Epoch: 44 [20480/50000 (45%)]\tLoss: 0.392541, Accuracy: 84.38\n",
      "Train Epoch: 44 [21760/50000 (48%)]\tLoss: 0.428997, Accuracy: 84.77\n",
      "Train Epoch: 44 [23040/50000 (51%)]\tLoss: 0.286059, Accuracy: 92.19\n",
      "Train Epoch: 44 [24320/50000 (54%)]\tLoss: 0.412623, Accuracy: 84.38\n",
      "Train Epoch: 44 [25600/50000 (57%)]\tLoss: 0.433121, Accuracy: 84.38\n",
      "Train Epoch: 44 [26880/50000 (60%)]\tLoss: 0.406196, Accuracy: 87.50\n",
      "Train Epoch: 44 [28160/50000 (62%)]\tLoss: 0.431521, Accuracy: 83.98\n",
      "Train Epoch: 44 [29440/50000 (65%)]\tLoss: 0.263336, Accuracy: 92.58\n",
      "Train Epoch: 44 [30720/50000 (68%)]\tLoss: 0.414126, Accuracy: 85.55\n",
      "Train Epoch: 44 [32000/50000 (71%)]\tLoss: 0.528431, Accuracy: 82.81\n",
      "Train Epoch: 44 [33280/50000 (74%)]\tLoss: 0.334653, Accuracy: 89.84\n",
      "Train Epoch: 44 [34560/50000 (77%)]\tLoss: 0.372078, Accuracy: 86.72\n",
      "Train Epoch: 44 [35840/50000 (80%)]\tLoss: 0.433341, Accuracy: 84.77\n",
      "Train Epoch: 44 [37120/50000 (82%)]\tLoss: 0.411951, Accuracy: 88.28\n",
      "Train Epoch: 44 [38400/50000 (85%)]\tLoss: 0.367339, Accuracy: 87.89\n",
      "Train Epoch: 44 [39680/50000 (88%)]\tLoss: 0.342617, Accuracy: 86.72\n",
      "Train Epoch: 44 [40960/50000 (91%)]\tLoss: 0.283583, Accuracy: 89.06\n",
      "Train Epoch: 44 [42240/50000 (94%)]\tLoss: 0.395011, Accuracy: 85.55\n",
      "Train Epoch: 44 [43520/50000 (97%)]\tLoss: 0.420819, Accuracy: 87.11\n",
      "Train Epoch: 44 [35000/50000 (99%)]\tLoss: 0.368762, Accuracy: 87.50\n",
      "\n",
      "Validation set: Average loss: 0.7129, Accuracy: 3880/5000 (77.00%)\n",
      "\n",
      "the time of this epoch:[37.67084074020386 s]\n",
      "\n",
      "Test set: Average loss: 0.7083, Accuracy: 7771/10000 (77.71%)\n",
      "\n",
      "Train Epoch: 45 [0/50000 (0%)]\tLoss: 0.370597, Accuracy: 87.89\n",
      "Train Epoch: 45 [1280/50000 (3%)]\tLoss: 0.309838, Accuracy: 89.06\n",
      "Train Epoch: 45 [2560/50000 (6%)]\tLoss: 0.383286, Accuracy: 86.72\n",
      "Train Epoch: 45 [3840/50000 (9%)]\tLoss: 0.386708, Accuracy: 87.11\n",
      "Train Epoch: 45 [5120/50000 (11%)]\tLoss: 0.395403, Accuracy: 85.94\n",
      "Train Epoch: 45 [6400/50000 (14%)]\tLoss: 0.286957, Accuracy: 90.62\n",
      "Train Epoch: 45 [7680/50000 (17%)]\tLoss: 0.418259, Accuracy: 82.42\n",
      "Train Epoch: 45 [8960/50000 (20%)]\tLoss: 0.333473, Accuracy: 90.23\n",
      "Train Epoch: 45 [10240/50000 (23%)]\tLoss: 0.443868, Accuracy: 85.55\n",
      "Train Epoch: 45 [11520/50000 (26%)]\tLoss: 0.391713, Accuracy: 85.16\n",
      "Train Epoch: 45 [12800/50000 (28%)]\tLoss: 0.366367, Accuracy: 87.89\n",
      "Train Epoch: 45 [14080/50000 (31%)]\tLoss: 0.396772, Accuracy: 89.84\n",
      "Train Epoch: 45 [15360/50000 (34%)]\tLoss: 0.326794, Accuracy: 88.67\n",
      "Train Epoch: 45 [16640/50000 (37%)]\tLoss: 0.426475, Accuracy: 85.55\n",
      "Train Epoch: 45 [17920/50000 (40%)]\tLoss: 0.376209, Accuracy: 86.72\n",
      "Train Epoch: 45 [19200/50000 (43%)]\tLoss: 0.396837, Accuracy: 85.16\n",
      "Train Epoch: 45 [20480/50000 (45%)]\tLoss: 0.356459, Accuracy: 86.33\n",
      "Train Epoch: 45 [21760/50000 (48%)]\tLoss: 0.364455, Accuracy: 87.50\n",
      "Train Epoch: 45 [23040/50000 (51%)]\tLoss: 0.376234, Accuracy: 85.94\n",
      "Train Epoch: 45 [24320/50000 (54%)]\tLoss: 0.381626, Accuracy: 87.89\n",
      "Train Epoch: 45 [25600/50000 (57%)]\tLoss: 0.449803, Accuracy: 85.55\n",
      "Train Epoch: 45 [26880/50000 (60%)]\tLoss: 0.365371, Accuracy: 87.50\n",
      "Train Epoch: 45 [28160/50000 (62%)]\tLoss: 0.360607, Accuracy: 86.72\n",
      "Train Epoch: 45 [29440/50000 (65%)]\tLoss: 0.314111, Accuracy: 89.45\n",
      "Train Epoch: 45 [30720/50000 (68%)]\tLoss: 0.435278, Accuracy: 84.38\n",
      "Train Epoch: 45 [32000/50000 (71%)]\tLoss: 0.431936, Accuracy: 85.16\n",
      "Train Epoch: 45 [33280/50000 (74%)]\tLoss: 0.390494, Accuracy: 86.33\n",
      "Train Epoch: 45 [34560/50000 (77%)]\tLoss: 0.322817, Accuracy: 89.45\n",
      "Train Epoch: 45 [35840/50000 (80%)]\tLoss: 0.585472, Accuracy: 80.86\n",
      "Train Epoch: 45 [37120/50000 (82%)]\tLoss: 0.440498, Accuracy: 84.38\n",
      "Train Epoch: 45 [38400/50000 (85%)]\tLoss: 0.331943, Accuracy: 89.84\n",
      "Train Epoch: 45 [39680/50000 (88%)]\tLoss: 0.328641, Accuracy: 88.28\n",
      "Train Epoch: 45 [40960/50000 (91%)]\tLoss: 0.412677, Accuracy: 86.33\n",
      "Train Epoch: 45 [42240/50000 (94%)]\tLoss: 0.341861, Accuracy: 89.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 45 [43520/50000 (97%)]\tLoss: 0.380438, Accuracy: 85.55\n",
      "Train Epoch: 45 [35000/50000 (99%)]\tLoss: 0.429902, Accuracy: 86.00\n",
      "\n",
      "Validation set: Average loss: 0.5867, Accuracy: 4031/5000 (80.00%)\n",
      "\n",
      "the time of this epoch:[40.7793390750885 s]\n",
      "Train Epoch: 46 [0/50000 (0%)]\tLoss: 0.454373, Accuracy: 83.20\n",
      "Train Epoch: 46 [1280/50000 (3%)]\tLoss: 0.421475, Accuracy: 85.55\n",
      "Train Epoch: 46 [2560/50000 (6%)]\tLoss: 0.318954, Accuracy: 87.11\n",
      "Train Epoch: 46 [3840/50000 (9%)]\tLoss: 0.406594, Accuracy: 87.11\n",
      "Train Epoch: 46 [5120/50000 (11%)]\tLoss: 0.349132, Accuracy: 89.45\n",
      "Train Epoch: 46 [6400/50000 (14%)]\tLoss: 0.350264, Accuracy: 86.72\n",
      "Train Epoch: 46 [7680/50000 (17%)]\tLoss: 0.385994, Accuracy: 88.67\n",
      "Train Epoch: 46 [8960/50000 (20%)]\tLoss: 0.346330, Accuracy: 89.06\n",
      "Train Epoch: 46 [10240/50000 (23%)]\tLoss: 0.495112, Accuracy: 83.98\n",
      "Train Epoch: 46 [11520/50000 (26%)]\tLoss: 0.378237, Accuracy: 87.89\n",
      "Train Epoch: 46 [12800/50000 (28%)]\tLoss: 0.294858, Accuracy: 88.67\n",
      "Train Epoch: 46 [14080/50000 (31%)]\tLoss: 0.397858, Accuracy: 86.33\n",
      "Train Epoch: 46 [15360/50000 (34%)]\tLoss: 0.402343, Accuracy: 85.16\n",
      "Train Epoch: 46 [16640/50000 (37%)]\tLoss: 0.420747, Accuracy: 85.16\n",
      "Train Epoch: 46 [17920/50000 (40%)]\tLoss: 0.426573, Accuracy: 87.11\n",
      "Train Epoch: 46 [19200/50000 (43%)]\tLoss: 0.483555, Accuracy: 84.77\n",
      "Train Epoch: 46 [20480/50000 (45%)]\tLoss: 0.426271, Accuracy: 84.77\n",
      "Train Epoch: 46 [21760/50000 (48%)]\tLoss: 0.431597, Accuracy: 85.55\n",
      "Train Epoch: 46 [23040/50000 (51%)]\tLoss: 0.395820, Accuracy: 86.72\n",
      "Train Epoch: 46 [24320/50000 (54%)]\tLoss: 0.331053, Accuracy: 88.28\n",
      "Train Epoch: 46 [25600/50000 (57%)]\tLoss: 0.347244, Accuracy: 87.11\n",
      "Train Epoch: 46 [26880/50000 (60%)]\tLoss: 0.383362, Accuracy: 87.50\n",
      "Train Epoch: 46 [28160/50000 (62%)]\tLoss: 0.409444, Accuracy: 86.33\n",
      "Train Epoch: 46 [29440/50000 (65%)]\tLoss: 0.301752, Accuracy: 92.19\n",
      "Train Epoch: 46 [30720/50000 (68%)]\tLoss: 0.322223, Accuracy: 88.28\n",
      "Train Epoch: 46 [32000/50000 (71%)]\tLoss: 0.322137, Accuracy: 87.89\n",
      "Train Epoch: 46 [33280/50000 (74%)]\tLoss: 0.322988, Accuracy: 90.62\n",
      "Train Epoch: 46 [34560/50000 (77%)]\tLoss: 0.384361, Accuracy: 88.67\n",
      "Train Epoch: 46 [35840/50000 (80%)]\tLoss: 0.401988, Accuracy: 87.50\n",
      "Train Epoch: 46 [37120/50000 (82%)]\tLoss: 0.380272, Accuracy: 86.33\n",
      "Train Epoch: 46 [38400/50000 (85%)]\tLoss: 0.326908, Accuracy: 89.06\n",
      "Train Epoch: 46 [39680/50000 (88%)]\tLoss: 0.386468, Accuracy: 87.11\n",
      "Train Epoch: 46 [40960/50000 (91%)]\tLoss: 0.323332, Accuracy: 89.06\n",
      "Train Epoch: 46 [42240/50000 (94%)]\tLoss: 0.356269, Accuracy: 88.67\n",
      "Train Epoch: 46 [43520/50000 (97%)]\tLoss: 0.397893, Accuracy: 85.94\n",
      "Train Epoch: 46 [35000/50000 (99%)]\tLoss: 0.490943, Accuracy: 84.00\n",
      "\n",
      "Validation set: Average loss: 0.5320, Accuracy: 4123/5000 (82.00%)\n",
      "\n",
      "the time of this epoch:[37.406940937042236 s]\n",
      "\n",
      "Test set: Average loss: 0.5336, Accuracy: 8234/10000 (82.34%)\n",
      "\n",
      "Train Epoch: 47 [0/50000 (0%)]\tLoss: 0.324440, Accuracy: 89.84\n",
      "Train Epoch: 47 [1280/50000 (3%)]\tLoss: 0.307191, Accuracy: 89.45\n",
      "Train Epoch: 47 [2560/50000 (6%)]\tLoss: 0.448318, Accuracy: 84.38\n",
      "torch.Size([512, 1, 1])\n",
      "tensor([[[-0.0731]],\n",
      "\n",
      "        [[-0.7762]],\n",
      "\n",
      "        [[ 2.5943]],\n",
      "\n",
      "        [[ 1.2015]],\n",
      "\n",
      "        [[-0.9959]],\n",
      "\n",
      "        [[-2.0750]],\n",
      "\n",
      "        [[-1.5456]],\n",
      "\n",
      "        [[-0.8069]],\n",
      "\n",
      "        [[ 0.4040]],\n",
      "\n",
      "        [[ 0.3701]],\n",
      "\n",
      "        [[ 0.3144]],\n",
      "\n",
      "        [[ 0.3374]],\n",
      "\n",
      "        [[-0.3562]],\n",
      "\n",
      "        [[-2.1381]],\n",
      "\n",
      "        [[ 0.5591]],\n",
      "\n",
      "        [[ 0.3898]],\n",
      "\n",
      "        [[-1.3655]],\n",
      "\n",
      "        [[-1.4417]],\n",
      "\n",
      "        [[-0.6918]],\n",
      "\n",
      "        [[-0.4888]],\n",
      "\n",
      "        [[ 1.0969]],\n",
      "\n",
      "        [[ 0.4751]],\n",
      "\n",
      "        [[-1.0082]],\n",
      "\n",
      "        [[-1.2493]],\n",
      "\n",
      "        [[ 1.4611]],\n",
      "\n",
      "        [[-1.4236]],\n",
      "\n",
      "        [[-0.2447]],\n",
      "\n",
      "        [[-0.4947]],\n",
      "\n",
      "        [[ 1.5352]],\n",
      "\n",
      "        [[ 1.0114]],\n",
      "\n",
      "        [[-0.5711]],\n",
      "\n",
      "        [[-1.4818]],\n",
      "\n",
      "        [[ 0.5869]],\n",
      "\n",
      "        [[ 2.0048]],\n",
      "\n",
      "        [[ 0.2588]],\n",
      "\n",
      "        [[-1.6276]],\n",
      "\n",
      "        [[-0.5258]],\n",
      "\n",
      "        [[ 0.2754]],\n",
      "\n",
      "        [[-0.7855]],\n",
      "\n",
      "        [[ 0.3644]],\n",
      "\n",
      "        [[ 0.3481]],\n",
      "\n",
      "        [[ 1.6977]],\n",
      "\n",
      "        [[-1.7321]],\n",
      "\n",
      "        [[ 0.0872]],\n",
      "\n",
      "        [[ 2.3690]],\n",
      "\n",
      "        [[ 0.1316]],\n",
      "\n",
      "        [[-1.8992]],\n",
      "\n",
      "        [[-0.6198]],\n",
      "\n",
      "        [[ 1.4135]],\n",
      "\n",
      "        [[ 2.1496]],\n",
      "\n",
      "        [[-0.3936]],\n",
      "\n",
      "        [[-0.8880]],\n",
      "\n",
      "        [[-0.2437]],\n",
      "\n",
      "        [[-0.6217]],\n",
      "\n",
      "        [[-0.3073]],\n",
      "\n",
      "        [[-0.5836]],\n",
      "\n",
      "        [[-1.7859]],\n",
      "\n",
      "        [[ 0.3991]],\n",
      "\n",
      "        [[-1.6796]],\n",
      "\n",
      "        [[ 0.5423]],\n",
      "\n",
      "        [[ 0.3798]],\n",
      "\n",
      "        [[ 0.2995]],\n",
      "\n",
      "        [[-0.7298]],\n",
      "\n",
      "        [[-1.2011]],\n",
      "\n",
      "        [[-1.4750]],\n",
      "\n",
      "        [[ 0.8949]],\n",
      "\n",
      "        [[-0.3419]],\n",
      "\n",
      "        [[ 2.2189]],\n",
      "\n",
      "        [[-1.1324]],\n",
      "\n",
      "        [[ 0.0293]],\n",
      "\n",
      "        [[-0.3283]],\n",
      "\n",
      "        [[ 0.9351]],\n",
      "\n",
      "        [[ 0.2722]],\n",
      "\n",
      "        [[-0.9057]],\n",
      "\n",
      "        [[ 0.9029]],\n",
      "\n",
      "        [[-0.7555]],\n",
      "\n",
      "        [[ 1.1918]],\n",
      "\n",
      "        [[ 0.0090]],\n",
      "\n",
      "        [[ 1.0271]],\n",
      "\n",
      "        [[ 0.6919]],\n",
      "\n",
      "        [[ 1.6962]],\n",
      "\n",
      "        [[-0.8313]],\n",
      "\n",
      "        [[-2.1042]],\n",
      "\n",
      "        [[ 0.5425]],\n",
      "\n",
      "        [[-1.8066]],\n",
      "\n",
      "        [[-0.4526]],\n",
      "\n",
      "        [[ 0.2272]],\n",
      "\n",
      "        [[ 0.5049]],\n",
      "\n",
      "        [[-2.6249]],\n",
      "\n",
      "        [[ 0.9585]],\n",
      "\n",
      "        [[-0.6885]],\n",
      "\n",
      "        [[ 0.0870]],\n",
      "\n",
      "        [[ 0.4034]],\n",
      "\n",
      "        [[ 0.5768]],\n",
      "\n",
      "        [[-0.8870]],\n",
      "\n",
      "        [[ 1.1013]],\n",
      "\n",
      "        [[-0.5183]],\n",
      "\n",
      "        [[ 0.8730]],\n",
      "\n",
      "        [[-0.4113]],\n",
      "\n",
      "        [[-1.3122]],\n",
      "\n",
      "        [[ 1.5750]],\n",
      "\n",
      "        [[ 1.7438]],\n",
      "\n",
      "        [[ 2.2655]],\n",
      "\n",
      "        [[-0.4553]],\n",
      "\n",
      "        [[-1.1959]],\n",
      "\n",
      "        [[-1.4577]],\n",
      "\n",
      "        [[-1.5406]],\n",
      "\n",
      "        [[-1.6686]],\n",
      "\n",
      "        [[ 0.0931]],\n",
      "\n",
      "        [[ 1.0131]],\n",
      "\n",
      "        [[-0.6807]],\n",
      "\n",
      "        [[-1.0791]],\n",
      "\n",
      "        [[-0.7887]],\n",
      "\n",
      "        [[-0.3383]],\n",
      "\n",
      "        [[ 0.4070]],\n",
      "\n",
      "        [[-1.2905]],\n",
      "\n",
      "        [[-0.9795]],\n",
      "\n",
      "        [[ 0.0190]],\n",
      "\n",
      "        [[-0.6791]],\n",
      "\n",
      "        [[ 0.1059]],\n",
      "\n",
      "        [[-1.5495]],\n",
      "\n",
      "        [[ 0.2648]],\n",
      "\n",
      "        [[ 1.5090]],\n",
      "\n",
      "        [[-0.5886]],\n",
      "\n",
      "        [[-1.0457]],\n",
      "\n",
      "        [[-1.4483]],\n",
      "\n",
      "        [[-0.4349]],\n",
      "\n",
      "        [[-1.2264]],\n",
      "\n",
      "        [[-0.2719]],\n",
      "\n",
      "        [[-1.3326]],\n",
      "\n",
      "        [[-0.0784]],\n",
      "\n",
      "        [[ 0.2732]],\n",
      "\n",
      "        [[-0.0070]],\n",
      "\n",
      "        [[-0.4241]],\n",
      "\n",
      "        [[ 1.4742]],\n",
      "\n",
      "        [[-0.1790]],\n",
      "\n",
      "        [[-0.4109]],\n",
      "\n",
      "        [[-0.0348]],\n",
      "\n",
      "        [[-1.1232]],\n",
      "\n",
      "        [[ 1.7840]],\n",
      "\n",
      "        [[ 1.0189]],\n",
      "\n",
      "        [[ 1.0150]],\n",
      "\n",
      "        [[-0.5734]],\n",
      "\n",
      "        [[ 0.3490]],\n",
      "\n",
      "        [[ 0.0685]],\n",
      "\n",
      "        [[ 0.4662]],\n",
      "\n",
      "        [[ 0.3971]],\n",
      "\n",
      "        [[ 0.6994]],\n",
      "\n",
      "        [[-0.0078]],\n",
      "\n",
      "        [[ 1.3586]],\n",
      "\n",
      "        [[ 1.1380]],\n",
      "\n",
      "        [[-0.1964]],\n",
      "\n",
      "        [[ 0.7883]],\n",
      "\n",
      "        [[-0.4123]],\n",
      "\n",
      "        [[ 0.9523]],\n",
      "\n",
      "        [[ 3.0201]],\n",
      "\n",
      "        [[-0.4111]],\n",
      "\n",
      "        [[ 2.3799]],\n",
      "\n",
      "        [[-0.4884]],\n",
      "\n",
      "        [[-1.4611]],\n",
      "\n",
      "        [[ 0.8512]],\n",
      "\n",
      "        [[ 0.2519]],\n",
      "\n",
      "        [[-1.0824]],\n",
      "\n",
      "        [[-0.8454]],\n",
      "\n",
      "        [[ 1.5527]],\n",
      "\n",
      "        [[-0.2182]],\n",
      "\n",
      "        [[-0.7605]],\n",
      "\n",
      "        [[-1.9398]],\n",
      "\n",
      "        [[ 0.0200]],\n",
      "\n",
      "        [[ 0.2611]],\n",
      "\n",
      "        [[ 0.1043]],\n",
      "\n",
      "        [[-1.0502]],\n",
      "\n",
      "        [[-0.5844]],\n",
      "\n",
      "        [[ 0.8979]],\n",
      "\n",
      "        [[-0.8006]],\n",
      "\n",
      "        [[ 1.6498]],\n",
      "\n",
      "        [[-1.8579]],\n",
      "\n",
      "        [[ 0.0607]],\n",
      "\n",
      "        [[-0.1718]],\n",
      "\n",
      "        [[ 1.2559]],\n",
      "\n",
      "        [[-0.4877]],\n",
      "\n",
      "        [[-0.5357]],\n",
      "\n",
      "        [[-1.3739]],\n",
      "\n",
      "        [[ 0.7684]],\n",
      "\n",
      "        [[-0.0231]],\n",
      "\n",
      "        [[ 0.1429]],\n",
      "\n",
      "        [[ 1.5742]],\n",
      "\n",
      "        [[-0.5847]],\n",
      "\n",
      "        [[-1.1472]],\n",
      "\n",
      "        [[-0.4192]],\n",
      "\n",
      "        [[-0.6114]],\n",
      "\n",
      "        [[ 1.3043]],\n",
      "\n",
      "        [[-0.2062]],\n",
      "\n",
      "        [[-0.0429]],\n",
      "\n",
      "        [[-0.3743]],\n",
      "\n",
      "        [[-1.3199]],\n",
      "\n",
      "        [[-0.0385]],\n",
      "\n",
      "        [[ 0.1281]],\n",
      "\n",
      "        [[-1.1385]],\n",
      "\n",
      "        [[ 0.3552]],\n",
      "\n",
      "        [[ 1.0325]],\n",
      "\n",
      "        [[ 0.5162]],\n",
      "\n",
      "        [[ 0.4306]],\n",
      "\n",
      "        [[-0.5469]],\n",
      "\n",
      "        [[-1.3542]],\n",
      "\n",
      "        [[-0.3377]],\n",
      "\n",
      "        [[ 1.3852]],\n",
      "\n",
      "        [[ 0.4027]],\n",
      "\n",
      "        [[ 0.6747]],\n",
      "\n",
      "        [[-1.4941]],\n",
      "\n",
      "        [[-1.4699]],\n",
      "\n",
      "        [[-1.3702]],\n",
      "\n",
      "        [[ 0.9157]],\n",
      "\n",
      "        [[-1.0266]],\n",
      "\n",
      "        [[ 0.0897]],\n",
      "\n",
      "        [[-0.3043]],\n",
      "\n",
      "        [[-1.2672]],\n",
      "\n",
      "        [[ 1.3731]],\n",
      "\n",
      "        [[-0.4180]],\n",
      "\n",
      "        [[ 0.0148]],\n",
      "\n",
      "        [[ 0.2334]],\n",
      "\n",
      "        [[-1.0420]],\n",
      "\n",
      "        [[-2.1344]],\n",
      "\n",
      "        [[-0.8614]],\n",
      "\n",
      "        [[-1.3705]],\n",
      "\n",
      "        [[ 0.3067]],\n",
      "\n",
      "        [[ 0.2702]],\n",
      "\n",
      "        [[ 1.3344]],\n",
      "\n",
      "        [[ 1.8429]],\n",
      "\n",
      "        [[ 2.0840]],\n",
      "\n",
      "        [[-0.0030]],\n",
      "\n",
      "        [[-1.9942]],\n",
      "\n",
      "        [[ 0.0305]],\n",
      "\n",
      "        [[ 0.5847]],\n",
      "\n",
      "        [[-0.1340]],\n",
      "\n",
      "        [[-0.3711]],\n",
      "\n",
      "        [[-0.2769]],\n",
      "\n",
      "        [[-0.4971]],\n",
      "\n",
      "        [[ 0.3749]],\n",
      "\n",
      "        [[ 0.7588]],\n",
      "\n",
      "        [[ 0.3026]],\n",
      "\n",
      "        [[-0.2215]],\n",
      "\n",
      "        [[-0.5036]],\n",
      "\n",
      "        [[ 0.7459]],\n",
      "\n",
      "        [[-0.5341]],\n",
      "\n",
      "        [[ 1.1481]],\n",
      "\n",
      "        [[-1.2136]],\n",
      "\n",
      "        [[ 0.3899]],\n",
      "\n",
      "        [[ 0.1334]],\n",
      "\n",
      "        [[ 1.0632]],\n",
      "\n",
      "        [[ 0.7912]],\n",
      "\n",
      "        [[ 1.0125]],\n",
      "\n",
      "        [[ 0.1414]],\n",
      "\n",
      "        [[-0.0513]],\n",
      "\n",
      "        [[-0.7378]],\n",
      "\n",
      "        [[-0.6232]],\n",
      "\n",
      "        [[-0.1788]],\n",
      "\n",
      "        [[ 1.1816]],\n",
      "\n",
      "        [[-0.6954]],\n",
      "\n",
      "        [[ 0.5026]],\n",
      "\n",
      "        [[ 0.6547]],\n",
      "\n",
      "        [[ 0.0794]],\n",
      "\n",
      "        [[-1.0737]],\n",
      "\n",
      "        [[-0.1824]],\n",
      "\n",
      "        [[ 0.5763]],\n",
      "\n",
      "        [[-0.1184]],\n",
      "\n",
      "        [[ 0.0831]],\n",
      "\n",
      "        [[ 0.3894]],\n",
      "\n",
      "        [[-2.1483]],\n",
      "\n",
      "        [[-2.5904]],\n",
      "\n",
      "        [[ 1.4126]],\n",
      "\n",
      "        [[-0.0166]],\n",
      "\n",
      "        [[-0.6330]],\n",
      "\n",
      "        [[-1.8186]],\n",
      "\n",
      "        [[ 0.7360]],\n",
      "\n",
      "        [[-1.8877]],\n",
      "\n",
      "        [[ 0.2198]],\n",
      "\n",
      "        [[ 0.9072]],\n",
      "\n",
      "        [[-0.9776]],\n",
      "\n",
      "        [[-1.9775]],\n",
      "\n",
      "        [[-1.2398]],\n",
      "\n",
      "        [[ 1.1827]],\n",
      "\n",
      "        [[-0.1117]],\n",
      "\n",
      "        [[-1.8821]],\n",
      "\n",
      "        [[-0.0693]],\n",
      "\n",
      "        [[ 0.1765]],\n",
      "\n",
      "        [[ 0.6394]],\n",
      "\n",
      "        [[-0.9152]],\n",
      "\n",
      "        [[ 1.2238]],\n",
      "\n",
      "        [[ 0.0084]],\n",
      "\n",
      "        [[ 1.6909]],\n",
      "\n",
      "        [[ 1.3554]],\n",
      "\n",
      "        [[-0.9695]],\n",
      "\n",
      "        [[ 0.4524]],\n",
      "\n",
      "        [[-0.0371]],\n",
      "\n",
      "        [[ 1.3242]],\n",
      "\n",
      "        [[ 0.7776]],\n",
      "\n",
      "        [[-2.0488]],\n",
      "\n",
      "        [[-0.6246]],\n",
      "\n",
      "        [[-2.4015]],\n",
      "\n",
      "        [[ 0.9048]],\n",
      "\n",
      "        [[ 1.0635]],\n",
      "\n",
      "        [[ 0.3501]],\n",
      "\n",
      "        [[ 0.1717]],\n",
      "\n",
      "        [[ 0.0121]],\n",
      "\n",
      "        [[ 1.3089]],\n",
      "\n",
      "        [[-0.8589]],\n",
      "\n",
      "        [[-1.6972]],\n",
      "\n",
      "        [[-1.4290]],\n",
      "\n",
      "        [[ 0.5218]],\n",
      "\n",
      "        [[ 1.3653]],\n",
      "\n",
      "        [[-0.0172]],\n",
      "\n",
      "        [[ 0.3235]],\n",
      "\n",
      "        [[ 0.1210]],\n",
      "\n",
      "        [[ 0.5381]],\n",
      "\n",
      "        [[ 1.2589]],\n",
      "\n",
      "        [[ 1.2657]],\n",
      "\n",
      "        [[ 2.6169]],\n",
      "\n",
      "        [[-0.1300]],\n",
      "\n",
      "        [[ 0.0194]],\n",
      "\n",
      "        [[-0.5214]],\n",
      "\n",
      "        [[ 0.4084]],\n",
      "\n",
      "        [[-0.6382]],\n",
      "\n",
      "        [[-0.6658]],\n",
      "\n",
      "        [[-1.0991]],\n",
      "\n",
      "        [[ 0.3045]],\n",
      "\n",
      "        [[ 0.3649]],\n",
      "\n",
      "        [[ 1.8280]],\n",
      "\n",
      "        [[-1.1866]],\n",
      "\n",
      "        [[-0.2651]],\n",
      "\n",
      "        [[ 0.3213]],\n",
      "\n",
      "        [[-0.1034]],\n",
      "\n",
      "        [[ 0.7066]],\n",
      "\n",
      "        [[ 0.0985]],\n",
      "\n",
      "        [[-0.3414]],\n",
      "\n",
      "        [[-1.8706]],\n",
      "\n",
      "        [[-0.5966]],\n",
      "\n",
      "        [[ 1.1009]],\n",
      "\n",
      "        [[ 0.0398]],\n",
      "\n",
      "        [[ 1.1136]],\n",
      "\n",
      "        [[ 0.2558]],\n",
      "\n",
      "        [[ 1.8353]],\n",
      "\n",
      "        [[-1.1958]],\n",
      "\n",
      "        [[-0.0156]],\n",
      "\n",
      "        [[-0.0210]],\n",
      "\n",
      "        [[ 0.2054]],\n",
      "\n",
      "        [[ 0.1151]],\n",
      "\n",
      "        [[ 1.3133]],\n",
      "\n",
      "        [[-1.3291]],\n",
      "\n",
      "        [[-1.5774]],\n",
      "\n",
      "        [[-0.3754]],\n",
      "\n",
      "        [[ 0.0795]],\n",
      "\n",
      "        [[-1.7407]],\n",
      "\n",
      "        [[-0.1112]],\n",
      "\n",
      "        [[-1.0388]],\n",
      "\n",
      "        [[-0.5468]],\n",
      "\n",
      "        [[-0.7742]],\n",
      "\n",
      "        [[-0.5438]],\n",
      "\n",
      "        [[ 0.1015]],\n",
      "\n",
      "        [[-0.1213]],\n",
      "\n",
      "        [[-0.7584]],\n",
      "\n",
      "        [[-0.4020]],\n",
      "\n",
      "        [[ 0.5085]],\n",
      "\n",
      "        [[-1.1135]],\n",
      "\n",
      "        [[-0.7285]],\n",
      "\n",
      "        [[ 0.0084]],\n",
      "\n",
      "        [[-0.3385]],\n",
      "\n",
      "        [[-0.1743]],\n",
      "\n",
      "        [[-0.8365]],\n",
      "\n",
      "        [[-0.1556]],\n",
      "\n",
      "        [[-0.2618]],\n",
      "\n",
      "        [[ 0.3034]],\n",
      "\n",
      "        [[ 1.2047]],\n",
      "\n",
      "        [[ 1.6645]],\n",
      "\n",
      "        [[-0.8961]],\n",
      "\n",
      "        [[ 1.2989]],\n",
      "\n",
      "        [[-0.4305]],\n",
      "\n",
      "        [[-0.0551]],\n",
      "\n",
      "        [[ 0.3547]],\n",
      "\n",
      "        [[-1.0011]],\n",
      "\n",
      "        [[-0.3879]],\n",
      "\n",
      "        [[-0.7565]],\n",
      "\n",
      "        [[-0.9895]],\n",
      "\n",
      "        [[ 1.0380]],\n",
      "\n",
      "        [[-0.7829]],\n",
      "\n",
      "        [[-0.9222]],\n",
      "\n",
      "        [[-0.8044]],\n",
      "\n",
      "        [[-1.4840]],\n",
      "\n",
      "        [[-0.8137]],\n",
      "\n",
      "        [[ 0.9864]],\n",
      "\n",
      "        [[-0.6040]],\n",
      "\n",
      "        [[ 0.5564]],\n",
      "\n",
      "        [[ 0.2841]],\n",
      "\n",
      "        [[-1.2318]],\n",
      "\n",
      "        [[-0.0046]],\n",
      "\n",
      "        [[ 1.6170]],\n",
      "\n",
      "        [[ 1.0980]],\n",
      "\n",
      "        [[ 0.4693]],\n",
      "\n",
      "        [[-0.0570]],\n",
      "\n",
      "        [[-0.1520]],\n",
      "\n",
      "        [[-0.5234]],\n",
      "\n",
      "        [[-1.2062]],\n",
      "\n",
      "        [[-1.3190]],\n",
      "\n",
      "        [[-0.5367]],\n",
      "\n",
      "        [[ 1.1872]],\n",
      "\n",
      "        [[ 0.9423]],\n",
      "\n",
      "        [[ 1.3551]],\n",
      "\n",
      "        [[-2.3204]],\n",
      "\n",
      "        [[-1.0781]],\n",
      "\n",
      "        [[-0.1889]],\n",
      "\n",
      "        [[-0.0371]],\n",
      "\n",
      "        [[-0.0548]],\n",
      "\n",
      "        [[ 1.2563]],\n",
      "\n",
      "        [[-0.9944]],\n",
      "\n",
      "        [[ 1.6669]],\n",
      "\n",
      "        [[ 0.4446]],\n",
      "\n",
      "        [[-2.2353]],\n",
      "\n",
      "        [[ 1.5894]],\n",
      "\n",
      "        [[-0.5978]],\n",
      "\n",
      "        [[ 0.5212]],\n",
      "\n",
      "        [[-0.0662]],\n",
      "\n",
      "        [[-0.4915]],\n",
      "\n",
      "        [[ 2.1131]],\n",
      "\n",
      "        [[ 0.0543]],\n",
      "\n",
      "        [[ 1.5902]],\n",
      "\n",
      "        [[-1.3970]],\n",
      "\n",
      "        [[-0.6914]],\n",
      "\n",
      "        [[ 1.2872]],\n",
      "\n",
      "        [[ 0.4926]],\n",
      "\n",
      "        [[ 1.3359]],\n",
      "\n",
      "        [[ 0.6385]],\n",
      "\n",
      "        [[ 0.9790]],\n",
      "\n",
      "        [[ 0.3919]],\n",
      "\n",
      "        [[-0.4527]],\n",
      "\n",
      "        [[-0.3632]],\n",
      "\n",
      "        [[ 1.2788]],\n",
      "\n",
      "        [[ 0.4990]],\n",
      "\n",
      "        [[-2.0200]],\n",
      "\n",
      "        [[ 0.7999]],\n",
      "\n",
      "        [[-1.0202]],\n",
      "\n",
      "        [[ 1.1505]],\n",
      "\n",
      "        [[-0.1448]],\n",
      "\n",
      "        [[ 1.7400]],\n",
      "\n",
      "        [[-1.3648]],\n",
      "\n",
      "        [[-0.5804]],\n",
      "\n",
      "        [[-1.3624]],\n",
      "\n",
      "        [[-0.1435]],\n",
      "\n",
      "        [[-1.8197]],\n",
      "\n",
      "        [[ 0.0297]],\n",
      "\n",
      "        [[ 1.1138]],\n",
      "\n",
      "        [[-0.8284]],\n",
      "\n",
      "        [[ 2.5036]],\n",
      "\n",
      "        [[ 1.1411]],\n",
      "\n",
      "        [[-0.9717]],\n",
      "\n",
      "        [[-1.4619]],\n",
      "\n",
      "        [[-0.3036]],\n",
      "\n",
      "        [[ 0.8874]],\n",
      "\n",
      "        [[ 0.3608]],\n",
      "\n",
      "        [[ 1.1938]],\n",
      "\n",
      "        [[-2.7692]],\n",
      "\n",
      "        [[-0.3659]],\n",
      "\n",
      "        [[-0.9492]],\n",
      "\n",
      "        [[ 0.6737]],\n",
      "\n",
      "        [[ 0.7901]],\n",
      "\n",
      "        [[ 1.9289]],\n",
      "\n",
      "        [[-0.5540]],\n",
      "\n",
      "        [[-1.8926]],\n",
      "\n",
      "        [[ 0.4701]],\n",
      "\n",
      "        [[ 0.1872]],\n",
      "\n",
      "        [[-0.8151]],\n",
      "\n",
      "        [[-0.3404]],\n",
      "\n",
      "        [[ 0.8768]],\n",
      "\n",
      "        [[ 0.5258]],\n",
      "\n",
      "        [[ 0.6269]],\n",
      "\n",
      "        [[-1.3851]],\n",
      "\n",
      "        [[-0.9525]],\n",
      "\n",
      "        [[ 0.5318]],\n",
      "\n",
      "        [[ 0.6926]],\n",
      "\n",
      "        [[ 0.0838]],\n",
      "\n",
      "        [[ 1.1776]],\n",
      "\n",
      "        [[-0.5838]],\n",
      "\n",
      "        [[-0.3907]],\n",
      "\n",
      "        [[ 0.8973]],\n",
      "\n",
      "        [[ 1.8241]],\n",
      "\n",
      "        [[ 0.4875]],\n",
      "\n",
      "        [[-0.8403]],\n",
      "\n",
      "        [[ 1.0263]],\n",
      "\n",
      "        [[ 0.0472]],\n",
      "\n",
      "        [[-0.5578]],\n",
      "\n",
      "        [[ 1.9792]],\n",
      "\n",
      "        [[-0.9210]],\n",
      "\n",
      "        [[ 0.0661]],\n",
      "\n",
      "        [[ 0.0764]],\n",
      "\n",
      "        [[ 0.8843]],\n",
      "\n",
      "        [[ 1.1415]],\n",
      "\n",
      "        [[-1.2350]],\n",
      "\n",
      "        [[-0.0021]],\n",
      "\n",
      "        [[ 0.9419]],\n",
      "\n",
      "        [[-0.0353]],\n",
      "\n",
      "        [[ 0.1056]],\n",
      "\n",
      "        [[ 0.0600]],\n",
      "\n",
      "        [[-0.5335]],\n",
      "\n",
      "        [[ 1.1354]],\n",
      "\n",
      "        [[-0.2003]],\n",
      "\n",
      "        [[-0.3349]],\n",
      "\n",
      "        [[ 0.2584]],\n",
      "\n",
      "        [[ 1.2794]],\n",
      "\n",
      "        [[-0.3654]],\n",
      "\n",
      "        [[-0.6152]],\n",
      "\n",
      "        [[-0.0774]],\n",
      "\n",
      "        [[ 0.2902]],\n",
      "\n",
      "        [[ 0.5646]]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor(1.00000e-02 *\n",
      "       [[[-1.0612]]], device='cuda:0')\n",
      "torch.Size([1, 448, 512])\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 1.9534,  1.9530,  1.9532,  ...,  1.9531,  1.9530,  1.9530],\n",
      "         [ 1.9530,  1.9529,  1.9532,  ...,  1.9528,  1.9530,  1.9531],\n",
      "         [ 1.9531,  1.9533,  1.9533,  ...,  1.9532,  1.9531,  1.9529],\n",
      "         ...,\n",
      "         [ 1.9532,  1.9533,  1.9535,  ...,  1.9532,  1.9530,  1.9531],\n",
      "         [ 1.9533,  1.9530,  1.9529,  ...,  1.9532,  1.9531,  1.9532],\n",
      "         [ 1.9531,  1.9531,  1.9530,  ...,  1.9531,  1.9529,  1.9530]]], device='cuda:0')\n",
      "Train Epoch: 47 [3840/50000 (9%)]\tLoss: 0.301760, Accuracy: 88.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 47 [5120/50000 (11%)]\tLoss: 0.355293, Accuracy: 86.33\n",
      "Train Epoch: 47 [6400/50000 (14%)]\tLoss: 0.373473, Accuracy: 86.33\n",
      "Train Epoch: 47 [7680/50000 (17%)]\tLoss: 0.391182, Accuracy: 86.72\n",
      "Train Epoch: 47 [8960/50000 (20%)]\tLoss: 0.359940, Accuracy: 87.89\n",
      "Train Epoch: 47 [10240/50000 (23%)]\tLoss: 0.469601, Accuracy: 84.38\n",
      "Train Epoch: 47 [11520/50000 (26%)]\tLoss: 0.412837, Accuracy: 86.72\n",
      "Train Epoch: 47 [12800/50000 (28%)]\tLoss: 0.353774, Accuracy: 88.67\n",
      "Train Epoch: 47 [14080/50000 (31%)]\tLoss: 0.296267, Accuracy: 89.06\n",
      "Train Epoch: 47 [15360/50000 (34%)]\tLoss: 0.274481, Accuracy: 90.23\n",
      "Train Epoch: 47 [16640/50000 (37%)]\tLoss: 0.317149, Accuracy: 90.23\n",
      "Train Epoch: 47 [17920/50000 (40%)]\tLoss: 0.459178, Accuracy: 85.94\n",
      "Train Epoch: 47 [19200/50000 (43%)]\tLoss: 0.409329, Accuracy: 87.11\n",
      "Train Epoch: 47 [20480/50000 (45%)]\tLoss: 0.404857, Accuracy: 86.72\n",
      "Train Epoch: 47 [21760/50000 (48%)]\tLoss: 0.369258, Accuracy: 89.06\n",
      "Train Epoch: 47 [23040/50000 (51%)]\tLoss: 0.379180, Accuracy: 84.38\n",
      "Train Epoch: 47 [24320/50000 (54%)]\tLoss: 0.453408, Accuracy: 83.98\n",
      "Train Epoch: 47 [25600/50000 (57%)]\tLoss: 0.477599, Accuracy: 83.98\n",
      "Train Epoch: 47 [26880/50000 (60%)]\tLoss: 0.490325, Accuracy: 82.03\n",
      "Train Epoch: 47 [28160/50000 (62%)]\tLoss: 0.390719, Accuracy: 84.38\n",
      "Train Epoch: 47 [29440/50000 (65%)]\tLoss: 0.450085, Accuracy: 84.77\n",
      "Train Epoch: 47 [30720/50000 (68%)]\tLoss: 0.308738, Accuracy: 88.28\n",
      "Train Epoch: 47 [32000/50000 (71%)]\tLoss: 0.346114, Accuracy: 85.94\n",
      "Train Epoch: 47 [33280/50000 (74%)]\tLoss: 0.414118, Accuracy: 86.72\n",
      "Train Epoch: 47 [34560/50000 (77%)]\tLoss: 0.387383, Accuracy: 86.72\n",
      "Train Epoch: 47 [35840/50000 (80%)]\tLoss: 0.479144, Accuracy: 83.59\n",
      "Train Epoch: 47 [37120/50000 (82%)]\tLoss: 0.440573, Accuracy: 86.33\n",
      "Train Epoch: 47 [38400/50000 (85%)]\tLoss: 0.340786, Accuracy: 90.62\n",
      "Train Epoch: 47 [39680/50000 (88%)]\tLoss: 0.380199, Accuracy: 88.28\n",
      "Train Epoch: 47 [40960/50000 (91%)]\tLoss: 0.397261, Accuracy: 88.28\n",
      "Train Epoch: 47 [42240/50000 (94%)]\tLoss: 0.291281, Accuracy: 89.84\n",
      "Train Epoch: 47 [43520/50000 (97%)]\tLoss: 0.338877, Accuracy: 89.06\n",
      "Train Epoch: 47 [35000/50000 (99%)]\tLoss: 0.361541, Accuracy: 88.00\n",
      "\n",
      "Validation set: Average loss: 0.9252, Accuracy: 3614/5000 (72.00%)\n",
      "\n",
      "the time of this epoch:[40.89404821395874 s]\n",
      "Train Epoch: 48 [0/50000 (0%)]\tLoss: 0.322152, Accuracy: 88.28\n",
      "Train Epoch: 48 [1280/50000 (3%)]\tLoss: 0.370808, Accuracy: 88.67\n",
      "Train Epoch: 48 [2560/50000 (6%)]\tLoss: 0.327054, Accuracy: 89.06\n",
      "Train Epoch: 48 [3840/50000 (9%)]\tLoss: 0.345994, Accuracy: 87.11\n",
      "Train Epoch: 48 [5120/50000 (11%)]\tLoss: 0.329622, Accuracy: 91.02\n",
      "Train Epoch: 48 [6400/50000 (14%)]\tLoss: 0.301307, Accuracy: 89.84\n",
      "Train Epoch: 48 [7680/50000 (17%)]\tLoss: 0.330775, Accuracy: 89.45\n",
      "Train Epoch: 48 [8960/50000 (20%)]\tLoss: 0.320893, Accuracy: 87.50\n",
      "Train Epoch: 48 [10240/50000 (23%)]\tLoss: 0.362734, Accuracy: 88.67\n",
      "Train Epoch: 48 [11520/50000 (26%)]\tLoss: 0.373521, Accuracy: 85.94\n",
      "Train Epoch: 48 [12800/50000 (28%)]\tLoss: 0.385342, Accuracy: 87.11\n",
      "Train Epoch: 48 [14080/50000 (31%)]\tLoss: 0.359840, Accuracy: 89.06\n",
      "Train Epoch: 48 [15360/50000 (34%)]\tLoss: 0.359198, Accuracy: 87.50\n",
      "Train Epoch: 48 [16640/50000 (37%)]\tLoss: 0.475542, Accuracy: 83.98\n",
      "Train Epoch: 48 [17920/50000 (40%)]\tLoss: 0.415644, Accuracy: 85.94\n",
      "Train Epoch: 48 [19200/50000 (43%)]\tLoss: 0.368983, Accuracy: 88.67\n",
      "Train Epoch: 48 [20480/50000 (45%)]\tLoss: 0.354787, Accuracy: 88.28\n",
      "Train Epoch: 48 [21760/50000 (48%)]\tLoss: 0.372788, Accuracy: 82.81\n",
      "Train Epoch: 48 [23040/50000 (51%)]\tLoss: 0.293490, Accuracy: 91.41\n",
      "Train Epoch: 48 [24320/50000 (54%)]\tLoss: 0.340887, Accuracy: 89.84\n",
      "Train Epoch: 48 [25600/50000 (57%)]\tLoss: 0.398935, Accuracy: 86.33\n",
      "Train Epoch: 48 [26880/50000 (60%)]\tLoss: 0.364237, Accuracy: 89.45\n",
      "Train Epoch: 48 [28160/50000 (62%)]\tLoss: 0.406426, Accuracy: 87.11\n",
      "Train Epoch: 48 [29440/50000 (65%)]\tLoss: 0.505579, Accuracy: 84.38\n",
      "Train Epoch: 48 [30720/50000 (68%)]\tLoss: 0.404059, Accuracy: 87.50\n",
      "Train Epoch: 48 [32000/50000 (71%)]\tLoss: 0.436457, Accuracy: 85.16\n",
      "Train Epoch: 48 [33280/50000 (74%)]\tLoss: 0.352269, Accuracy: 85.94\n",
      "Train Epoch: 48 [34560/50000 (77%)]\tLoss: 0.396176, Accuracy: 85.94\n",
      "Train Epoch: 48 [35840/50000 (80%)]\tLoss: 0.402635, Accuracy: 87.50\n",
      "Train Epoch: 48 [37120/50000 (82%)]\tLoss: 0.258740, Accuracy: 89.84\n",
      "Train Epoch: 48 [38400/50000 (85%)]\tLoss: 0.409283, Accuracy: 86.33\n",
      "Train Epoch: 48 [39680/50000 (88%)]\tLoss: 0.553476, Accuracy: 82.03\n",
      "Train Epoch: 48 [40960/50000 (91%)]\tLoss: 0.434991, Accuracy: 83.98\n",
      "Train Epoch: 48 [42240/50000 (94%)]\tLoss: 0.380514, Accuracy: 83.98\n",
      "Train Epoch: 48 [43520/50000 (97%)]\tLoss: 0.434443, Accuracy: 85.94\n",
      "Train Epoch: 48 [35000/50000 (99%)]\tLoss: 0.425667, Accuracy: 85.00\n",
      "\n",
      "Validation set: Average loss: 0.6569, Accuracy: 3944/5000 (78.00%)\n",
      "\n",
      "the time of this epoch:[37.66659355163574 s]\n",
      "\n",
      "Test set: Average loss: 0.7011, Accuracy: 7793/10000 (77.93%)\n",
      "\n",
      "Train Epoch: 49 [0/50000 (0%)]\tLoss: 0.380820, Accuracy: 88.67\n",
      "Train Epoch: 49 [1280/50000 (3%)]\tLoss: 0.338577, Accuracy: 89.06\n",
      "Train Epoch: 49 [2560/50000 (6%)]\tLoss: 0.426954, Accuracy: 86.33\n",
      "Train Epoch: 49 [3840/50000 (9%)]\tLoss: 0.429159, Accuracy: 87.11\n",
      "Train Epoch: 49 [5120/50000 (11%)]\tLoss: 0.449466, Accuracy: 84.77\n",
      "Train Epoch: 49 [6400/50000 (14%)]\tLoss: 0.304020, Accuracy: 88.67\n",
      "Train Epoch: 49 [7680/50000 (17%)]\tLoss: 0.347424, Accuracy: 87.50\n",
      "Train Epoch: 49 [8960/50000 (20%)]\tLoss: 0.316419, Accuracy: 87.89\n",
      "Train Epoch: 49 [10240/50000 (23%)]\tLoss: 0.320491, Accuracy: 89.06\n",
      "Train Epoch: 49 [11520/50000 (26%)]\tLoss: 0.332192, Accuracy: 87.50\n",
      "Train Epoch: 49 [12800/50000 (28%)]\tLoss: 0.472149, Accuracy: 84.77\n",
      "Train Epoch: 49 [14080/50000 (31%)]\tLoss: 0.373183, Accuracy: 87.89\n",
      "Train Epoch: 49 [15360/50000 (34%)]\tLoss: 0.349656, Accuracy: 86.72\n",
      "Train Epoch: 49 [16640/50000 (37%)]\tLoss: 0.393969, Accuracy: 87.11\n",
      "Train Epoch: 49 [17920/50000 (40%)]\tLoss: 0.303076, Accuracy: 90.23\n",
      "Train Epoch: 49 [19200/50000 (43%)]\tLoss: 0.416564, Accuracy: 85.94\n",
      "Train Epoch: 49 [20480/50000 (45%)]\tLoss: 0.482165, Accuracy: 85.55\n",
      "Train Epoch: 49 [21760/50000 (48%)]\tLoss: 0.366965, Accuracy: 86.33\n",
      "Train Epoch: 49 [23040/50000 (51%)]\tLoss: 0.356724, Accuracy: 88.67\n",
      "Train Epoch: 49 [24320/50000 (54%)]\tLoss: 0.348230, Accuracy: 87.50\n",
      "Train Epoch: 49 [25600/50000 (57%)]\tLoss: 0.372617, Accuracy: 85.94\n",
      "Train Epoch: 49 [26880/50000 (60%)]\tLoss: 0.436381, Accuracy: 83.98\n",
      "Train Epoch: 49 [28160/50000 (62%)]\tLoss: 0.382087, Accuracy: 88.67\n",
      "Train Epoch: 49 [29440/50000 (65%)]\tLoss: 0.386041, Accuracy: 87.11\n",
      "Train Epoch: 49 [30720/50000 (68%)]\tLoss: 0.361329, Accuracy: 91.02\n",
      "Train Epoch: 49 [32000/50000 (71%)]\tLoss: 0.399605, Accuracy: 86.33\n",
      "Train Epoch: 49 [33280/50000 (74%)]\tLoss: 0.427584, Accuracy: 83.98\n",
      "Train Epoch: 49 [34560/50000 (77%)]\tLoss: 0.397440, Accuracy: 87.11\n",
      "Train Epoch: 49 [35840/50000 (80%)]\tLoss: 0.348522, Accuracy: 89.06\n",
      "Train Epoch: 49 [37120/50000 (82%)]\tLoss: 0.476957, Accuracy: 84.77\n",
      "Train Epoch: 49 [38400/50000 (85%)]\tLoss: 0.281149, Accuracy: 91.02\n",
      "Train Epoch: 49 [39680/50000 (88%)]\tLoss: 0.418162, Accuracy: 86.33\n",
      "Train Epoch: 49 [40960/50000 (91%)]\tLoss: 0.423700, Accuracy: 83.20\n",
      "Train Epoch: 49 [42240/50000 (94%)]\tLoss: 0.403144, Accuracy: 87.89\n",
      "Train Epoch: 49 [43520/50000 (97%)]\tLoss: 0.408548, Accuracy: 89.06\n",
      "Train Epoch: 49 [35000/50000 (99%)]\tLoss: 0.389960, Accuracy: 86.50\n",
      "\n",
      "Validation set: Average loss: 0.5026, Accuracy: 4152/5000 (83.00%)\n",
      "\n",
      "the time of this epoch:[40.64146327972412 s]\n",
      "Train Epoch: 50 [0/50000 (0%)]\tLoss: 0.364397, Accuracy: 86.72\n",
      "Train Epoch: 50 [1280/50000 (3%)]\tLoss: 0.393159, Accuracy: 86.33\n",
      "Train Epoch: 50 [2560/50000 (6%)]\tLoss: 0.306122, Accuracy: 89.84\n",
      "Train Epoch: 50 [3840/50000 (9%)]\tLoss: 0.397735, Accuracy: 85.55\n",
      "Train Epoch: 50 [5120/50000 (11%)]\tLoss: 0.326147, Accuracy: 88.67\n",
      "Train Epoch: 50 [6400/50000 (14%)]\tLoss: 0.349329, Accuracy: 89.45\n",
      "Train Epoch: 50 [7680/50000 (17%)]\tLoss: 0.335031, Accuracy: 86.72\n",
      "Train Epoch: 50 [8960/50000 (20%)]\tLoss: 0.381032, Accuracy: 87.11\n",
      "Train Epoch: 50 [10240/50000 (23%)]\tLoss: 0.360179, Accuracy: 88.67\n",
      "Train Epoch: 50 [11520/50000 (26%)]\tLoss: 0.317974, Accuracy: 89.84\n",
      "Train Epoch: 50 [12800/50000 (28%)]\tLoss: 0.394098, Accuracy: 87.50\n",
      "Train Epoch: 50 [14080/50000 (31%)]\tLoss: 0.417047, Accuracy: 83.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 50 [15360/50000 (34%)]\tLoss: 0.400045, Accuracy: 86.72\n",
      "Train Epoch: 50 [16640/50000 (37%)]\tLoss: 0.444459, Accuracy: 85.16\n",
      "Train Epoch: 50 [17920/50000 (40%)]\tLoss: 0.488775, Accuracy: 85.94\n",
      "Train Epoch: 50 [19200/50000 (43%)]\tLoss: 0.337451, Accuracy: 87.11\n",
      "Train Epoch: 50 [20480/50000 (45%)]\tLoss: 0.374289, Accuracy: 87.11\n",
      "Train Epoch: 50 [21760/50000 (48%)]\tLoss: 0.376156, Accuracy: 86.72\n",
      "Train Epoch: 50 [23040/50000 (51%)]\tLoss: 0.372664, Accuracy: 85.55\n",
      "Train Epoch: 50 [24320/50000 (54%)]\tLoss: 0.346666, Accuracy: 87.89\n",
      "Train Epoch: 50 [25600/50000 (57%)]\tLoss: 0.417618, Accuracy: 84.38\n",
      "Train Epoch: 50 [26880/50000 (60%)]\tLoss: 0.383533, Accuracy: 88.28\n",
      "Train Epoch: 50 [28160/50000 (62%)]\tLoss: 0.336744, Accuracy: 87.11\n",
      "Train Epoch: 50 [29440/50000 (65%)]\tLoss: 0.410483, Accuracy: 84.77\n",
      "Train Epoch: 50 [30720/50000 (68%)]\tLoss: 0.355068, Accuracy: 87.11\n",
      "Train Epoch: 50 [32000/50000 (71%)]\tLoss: 0.349775, Accuracy: 85.94\n",
      "Train Epoch: 50 [33280/50000 (74%)]\tLoss: 0.456426, Accuracy: 84.38\n",
      "Train Epoch: 50 [34560/50000 (77%)]\tLoss: 0.364589, Accuracy: 88.67\n",
      "Train Epoch: 50 [35840/50000 (80%)]\tLoss: 0.304513, Accuracy: 88.28\n",
      "Train Epoch: 50 [37120/50000 (82%)]\tLoss: 0.480683, Accuracy: 84.38\n",
      "Train Epoch: 50 [38400/50000 (85%)]\tLoss: 0.351299, Accuracy: 86.72\n",
      "Train Epoch: 50 [39680/50000 (88%)]\tLoss: 0.361641, Accuracy: 87.89\n",
      "Train Epoch: 50 [40960/50000 (91%)]\tLoss: 0.410664, Accuracy: 86.72\n",
      "Train Epoch: 50 [42240/50000 (94%)]\tLoss: 0.429997, Accuracy: 84.38\n",
      "Train Epoch: 50 [43520/50000 (97%)]\tLoss: 0.342105, Accuracy: 88.67\n",
      "Train Epoch: 50 [35000/50000 (99%)]\tLoss: 0.415192, Accuracy: 86.00\n",
      "\n",
      "Validation set: Average loss: 0.8311, Accuracy: 3678/5000 (73.00%)\n",
      "\n",
      "the time of this epoch:[37.47148418426514 s]\n",
      "\n",
      "Test set: Average loss: 0.8564, Accuracy: 7318/10000 (73.18%)\n",
      "\n",
      "Train Epoch: 51 [0/50000 (0%)]\tLoss: 0.308925, Accuracy: 89.06\n",
      "Train Epoch: 51 [1280/50000 (3%)]\tLoss: 0.393648, Accuracy: 86.72\n",
      "Train Epoch: 51 [2560/50000 (6%)]\tLoss: 0.277315, Accuracy: 91.02\n",
      "Train Epoch: 51 [3840/50000 (9%)]\tLoss: 0.252100, Accuracy: 92.58\n",
      "Train Epoch: 51 [5120/50000 (11%)]\tLoss: 0.365093, Accuracy: 86.33\n",
      "Train Epoch: 51 [6400/50000 (14%)]\tLoss: 0.314454, Accuracy: 89.06\n",
      "Train Epoch: 51 [7680/50000 (17%)]\tLoss: 0.257820, Accuracy: 91.80\n",
      "Train Epoch: 51 [8960/50000 (20%)]\tLoss: 0.281766, Accuracy: 91.41\n",
      "Train Epoch: 51 [10240/50000 (23%)]\tLoss: 0.257181, Accuracy: 89.45\n",
      "Train Epoch: 51 [11520/50000 (26%)]\tLoss: 0.285384, Accuracy: 91.02\n",
      "Train Epoch: 51 [12800/50000 (28%)]\tLoss: 0.201907, Accuracy: 93.36\n",
      "Train Epoch: 51 [14080/50000 (31%)]\tLoss: 0.250211, Accuracy: 91.80\n",
      "Train Epoch: 51 [15360/50000 (34%)]\tLoss: 0.221910, Accuracy: 92.97\n",
      "Train Epoch: 51 [16640/50000 (37%)]\tLoss: 0.251567, Accuracy: 91.41\n",
      "Train Epoch: 51 [17920/50000 (40%)]\tLoss: 0.249484, Accuracy: 89.45\n",
      "Train Epoch: 51 [19200/50000 (43%)]\tLoss: 0.212128, Accuracy: 92.97\n",
      "Train Epoch: 51 [20480/50000 (45%)]\tLoss: 0.256742, Accuracy: 91.02\n",
      "Train Epoch: 51 [21760/50000 (48%)]\tLoss: 0.236234, Accuracy: 91.80\n",
      "Train Epoch: 51 [23040/50000 (51%)]\tLoss: 0.187610, Accuracy: 95.31\n",
      "Train Epoch: 51 [24320/50000 (54%)]\tLoss: 0.226815, Accuracy: 93.75\n",
      "Train Epoch: 51 [25600/50000 (57%)]\tLoss: 0.242686, Accuracy: 93.75\n",
      "Train Epoch: 51 [26880/50000 (60%)]\tLoss: 0.204225, Accuracy: 93.75\n",
      "Train Epoch: 51 [28160/50000 (62%)]\tLoss: 0.224766, Accuracy: 90.62\n",
      "Train Epoch: 51 [29440/50000 (65%)]\tLoss: 0.220828, Accuracy: 93.36\n",
      "Train Epoch: 51 [30720/50000 (68%)]\tLoss: 0.208578, Accuracy: 93.75\n",
      "Train Epoch: 51 [32000/50000 (71%)]\tLoss: 0.216917, Accuracy: 92.19\n",
      "Train Epoch: 51 [33280/50000 (74%)]\tLoss: 0.270235, Accuracy: 89.84\n",
      "Train Epoch: 51 [34560/50000 (77%)]\tLoss: 0.227836, Accuracy: 92.97\n",
      "Train Epoch: 51 [35840/50000 (80%)]\tLoss: 0.182914, Accuracy: 94.14\n",
      "Train Epoch: 51 [37120/50000 (82%)]\tLoss: 0.152393, Accuracy: 94.92\n",
      "Train Epoch: 51 [38400/50000 (85%)]\tLoss: 0.285242, Accuracy: 90.23\n",
      "Train Epoch: 51 [39680/50000 (88%)]\tLoss: 0.192606, Accuracy: 94.14\n",
      "Train Epoch: 51 [40960/50000 (91%)]\tLoss: 0.265029, Accuracy: 90.62\n",
      "Train Epoch: 51 [42240/50000 (94%)]\tLoss: 0.211867, Accuracy: 92.97\n",
      "Train Epoch: 51 [43520/50000 (97%)]\tLoss: 0.253459, Accuracy: 92.19\n",
      "Train Epoch: 51 [35000/50000 (99%)]\tLoss: 0.189884, Accuracy: 92.00\n",
      "\n",
      "Validation set: Average loss: 0.2906, Accuracy: 4497/5000 (89.00%)\n",
      "\n",
      "the time of this epoch:[40.52852821350098 s]\n",
      "Train Epoch: 52 [0/50000 (0%)]\tLoss: 0.160389, Accuracy: 95.31\n",
      "Train Epoch: 52 [1280/50000 (3%)]\tLoss: 0.235995, Accuracy: 91.02\n",
      "Train Epoch: 52 [2560/50000 (6%)]\tLoss: 0.192664, Accuracy: 92.97\n",
      "Train Epoch: 52 [3840/50000 (9%)]\tLoss: 0.248168, Accuracy: 90.62\n",
      "Train Epoch: 52 [5120/50000 (11%)]\tLoss: 0.191120, Accuracy: 94.14\n",
      "Train Epoch: 52 [6400/50000 (14%)]\tLoss: 0.173585, Accuracy: 94.14\n",
      "Train Epoch: 52 [7680/50000 (17%)]\tLoss: 0.162526, Accuracy: 94.92\n",
      "Train Epoch: 52 [8960/50000 (20%)]\tLoss: 0.172645, Accuracy: 92.97\n",
      "Train Epoch: 52 [10240/50000 (23%)]\tLoss: 0.229077, Accuracy: 92.58\n",
      "Train Epoch: 52 [11520/50000 (26%)]\tLoss: 0.189583, Accuracy: 91.80\n",
      "Train Epoch: 52 [12800/50000 (28%)]\tLoss: 0.116117, Accuracy: 96.48\n",
      "Train Epoch: 52 [14080/50000 (31%)]\tLoss: 0.230242, Accuracy: 91.41\n",
      "Train Epoch: 52 [15360/50000 (34%)]\tLoss: 0.136434, Accuracy: 96.48\n",
      "Train Epoch: 52 [16640/50000 (37%)]\tLoss: 0.225098, Accuracy: 92.58\n",
      "Train Epoch: 52 [17920/50000 (40%)]\tLoss: 0.215851, Accuracy: 93.36\n",
      "Train Epoch: 52 [19200/50000 (43%)]\tLoss: 0.213008, Accuracy: 91.80\n",
      "Train Epoch: 52 [20480/50000 (45%)]\tLoss: 0.218948, Accuracy: 93.36\n",
      "Train Epoch: 52 [21760/50000 (48%)]\tLoss: 0.140990, Accuracy: 95.70\n",
      "Train Epoch: 52 [23040/50000 (51%)]\tLoss: 0.147281, Accuracy: 95.31\n",
      "Train Epoch: 52 [24320/50000 (54%)]\tLoss: 0.179471, Accuracy: 92.97\n",
      "Train Epoch: 52 [25600/50000 (57%)]\tLoss: 0.201977, Accuracy: 93.36\n",
      "Train Epoch: 52 [26880/50000 (60%)]\tLoss: 0.297586, Accuracy: 91.02\n",
      "Train Epoch: 52 [28160/50000 (62%)]\tLoss: 0.169568, Accuracy: 96.48\n",
      "Train Epoch: 52 [29440/50000 (65%)]\tLoss: 0.182555, Accuracy: 94.14\n",
      "Train Epoch: 52 [30720/50000 (68%)]\tLoss: 0.250609, Accuracy: 91.02\n",
      "Train Epoch: 52 [32000/50000 (71%)]\tLoss: 0.182339, Accuracy: 92.19\n",
      "Train Epoch: 52 [33280/50000 (74%)]\tLoss: 0.162848, Accuracy: 95.31\n",
      "Train Epoch: 52 [34560/50000 (77%)]\tLoss: 0.212360, Accuracy: 91.80\n",
      "Train Epoch: 52 [35840/50000 (80%)]\tLoss: 0.212828, Accuracy: 93.36\n",
      "Train Epoch: 52 [37120/50000 (82%)]\tLoss: 0.261883, Accuracy: 93.75\n",
      "Train Epoch: 52 [38400/50000 (85%)]\tLoss: 0.252921, Accuracy: 92.97\n",
      "Train Epoch: 52 [39680/50000 (88%)]\tLoss: 0.214030, Accuracy: 93.36\n",
      "Train Epoch: 52 [40960/50000 (91%)]\tLoss: 0.152391, Accuracy: 94.14\n",
      "Train Epoch: 52 [42240/50000 (94%)]\tLoss: 0.135078, Accuracy: 94.92\n",
      "Train Epoch: 52 [43520/50000 (97%)]\tLoss: 0.199085, Accuracy: 94.14\n",
      "Train Epoch: 52 [35000/50000 (99%)]\tLoss: 0.257079, Accuracy: 92.00\n",
      "\n",
      "Validation set: Average loss: 0.2822, Accuracy: 4509/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[37.990387201309204 s]\n",
      "\n",
      "Test set: Average loss: 0.2991, Accuracy: 9041/10000 (90.41%)\n",
      "\n",
      "Train Epoch: 53 [0/50000 (0%)]\tLoss: 0.178114, Accuracy: 94.53\n",
      "Train Epoch: 53 [1280/50000 (3%)]\tLoss: 0.206270, Accuracy: 91.80\n",
      "Train Epoch: 53 [2560/50000 (6%)]\tLoss: 0.132980, Accuracy: 94.92\n",
      "Train Epoch: 53 [3840/50000 (9%)]\tLoss: 0.119369, Accuracy: 96.09\n",
      "Train Epoch: 53 [5120/50000 (11%)]\tLoss: 0.262926, Accuracy: 90.23\n",
      "Train Epoch: 53 [6400/50000 (14%)]\tLoss: 0.124862, Accuracy: 96.09\n",
      "Train Epoch: 53 [7680/50000 (17%)]\tLoss: 0.163761, Accuracy: 93.36\n",
      "Train Epoch: 53 [8960/50000 (20%)]\tLoss: 0.116701, Accuracy: 96.09\n",
      "Train Epoch: 53 [10240/50000 (23%)]\tLoss: 0.239579, Accuracy: 91.80\n",
      "Train Epoch: 53 [11520/50000 (26%)]\tLoss: 0.157558, Accuracy: 94.53\n",
      "Train Epoch: 53 [12800/50000 (28%)]\tLoss: 0.173373, Accuracy: 93.75\n",
      "Train Epoch: 53 [14080/50000 (31%)]\tLoss: 0.125924, Accuracy: 96.09\n",
      "Train Epoch: 53 [15360/50000 (34%)]\tLoss: 0.186259, Accuracy: 92.58\n",
      "Train Epoch: 53 [16640/50000 (37%)]\tLoss: 0.191942, Accuracy: 93.36\n",
      "Train Epoch: 53 [17920/50000 (40%)]\tLoss: 0.181953, Accuracy: 94.53\n",
      "Train Epoch: 53 [19200/50000 (43%)]\tLoss: 0.143640, Accuracy: 94.92\n",
      "Train Epoch: 53 [20480/50000 (45%)]\tLoss: 0.210075, Accuracy: 92.58\n",
      "Train Epoch: 53 [21760/50000 (48%)]\tLoss: 0.171879, Accuracy: 94.14\n",
      "Train Epoch: 53 [23040/50000 (51%)]\tLoss: 0.116058, Accuracy: 95.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 53 [24320/50000 (54%)]\tLoss: 0.190674, Accuracy: 94.53\n",
      "Train Epoch: 53 [25600/50000 (57%)]\tLoss: 0.229933, Accuracy: 92.58\n",
      "Train Epoch: 53 [26880/50000 (60%)]\tLoss: 0.222660, Accuracy: 91.41\n",
      "Train Epoch: 53 [28160/50000 (62%)]\tLoss: 0.195017, Accuracy: 92.97\n",
      "Train Epoch: 53 [29440/50000 (65%)]\tLoss: 0.155528, Accuracy: 94.92\n",
      "Train Epoch: 53 [30720/50000 (68%)]\tLoss: 0.143075, Accuracy: 95.70\n",
      "Train Epoch: 53 [32000/50000 (71%)]\tLoss: 0.154705, Accuracy: 94.14\n",
      "Train Epoch: 53 [33280/50000 (74%)]\tLoss: 0.163950, Accuracy: 94.92\n",
      "Train Epoch: 53 [34560/50000 (77%)]\tLoss: 0.217613, Accuracy: 91.80\n",
      "Train Epoch: 53 [35840/50000 (80%)]\tLoss: 0.143172, Accuracy: 94.53\n",
      "Train Epoch: 53 [37120/50000 (82%)]\tLoss: 0.135115, Accuracy: 96.09\n",
      "Train Epoch: 53 [38400/50000 (85%)]\tLoss: 0.228219, Accuracy: 93.36\n",
      "torch.Size([512, 1, 1])\n",
      "tensor([[[-0.0265]],\n",
      "\n",
      "        [[-0.3557]],\n",
      "\n",
      "        [[ 0.5501]],\n",
      "\n",
      "        [[-0.4273]],\n",
      "\n",
      "        [[ 1.0672]],\n",
      "\n",
      "        [[ 0.6163]],\n",
      "\n",
      "        [[-1.3269]],\n",
      "\n",
      "        [[ 0.6070]],\n",
      "\n",
      "        [[ 0.3648]],\n",
      "\n",
      "        [[ 1.4485]],\n",
      "\n",
      "        [[ 0.5172]],\n",
      "\n",
      "        [[-0.9410]],\n",
      "\n",
      "        [[-0.4830]],\n",
      "\n",
      "        [[ 1.6693]],\n",
      "\n",
      "        [[-0.4625]],\n",
      "\n",
      "        [[-0.8171]],\n",
      "\n",
      "        [[-1.9558]],\n",
      "\n",
      "        [[ 0.7418]],\n",
      "\n",
      "        [[-1.5979]],\n",
      "\n",
      "        [[-0.5374]],\n",
      "\n",
      "        [[ 0.1902]],\n",
      "\n",
      "        [[ 0.6451]],\n",
      "\n",
      "        [[ 0.4148]],\n",
      "\n",
      "        [[ 0.6607]],\n",
      "\n",
      "        [[-0.1198]],\n",
      "\n",
      "        [[ 1.1368]],\n",
      "\n",
      "        [[ 0.5311]],\n",
      "\n",
      "        [[-0.2336]],\n",
      "\n",
      "        [[-0.5645]],\n",
      "\n",
      "        [[ 0.0441]],\n",
      "\n",
      "        [[ 1.2329]],\n",
      "\n",
      "        [[ 1.6678]],\n",
      "\n",
      "        [[ 1.0621]],\n",
      "\n",
      "        [[ 1.0628]],\n",
      "\n",
      "        [[-0.1561]],\n",
      "\n",
      "        [[-1.7401]],\n",
      "\n",
      "        [[ 0.1212]],\n",
      "\n",
      "        [[ 0.2893]],\n",
      "\n",
      "        [[-1.5271]],\n",
      "\n",
      "        [[-0.0388]],\n",
      "\n",
      "        [[ 1.0680]],\n",
      "\n",
      "        [[ 0.0702]],\n",
      "\n",
      "        [[ 0.5347]],\n",
      "\n",
      "        [[-1.5976]],\n",
      "\n",
      "        [[-0.4773]],\n",
      "\n",
      "        [[ 0.5018]],\n",
      "\n",
      "        [[ 0.6882]],\n",
      "\n",
      "        [[ 0.1901]],\n",
      "\n",
      "        [[ 0.6805]],\n",
      "\n",
      "        [[ 3.9609]],\n",
      "\n",
      "        [[-0.6851]],\n",
      "\n",
      "        [[ 0.1543]],\n",
      "\n",
      "        [[ 0.7141]],\n",
      "\n",
      "        [[ 1.2411]],\n",
      "\n",
      "        [[-1.0098]],\n",
      "\n",
      "        [[ 0.1212]],\n",
      "\n",
      "        [[-0.9676]],\n",
      "\n",
      "        [[ 1.6297]],\n",
      "\n",
      "        [[-0.7443]],\n",
      "\n",
      "        [[ 1.9125]],\n",
      "\n",
      "        [[ 0.7202]],\n",
      "\n",
      "        [[ 0.7880]],\n",
      "\n",
      "        [[ 1.1690]],\n",
      "\n",
      "        [[ 1.2583]],\n",
      "\n",
      "        [[-0.5441]],\n",
      "\n",
      "        [[-0.5517]],\n",
      "\n",
      "        [[ 0.2512]],\n",
      "\n",
      "        [[-1.6770]],\n",
      "\n",
      "        [[ 1.7870]],\n",
      "\n",
      "        [[-1.4942]],\n",
      "\n",
      "        [[ 0.7802]],\n",
      "\n",
      "        [[ 0.0540]],\n",
      "\n",
      "        [[ 0.7027]],\n",
      "\n",
      "        [[-0.9303]],\n",
      "\n",
      "        [[-1.8692]],\n",
      "\n",
      "        [[ 0.9652]],\n",
      "\n",
      "        [[-0.8457]],\n",
      "\n",
      "        [[ 0.3407]],\n",
      "\n",
      "        [[ 0.5475]],\n",
      "\n",
      "        [[-1.9958]],\n",
      "\n",
      "        [[-1.4304]],\n",
      "\n",
      "        [[ 0.2154]],\n",
      "\n",
      "        [[ 1.0809]],\n",
      "\n",
      "        [[ 1.2396]],\n",
      "\n",
      "        [[-0.0561]],\n",
      "\n",
      "        [[ 0.7621]],\n",
      "\n",
      "        [[ 0.5196]],\n",
      "\n",
      "        [[-1.0882]],\n",
      "\n",
      "        [[ 0.0323]],\n",
      "\n",
      "        [[ 0.5763]],\n",
      "\n",
      "        [[ 1.1829]],\n",
      "\n",
      "        [[ 0.8290]],\n",
      "\n",
      "        [[-0.1739]],\n",
      "\n",
      "        [[-0.7692]],\n",
      "\n",
      "        [[-1.9391]],\n",
      "\n",
      "        [[ 1.2535]],\n",
      "\n",
      "        [[ 0.5093]],\n",
      "\n",
      "        [[-0.2870]],\n",
      "\n",
      "        [[ 0.5330]],\n",
      "\n",
      "        [[-0.3125]],\n",
      "\n",
      "        [[ 0.4213]],\n",
      "\n",
      "        [[-0.1514]],\n",
      "\n",
      "        [[ 0.4846]],\n",
      "\n",
      "        [[-0.9461]],\n",
      "\n",
      "        [[ 1.1588]],\n",
      "\n",
      "        [[ 0.6202]],\n",
      "\n",
      "        [[ 0.5069]],\n",
      "\n",
      "        [[-0.4604]],\n",
      "\n",
      "        [[ 1.0821]],\n",
      "\n",
      "        [[ 0.2060]],\n",
      "\n",
      "        [[ 1.2898]],\n",
      "\n",
      "        [[-1.9829]],\n",
      "\n",
      "        [[-0.2262]],\n",
      "\n",
      "        [[-0.7748]],\n",
      "\n",
      "        [[-0.2441]],\n",
      "\n",
      "        [[ 0.6303]],\n",
      "\n",
      "        [[ 1.3489]],\n",
      "\n",
      "        [[ 0.7937]],\n",
      "\n",
      "        [[ 1.2521]],\n",
      "\n",
      "        [[ 0.1570]],\n",
      "\n",
      "        [[-0.3465]],\n",
      "\n",
      "        [[ 0.0251]],\n",
      "\n",
      "        [[-0.7139]],\n",
      "\n",
      "        [[-0.5912]],\n",
      "\n",
      "        [[ 1.1245]],\n",
      "\n",
      "        [[-0.8911]],\n",
      "\n",
      "        [[ 1.8245]],\n",
      "\n",
      "        [[ 2.0272]],\n",
      "\n",
      "        [[-0.3279]],\n",
      "\n",
      "        [[ 0.5629]],\n",
      "\n",
      "        [[-0.6999]],\n",
      "\n",
      "        [[ 0.2893]],\n",
      "\n",
      "        [[-0.2323]],\n",
      "\n",
      "        [[-0.6267]],\n",
      "\n",
      "        [[-0.2661]],\n",
      "\n",
      "        [[-0.5211]],\n",
      "\n",
      "        [[-2.0205]],\n",
      "\n",
      "        [[-1.2336]],\n",
      "\n",
      "        [[ 1.6719]],\n",
      "\n",
      "        [[ 0.3543]],\n",
      "\n",
      "        [[ 0.0307]],\n",
      "\n",
      "        [[ 0.1484]],\n",
      "\n",
      "        [[ 1.1859]],\n",
      "\n",
      "        [[-0.0235]],\n",
      "\n",
      "        [[ 1.2599]],\n",
      "\n",
      "        [[-0.0882]],\n",
      "\n",
      "        [[ 0.4555]],\n",
      "\n",
      "        [[-0.2216]],\n",
      "\n",
      "        [[ 1.4009]],\n",
      "\n",
      "        [[-0.5176]],\n",
      "\n",
      "        [[-1.0314]],\n",
      "\n",
      "        [[ 1.7974]],\n",
      "\n",
      "        [[ 0.1585]],\n",
      "\n",
      "        [[ 0.4209]],\n",
      "\n",
      "        [[-0.0665]],\n",
      "\n",
      "        [[ 0.4482]],\n",
      "\n",
      "        [[ 0.7777]],\n",
      "\n",
      "        [[-0.7535]],\n",
      "\n",
      "        [[ 0.1573]],\n",
      "\n",
      "        [[ 0.3334]],\n",
      "\n",
      "        [[-0.3645]],\n",
      "\n",
      "        [[-0.9874]],\n",
      "\n",
      "        [[-0.8143]],\n",
      "\n",
      "        [[-1.8183]],\n",
      "\n",
      "        [[-0.1223]],\n",
      "\n",
      "        [[-0.2047]],\n",
      "\n",
      "        [[-0.3271]],\n",
      "\n",
      "        [[-0.9165]],\n",
      "\n",
      "        [[-0.4784]],\n",
      "\n",
      "        [[ 0.2738]],\n",
      "\n",
      "        [[ 0.4800]],\n",
      "\n",
      "        [[-0.1522]],\n",
      "\n",
      "        [[ 0.6451]],\n",
      "\n",
      "        [[ 0.5088]],\n",
      "\n",
      "        [[ 1.3897]],\n",
      "\n",
      "        [[-1.4692]],\n",
      "\n",
      "        [[ 0.2622]],\n",
      "\n",
      "        [[ 1.5150]],\n",
      "\n",
      "        [[-0.9509]],\n",
      "\n",
      "        [[-1.3494]],\n",
      "\n",
      "        [[-0.1497]],\n",
      "\n",
      "        [[-0.9756]],\n",
      "\n",
      "        [[ 1.3744]],\n",
      "\n",
      "        [[ 0.4129]],\n",
      "\n",
      "        [[-0.6501]],\n",
      "\n",
      "        [[ 0.9355]],\n",
      "\n",
      "        [[ 0.1196]],\n",
      "\n",
      "        [[ 0.8646]],\n",
      "\n",
      "        [[ 0.4148]],\n",
      "\n",
      "        [[ 0.6261]],\n",
      "\n",
      "        [[-0.8870]],\n",
      "\n",
      "        [[-0.5102]],\n",
      "\n",
      "        [[-0.5952]],\n",
      "\n",
      "        [[ 0.5695]],\n",
      "\n",
      "        [[-0.6322]],\n",
      "\n",
      "        [[ 0.3819]],\n",
      "\n",
      "        [[ 0.0081]],\n",
      "\n",
      "        [[-0.2374]],\n",
      "\n",
      "        [[ 0.3866]],\n",
      "\n",
      "        [[ 0.7849]],\n",
      "\n",
      "        [[ 0.1928]],\n",
      "\n",
      "        [[-0.4990]],\n",
      "\n",
      "        [[-0.0872]],\n",
      "\n",
      "        [[ 1.6462]],\n",
      "\n",
      "        [[-1.6936]],\n",
      "\n",
      "        [[ 0.3819]],\n",
      "\n",
      "        [[-0.2931]],\n",
      "\n",
      "        [[ 0.6587]],\n",
      "\n",
      "        [[ 0.6245]],\n",
      "\n",
      "        [[ 0.6181]],\n",
      "\n",
      "        [[-1.3875]],\n",
      "\n",
      "        [[-0.6501]],\n",
      "\n",
      "        [[ 0.9987]],\n",
      "\n",
      "        [[-0.3507]],\n",
      "\n",
      "        [[-1.4447]],\n",
      "\n",
      "        [[ 0.1416]],\n",
      "\n",
      "        [[-1.8626]],\n",
      "\n",
      "        [[-1.7318]],\n",
      "\n",
      "        [[-0.7956]],\n",
      "\n",
      "        [[-1.3507]],\n",
      "\n",
      "        [[ 0.3365]],\n",
      "\n",
      "        [[ 0.1866]],\n",
      "\n",
      "        [[-0.9977]],\n",
      "\n",
      "        [[-0.3731]],\n",
      "\n",
      "        [[ 2.0492]],\n",
      "\n",
      "        [[-0.4217]],\n",
      "\n",
      "        [[ 0.5418]],\n",
      "\n",
      "        [[-0.3046]],\n",
      "\n",
      "        [[ 0.5244]],\n",
      "\n",
      "        [[ 0.8743]],\n",
      "\n",
      "        [[-1.1317]],\n",
      "\n",
      "        [[-1.2309]],\n",
      "\n",
      "        [[-0.4953]],\n",
      "\n",
      "        [[ 0.9996]],\n",
      "\n",
      "        [[-0.9927]],\n",
      "\n",
      "        [[-0.8393]],\n",
      "\n",
      "        [[ 0.3235]],\n",
      "\n",
      "        [[-0.4198]],\n",
      "\n",
      "        [[ 0.6746]],\n",
      "\n",
      "        [[-0.7323]],\n",
      "\n",
      "        [[ 0.1607]],\n",
      "\n",
      "        [[ 0.1331]],\n",
      "\n",
      "        [[-1.4170]],\n",
      "\n",
      "        [[-0.0299]],\n",
      "\n",
      "        [[-0.0563]],\n",
      "\n",
      "        [[-0.0576]],\n",
      "\n",
      "        [[-0.3120]],\n",
      "\n",
      "        [[-1.2655]],\n",
      "\n",
      "        [[-1.1622]],\n",
      "\n",
      "        [[-0.3300]],\n",
      "\n",
      "        [[ 0.4655]],\n",
      "\n",
      "        [[ 1.2885]],\n",
      "\n",
      "        [[-1.1724]],\n",
      "\n",
      "        [[-0.7027]],\n",
      "\n",
      "        [[-1.0552]],\n",
      "\n",
      "        [[ 1.6481]],\n",
      "\n",
      "        [[-1.2019]],\n",
      "\n",
      "        [[ 0.7197]],\n",
      "\n",
      "        [[-0.6020]],\n",
      "\n",
      "        [[ 1.4722]],\n",
      "\n",
      "        [[ 1.3315]],\n",
      "\n",
      "        [[ 0.2317]],\n",
      "\n",
      "        [[ 0.2379]],\n",
      "\n",
      "        [[-0.6347]],\n",
      "\n",
      "        [[-0.6615]],\n",
      "\n",
      "        [[-0.8116]],\n",
      "\n",
      "        [[ 0.5750]],\n",
      "\n",
      "        [[ 1.1552]],\n",
      "\n",
      "        [[-1.1994]],\n",
      "\n",
      "        [[ 2.1744]],\n",
      "\n",
      "        [[ 0.5972]],\n",
      "\n",
      "        [[ 0.4813]],\n",
      "\n",
      "        [[-1.3747]],\n",
      "\n",
      "        [[-0.1108]],\n",
      "\n",
      "        [[ 0.9263]],\n",
      "\n",
      "        [[-0.5717]],\n",
      "\n",
      "        [[-0.7669]],\n",
      "\n",
      "        [[-1.2201]],\n",
      "\n",
      "        [[-1.1620]],\n",
      "\n",
      "        [[-0.3627]],\n",
      "\n",
      "        [[-1.0189]],\n",
      "\n",
      "        [[-1.3128]],\n",
      "\n",
      "        [[-0.6713]],\n",
      "\n",
      "        [[-0.1156]],\n",
      "\n",
      "        [[ 1.1590]],\n",
      "\n",
      "        [[ 0.9539]],\n",
      "\n",
      "        [[ 2.4543]],\n",
      "\n",
      "        [[ 1.9029]],\n",
      "\n",
      "        [[-0.7115]],\n",
      "\n",
      "        [[ 0.4836]],\n",
      "\n",
      "        [[ 0.4619]],\n",
      "\n",
      "        [[-0.3493]],\n",
      "\n",
      "        [[ 1.4337]],\n",
      "\n",
      "        [[-0.1272]],\n",
      "\n",
      "        [[-1.0699]],\n",
      "\n",
      "        [[ 0.1143]],\n",
      "\n",
      "        [[ 0.4416]],\n",
      "\n",
      "        [[-0.1636]],\n",
      "\n",
      "        [[-1.2436]],\n",
      "\n",
      "        [[-0.5332]],\n",
      "\n",
      "        [[-2.2413]],\n",
      "\n",
      "        [[-0.4986]],\n",
      "\n",
      "        [[ 1.2267]],\n",
      "\n",
      "        [[ 0.4550]],\n",
      "\n",
      "        [[-1.2705]],\n",
      "\n",
      "        [[-1.1237]],\n",
      "\n",
      "        [[ 0.5043]],\n",
      "\n",
      "        [[ 0.2189]],\n",
      "\n",
      "        [[ 0.3782]],\n",
      "\n",
      "        [[ 0.4134]],\n",
      "\n",
      "        [[-0.5820]],\n",
      "\n",
      "        [[ 1.7777]],\n",
      "\n",
      "        [[ 1.6529]],\n",
      "\n",
      "        [[ 0.1711]],\n",
      "\n",
      "        [[ 0.2150]],\n",
      "\n",
      "        [[ 0.1184]],\n",
      "\n",
      "        [[-0.8798]],\n",
      "\n",
      "        [[-0.2273]],\n",
      "\n",
      "        [[-1.0152]],\n",
      "\n",
      "        [[-1.4926]],\n",
      "\n",
      "        [[ 0.5269]],\n",
      "\n",
      "        [[-2.1110]],\n",
      "\n",
      "        [[ 0.9359]],\n",
      "\n",
      "        [[-0.5100]],\n",
      "\n",
      "        [[ 0.2428]],\n",
      "\n",
      "        [[-1.4783]],\n",
      "\n",
      "        [[ 0.7686]],\n",
      "\n",
      "        [[-0.4786]],\n",
      "\n",
      "        [[-0.0873]],\n",
      "\n",
      "        [[-0.2140]],\n",
      "\n",
      "        [[-0.0556]],\n",
      "\n",
      "        [[-0.1588]],\n",
      "\n",
      "        [[ 0.6118]],\n",
      "\n",
      "        [[-0.7336]],\n",
      "\n",
      "        [[-1.0542]],\n",
      "\n",
      "        [[ 0.7098]],\n",
      "\n",
      "        [[ 0.8650]],\n",
      "\n",
      "        [[ 0.1763]],\n",
      "\n",
      "        [[-0.4786]],\n",
      "\n",
      "        [[-0.3466]],\n",
      "\n",
      "        [[-0.5696]],\n",
      "\n",
      "        [[ 1.0090]],\n",
      "\n",
      "        [[ 3.1732]],\n",
      "\n",
      "        [[-0.3242]],\n",
      "\n",
      "        [[-0.1019]],\n",
      "\n",
      "        [[ 0.0134]],\n",
      "\n",
      "        [[-1.7025]],\n",
      "\n",
      "        [[-0.9121]],\n",
      "\n",
      "        [[ 0.3238]],\n",
      "\n",
      "        [[ 0.2416]],\n",
      "\n",
      "        [[ 1.7486]],\n",
      "\n",
      "        [[-0.1128]],\n",
      "\n",
      "        [[ 0.0672]],\n",
      "\n",
      "        [[-1.8506]],\n",
      "\n",
      "        [[ 0.3665]],\n",
      "\n",
      "        [[-1.0452]],\n",
      "\n",
      "        [[-1.0428]],\n",
      "\n",
      "        [[-0.3069]],\n",
      "\n",
      "        [[-0.1307]],\n",
      "\n",
      "        [[ 0.0814]],\n",
      "\n",
      "        [[ 2.5636]],\n",
      "\n",
      "        [[ 0.5775]],\n",
      "\n",
      "        [[ 0.4549]],\n",
      "\n",
      "        [[ 0.0573]],\n",
      "\n",
      "        [[ 0.7367]],\n",
      "\n",
      "        [[ 0.6236]],\n",
      "\n",
      "        [[-0.3995]],\n",
      "\n",
      "        [[-0.3459]],\n",
      "\n",
      "        [[-0.2453]],\n",
      "\n",
      "        [[ 0.1811]],\n",
      "\n",
      "        [[-0.2998]],\n",
      "\n",
      "        [[ 0.4614]],\n",
      "\n",
      "        [[ 0.1977]],\n",
      "\n",
      "        [[ 0.0129]],\n",
      "\n",
      "        [[-0.0681]],\n",
      "\n",
      "        [[-0.4651]],\n",
      "\n",
      "        [[-0.8209]],\n",
      "\n",
      "        [[ 1.3786]],\n",
      "\n",
      "        [[-0.3326]],\n",
      "\n",
      "        [[ 0.1751]],\n",
      "\n",
      "        [[ 1.1976]],\n",
      "\n",
      "        [[ 0.4267]],\n",
      "\n",
      "        [[ 0.6277]],\n",
      "\n",
      "        [[-1.6796]],\n",
      "\n",
      "        [[ 1.1224]],\n",
      "\n",
      "        [[ 0.5482]],\n",
      "\n",
      "        [[ 0.4197]],\n",
      "\n",
      "        [[-0.8226]],\n",
      "\n",
      "        [[ 0.7994]],\n",
      "\n",
      "        [[ 0.2645]],\n",
      "\n",
      "        [[-0.8696]],\n",
      "\n",
      "        [[-0.3976]],\n",
      "\n",
      "        [[-2.0213]],\n",
      "\n",
      "        [[-0.3481]],\n",
      "\n",
      "        [[ 0.1467]],\n",
      "\n",
      "        [[ 0.7513]],\n",
      "\n",
      "        [[-0.7835]],\n",
      "\n",
      "        [[-1.7444]],\n",
      "\n",
      "        [[ 0.7321]],\n",
      "\n",
      "        [[ 1.0691]],\n",
      "\n",
      "        [[-0.7249]],\n",
      "\n",
      "        [[ 1.7904]],\n",
      "\n",
      "        [[ 0.7126]],\n",
      "\n",
      "        [[-0.4669]],\n",
      "\n",
      "        [[ 1.2555]],\n",
      "\n",
      "        [[-1.0056]],\n",
      "\n",
      "        [[-1.2495]],\n",
      "\n",
      "        [[ 0.5954]],\n",
      "\n",
      "        [[-1.8945]],\n",
      "\n",
      "        [[-0.0512]],\n",
      "\n",
      "        [[ 0.3567]],\n",
      "\n",
      "        [[ 0.1103]],\n",
      "\n",
      "        [[ 0.6519]],\n",
      "\n",
      "        [[ 1.1389]],\n",
      "\n",
      "        [[ 0.3744]],\n",
      "\n",
      "        [[-0.3030]],\n",
      "\n",
      "        [[ 0.3337]],\n",
      "\n",
      "        [[ 1.4442]],\n",
      "\n",
      "        [[-0.9716]],\n",
      "\n",
      "        [[-0.1677]],\n",
      "\n",
      "        [[-0.6476]],\n",
      "\n",
      "        [[ 0.4982]],\n",
      "\n",
      "        [[ 0.7163]],\n",
      "\n",
      "        [[-0.2670]],\n",
      "\n",
      "        [[-2.1347]],\n",
      "\n",
      "        [[ 0.4140]],\n",
      "\n",
      "        [[-0.7336]],\n",
      "\n",
      "        [[ 1.2711]],\n",
      "\n",
      "        [[ 1.4065]],\n",
      "\n",
      "        [[-0.0420]],\n",
      "\n",
      "        [[ 0.8810]],\n",
      "\n",
      "        [[-0.7405]],\n",
      "\n",
      "        [[ 0.5063]],\n",
      "\n",
      "        [[ 1.2061]],\n",
      "\n",
      "        [[-0.2162]],\n",
      "\n",
      "        [[ 1.7006]],\n",
      "\n",
      "        [[ 0.3373]],\n",
      "\n",
      "        [[-1.4622]],\n",
      "\n",
      "        [[-1.2999]],\n",
      "\n",
      "        [[-0.1512]],\n",
      "\n",
      "        [[ 0.9105]],\n",
      "\n",
      "        [[ 0.8774]],\n",
      "\n",
      "        [[ 0.4429]],\n",
      "\n",
      "        [[ 1.7916]],\n",
      "\n",
      "        [[ 0.4199]],\n",
      "\n",
      "        [[ 0.6925]],\n",
      "\n",
      "        [[-1.3118]],\n",
      "\n",
      "        [[-0.8421]],\n",
      "\n",
      "        [[ 0.2956]],\n",
      "\n",
      "        [[ 0.5451]],\n",
      "\n",
      "        [[ 3.6170]],\n",
      "\n",
      "        [[-1.7058]],\n",
      "\n",
      "        [[ 0.0307]],\n",
      "\n",
      "        [[-1.4771]],\n",
      "\n",
      "        [[-2.0267]],\n",
      "\n",
      "        [[-0.3369]],\n",
      "\n",
      "        [[ 0.7926]],\n",
      "\n",
      "        [[ 0.9606]],\n",
      "\n",
      "        [[-0.6466]],\n",
      "\n",
      "        [[-0.8282]],\n",
      "\n",
      "        [[ 0.1328]],\n",
      "\n",
      "        [[-1.3567]],\n",
      "\n",
      "        [[ 0.8961]],\n",
      "\n",
      "        [[-0.4661]],\n",
      "\n",
      "        [[-0.9694]],\n",
      "\n",
      "        [[ 0.3316]],\n",
      "\n",
      "        [[-1.7342]],\n",
      "\n",
      "        [[ 0.6480]],\n",
      "\n",
      "        [[-1.5147]],\n",
      "\n",
      "        [[-0.4502]],\n",
      "\n",
      "        [[ 0.0612]],\n",
      "\n",
      "        [[ 0.4717]],\n",
      "\n",
      "        [[ 0.1213]],\n",
      "\n",
      "        [[ 1.1323]],\n",
      "\n",
      "        [[ 0.4965]],\n",
      "\n",
      "        [[ 0.1766]],\n",
      "\n",
      "        [[-0.3822]],\n",
      "\n",
      "        [[-1.6880]],\n",
      "\n",
      "        [[ 1.1253]],\n",
      "\n",
      "        [[ 0.0189]],\n",
      "\n",
      "        [[ 1.1035]],\n",
      "\n",
      "        [[ 0.9250]],\n",
      "\n",
      "        [[-0.2051]],\n",
      "\n",
      "        [[ 1.4057]],\n",
      "\n",
      "        [[-0.5686]],\n",
      "\n",
      "        [[ 1.1444]],\n",
      "\n",
      "        [[-0.7822]],\n",
      "\n",
      "        [[ 1.1501]],\n",
      "\n",
      "        [[ 0.5717]],\n",
      "\n",
      "        [[-0.3686]],\n",
      "\n",
      "        [[-1.2072]],\n",
      "\n",
      "        [[ 1.7089]],\n",
      "\n",
      "        [[-1.7002]],\n",
      "\n",
      "        [[ 1.5301]],\n",
      "\n",
      "        [[ 0.0051]],\n",
      "\n",
      "        [[ 0.5153]],\n",
      "\n",
      "        [[-1.2160]],\n",
      "\n",
      "        [[-0.4209]],\n",
      "\n",
      "        [[ 0.6849]],\n",
      "\n",
      "        [[ 0.1712]],\n",
      "\n",
      "        [[ 2.6977]],\n",
      "\n",
      "        [[-0.1452]],\n",
      "\n",
      "        [[ 0.2229]],\n",
      "\n",
      "        [[ 0.5438]],\n",
      "\n",
      "        [[ 1.3684]],\n",
      "\n",
      "        [[-0.0816]],\n",
      "\n",
      "        [[ 1.6757]],\n",
      "\n",
      "        [[ 0.2484]],\n",
      "\n",
      "        [[-1.5647]],\n",
      "\n",
      "        [[ 0.3286]],\n",
      "\n",
      "        [[ 0.5633]],\n",
      "\n",
      "        [[ 1.6882]]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor(1.00000e-03 *\n",
      "       [[[-9.4777]]], device='cuda:0')\n",
      "torch.Size([1, 448, 512])\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 1.9530,  1.9530,  1.9531,  ...,  1.9531,  1.9533,  1.9534],\n",
      "         [ 1.9530,  1.9530,  1.9530,  ...,  1.9531,  1.9531,  1.9529],\n",
      "         [ 1.9530,  1.9530,  1.9531,  ...,  1.9531,  1.9532,  1.9533],\n",
      "         ...,\n",
      "         [ 1.9531,  1.9531,  1.9531,  ...,  1.9532,  1.9531,  1.9531],\n",
      "         [ 1.9532,  1.9534,  1.9533,  ...,  1.9529,  1.9530,  1.9532],\n",
      "         [ 1.9531,  1.9532,  1.9531,  ...,  1.9530,  1.9530,  1.9530]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 53 [39680/50000 (88%)]\tLoss: 0.154453, Accuracy: 94.53\n",
      "Train Epoch: 53 [40960/50000 (91%)]\tLoss: 0.106650, Accuracy: 96.48\n",
      "Train Epoch: 53 [42240/50000 (94%)]\tLoss: 0.172878, Accuracy: 95.31\n",
      "Train Epoch: 53 [43520/50000 (97%)]\tLoss: 0.189390, Accuracy: 94.53\n",
      "Train Epoch: 53 [35000/50000 (99%)]\tLoss: 0.237405, Accuracy: 91.00\n",
      "\n",
      "Validation set: Average loss: 0.2757, Accuracy: 4536/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[41.10352373123169 s]\n",
      "Train Epoch: 54 [0/50000 (0%)]\tLoss: 0.149189, Accuracy: 94.92\n",
      "Train Epoch: 54 [1280/50000 (3%)]\tLoss: 0.179680, Accuracy: 93.36\n",
      "Train Epoch: 54 [2560/50000 (6%)]\tLoss: 0.172213, Accuracy: 93.36\n",
      "Train Epoch: 54 [3840/50000 (9%)]\tLoss: 0.146812, Accuracy: 95.70\n",
      "Train Epoch: 54 [5120/50000 (11%)]\tLoss: 0.126261, Accuracy: 96.48\n",
      "Train Epoch: 54 [6400/50000 (14%)]\tLoss: 0.159850, Accuracy: 94.92\n",
      "Train Epoch: 54 [7680/50000 (17%)]\tLoss: 0.148807, Accuracy: 94.53\n",
      "Train Epoch: 54 [8960/50000 (20%)]\tLoss: 0.182713, Accuracy: 94.53\n",
      "Train Epoch: 54 [10240/50000 (23%)]\tLoss: 0.131068, Accuracy: 94.92\n",
      "Train Epoch: 54 [11520/50000 (26%)]\tLoss: 0.176345, Accuracy: 94.53\n",
      "Train Epoch: 54 [12800/50000 (28%)]\tLoss: 0.220806, Accuracy: 91.02\n",
      "Train Epoch: 54 [14080/50000 (31%)]\tLoss: 0.149708, Accuracy: 96.09\n",
      "Train Epoch: 54 [15360/50000 (34%)]\tLoss: 0.176291, Accuracy: 93.75\n",
      "Train Epoch: 54 [16640/50000 (37%)]\tLoss: 0.127229, Accuracy: 96.09\n",
      "Train Epoch: 54 [17920/50000 (40%)]\tLoss: 0.121470, Accuracy: 96.48\n",
      "Train Epoch: 54 [19200/50000 (43%)]\tLoss: 0.165824, Accuracy: 92.97\n",
      "Train Epoch: 54 [20480/50000 (45%)]\tLoss: 0.165455, Accuracy: 95.31\n",
      "Train Epoch: 54 [21760/50000 (48%)]\tLoss: 0.150769, Accuracy: 94.53\n",
      "Train Epoch: 54 [23040/50000 (51%)]\tLoss: 0.198174, Accuracy: 93.75\n",
      "Train Epoch: 54 [24320/50000 (54%)]\tLoss: 0.169381, Accuracy: 94.92\n",
      "Train Epoch: 54 [25600/50000 (57%)]\tLoss: 0.216951, Accuracy: 93.36\n",
      "Train Epoch: 54 [26880/50000 (60%)]\tLoss: 0.187576, Accuracy: 95.31\n",
      "Train Epoch: 54 [28160/50000 (62%)]\tLoss: 0.150485, Accuracy: 94.92\n",
      "Train Epoch: 54 [29440/50000 (65%)]\tLoss: 0.143869, Accuracy: 95.70\n",
      "Train Epoch: 54 [30720/50000 (68%)]\tLoss: 0.197537, Accuracy: 94.14\n",
      "Train Epoch: 54 [32000/50000 (71%)]\tLoss: 0.176336, Accuracy: 92.97\n",
      "Train Epoch: 54 [33280/50000 (74%)]\tLoss: 0.134000, Accuracy: 96.48\n",
      "Train Epoch: 54 [34560/50000 (77%)]\tLoss: 0.112875, Accuracy: 95.70\n",
      "Train Epoch: 54 [35840/50000 (80%)]\tLoss: 0.202084, Accuracy: 93.36\n",
      "Train Epoch: 54 [37120/50000 (82%)]\tLoss: 0.119400, Accuracy: 97.27\n",
      "Train Epoch: 54 [38400/50000 (85%)]\tLoss: 0.201994, Accuracy: 94.14\n",
      "Train Epoch: 54 [39680/50000 (88%)]\tLoss: 0.116572, Accuracy: 96.09\n",
      "Train Epoch: 54 [40960/50000 (91%)]\tLoss: 0.167161, Accuracy: 94.14\n",
      "Train Epoch: 54 [42240/50000 (94%)]\tLoss: 0.142687, Accuracy: 96.09\n",
      "Train Epoch: 54 [43520/50000 (97%)]\tLoss: 0.200271, Accuracy: 92.97\n",
      "Train Epoch: 54 [35000/50000 (99%)]\tLoss: 0.221323, Accuracy: 92.50\n",
      "\n",
      "Validation set: Average loss: 0.2775, Accuracy: 4539/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[37.682544469833374 s]\n",
      "\n",
      "Test set: Average loss: 0.2902, Accuracy: 9089/10000 (90.89%)\n",
      "\n",
      "Train Epoch: 55 [0/50000 (0%)]\tLoss: 0.159249, Accuracy: 95.31\n",
      "Train Epoch: 55 [1280/50000 (3%)]\tLoss: 0.147326, Accuracy: 94.14\n",
      "Train Epoch: 55 [2560/50000 (6%)]\tLoss: 0.176324, Accuracy: 94.92\n",
      "Train Epoch: 55 [3840/50000 (9%)]\tLoss: 0.169959, Accuracy: 93.75\n",
      "Train Epoch: 55 [5120/50000 (11%)]\tLoss: 0.137342, Accuracy: 95.31\n",
      "Train Epoch: 55 [6400/50000 (14%)]\tLoss: 0.150285, Accuracy: 95.31\n",
      "Train Epoch: 55 [7680/50000 (17%)]\tLoss: 0.146918, Accuracy: 95.31\n",
      "Train Epoch: 55 [8960/50000 (20%)]\tLoss: 0.108655, Accuracy: 96.48\n",
      "Train Epoch: 55 [10240/50000 (23%)]\tLoss: 0.152271, Accuracy: 94.53\n",
      "Train Epoch: 55 [11520/50000 (26%)]\tLoss: 0.165364, Accuracy: 95.31\n",
      "Train Epoch: 55 [12800/50000 (28%)]\tLoss: 0.157374, Accuracy: 94.53\n",
      "Train Epoch: 55 [14080/50000 (31%)]\tLoss: 0.110287, Accuracy: 97.27\n",
      "Train Epoch: 55 [15360/50000 (34%)]\tLoss: 0.146367, Accuracy: 96.09\n",
      "Train Epoch: 55 [16640/50000 (37%)]\tLoss: 0.146328, Accuracy: 94.53\n",
      "Train Epoch: 55 [17920/50000 (40%)]\tLoss: 0.164011, Accuracy: 95.70\n",
      "Train Epoch: 55 [19200/50000 (43%)]\tLoss: 0.117547, Accuracy: 97.27\n",
      "Train Epoch: 55 [20480/50000 (45%)]\tLoss: 0.195916, Accuracy: 93.36\n",
      "Train Epoch: 55 [21760/50000 (48%)]\tLoss: 0.127482, Accuracy: 94.92\n",
      "Train Epoch: 55 [23040/50000 (51%)]\tLoss: 0.137263, Accuracy: 94.53\n",
      "Train Epoch: 55 [24320/50000 (54%)]\tLoss: 0.169316, Accuracy: 94.92\n",
      "Train Epoch: 55 [25600/50000 (57%)]\tLoss: 0.121337, Accuracy: 97.27\n",
      "Train Epoch: 55 [26880/50000 (60%)]\tLoss: 0.190549, Accuracy: 92.19\n",
      "Train Epoch: 55 [28160/50000 (62%)]\tLoss: 0.214071, Accuracy: 94.14\n",
      "Train Epoch: 55 [29440/50000 (65%)]\tLoss: 0.199252, Accuracy: 92.19\n",
      "Train Epoch: 55 [30720/50000 (68%)]\tLoss: 0.170379, Accuracy: 94.14\n",
      "Train Epoch: 55 [32000/50000 (71%)]\tLoss: 0.173340, Accuracy: 92.97\n",
      "Train Epoch: 55 [33280/50000 (74%)]\tLoss: 0.169007, Accuracy: 94.53\n",
      "Train Epoch: 55 [34560/50000 (77%)]\tLoss: 0.156428, Accuracy: 96.48\n",
      "Train Epoch: 55 [35840/50000 (80%)]\tLoss: 0.115251, Accuracy: 94.53\n",
      "Train Epoch: 55 [37120/50000 (82%)]\tLoss: 0.244692, Accuracy: 91.41\n",
      "Train Epoch: 55 [38400/50000 (85%)]\tLoss: 0.137027, Accuracy: 95.70\n",
      "Train Epoch: 55 [39680/50000 (88%)]\tLoss: 0.171500, Accuracy: 93.36\n",
      "Train Epoch: 55 [40960/50000 (91%)]\tLoss: 0.139719, Accuracy: 95.70\n",
      "Train Epoch: 55 [42240/50000 (94%)]\tLoss: 0.161370, Accuracy: 94.53\n",
      "Train Epoch: 55 [43520/50000 (97%)]\tLoss: 0.205347, Accuracy: 92.58\n",
      "Train Epoch: 55 [35000/50000 (99%)]\tLoss: 0.121226, Accuracy: 95.50\n",
      "\n",
      "Validation set: Average loss: 0.2670, Accuracy: 4563/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[41.01060461997986 s]\n",
      "Train Epoch: 56 [0/50000 (0%)]\tLoss: 0.110992, Accuracy: 96.09\n",
      "Train Epoch: 56 [1280/50000 (3%)]\tLoss: 0.158377, Accuracy: 94.92\n",
      "Train Epoch: 56 [2560/50000 (6%)]\tLoss: 0.116462, Accuracy: 94.53\n",
      "Train Epoch: 56 [3840/50000 (9%)]\tLoss: 0.104744, Accuracy: 97.27\n",
      "Train Epoch: 56 [5120/50000 (11%)]\tLoss: 0.186826, Accuracy: 92.19\n",
      "Train Epoch: 56 [6400/50000 (14%)]\tLoss: 0.182174, Accuracy: 94.14\n",
      "Train Epoch: 56 [7680/50000 (17%)]\tLoss: 0.144701, Accuracy: 95.70\n",
      "Train Epoch: 56 [8960/50000 (20%)]\tLoss: 0.136643, Accuracy: 95.70\n",
      "Train Epoch: 56 [10240/50000 (23%)]\tLoss: 0.125618, Accuracy: 95.31\n",
      "Train Epoch: 56 [11520/50000 (26%)]\tLoss: 0.155493, Accuracy: 95.31\n",
      "Train Epoch: 56 [12800/50000 (28%)]\tLoss: 0.093261, Accuracy: 97.27\n",
      "Train Epoch: 56 [14080/50000 (31%)]\tLoss: 0.164131, Accuracy: 94.92\n",
      "Train Epoch: 56 [15360/50000 (34%)]\tLoss: 0.195217, Accuracy: 94.53\n",
      "Train Epoch: 56 [16640/50000 (37%)]\tLoss: 0.149975, Accuracy: 94.14\n",
      "Train Epoch: 56 [17920/50000 (40%)]\tLoss: 0.116043, Accuracy: 96.48\n",
      "Train Epoch: 56 [19200/50000 (43%)]\tLoss: 0.150672, Accuracy: 93.75\n",
      "Train Epoch: 56 [20480/50000 (45%)]\tLoss: 0.193584, Accuracy: 94.92\n",
      "Train Epoch: 56 [21760/50000 (48%)]\tLoss: 0.114445, Accuracy: 96.88\n",
      "Train Epoch: 56 [23040/50000 (51%)]\tLoss: 0.076066, Accuracy: 98.44\n",
      "Train Epoch: 56 [24320/50000 (54%)]\tLoss: 0.127071, Accuracy: 95.70\n",
      "Train Epoch: 56 [25600/50000 (57%)]\tLoss: 0.132101, Accuracy: 94.53\n",
      "Train Epoch: 56 [26880/50000 (60%)]\tLoss: 0.132882, Accuracy: 96.09\n",
      "Train Epoch: 56 [28160/50000 (62%)]\tLoss: 0.130058, Accuracy: 95.31\n",
      "Train Epoch: 56 [29440/50000 (65%)]\tLoss: 0.170731, Accuracy: 94.92\n",
      "Train Epoch: 56 [30720/50000 (68%)]\tLoss: 0.166397, Accuracy: 94.53\n",
      "Train Epoch: 56 [32000/50000 (71%)]\tLoss: 0.112986, Accuracy: 95.70\n",
      "Train Epoch: 56 [33280/50000 (74%)]\tLoss: 0.126822, Accuracy: 95.70\n",
      "Train Epoch: 56 [34560/50000 (77%)]\tLoss: 0.194280, Accuracy: 92.58\n",
      "Train Epoch: 56 [35840/50000 (80%)]\tLoss: 0.092692, Accuracy: 96.88\n",
      "Train Epoch: 56 [37120/50000 (82%)]\tLoss: 0.110909, Accuracy: 97.66\n",
      "Train Epoch: 56 [38400/50000 (85%)]\tLoss: 0.145780, Accuracy: 94.92\n",
      "Train Epoch: 56 [39680/50000 (88%)]\tLoss: 0.176065, Accuracy: 93.75\n",
      "Train Epoch: 56 [40960/50000 (91%)]\tLoss: 0.126844, Accuracy: 96.48\n",
      "Train Epoch: 56 [42240/50000 (94%)]\tLoss: 0.116111, Accuracy: 95.70\n",
      "Train Epoch: 56 [43520/50000 (97%)]\tLoss: 0.152205, Accuracy: 95.31\n",
      "Train Epoch: 56 [35000/50000 (99%)]\tLoss: 0.139925, Accuracy: 96.50\n",
      "\n",
      "Validation set: Average loss: 0.2788, Accuracy: 4548/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[37.658217906951904 s]\n",
      "\n",
      "Test set: Average loss: 0.2916, Accuracy: 9044/10000 (90.44%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 57 [0/50000 (0%)]\tLoss: 0.183726, Accuracy: 94.53\n",
      "Train Epoch: 57 [1280/50000 (3%)]\tLoss: 0.166690, Accuracy: 93.75\n",
      "Train Epoch: 57 [2560/50000 (6%)]\tLoss: 0.165334, Accuracy: 93.36\n",
      "Train Epoch: 57 [3840/50000 (9%)]\tLoss: 0.161996, Accuracy: 93.36\n",
      "Train Epoch: 57 [5120/50000 (11%)]\tLoss: 0.155340, Accuracy: 95.31\n",
      "Train Epoch: 57 [6400/50000 (14%)]\tLoss: 0.101679, Accuracy: 96.09\n",
      "Train Epoch: 57 [7680/50000 (17%)]\tLoss: 0.225032, Accuracy: 92.97\n",
      "Train Epoch: 57 [8960/50000 (20%)]\tLoss: 0.126079, Accuracy: 94.14\n",
      "Train Epoch: 57 [10240/50000 (23%)]\tLoss: 0.167113, Accuracy: 91.41\n",
      "Train Epoch: 57 [11520/50000 (26%)]\tLoss: 0.154661, Accuracy: 95.31\n",
      "Train Epoch: 57 [12800/50000 (28%)]\tLoss: 0.128858, Accuracy: 96.48\n",
      "Train Epoch: 57 [14080/50000 (31%)]\tLoss: 0.104969, Accuracy: 97.66\n",
      "Train Epoch: 57 [15360/50000 (34%)]\tLoss: 0.147730, Accuracy: 95.70\n",
      "Train Epoch: 57 [16640/50000 (37%)]\tLoss: 0.101930, Accuracy: 95.31\n",
      "Train Epoch: 57 [17920/50000 (40%)]\tLoss: 0.137529, Accuracy: 95.70\n",
      "Train Epoch: 57 [19200/50000 (43%)]\tLoss: 0.112756, Accuracy: 96.88\n",
      "Train Epoch: 57 [20480/50000 (45%)]\tLoss: 0.116553, Accuracy: 96.09\n",
      "Train Epoch: 57 [21760/50000 (48%)]\tLoss: 0.139131, Accuracy: 95.70\n",
      "Train Epoch: 57 [23040/50000 (51%)]\tLoss: 0.155478, Accuracy: 94.14\n",
      "Train Epoch: 57 [24320/50000 (54%)]\tLoss: 0.112229, Accuracy: 96.48\n",
      "Train Epoch: 57 [25600/50000 (57%)]\tLoss: 0.061573, Accuracy: 98.44\n",
      "Train Epoch: 57 [26880/50000 (60%)]\tLoss: 0.075645, Accuracy: 97.66\n",
      "Train Epoch: 57 [28160/50000 (62%)]\tLoss: 0.125222, Accuracy: 95.70\n",
      "Train Epoch: 57 [29440/50000 (65%)]\tLoss: 0.120004, Accuracy: 95.70\n",
      "Train Epoch: 57 [30720/50000 (68%)]\tLoss: 0.115460, Accuracy: 94.92\n",
      "Train Epoch: 57 [32000/50000 (71%)]\tLoss: 0.105673, Accuracy: 96.09\n",
      "Train Epoch: 57 [33280/50000 (74%)]\tLoss: 0.082855, Accuracy: 97.66\n",
      "Train Epoch: 57 [34560/50000 (77%)]\tLoss: 0.110886, Accuracy: 96.09\n",
      "Train Epoch: 57 [35840/50000 (80%)]\tLoss: 0.130458, Accuracy: 96.09\n",
      "Train Epoch: 57 [37120/50000 (82%)]\tLoss: 0.123268, Accuracy: 95.31\n",
      "Train Epoch: 57 [38400/50000 (85%)]\tLoss: 0.102085, Accuracy: 97.27\n",
      "Train Epoch: 57 [39680/50000 (88%)]\tLoss: 0.112677, Accuracy: 95.70\n",
      "Train Epoch: 57 [40960/50000 (91%)]\tLoss: 0.146434, Accuracy: 96.48\n",
      "Train Epoch: 57 [42240/50000 (94%)]\tLoss: 0.191185, Accuracy: 95.31\n",
      "Train Epoch: 57 [43520/50000 (97%)]\tLoss: 0.126564, Accuracy: 94.92\n",
      "Train Epoch: 57 [35000/50000 (99%)]\tLoss: 0.156415, Accuracy: 95.00\n",
      "\n",
      "Validation set: Average loss: 0.2759, Accuracy: 4533/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[41.10860872268677 s]\n",
      "Train Epoch: 58 [0/50000 (0%)]\tLoss: 0.126864, Accuracy: 95.31\n",
      "Train Epoch: 58 [1280/50000 (3%)]\tLoss: 0.125499, Accuracy: 96.48\n",
      "Train Epoch: 58 [2560/50000 (6%)]\tLoss: 0.119472, Accuracy: 95.70\n",
      "Train Epoch: 58 [3840/50000 (9%)]\tLoss: 0.114294, Accuracy: 97.66\n",
      "Train Epoch: 58 [5120/50000 (11%)]\tLoss: 0.140200, Accuracy: 96.09\n",
      "Train Epoch: 58 [6400/50000 (14%)]\tLoss: 0.119433, Accuracy: 96.48\n",
      "Train Epoch: 58 [7680/50000 (17%)]\tLoss: 0.142271, Accuracy: 95.31\n",
      "Train Epoch: 58 [8960/50000 (20%)]\tLoss: 0.183309, Accuracy: 94.53\n",
      "Train Epoch: 58 [10240/50000 (23%)]\tLoss: 0.137441, Accuracy: 95.31\n",
      "Train Epoch: 58 [11520/50000 (26%)]\tLoss: 0.207102, Accuracy: 91.80\n",
      "Train Epoch: 58 [12800/50000 (28%)]\tLoss: 0.123964, Accuracy: 96.48\n",
      "Train Epoch: 58 [14080/50000 (31%)]\tLoss: 0.233542, Accuracy: 92.19\n",
      "Train Epoch: 58 [15360/50000 (34%)]\tLoss: 0.127996, Accuracy: 97.27\n",
      "Train Epoch: 58 [16640/50000 (37%)]\tLoss: 0.141029, Accuracy: 96.48\n",
      "Train Epoch: 58 [17920/50000 (40%)]\tLoss: 0.092538, Accuracy: 96.48\n",
      "Train Epoch: 58 [19200/50000 (43%)]\tLoss: 0.113681, Accuracy: 96.09\n",
      "Train Epoch: 58 [20480/50000 (45%)]\tLoss: 0.136181, Accuracy: 94.92\n",
      "Train Epoch: 58 [21760/50000 (48%)]\tLoss: 0.178234, Accuracy: 95.31\n",
      "Train Epoch: 58 [23040/50000 (51%)]\tLoss: 0.164955, Accuracy: 94.53\n",
      "Train Epoch: 58 [24320/50000 (54%)]\tLoss: 0.098071, Accuracy: 96.48\n",
      "Train Epoch: 58 [25600/50000 (57%)]\tLoss: 0.137294, Accuracy: 95.31\n",
      "Train Epoch: 58 [26880/50000 (60%)]\tLoss: 0.181546, Accuracy: 94.53\n",
      "Train Epoch: 58 [28160/50000 (62%)]\tLoss: 0.079375, Accuracy: 98.05\n",
      "Train Epoch: 58 [29440/50000 (65%)]\tLoss: 0.148267, Accuracy: 94.53\n",
      "Train Epoch: 58 [30720/50000 (68%)]\tLoss: 0.142855, Accuracy: 95.70\n",
      "Train Epoch: 58 [32000/50000 (71%)]\tLoss: 0.126170, Accuracy: 95.31\n",
      "Train Epoch: 58 [33280/50000 (74%)]\tLoss: 0.151927, Accuracy: 94.92\n",
      "Train Epoch: 58 [34560/50000 (77%)]\tLoss: 0.082474, Accuracy: 97.27\n",
      "Train Epoch: 58 [35840/50000 (80%)]\tLoss: 0.135728, Accuracy: 96.09\n",
      "Train Epoch: 58 [37120/50000 (82%)]\tLoss: 0.151692, Accuracy: 95.70\n",
      "Train Epoch: 58 [38400/50000 (85%)]\tLoss: 0.137209, Accuracy: 95.70\n",
      "Train Epoch: 58 [39680/50000 (88%)]\tLoss: 0.143067, Accuracy: 94.92\n",
      "Train Epoch: 58 [40960/50000 (91%)]\tLoss: 0.135853, Accuracy: 96.09\n",
      "Train Epoch: 58 [42240/50000 (94%)]\tLoss: 0.127345, Accuracy: 96.09\n",
      "Train Epoch: 58 [43520/50000 (97%)]\tLoss: 0.132671, Accuracy: 93.75\n",
      "Train Epoch: 58 [35000/50000 (99%)]\tLoss: 0.136277, Accuracy: 95.00\n",
      "\n",
      "Validation set: Average loss: 0.2783, Accuracy: 4557/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[37.564868211746216 s]\n",
      "\n",
      "Test set: Average loss: 0.2947, Accuracy: 9104/10000 (91.04%)\n",
      "\n",
      "Train Epoch: 59 [0/50000 (0%)]\tLoss: 0.103250, Accuracy: 96.88\n",
      "Train Epoch: 59 [1280/50000 (3%)]\tLoss: 0.103088, Accuracy: 98.05\n",
      "Train Epoch: 59 [2560/50000 (6%)]\tLoss: 0.114981, Accuracy: 96.88\n",
      "Train Epoch: 59 [3840/50000 (9%)]\tLoss: 0.097160, Accuracy: 96.09\n",
      "Train Epoch: 59 [5120/50000 (11%)]\tLoss: 0.179271, Accuracy: 95.31\n",
      "Train Epoch: 59 [6400/50000 (14%)]\tLoss: 0.157698, Accuracy: 94.14\n",
      "Train Epoch: 59 [7680/50000 (17%)]\tLoss: 0.132145, Accuracy: 96.48\n",
      "Train Epoch: 59 [8960/50000 (20%)]\tLoss: 0.105700, Accuracy: 97.66\n",
      "Train Epoch: 59 [10240/50000 (23%)]\tLoss: 0.084789, Accuracy: 96.09\n",
      "Train Epoch: 59 [11520/50000 (26%)]\tLoss: 0.114304, Accuracy: 96.09\n",
      "Train Epoch: 59 [12800/50000 (28%)]\tLoss: 0.103769, Accuracy: 94.92\n",
      "Train Epoch: 59 [14080/50000 (31%)]\tLoss: 0.096713, Accuracy: 96.88\n",
      "Train Epoch: 59 [15360/50000 (34%)]\tLoss: 0.117318, Accuracy: 96.09\n",
      "Train Epoch: 59 [16640/50000 (37%)]\tLoss: 0.124270, Accuracy: 96.48\n",
      "Train Epoch: 59 [17920/50000 (40%)]\tLoss: 0.126421, Accuracy: 96.09\n",
      "Train Epoch: 59 [19200/50000 (43%)]\tLoss: 0.108545, Accuracy: 95.70\n",
      "Train Epoch: 59 [20480/50000 (45%)]\tLoss: 0.180606, Accuracy: 92.58\n",
      "Train Epoch: 59 [21760/50000 (48%)]\tLoss: 0.089245, Accuracy: 98.05\n",
      "Train Epoch: 59 [23040/50000 (51%)]\tLoss: 0.096873, Accuracy: 97.66\n",
      "Train Epoch: 59 [24320/50000 (54%)]\tLoss: 0.125605, Accuracy: 94.53\n",
      "Train Epoch: 59 [25600/50000 (57%)]\tLoss: 0.099162, Accuracy: 96.48\n",
      "Train Epoch: 59 [26880/50000 (60%)]\tLoss: 0.178950, Accuracy: 92.58\n",
      "Train Epoch: 59 [28160/50000 (62%)]\tLoss: 0.093199, Accuracy: 97.66\n",
      "Train Epoch: 59 [29440/50000 (65%)]\tLoss: 0.142838, Accuracy: 95.31\n",
      "Train Epoch: 59 [30720/50000 (68%)]\tLoss: 0.146684, Accuracy: 96.88\n",
      "Train Epoch: 59 [32000/50000 (71%)]\tLoss: 0.168240, Accuracy: 94.92\n",
      "Train Epoch: 59 [33280/50000 (74%)]\tLoss: 0.185004, Accuracy: 94.53\n",
      "Train Epoch: 59 [34560/50000 (77%)]\tLoss: 0.132466, Accuracy: 96.48\n",
      "Train Epoch: 59 [35840/50000 (80%)]\tLoss: 0.132204, Accuracy: 96.09\n",
      "Train Epoch: 59 [37120/50000 (82%)]\tLoss: 0.109936, Accuracy: 96.88\n",
      "Train Epoch: 59 [38400/50000 (85%)]\tLoss: 0.095044, Accuracy: 97.27\n",
      "Train Epoch: 59 [39680/50000 (88%)]\tLoss: 0.081455, Accuracy: 96.48\n",
      "Train Epoch: 59 [40960/50000 (91%)]\tLoss: 0.074624, Accuracy: 98.05\n",
      "Train Epoch: 59 [42240/50000 (94%)]\tLoss: 0.143923, Accuracy: 95.31\n",
      "Train Epoch: 59 [43520/50000 (97%)]\tLoss: 0.172067, Accuracy: 94.53\n",
      "Train Epoch: 59 [35000/50000 (99%)]\tLoss: 0.112685, Accuracy: 96.50\n",
      "\n",
      "Validation set: Average loss: 0.2877, Accuracy: 4546/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[40.765535831451416 s]\n",
      "Train Epoch: 60 [0/50000 (0%)]\tLoss: 0.076610, Accuracy: 98.44\n",
      "Train Epoch: 60 [1280/50000 (3%)]\tLoss: 0.119344, Accuracy: 96.09\n",
      "Train Epoch: 60 [2560/50000 (6%)]\tLoss: 0.098390, Accuracy: 96.88\n",
      "Train Epoch: 60 [3840/50000 (9%)]\tLoss: 0.087101, Accuracy: 96.88\n",
      "Train Epoch: 60 [5120/50000 (11%)]\tLoss: 0.114658, Accuracy: 96.09\n",
      "Train Epoch: 60 [6400/50000 (14%)]\tLoss: 0.084265, Accuracy: 96.88\n",
      "Train Epoch: 60 [7680/50000 (17%)]\tLoss: 0.092820, Accuracy: 96.09\n",
      "Train Epoch: 60 [8960/50000 (20%)]\tLoss: 0.131491, Accuracy: 94.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 60 [10240/50000 (23%)]\tLoss: 0.117005, Accuracy: 96.48\n",
      "Train Epoch: 60 [11520/50000 (26%)]\tLoss: 0.084419, Accuracy: 97.66\n",
      "Train Epoch: 60 [12800/50000 (28%)]\tLoss: 0.158482, Accuracy: 94.92\n",
      "Train Epoch: 60 [14080/50000 (31%)]\tLoss: 0.080060, Accuracy: 97.27\n",
      "Train Epoch: 60 [15360/50000 (34%)]\tLoss: 0.100205, Accuracy: 96.88\n",
      "Train Epoch: 60 [16640/50000 (37%)]\tLoss: 0.112129, Accuracy: 96.09\n",
      "Train Epoch: 60 [17920/50000 (40%)]\tLoss: 0.096430, Accuracy: 96.09\n",
      "Train Epoch: 60 [19200/50000 (43%)]\tLoss: 0.115551, Accuracy: 95.31\n",
      "Train Epoch: 60 [20480/50000 (45%)]\tLoss: 0.077370, Accuracy: 98.44\n",
      "Train Epoch: 60 [21760/50000 (48%)]\tLoss: 0.116155, Accuracy: 96.09\n",
      "Train Epoch: 60 [23040/50000 (51%)]\tLoss: 0.111839, Accuracy: 96.48\n",
      "Train Epoch: 60 [24320/50000 (54%)]\tLoss: 0.115775, Accuracy: 95.70\n",
      "Train Epoch: 60 [25600/50000 (57%)]\tLoss: 0.124857, Accuracy: 96.88\n",
      "Train Epoch: 60 [26880/50000 (60%)]\tLoss: 0.129968, Accuracy: 96.09\n",
      "Train Epoch: 60 [28160/50000 (62%)]\tLoss: 0.175602, Accuracy: 94.14\n",
      "Train Epoch: 60 [29440/50000 (65%)]\tLoss: 0.071515, Accuracy: 98.44\n",
      "Train Epoch: 60 [30720/50000 (68%)]\tLoss: 0.098620, Accuracy: 96.88\n",
      "Train Epoch: 60 [32000/50000 (71%)]\tLoss: 0.085392, Accuracy: 97.27\n",
      "Train Epoch: 60 [33280/50000 (74%)]\tLoss: 0.166654, Accuracy: 92.97\n",
      "torch.Size([512, 1, 1])\n",
      "tensor([[[-1.2862]],\n",
      "\n",
      "        [[-0.5372]],\n",
      "\n",
      "        [[ 0.5067]],\n",
      "\n",
      "        [[-1.1281]],\n",
      "\n",
      "        [[-0.1240]],\n",
      "\n",
      "        [[-0.5409]],\n",
      "\n",
      "        [[-0.4035]],\n",
      "\n",
      "        [[-0.8503]],\n",
      "\n",
      "        [[ 0.3291]],\n",
      "\n",
      "        [[-1.0462]],\n",
      "\n",
      "        [[ 0.2451]],\n",
      "\n",
      "        [[-0.0791]],\n",
      "\n",
      "        [[-0.6861]],\n",
      "\n",
      "        [[-0.3873]],\n",
      "\n",
      "        [[-1.8495]],\n",
      "\n",
      "        [[ 2.4077]],\n",
      "\n",
      "        [[-0.8151]],\n",
      "\n",
      "        [[ 0.1340]],\n",
      "\n",
      "        [[ 0.5542]],\n",
      "\n",
      "        [[-0.5343]],\n",
      "\n",
      "        [[ 0.2301]],\n",
      "\n",
      "        [[-0.9702]],\n",
      "\n",
      "        [[-1.3776]],\n",
      "\n",
      "        [[-0.1886]],\n",
      "\n",
      "        [[-0.2855]],\n",
      "\n",
      "        [[ 0.6131]],\n",
      "\n",
      "        [[ 1.6318]],\n",
      "\n",
      "        [[ 0.5503]],\n",
      "\n",
      "        [[-0.2864]],\n",
      "\n",
      "        [[ 0.0054]],\n",
      "\n",
      "        [[-1.6047]],\n",
      "\n",
      "        [[-1.1403]],\n",
      "\n",
      "        [[-0.3714]],\n",
      "\n",
      "        [[-1.8845]],\n",
      "\n",
      "        [[ 0.6120]],\n",
      "\n",
      "        [[-0.2425]],\n",
      "\n",
      "        [[-0.3490]],\n",
      "\n",
      "        [[ 1.3724]],\n",
      "\n",
      "        [[ 0.2358]],\n",
      "\n",
      "        [[-0.9418]],\n",
      "\n",
      "        [[-0.9502]],\n",
      "\n",
      "        [[-1.3512]],\n",
      "\n",
      "        [[-1.5876]],\n",
      "\n",
      "        [[ 0.6247]],\n",
      "\n",
      "        [[ 0.5473]],\n",
      "\n",
      "        [[-0.4599]],\n",
      "\n",
      "        [[ 0.3215]],\n",
      "\n",
      "        [[-0.2561]],\n",
      "\n",
      "        [[ 1.6313]],\n",
      "\n",
      "        [[-0.2363]],\n",
      "\n",
      "        [[-0.1895]],\n",
      "\n",
      "        [[ 0.8978]],\n",
      "\n",
      "        [[ 0.8987]],\n",
      "\n",
      "        [[-0.3398]],\n",
      "\n",
      "        [[-0.3450]],\n",
      "\n",
      "        [[-0.4371]],\n",
      "\n",
      "        [[ 1.4968]],\n",
      "\n",
      "        [[-0.1306]],\n",
      "\n",
      "        [[-1.1840]],\n",
      "\n",
      "        [[ 1.4927]],\n",
      "\n",
      "        [[ 0.5559]],\n",
      "\n",
      "        [[ 0.7447]],\n",
      "\n",
      "        [[ 1.3988]],\n",
      "\n",
      "        [[-1.7794]],\n",
      "\n",
      "        [[-0.5366]],\n",
      "\n",
      "        [[-0.5960]],\n",
      "\n",
      "        [[ 0.9652]],\n",
      "\n",
      "        [[-2.3051]],\n",
      "\n",
      "        [[-1.8559]],\n",
      "\n",
      "        [[ 1.2595]],\n",
      "\n",
      "        [[ 0.7434]],\n",
      "\n",
      "        [[ 0.1809]],\n",
      "\n",
      "        [[-1.2569]],\n",
      "\n",
      "        [[ 0.9086]],\n",
      "\n",
      "        [[-0.5780]],\n",
      "\n",
      "        [[-0.8731]],\n",
      "\n",
      "        [[-0.0224]],\n",
      "\n",
      "        [[ 0.4252]],\n",
      "\n",
      "        [[ 0.9525]],\n",
      "\n",
      "        [[-0.6866]],\n",
      "\n",
      "        [[ 0.7247]],\n",
      "\n",
      "        [[-1.4120]],\n",
      "\n",
      "        [[-0.2766]],\n",
      "\n",
      "        [[-0.6542]],\n",
      "\n",
      "        [[ 1.4266]],\n",
      "\n",
      "        [[ 0.1118]],\n",
      "\n",
      "        [[-0.4373]],\n",
      "\n",
      "        [[ 0.0344]],\n",
      "\n",
      "        [[-0.5529]],\n",
      "\n",
      "        [[-0.5679]],\n",
      "\n",
      "        [[ 0.8827]],\n",
      "\n",
      "        [[-1.2317]],\n",
      "\n",
      "        [[-2.2666]],\n",
      "\n",
      "        [[-1.2277]],\n",
      "\n",
      "        [[-0.4457]],\n",
      "\n",
      "        [[-1.3300]],\n",
      "\n",
      "        [[-1.3969]],\n",
      "\n",
      "        [[-1.4225]],\n",
      "\n",
      "        [[ 2.4617]],\n",
      "\n",
      "        [[ 1.9782]],\n",
      "\n",
      "        [[ 0.5157]],\n",
      "\n",
      "        [[ 0.3570]],\n",
      "\n",
      "        [[-1.1503]],\n",
      "\n",
      "        [[-1.1134]],\n",
      "\n",
      "        [[ 0.1168]],\n",
      "\n",
      "        [[ 1.9614]],\n",
      "\n",
      "        [[-1.6661]],\n",
      "\n",
      "        [[ 0.1225]],\n",
      "\n",
      "        [[-0.1302]],\n",
      "\n",
      "        [[ 0.4039]],\n",
      "\n",
      "        [[ 0.1575]],\n",
      "\n",
      "        [[ 0.3719]],\n",
      "\n",
      "        [[ 0.2412]],\n",
      "\n",
      "        [[-1.4947]],\n",
      "\n",
      "        [[ 2.0998]],\n",
      "\n",
      "        [[ 0.9922]],\n",
      "\n",
      "        [[ 1.2446]],\n",
      "\n",
      "        [[ 1.0967]],\n",
      "\n",
      "        [[-0.6955]],\n",
      "\n",
      "        [[-0.2643]],\n",
      "\n",
      "        [[ 2.5121]],\n",
      "\n",
      "        [[-0.3823]],\n",
      "\n",
      "        [[-0.7976]],\n",
      "\n",
      "        [[-0.1914]],\n",
      "\n",
      "        [[ 1.4725]],\n",
      "\n",
      "        [[ 0.7689]],\n",
      "\n",
      "        [[-0.6400]],\n",
      "\n",
      "        [[ 0.9067]],\n",
      "\n",
      "        [[ 0.0885]],\n",
      "\n",
      "        [[-1.3791]],\n",
      "\n",
      "        [[-0.6576]],\n",
      "\n",
      "        [[ 1.5824]],\n",
      "\n",
      "        [[-0.7582]],\n",
      "\n",
      "        [[-0.2440]],\n",
      "\n",
      "        [[ 0.1722]],\n",
      "\n",
      "        [[ 1.1844]],\n",
      "\n",
      "        [[-0.7018]],\n",
      "\n",
      "        [[-0.6535]],\n",
      "\n",
      "        [[ 0.8954]],\n",
      "\n",
      "        [[-1.1418]],\n",
      "\n",
      "        [[-0.9081]],\n",
      "\n",
      "        [[ 0.2837]],\n",
      "\n",
      "        [[ 1.0508]],\n",
      "\n",
      "        [[-0.2056]],\n",
      "\n",
      "        [[-0.6812]],\n",
      "\n",
      "        [[ 0.6463]],\n",
      "\n",
      "        [[-0.5282]],\n",
      "\n",
      "        [[ 0.3223]],\n",
      "\n",
      "        [[-0.0393]],\n",
      "\n",
      "        [[ 0.1812]],\n",
      "\n",
      "        [[ 0.8668]],\n",
      "\n",
      "        [[-0.6210]],\n",
      "\n",
      "        [[-1.2067]],\n",
      "\n",
      "        [[ 0.6031]],\n",
      "\n",
      "        [[-0.5371]],\n",
      "\n",
      "        [[ 0.0024]],\n",
      "\n",
      "        [[-0.2501]],\n",
      "\n",
      "        [[-0.6952]],\n",
      "\n",
      "        [[-1.7631]],\n",
      "\n",
      "        [[ 0.7172]],\n",
      "\n",
      "        [[-0.4884]],\n",
      "\n",
      "        [[ 0.7466]],\n",
      "\n",
      "        [[ 1.4456]],\n",
      "\n",
      "        [[ 0.5667]],\n",
      "\n",
      "        [[-0.2170]],\n",
      "\n",
      "        [[-0.2944]],\n",
      "\n",
      "        [[ 1.0923]],\n",
      "\n",
      "        [[-0.6426]],\n",
      "\n",
      "        [[-0.5423]],\n",
      "\n",
      "        [[ 1.6407]],\n",
      "\n",
      "        [[-0.5628]],\n",
      "\n",
      "        [[-0.1414]],\n",
      "\n",
      "        [[ 1.7061]],\n",
      "\n",
      "        [[ 0.0774]],\n",
      "\n",
      "        [[-0.5583]],\n",
      "\n",
      "        [[ 1.1752]],\n",
      "\n",
      "        [[-0.2879]],\n",
      "\n",
      "        [[ 0.4245]],\n",
      "\n",
      "        [[ 0.7912]],\n",
      "\n",
      "        [[ 0.1672]],\n",
      "\n",
      "        [[-1.4349]],\n",
      "\n",
      "        [[-0.7821]],\n",
      "\n",
      "        [[-0.7587]],\n",
      "\n",
      "        [[-1.6291]],\n",
      "\n",
      "        [[ 0.7618]],\n",
      "\n",
      "        [[-0.2913]],\n",
      "\n",
      "        [[-0.1859]],\n",
      "\n",
      "        [[-0.1378]],\n",
      "\n",
      "        [[-0.8250]],\n",
      "\n",
      "        [[ 0.4674]],\n",
      "\n",
      "        [[ 1.3149]],\n",
      "\n",
      "        [[-0.8566]],\n",
      "\n",
      "        [[ 0.2035]],\n",
      "\n",
      "        [[ 0.1625]],\n",
      "\n",
      "        [[ 2.1316]],\n",
      "\n",
      "        [[-0.3963]],\n",
      "\n",
      "        [[-0.8862]],\n",
      "\n",
      "        [[-0.7599]],\n",
      "\n",
      "        [[ 0.9808]],\n",
      "\n",
      "        [[ 0.4191]],\n",
      "\n",
      "        [[ 0.9060]],\n",
      "\n",
      "        [[ 1.0460]],\n",
      "\n",
      "        [[-0.0152]],\n",
      "\n",
      "        [[-0.6428]],\n",
      "\n",
      "        [[ 0.0690]],\n",
      "\n",
      "        [[-0.2330]],\n",
      "\n",
      "        [[ 0.4228]],\n",
      "\n",
      "        [[ 0.0084]],\n",
      "\n",
      "        [[-1.2907]],\n",
      "\n",
      "        [[-0.0422]],\n",
      "\n",
      "        [[ 0.8404]],\n",
      "\n",
      "        [[ 2.2103]],\n",
      "\n",
      "        [[ 0.0962]],\n",
      "\n",
      "        [[-2.3615]],\n",
      "\n",
      "        [[-0.3236]],\n",
      "\n",
      "        [[ 0.0785]],\n",
      "\n",
      "        [[-0.6350]],\n",
      "\n",
      "        [[-0.8240]],\n",
      "\n",
      "        [[ 0.3336]],\n",
      "\n",
      "        [[-0.3643]],\n",
      "\n",
      "        [[-0.1284]],\n",
      "\n",
      "        [[ 0.4975]],\n",
      "\n",
      "        [[ 2.2368]],\n",
      "\n",
      "        [[ 0.3305]],\n",
      "\n",
      "        [[-1.9432]],\n",
      "\n",
      "        [[ 0.8056]],\n",
      "\n",
      "        [[-0.7339]],\n",
      "\n",
      "        [[-0.2947]],\n",
      "\n",
      "        [[-0.3243]],\n",
      "\n",
      "        [[ 0.3575]],\n",
      "\n",
      "        [[-0.4567]],\n",
      "\n",
      "        [[ 0.1324]],\n",
      "\n",
      "        [[ 2.3190]],\n",
      "\n",
      "        [[ 0.3444]],\n",
      "\n",
      "        [[-0.5736]],\n",
      "\n",
      "        [[ 1.3145]],\n",
      "\n",
      "        [[ 1.6479]],\n",
      "\n",
      "        [[ 0.0549]],\n",
      "\n",
      "        [[-1.5627]],\n",
      "\n",
      "        [[-0.2135]],\n",
      "\n",
      "        [[-0.6456]],\n",
      "\n",
      "        [[ 1.1310]],\n",
      "\n",
      "        [[-0.1044]],\n",
      "\n",
      "        [[-0.9808]],\n",
      "\n",
      "        [[-0.9395]],\n",
      "\n",
      "        [[-1.5398]],\n",
      "\n",
      "        [[-1.4379]],\n",
      "\n",
      "        [[ 0.7677]],\n",
      "\n",
      "        [[-0.7253]],\n",
      "\n",
      "        [[-0.7425]],\n",
      "\n",
      "        [[ 1.0452]],\n",
      "\n",
      "        [[ 0.0441]],\n",
      "\n",
      "        [[ 0.5690]],\n",
      "\n",
      "        [[ 0.1160]],\n",
      "\n",
      "        [[-0.2426]],\n",
      "\n",
      "        [[ 0.5441]],\n",
      "\n",
      "        [[-0.2989]],\n",
      "\n",
      "        [[-0.7497]],\n",
      "\n",
      "        [[-0.3687]],\n",
      "\n",
      "        [[-0.6773]],\n",
      "\n",
      "        [[-0.3918]],\n",
      "\n",
      "        [[ 0.3661]],\n",
      "\n",
      "        [[-0.0775]],\n",
      "\n",
      "        [[-0.3989]],\n",
      "\n",
      "        [[-1.4201]],\n",
      "\n",
      "        [[-1.3329]],\n",
      "\n",
      "        [[ 1.3773]],\n",
      "\n",
      "        [[-1.0640]],\n",
      "\n",
      "        [[-0.4165]],\n",
      "\n",
      "        [[-0.2523]],\n",
      "\n",
      "        [[ 0.7906]],\n",
      "\n",
      "        [[-0.3122]],\n",
      "\n",
      "        [[ 0.1853]],\n",
      "\n",
      "        [[-1.3106]],\n",
      "\n",
      "        [[-0.6209]],\n",
      "\n",
      "        [[-0.0660]],\n",
      "\n",
      "        [[ 1.9740]],\n",
      "\n",
      "        [[-0.2046]],\n",
      "\n",
      "        [[ 1.5117]],\n",
      "\n",
      "        [[-0.5302]],\n",
      "\n",
      "        [[-0.2794]],\n",
      "\n",
      "        [[-0.8303]],\n",
      "\n",
      "        [[ 1.0483]],\n",
      "\n",
      "        [[ 0.6492]],\n",
      "\n",
      "        [[ 0.9675]],\n",
      "\n",
      "        [[-0.0182]],\n",
      "\n",
      "        [[ 1.3125]],\n",
      "\n",
      "        [[ 0.0720]],\n",
      "\n",
      "        [[ 0.9638]],\n",
      "\n",
      "        [[-1.2596]],\n",
      "\n",
      "        [[-0.0345]],\n",
      "\n",
      "        [[ 1.3990]],\n",
      "\n",
      "        [[ 0.3043]],\n",
      "\n",
      "        [[ 0.6722]],\n",
      "\n",
      "        [[ 0.4818]],\n",
      "\n",
      "        [[ 1.1051]],\n",
      "\n",
      "        [[ 0.1354]],\n",
      "\n",
      "        [[ 0.5965]],\n",
      "\n",
      "        [[-0.3978]],\n",
      "\n",
      "        [[-0.1738]],\n",
      "\n",
      "        [[-0.7632]],\n",
      "\n",
      "        [[-0.7474]],\n",
      "\n",
      "        [[ 1.8302]],\n",
      "\n",
      "        [[ 1.0846]],\n",
      "\n",
      "        [[-0.5566]],\n",
      "\n",
      "        [[ 0.4532]],\n",
      "\n",
      "        [[ 0.3868]],\n",
      "\n",
      "        [[-0.6832]],\n",
      "\n",
      "        [[ 0.2711]],\n",
      "\n",
      "        [[-1.3956]],\n",
      "\n",
      "        [[ 2.1123]],\n",
      "\n",
      "        [[-0.8637]],\n",
      "\n",
      "        [[-0.1244]],\n",
      "\n",
      "        [[-0.2533]],\n",
      "\n",
      "        [[ 1.8648]],\n",
      "\n",
      "        [[ 0.2238]],\n",
      "\n",
      "        [[-1.4841]],\n",
      "\n",
      "        [[ 0.1484]],\n",
      "\n",
      "        [[-0.4474]],\n",
      "\n",
      "        [[-0.4447]],\n",
      "\n",
      "        [[ 0.2212]],\n",
      "\n",
      "        [[-0.9555]],\n",
      "\n",
      "        [[-1.3253]],\n",
      "\n",
      "        [[ 0.1869]],\n",
      "\n",
      "        [[-1.2503]],\n",
      "\n",
      "        [[-0.5810]],\n",
      "\n",
      "        [[-2.6321]],\n",
      "\n",
      "        [[-0.7204]],\n",
      "\n",
      "        [[ 0.3307]],\n",
      "\n",
      "        [[-0.1747]],\n",
      "\n",
      "        [[-1.0379]],\n",
      "\n",
      "        [[ 0.1365]],\n",
      "\n",
      "        [[ 0.4044]],\n",
      "\n",
      "        [[ 1.3231]],\n",
      "\n",
      "        [[-1.8208]],\n",
      "\n",
      "        [[-0.0291]],\n",
      "\n",
      "        [[ 0.7809]],\n",
      "\n",
      "        [[-0.0932]],\n",
      "\n",
      "        [[ 0.6352]],\n",
      "\n",
      "        [[ 1.3960]],\n",
      "\n",
      "        [[-0.9704]],\n",
      "\n",
      "        [[-0.1693]],\n",
      "\n",
      "        [[ 1.1788]],\n",
      "\n",
      "        [[-0.8834]],\n",
      "\n",
      "        [[ 1.4065]],\n",
      "\n",
      "        [[-0.2972]],\n",
      "\n",
      "        [[ 0.3608]],\n",
      "\n",
      "        [[ 0.6462]],\n",
      "\n",
      "        [[ 0.6423]],\n",
      "\n",
      "        [[-0.9252]],\n",
      "\n",
      "        [[ 0.9806]],\n",
      "\n",
      "        [[-1.5166]],\n",
      "\n",
      "        [[ 0.0707]],\n",
      "\n",
      "        [[ 2.1091]],\n",
      "\n",
      "        [[-1.2141]],\n",
      "\n",
      "        [[ 0.0254]],\n",
      "\n",
      "        [[-1.8190]],\n",
      "\n",
      "        [[ 1.3290]],\n",
      "\n",
      "        [[ 0.6044]],\n",
      "\n",
      "        [[-0.1408]],\n",
      "\n",
      "        [[ 0.2169]],\n",
      "\n",
      "        [[-1.6529]],\n",
      "\n",
      "        [[-0.1172]],\n",
      "\n",
      "        [[-0.7235]],\n",
      "\n",
      "        [[-1.3083]],\n",
      "\n",
      "        [[-0.5984]],\n",
      "\n",
      "        [[-0.2156]],\n",
      "\n",
      "        [[ 2.5634]],\n",
      "\n",
      "        [[ 0.2160]],\n",
      "\n",
      "        [[ 0.9901]],\n",
      "\n",
      "        [[ 1.5798]],\n",
      "\n",
      "        [[-0.0317]],\n",
      "\n",
      "        [[ 0.4933]],\n",
      "\n",
      "        [[-0.5201]],\n",
      "\n",
      "        [[-0.5500]],\n",
      "\n",
      "        [[-0.7940]],\n",
      "\n",
      "        [[ 0.9777]],\n",
      "\n",
      "        [[ 0.6261]],\n",
      "\n",
      "        [[-0.8704]],\n",
      "\n",
      "        [[-1.8442]],\n",
      "\n",
      "        [[-0.2975]],\n",
      "\n",
      "        [[-0.4173]],\n",
      "\n",
      "        [[ 0.8081]],\n",
      "\n",
      "        [[-0.3613]],\n",
      "\n",
      "        [[ 1.3902]],\n",
      "\n",
      "        [[ 1.1416]],\n",
      "\n",
      "        [[-0.8292]],\n",
      "\n",
      "        [[-0.2122]],\n",
      "\n",
      "        [[ 1.1875]],\n",
      "\n",
      "        [[-1.3461]],\n",
      "\n",
      "        [[ 1.1226]],\n",
      "\n",
      "        [[ 0.6444]],\n",
      "\n",
      "        [[ 0.0395]],\n",
      "\n",
      "        [[ 1.5783]],\n",
      "\n",
      "        [[ 0.5237]],\n",
      "\n",
      "        [[-0.0018]],\n",
      "\n",
      "        [[-1.3305]],\n",
      "\n",
      "        [[-1.9323]],\n",
      "\n",
      "        [[ 0.8968]],\n",
      "\n",
      "        [[-0.2537]],\n",
      "\n",
      "        [[ 0.8964]],\n",
      "\n",
      "        [[ 0.2269]],\n",
      "\n",
      "        [[ 0.2192]],\n",
      "\n",
      "        [[-0.7781]],\n",
      "\n",
      "        [[ 0.9732]],\n",
      "\n",
      "        [[ 0.6959]],\n",
      "\n",
      "        [[ 0.5055]],\n",
      "\n",
      "        [[ 0.6900]],\n",
      "\n",
      "        [[-2.0345]],\n",
      "\n",
      "        [[-0.3938]],\n",
      "\n",
      "        [[-0.7700]],\n",
      "\n",
      "        [[-1.7654]],\n",
      "\n",
      "        [[-0.1973]],\n",
      "\n",
      "        [[ 1.4169]],\n",
      "\n",
      "        [[ 0.2851]],\n",
      "\n",
      "        [[ 0.9902]],\n",
      "\n",
      "        [[-0.8575]],\n",
      "\n",
      "        [[-1.1147]],\n",
      "\n",
      "        [[ 1.4873]],\n",
      "\n",
      "        [[ 1.1465]],\n",
      "\n",
      "        [[-0.3131]],\n",
      "\n",
      "        [[ 0.7491]],\n",
      "\n",
      "        [[-0.6078]],\n",
      "\n",
      "        [[ 0.8677]],\n",
      "\n",
      "        [[-0.1983]],\n",
      "\n",
      "        [[-0.3281]],\n",
      "\n",
      "        [[-1.3838]],\n",
      "\n",
      "        [[ 1.3909]],\n",
      "\n",
      "        [[-0.7156]],\n",
      "\n",
      "        [[ 0.9189]],\n",
      "\n",
      "        [[ 0.2691]],\n",
      "\n",
      "        [[-0.3764]],\n",
      "\n",
      "        [[-0.1996]],\n",
      "\n",
      "        [[-1.3669]],\n",
      "\n",
      "        [[ 0.8342]],\n",
      "\n",
      "        [[-0.7582]],\n",
      "\n",
      "        [[ 0.6392]],\n",
      "\n",
      "        [[-2.0964]],\n",
      "\n",
      "        [[ 0.2986]],\n",
      "\n",
      "        [[-0.9960]],\n",
      "\n",
      "        [[ 0.2742]],\n",
      "\n",
      "        [[ 0.6967]],\n",
      "\n",
      "        [[ 0.3990]],\n",
      "\n",
      "        [[ 1.3896]],\n",
      "\n",
      "        [[-0.3578]],\n",
      "\n",
      "        [[ 0.3444]],\n",
      "\n",
      "        [[ 1.7054]],\n",
      "\n",
      "        [[ 2.3229]],\n",
      "\n",
      "        [[-0.6263]],\n",
      "\n",
      "        [[ 1.4167]],\n",
      "\n",
      "        [[ 0.0125]],\n",
      "\n",
      "        [[-0.1844]],\n",
      "\n",
      "        [[ 1.2182]],\n",
      "\n",
      "        [[-2.2793]],\n",
      "\n",
      "        [[-0.0192]],\n",
      "\n",
      "        [[-0.6445]],\n",
      "\n",
      "        [[-1.3073]],\n",
      "\n",
      "        [[-0.4317]],\n",
      "\n",
      "        [[-0.8446]],\n",
      "\n",
      "        [[ 1.1035]],\n",
      "\n",
      "        [[-0.0088]],\n",
      "\n",
      "        [[ 0.0632]],\n",
      "\n",
      "        [[-0.9217]],\n",
      "\n",
      "        [[ 1.1308]],\n",
      "\n",
      "        [[-0.5764]],\n",
      "\n",
      "        [[-0.9107]],\n",
      "\n",
      "        [[-1.3882]],\n",
      "\n",
      "        [[-1.1022]],\n",
      "\n",
      "        [[-0.4184]],\n",
      "\n",
      "        [[ 0.8664]],\n",
      "\n",
      "        [[ 1.4978]],\n",
      "\n",
      "        [[-0.6893]],\n",
      "\n",
      "        [[-0.1575]],\n",
      "\n",
      "        [[-0.8791]],\n",
      "\n",
      "        [[ 0.0357]],\n",
      "\n",
      "        [[-0.2748]],\n",
      "\n",
      "        [[-0.6009]],\n",
      "\n",
      "        [[ 0.4581]],\n",
      "\n",
      "        [[ 1.2415]],\n",
      "\n",
      "        [[-0.6360]],\n",
      "\n",
      "        [[-0.3831]],\n",
      "\n",
      "        [[-0.3300]],\n",
      "\n",
      "        [[ 1.2772]],\n",
      "\n",
      "        [[ 0.6392]],\n",
      "\n",
      "        [[ 1.3423]],\n",
      "\n",
      "        [[ 0.1526]],\n",
      "\n",
      "        [[ 0.2220]],\n",
      "\n",
      "        [[-2.2319]],\n",
      "\n",
      "        [[ 1.0270]],\n",
      "\n",
      "        [[ 0.0080]],\n",
      "\n",
      "        [[ 1.6572]],\n",
      "\n",
      "        [[ 0.6790]],\n",
      "\n",
      "        [[ 3.7140]],\n",
      "\n",
      "        [[-0.0172]],\n",
      "\n",
      "        [[ 0.2775]],\n",
      "\n",
      "        [[ 0.2381]],\n",
      "\n",
      "        [[-0.4341]],\n",
      "\n",
      "        [[-0.3259]],\n",
      "\n",
      "        [[ 0.9397]],\n",
      "\n",
      "        [[-1.6278]],\n",
      "\n",
      "        [[-0.4798]],\n",
      "\n",
      "        [[ 0.7075]],\n",
      "\n",
      "        [[ 1.7660]],\n",
      "\n",
      "        [[ 1.2734]],\n",
      "\n",
      "        [[-1.0302]],\n",
      "\n",
      "        [[ 0.3579]],\n",
      "\n",
      "        [[ 1.0976]],\n",
      "\n",
      "        [[-0.4598]],\n",
      "\n",
      "        [[-0.2246]],\n",
      "\n",
      "        [[-0.0528]],\n",
      "\n",
      "        [[-0.8122]],\n",
      "\n",
      "        [[ 0.6628]]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor(1.00000e-03 *\n",
      "       [[[-8.9248]]], device='cuda:0')\n",
      "torch.Size([1, 448, 512])\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 1.9530,  1.9531,  1.9531,  ...,  1.9531,  1.9532,  1.9531],\n",
      "         [ 1.9529,  1.9529,  1.9529,  ...,  1.9531,  1.9531,  1.9529],\n",
      "         [ 1.9531,  1.9531,  1.9532,  ...,  1.9532,  1.9532,  1.9532],\n",
      "         ...,\n",
      "         [ 1.9531,  1.9531,  1.9532,  ...,  1.9533,  1.9530,  1.9532],\n",
      "         [ 1.9532,  1.9533,  1.9532,  ...,  1.9529,  1.9531,  1.9531],\n",
      "         [ 1.9531,  1.9531,  1.9531,  ...,  1.9530,  1.9530,  1.9531]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 60 [34560/50000 (77%)]\tLoss: 0.114017, Accuracy: 95.70\n",
      "Train Epoch: 60 [35840/50000 (80%)]\tLoss: 0.083394, Accuracy: 97.66\n",
      "Train Epoch: 60 [37120/50000 (82%)]\tLoss: 0.098044, Accuracy: 97.66\n",
      "Train Epoch: 60 [38400/50000 (85%)]\tLoss: 0.084954, Accuracy: 96.88\n",
      "Train Epoch: 60 [39680/50000 (88%)]\tLoss: 0.044862, Accuracy: 98.83\n",
      "Train Epoch: 60 [40960/50000 (91%)]\tLoss: 0.187623, Accuracy: 93.36\n",
      "Train Epoch: 60 [42240/50000 (94%)]\tLoss: 0.133876, Accuracy: 96.09\n",
      "Train Epoch: 60 [43520/50000 (97%)]\tLoss: 0.112207, Accuracy: 97.27\n",
      "Train Epoch: 60 [35000/50000 (99%)]\tLoss: 0.131226, Accuracy: 95.00\n",
      "\n",
      "Validation set: Average loss: 0.2866, Accuracy: 4566/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[37.819961071014404 s]\n",
      "\n",
      "Test set: Average loss: 0.3020, Accuracy: 9108/10000 (91.08%)\n",
      "\n",
      "Train Epoch: 61 [0/50000 (0%)]\tLoss: 0.117340, Accuracy: 95.31\n",
      "Train Epoch: 61 [1280/50000 (3%)]\tLoss: 0.113414, Accuracy: 96.48\n",
      "Train Epoch: 61 [2560/50000 (6%)]\tLoss: 0.087039, Accuracy: 96.48\n",
      "Train Epoch: 61 [3840/50000 (9%)]\tLoss: 0.113109, Accuracy: 96.09\n",
      "Train Epoch: 61 [5120/50000 (11%)]\tLoss: 0.179763, Accuracy: 92.58\n",
      "Train Epoch: 61 [6400/50000 (14%)]\tLoss: 0.100995, Accuracy: 95.70\n",
      "Train Epoch: 61 [7680/50000 (17%)]\tLoss: 0.121073, Accuracy: 95.70\n",
      "Train Epoch: 61 [8960/50000 (20%)]\tLoss: 0.126331, Accuracy: 95.31\n",
      "Train Epoch: 61 [10240/50000 (23%)]\tLoss: 0.114638, Accuracy: 95.31\n",
      "Train Epoch: 61 [11520/50000 (26%)]\tLoss: 0.068239, Accuracy: 98.44\n",
      "Train Epoch: 61 [12800/50000 (28%)]\tLoss: 0.133997, Accuracy: 94.92\n",
      "Train Epoch: 61 [14080/50000 (31%)]\tLoss: 0.087942, Accuracy: 97.66\n",
      "Train Epoch: 61 [15360/50000 (34%)]\tLoss: 0.102724, Accuracy: 97.27\n",
      "Train Epoch: 61 [16640/50000 (37%)]\tLoss: 0.165265, Accuracy: 94.53\n",
      "Train Epoch: 61 [17920/50000 (40%)]\tLoss: 0.104546, Accuracy: 95.70\n",
      "Train Epoch: 61 [19200/50000 (43%)]\tLoss: 0.083255, Accuracy: 96.48\n",
      "Train Epoch: 61 [20480/50000 (45%)]\tLoss: 0.096032, Accuracy: 96.88\n",
      "Train Epoch: 61 [21760/50000 (48%)]\tLoss: 0.099475, Accuracy: 96.88\n",
      "Train Epoch: 61 [23040/50000 (51%)]\tLoss: 0.160603, Accuracy: 92.97\n",
      "Train Epoch: 61 [24320/50000 (54%)]\tLoss: 0.134655, Accuracy: 94.53\n",
      "Train Epoch: 61 [25600/50000 (57%)]\tLoss: 0.083953, Accuracy: 96.48\n",
      "Train Epoch: 61 [26880/50000 (60%)]\tLoss: 0.079551, Accuracy: 98.05\n",
      "Train Epoch: 61 [28160/50000 (62%)]\tLoss: 0.077521, Accuracy: 98.44\n",
      "Train Epoch: 61 [29440/50000 (65%)]\tLoss: 0.076244, Accuracy: 98.05\n",
      "Train Epoch: 61 [30720/50000 (68%)]\tLoss: 0.157453, Accuracy: 94.92\n",
      "Train Epoch: 61 [32000/50000 (71%)]\tLoss: 0.113685, Accuracy: 97.66\n",
      "Train Epoch: 61 [33280/50000 (74%)]\tLoss: 0.072164, Accuracy: 98.05\n",
      "Train Epoch: 61 [34560/50000 (77%)]\tLoss: 0.144367, Accuracy: 96.09\n",
      "Train Epoch: 61 [35840/50000 (80%)]\tLoss: 0.097524, Accuracy: 95.31\n",
      "Train Epoch: 61 [37120/50000 (82%)]\tLoss: 0.065863, Accuracy: 98.05\n",
      "Train Epoch: 61 [38400/50000 (85%)]\tLoss: 0.135808, Accuracy: 96.09\n",
      "Train Epoch: 61 [39680/50000 (88%)]\tLoss: 0.137475, Accuracy: 95.70\n",
      "Train Epoch: 61 [40960/50000 (91%)]\tLoss: 0.074502, Accuracy: 97.66\n",
      "Train Epoch: 61 [42240/50000 (94%)]\tLoss: 0.120708, Accuracy: 95.70\n",
      "Train Epoch: 61 [43520/50000 (97%)]\tLoss: 0.088955, Accuracy: 96.09\n",
      "Train Epoch: 61 [35000/50000 (99%)]\tLoss: 0.148545, Accuracy: 94.50\n",
      "\n",
      "Validation set: Average loss: 0.2968, Accuracy: 4544/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[41.016956090927124 s]\n",
      "Train Epoch: 62 [0/50000 (0%)]\tLoss: 0.132571, Accuracy: 96.48\n",
      "Train Epoch: 62 [1280/50000 (3%)]\tLoss: 0.111572, Accuracy: 96.48\n",
      "Train Epoch: 62 [2560/50000 (6%)]\tLoss: 0.051252, Accuracy: 98.83\n",
      "Train Epoch: 62 [3840/50000 (9%)]\tLoss: 0.107031, Accuracy: 96.48\n",
      "Train Epoch: 62 [5120/50000 (11%)]\tLoss: 0.107134, Accuracy: 97.66\n",
      "Train Epoch: 62 [6400/50000 (14%)]\tLoss: 0.087647, Accuracy: 97.27\n",
      "Train Epoch: 62 [7680/50000 (17%)]\tLoss: 0.133002, Accuracy: 95.70\n",
      "Train Epoch: 62 [8960/50000 (20%)]\tLoss: 0.070128, Accuracy: 98.83\n",
      "Train Epoch: 62 [10240/50000 (23%)]\tLoss: 0.073321, Accuracy: 97.66\n",
      "Train Epoch: 62 [11520/50000 (26%)]\tLoss: 0.074677, Accuracy: 97.66\n",
      "Train Epoch: 62 [12800/50000 (28%)]\tLoss: 0.075195, Accuracy: 98.44\n",
      "Train Epoch: 62 [14080/50000 (31%)]\tLoss: 0.131728, Accuracy: 96.48\n",
      "Train Epoch: 62 [15360/50000 (34%)]\tLoss: 0.094921, Accuracy: 96.88\n",
      "Train Epoch: 62 [16640/50000 (37%)]\tLoss: 0.078641, Accuracy: 98.05\n",
      "Train Epoch: 62 [17920/50000 (40%)]\tLoss: 0.150562, Accuracy: 96.09\n",
      "Train Epoch: 62 [19200/50000 (43%)]\tLoss: 0.074445, Accuracy: 98.05\n",
      "Train Epoch: 62 [20480/50000 (45%)]\tLoss: 0.097670, Accuracy: 96.48\n",
      "Train Epoch: 62 [21760/50000 (48%)]\tLoss: 0.103844, Accuracy: 96.88\n",
      "Train Epoch: 62 [23040/50000 (51%)]\tLoss: 0.075173, Accuracy: 97.66\n",
      "Train Epoch: 62 [24320/50000 (54%)]\tLoss: 0.086509, Accuracy: 97.27\n",
      "Train Epoch: 62 [25600/50000 (57%)]\tLoss: 0.093079, Accuracy: 96.88\n",
      "Train Epoch: 62 [26880/50000 (60%)]\tLoss: 0.079558, Accuracy: 96.48\n",
      "Train Epoch: 62 [28160/50000 (62%)]\tLoss: 0.053776, Accuracy: 98.05\n",
      "Train Epoch: 62 [29440/50000 (65%)]\tLoss: 0.093510, Accuracy: 97.27\n",
      "Train Epoch: 62 [30720/50000 (68%)]\tLoss: 0.152613, Accuracy: 94.53\n",
      "Train Epoch: 62 [32000/50000 (71%)]\tLoss: 0.132229, Accuracy: 94.92\n",
      "Train Epoch: 62 [33280/50000 (74%)]\tLoss: 0.106906, Accuracy: 96.88\n",
      "Train Epoch: 62 [34560/50000 (77%)]\tLoss: 0.068755, Accuracy: 97.66\n",
      "Train Epoch: 62 [35840/50000 (80%)]\tLoss: 0.097406, Accuracy: 96.09\n",
      "Train Epoch: 62 [37120/50000 (82%)]\tLoss: 0.099517, Accuracy: 96.88\n",
      "Train Epoch: 62 [38400/50000 (85%)]\tLoss: 0.133729, Accuracy: 96.48\n",
      "Train Epoch: 62 [39680/50000 (88%)]\tLoss: 0.117804, Accuracy: 96.09\n",
      "Train Epoch: 62 [40960/50000 (91%)]\tLoss: 0.107519, Accuracy: 96.48\n",
      "Train Epoch: 62 [42240/50000 (94%)]\tLoss: 0.152209, Accuracy: 96.09\n",
      "Train Epoch: 62 [43520/50000 (97%)]\tLoss: 0.131544, Accuracy: 95.70\n",
      "Train Epoch: 62 [35000/50000 (99%)]\tLoss: 0.097119, Accuracy: 96.50\n",
      "\n",
      "Validation set: Average loss: 0.3025, Accuracy: 4556/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[37.708208322525024 s]\n",
      "\n",
      "Test set: Average loss: 0.3059, Accuracy: 9076/10000 (90.76%)\n",
      "\n",
      "Train Epoch: 63 [0/50000 (0%)]\tLoss: 0.034741, Accuracy: 99.22\n",
      "Train Epoch: 63 [1280/50000 (3%)]\tLoss: 0.110945, Accuracy: 94.92\n",
      "Train Epoch: 63 [2560/50000 (6%)]\tLoss: 0.100597, Accuracy: 95.31\n",
      "Train Epoch: 63 [3840/50000 (9%)]\tLoss: 0.084412, Accuracy: 96.88\n",
      "Train Epoch: 63 [5120/50000 (11%)]\tLoss: 0.095622, Accuracy: 96.09\n",
      "Train Epoch: 63 [6400/50000 (14%)]\tLoss: 0.149467, Accuracy: 95.70\n",
      "Train Epoch: 63 [7680/50000 (17%)]\tLoss: 0.108242, Accuracy: 96.88\n",
      "Train Epoch: 63 [8960/50000 (20%)]\tLoss: 0.102717, Accuracy: 96.88\n",
      "Train Epoch: 63 [10240/50000 (23%)]\tLoss: 0.085722, Accuracy: 97.27\n",
      "Train Epoch: 63 [11520/50000 (26%)]\tLoss: 0.078019, Accuracy: 98.44\n",
      "Train Epoch: 63 [12800/50000 (28%)]\tLoss: 0.117064, Accuracy: 96.09\n",
      "Train Epoch: 63 [14080/50000 (31%)]\tLoss: 0.095377, Accuracy: 97.27\n",
      "Train Epoch: 63 [15360/50000 (34%)]\tLoss: 0.123353, Accuracy: 95.31\n",
      "Train Epoch: 63 [16640/50000 (37%)]\tLoss: 0.083087, Accuracy: 97.27\n",
      "Train Epoch: 63 [17920/50000 (40%)]\tLoss: 0.098110, Accuracy: 96.09\n",
      "Train Epoch: 63 [19200/50000 (43%)]\tLoss: 0.100665, Accuracy: 96.48\n",
      "Train Epoch: 63 [20480/50000 (45%)]\tLoss: 0.076339, Accuracy: 98.44\n",
      "Train Epoch: 63 [21760/50000 (48%)]\tLoss: 0.066552, Accuracy: 97.66\n",
      "Train Epoch: 63 [23040/50000 (51%)]\tLoss: 0.143990, Accuracy: 95.70\n",
      "Train Epoch: 63 [24320/50000 (54%)]\tLoss: 0.107105, Accuracy: 96.88\n",
      "Train Epoch: 63 [25600/50000 (57%)]\tLoss: 0.102282, Accuracy: 95.70\n",
      "Train Epoch: 63 [26880/50000 (60%)]\tLoss: 0.096506, Accuracy: 96.48\n",
      "Train Epoch: 63 [28160/50000 (62%)]\tLoss: 0.098513, Accuracy: 96.88\n",
      "Train Epoch: 63 [29440/50000 (65%)]\tLoss: 0.087808, Accuracy: 96.88\n",
      "Train Epoch: 63 [30720/50000 (68%)]\tLoss: 0.087909, Accuracy: 96.48\n",
      "Train Epoch: 63 [32000/50000 (71%)]\tLoss: 0.120161, Accuracy: 95.70\n",
      "torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.6536]],\n",
      "\n",
      "        [[-1.5718]],\n",
      "\n",
      "        [[ 2.9293]],\n",
      "\n",
      "        [[ 0.0438]],\n",
      "\n",
      "        [[-0.0494]],\n",
      "\n",
      "        [[-1.1392]],\n",
      "\n",
      "        [[ 0.4124]],\n",
      "\n",
      "        [[ 1.3414]],\n",
      "\n",
      "        [[-0.3718]],\n",
      "\n",
      "        [[-2.5520]],\n",
      "\n",
      "        [[-0.1119]],\n",
      "\n",
      "        [[ 1.0974]],\n",
      "\n",
      "        [[-1.3616]],\n",
      "\n",
      "        [[ 2.3197]],\n",
      "\n",
      "        [[ 0.5302]],\n",
      "\n",
      "        [[-1.2581]],\n",
      "\n",
      "        [[-0.1803]],\n",
      "\n",
      "        [[ 1.6196]],\n",
      "\n",
      "        [[-0.5121]],\n",
      "\n",
      "        [[ 0.6304]],\n",
      "\n",
      "        [[-0.8326]],\n",
      "\n",
      "        [[ 0.8422]],\n",
      "\n",
      "        [[-0.7765]],\n",
      "\n",
      "        [[-2.0039]],\n",
      "\n",
      "        [[ 0.6685]],\n",
      "\n",
      "        [[ 2.2394]],\n",
      "\n",
      "        [[-0.1057]],\n",
      "\n",
      "        [[ 0.5011]],\n",
      "\n",
      "        [[ 0.1540]],\n",
      "\n",
      "        [[-0.5604]],\n",
      "\n",
      "        [[ 0.4553]],\n",
      "\n",
      "        [[-1.7948]],\n",
      "\n",
      "        [[-0.3101]],\n",
      "\n",
      "        [[-0.0655]],\n",
      "\n",
      "        [[-0.6533]],\n",
      "\n",
      "        [[-0.4618]],\n",
      "\n",
      "        [[-0.6924]],\n",
      "\n",
      "        [[-0.5789]],\n",
      "\n",
      "        [[-0.6567]],\n",
      "\n",
      "        [[ 1.6536]],\n",
      "\n",
      "        [[-0.6849]],\n",
      "\n",
      "        [[-1.7326]],\n",
      "\n",
      "        [[-1.3871]],\n",
      "\n",
      "        [[-0.8713]],\n",
      "\n",
      "        [[ 0.6137]],\n",
      "\n",
      "        [[ 0.1239]],\n",
      "\n",
      "        [[-0.1285]],\n",
      "\n",
      "        [[ 0.5471]],\n",
      "\n",
      "        [[-0.1950]],\n",
      "\n",
      "        [[ 0.3916]],\n",
      "\n",
      "        [[-1.8812]],\n",
      "\n",
      "        [[-1.7435]],\n",
      "\n",
      "        [[-0.8447]],\n",
      "\n",
      "        [[ 0.7622]],\n",
      "\n",
      "        [[ 0.3447]],\n",
      "\n",
      "        [[-0.7728]],\n",
      "\n",
      "        [[-0.9424]],\n",
      "\n",
      "        [[-0.5435]],\n",
      "\n",
      "        [[-2.0381]],\n",
      "\n",
      "        [[-0.5532]],\n",
      "\n",
      "        [[-2.5178]],\n",
      "\n",
      "        [[-1.4196]],\n",
      "\n",
      "        [[ 1.1121]],\n",
      "\n",
      "        [[ 2.9022]],\n",
      "\n",
      "        [[-0.3351]],\n",
      "\n",
      "        [[ 1.4436]],\n",
      "\n",
      "        [[ 0.7425]],\n",
      "\n",
      "        [[ 0.2156]],\n",
      "\n",
      "        [[ 0.2690]],\n",
      "\n",
      "        [[-0.3171]],\n",
      "\n",
      "        [[ 0.5777]],\n",
      "\n",
      "        [[-1.1242]],\n",
      "\n",
      "        [[ 0.8832]],\n",
      "\n",
      "        [[-0.1737]],\n",
      "\n",
      "        [[ 0.2353]],\n",
      "\n",
      "        [[-1.3276]],\n",
      "\n",
      "        [[-0.0523]],\n",
      "\n",
      "        [[ 1.2205]],\n",
      "\n",
      "        [[-1.6590]],\n",
      "\n",
      "        [[ 0.2820]],\n",
      "\n",
      "        [[-1.0446]],\n",
      "\n",
      "        [[ 0.8183]],\n",
      "\n",
      "        [[-0.8485]],\n",
      "\n",
      "        [[-1.1609]],\n",
      "\n",
      "        [[-1.6809]],\n",
      "\n",
      "        [[ 1.0544]],\n",
      "\n",
      "        [[-0.7999]],\n",
      "\n",
      "        [[-0.9423]],\n",
      "\n",
      "        [[-0.3905]],\n",
      "\n",
      "        [[ 0.1354]],\n",
      "\n",
      "        [[ 0.0938]],\n",
      "\n",
      "        [[-0.1083]],\n",
      "\n",
      "        [[-2.2944]],\n",
      "\n",
      "        [[-1.9168]],\n",
      "\n",
      "        [[-0.6096]],\n",
      "\n",
      "        [[ 1.1870]],\n",
      "\n",
      "        [[-1.2706]],\n",
      "\n",
      "        [[-0.2241]],\n",
      "\n",
      "        [[ 0.1596]],\n",
      "\n",
      "        [[ 1.1674]],\n",
      "\n",
      "        [[ 1.1183]],\n",
      "\n",
      "        [[ 0.5922]],\n",
      "\n",
      "        [[-2.4155]],\n",
      "\n",
      "        [[-1.2669]],\n",
      "\n",
      "        [[-0.7743]],\n",
      "\n",
      "        [[ 0.1342]],\n",
      "\n",
      "        [[ 0.9171]],\n",
      "\n",
      "        [[ 1.4331]],\n",
      "\n",
      "        [[ 0.0693]],\n",
      "\n",
      "        [[ 0.6060]],\n",
      "\n",
      "        [[ 0.3635]],\n",
      "\n",
      "        [[-0.0041]],\n",
      "\n",
      "        [[ 0.7651]],\n",
      "\n",
      "        [[-1.0061]],\n",
      "\n",
      "        [[-0.9229]],\n",
      "\n",
      "        [[-1.1608]],\n",
      "\n",
      "        [[-1.7352]],\n",
      "\n",
      "        [[ 2.7611]],\n",
      "\n",
      "        [[-1.7985]],\n",
      "\n",
      "        [[-1.0314]],\n",
      "\n",
      "        [[-1.3911]],\n",
      "\n",
      "        [[ 0.0198]],\n",
      "\n",
      "        [[-0.2732]],\n",
      "\n",
      "        [[ 0.9645]],\n",
      "\n",
      "        [[ 1.0693]],\n",
      "\n",
      "        [[-0.4627]],\n",
      "\n",
      "        [[-0.3437]],\n",
      "\n",
      "        [[ 1.1224]],\n",
      "\n",
      "        [[ 0.0776]],\n",
      "\n",
      "        [[ 1.1343]],\n",
      "\n",
      "        [[ 0.1720]],\n",
      "\n",
      "        [[ 0.6369]],\n",
      "\n",
      "        [[ 1.6921]],\n",
      "\n",
      "        [[-0.4905]],\n",
      "\n",
      "        [[ 0.5556]],\n",
      "\n",
      "        [[-0.5623]],\n",
      "\n",
      "        [[-0.4388]],\n",
      "\n",
      "        [[-0.5937]],\n",
      "\n",
      "        [[-0.3540]],\n",
      "\n",
      "        [[ 1.1686]],\n",
      "\n",
      "        [[-1.1937]],\n",
      "\n",
      "        [[-0.7901]],\n",
      "\n",
      "        [[-0.7805]],\n",
      "\n",
      "        [[-0.0037]],\n",
      "\n",
      "        [[-0.8064]],\n",
      "\n",
      "        [[ 2.0613]],\n",
      "\n",
      "        [[ 0.0540]],\n",
      "\n",
      "        [[ 1.1330]],\n",
      "\n",
      "        [[ 0.3828]],\n",
      "\n",
      "        [[-1.9544]],\n",
      "\n",
      "        [[ 0.9132]],\n",
      "\n",
      "        [[-0.5394]],\n",
      "\n",
      "        [[-0.1272]],\n",
      "\n",
      "        [[ 1.5403]],\n",
      "\n",
      "        [[-0.3666]],\n",
      "\n",
      "        [[-1.0528]],\n",
      "\n",
      "        [[-0.2025]],\n",
      "\n",
      "        [[ 0.3656]],\n",
      "\n",
      "        [[ 1.1924]],\n",
      "\n",
      "        [[ 0.5552]],\n",
      "\n",
      "        [[ 0.7202]],\n",
      "\n",
      "        [[-1.0322]],\n",
      "\n",
      "        [[ 0.8150]],\n",
      "\n",
      "        [[-0.5467]],\n",
      "\n",
      "        [[ 0.6929]],\n",
      "\n",
      "        [[ 0.7889]],\n",
      "\n",
      "        [[ 0.3370]],\n",
      "\n",
      "        [[-0.0677]],\n",
      "\n",
      "        [[-0.1887]],\n",
      "\n",
      "        [[ 0.6038]],\n",
      "\n",
      "        [[ 1.2714]],\n",
      "\n",
      "        [[-0.3330]],\n",
      "\n",
      "        [[ 0.4155]],\n",
      "\n",
      "        [[ 0.3132]],\n",
      "\n",
      "        [[ 1.0281]],\n",
      "\n",
      "        [[-0.4180]],\n",
      "\n",
      "        [[-0.3800]],\n",
      "\n",
      "        [[-0.4867]],\n",
      "\n",
      "        [[ 1.1619]],\n",
      "\n",
      "        [[-0.1341]],\n",
      "\n",
      "        [[-0.1747]],\n",
      "\n",
      "        [[-0.1675]],\n",
      "\n",
      "        [[-0.7931]],\n",
      "\n",
      "        [[-0.0984]],\n",
      "\n",
      "        [[ 1.8127]],\n",
      "\n",
      "        [[ 1.2770]],\n",
      "\n",
      "        [[ 0.0309]],\n",
      "\n",
      "        [[ 1.3597]],\n",
      "\n",
      "        [[-1.9604]],\n",
      "\n",
      "        [[ 0.4998]],\n",
      "\n",
      "        [[ 1.4175]],\n",
      "\n",
      "        [[-0.7712]],\n",
      "\n",
      "        [[ 1.0394]],\n",
      "\n",
      "        [[-0.6509]],\n",
      "\n",
      "        [[ 0.2125]],\n",
      "\n",
      "        [[-0.6819]],\n",
      "\n",
      "        [[-1.2688]],\n",
      "\n",
      "        [[-0.7078]],\n",
      "\n",
      "        [[-1.5716]],\n",
      "\n",
      "        [[-0.4784]],\n",
      "\n",
      "        [[ 0.8017]],\n",
      "\n",
      "        [[ 0.3898]],\n",
      "\n",
      "        [[-0.2388]],\n",
      "\n",
      "        [[-0.2389]],\n",
      "\n",
      "        [[ 0.6471]],\n",
      "\n",
      "        [[ 0.3345]],\n",
      "\n",
      "        [[-0.4329]],\n",
      "\n",
      "        [[ 0.0331]],\n",
      "\n",
      "        [[ 1.7787]],\n",
      "\n",
      "        [[-0.2840]],\n",
      "\n",
      "        [[-0.3174]],\n",
      "\n",
      "        [[ 0.7826]],\n",
      "\n",
      "        [[-0.1172]],\n",
      "\n",
      "        [[-0.7620]],\n",
      "\n",
      "        [[-2.0987]],\n",
      "\n",
      "        [[-1.1081]],\n",
      "\n",
      "        [[ 2.2007]],\n",
      "\n",
      "        [[ 0.7888]],\n",
      "\n",
      "        [[ 0.5371]],\n",
      "\n",
      "        [[ 0.7090]],\n",
      "\n",
      "        [[ 0.1798]],\n",
      "\n",
      "        [[-1.3844]],\n",
      "\n",
      "        [[-0.3171]],\n",
      "\n",
      "        [[ 0.8809]],\n",
      "\n",
      "        [[ 1.2829]],\n",
      "\n",
      "        [[ 0.0090]],\n",
      "\n",
      "        [[-1.8670]],\n",
      "\n",
      "        [[ 0.5983]],\n",
      "\n",
      "        [[ 0.0929]],\n",
      "\n",
      "        [[ 0.8730]],\n",
      "\n",
      "        [[ 0.5223]],\n",
      "\n",
      "        [[-0.4265]],\n",
      "\n",
      "        [[-0.1350]],\n",
      "\n",
      "        [[ 0.1617]],\n",
      "\n",
      "        [[-0.7066]],\n",
      "\n",
      "        [[ 0.2603]],\n",
      "\n",
      "        [[ 0.5122]],\n",
      "\n",
      "        [[-0.1408]],\n",
      "\n",
      "        [[ 0.3584]],\n",
      "\n",
      "        [[-0.8417]],\n",
      "\n",
      "        [[ 0.2699]],\n",
      "\n",
      "        [[-0.4608]],\n",
      "\n",
      "        [[-1.5351]],\n",
      "\n",
      "        [[-0.3107]],\n",
      "\n",
      "        [[-0.4760]],\n",
      "\n",
      "        [[ 0.2573]],\n",
      "\n",
      "        [[ 0.4154]],\n",
      "\n",
      "        [[-0.4101]],\n",
      "\n",
      "        [[-0.2659]],\n",
      "\n",
      "        [[ 0.3472]],\n",
      "\n",
      "        [[ 0.9164]],\n",
      "\n",
      "        [[ 0.1514]],\n",
      "\n",
      "        [[-0.9048]],\n",
      "\n",
      "        [[ 1.0869]],\n",
      "\n",
      "        [[ 1.1161]],\n",
      "\n",
      "        [[ 0.2052]],\n",
      "\n",
      "        [[ 0.3849]],\n",
      "\n",
      "        [[ 0.6059]],\n",
      "\n",
      "        [[-0.7204]],\n",
      "\n",
      "        [[-0.5193]],\n",
      "\n",
      "        [[ 1.4307]],\n",
      "\n",
      "        [[-2.5830]],\n",
      "\n",
      "        [[-0.4723]],\n",
      "\n",
      "        [[ 0.1668]],\n",
      "\n",
      "        [[ 0.6551]],\n",
      "\n",
      "        [[ 0.2894]],\n",
      "\n",
      "        [[ 0.2536]],\n",
      "\n",
      "        [[-1.4070]],\n",
      "\n",
      "        [[ 0.6297]],\n",
      "\n",
      "        [[-1.1294]],\n",
      "\n",
      "        [[ 0.0301]],\n",
      "\n",
      "        [[-0.2840]],\n",
      "\n",
      "        [[-1.1495]],\n",
      "\n",
      "        [[-0.1991]],\n",
      "\n",
      "        [[ 1.3645]],\n",
      "\n",
      "        [[ 0.9345]],\n",
      "\n",
      "        [[-1.0052]],\n",
      "\n",
      "        [[ 0.8141]],\n",
      "\n",
      "        [[ 0.6569]],\n",
      "\n",
      "        [[ 0.3533]],\n",
      "\n",
      "        [[ 0.1452]],\n",
      "\n",
      "        [[-2.0339]],\n",
      "\n",
      "        [[-1.5064]],\n",
      "\n",
      "        [[-1.3992]],\n",
      "\n",
      "        [[ 0.8355]],\n",
      "\n",
      "        [[-1.1521]],\n",
      "\n",
      "        [[ 0.4459]],\n",
      "\n",
      "        [[-0.3978]],\n",
      "\n",
      "        [[-1.4186]],\n",
      "\n",
      "        [[ 1.1900]],\n",
      "\n",
      "        [[ 0.8012]],\n",
      "\n",
      "        [[-0.9842]],\n",
      "\n",
      "        [[ 0.2963]],\n",
      "\n",
      "        [[ 1.3365]],\n",
      "\n",
      "        [[-0.4092]],\n",
      "\n",
      "        [[-0.1672]],\n",
      "\n",
      "        [[-0.0589]],\n",
      "\n",
      "        [[-0.1659]],\n",
      "\n",
      "        [[ 0.8030]],\n",
      "\n",
      "        [[-0.2986]],\n",
      "\n",
      "        [[-0.6182]],\n",
      "\n",
      "        [[ 0.5098]],\n",
      "\n",
      "        [[-0.5257]],\n",
      "\n",
      "        [[ 1.1543]],\n",
      "\n",
      "        [[ 0.0340]],\n",
      "\n",
      "        [[ 0.1502]],\n",
      "\n",
      "        [[-0.0687]],\n",
      "\n",
      "        [[-0.1905]],\n",
      "\n",
      "        [[-0.7021]],\n",
      "\n",
      "        [[-0.6011]],\n",
      "\n",
      "        [[ 0.4760]],\n",
      "\n",
      "        [[-0.7613]],\n",
      "\n",
      "        [[-0.2116]],\n",
      "\n",
      "        [[ 1.3112]],\n",
      "\n",
      "        [[-0.2163]],\n",
      "\n",
      "        [[ 0.6534]],\n",
      "\n",
      "        [[ 1.0814]],\n",
      "\n",
      "        [[-2.2302]],\n",
      "\n",
      "        [[ 0.4859]],\n",
      "\n",
      "        [[ 0.5917]],\n",
      "\n",
      "        [[-0.1543]],\n",
      "\n",
      "        [[-2.1691]],\n",
      "\n",
      "        [[ 1.8545]],\n",
      "\n",
      "        [[-0.7268]],\n",
      "\n",
      "        [[-1.1098]],\n",
      "\n",
      "        [[ 1.0395]],\n",
      "\n",
      "        [[-0.4622]],\n",
      "\n",
      "        [[ 0.4654]],\n",
      "\n",
      "        [[ 0.2699]],\n",
      "\n",
      "        [[ 0.0456]],\n",
      "\n",
      "        [[ 0.8941]],\n",
      "\n",
      "        [[-1.0758]],\n",
      "\n",
      "        [[-0.5329]],\n",
      "\n",
      "        [[-0.5588]],\n",
      "\n",
      "        [[-1.0465]],\n",
      "\n",
      "        [[ 0.5451]],\n",
      "\n",
      "        [[-0.0911]],\n",
      "\n",
      "        [[-0.7414]],\n",
      "\n",
      "        [[ 0.7429]],\n",
      "\n",
      "        [[ 1.3124]],\n",
      "\n",
      "        [[ 0.6516]],\n",
      "\n",
      "        [[-2.0406]],\n",
      "\n",
      "        [[ 0.5160]],\n",
      "\n",
      "        [[ 0.0378]],\n",
      "\n",
      "        [[-0.0697]],\n",
      "\n",
      "        [[ 0.1186]],\n",
      "\n",
      "        [[ 0.6140]],\n",
      "\n",
      "        [[ 0.6677]],\n",
      "\n",
      "        [[-1.6313]],\n",
      "\n",
      "        [[-0.5557]],\n",
      "\n",
      "        [[ 0.9057]],\n",
      "\n",
      "        [[-0.1100]],\n",
      "\n",
      "        [[-0.4571]],\n",
      "\n",
      "        [[-0.6360]],\n",
      "\n",
      "        [[-0.3354]],\n",
      "\n",
      "        [[-1.7908]],\n",
      "\n",
      "        [[-0.6392]],\n",
      "\n",
      "        [[-0.5242]],\n",
      "\n",
      "        [[-0.6686]],\n",
      "\n",
      "        [[-0.0121]],\n",
      "\n",
      "        [[-0.4298]],\n",
      "\n",
      "        [[-0.1811]],\n",
      "\n",
      "        [[ 0.5397]],\n",
      "\n",
      "        [[ 1.5301]],\n",
      "\n",
      "        [[-0.5723]],\n",
      "\n",
      "        [[-0.0421]],\n",
      "\n",
      "        [[ 0.6827]],\n",
      "\n",
      "        [[ 1.1685]],\n",
      "\n",
      "        [[ 0.7476]],\n",
      "\n",
      "        [[ 0.6390]],\n",
      "\n",
      "        [[-0.9265]],\n",
      "\n",
      "        [[ 1.3631]],\n",
      "\n",
      "        [[ 0.2928]],\n",
      "\n",
      "        [[ 0.7438]],\n",
      "\n",
      "        [[ 0.9775]],\n",
      "\n",
      "        [[ 1.0450]],\n",
      "\n",
      "        [[ 0.2478]],\n",
      "\n",
      "        [[ 1.1103]],\n",
      "\n",
      "        [[ 0.6005]],\n",
      "\n",
      "        [[-0.1156]],\n",
      "\n",
      "        [[-2.3660]],\n",
      "\n",
      "        [[ 0.8510]],\n",
      "\n",
      "        [[ 1.1894]],\n",
      "\n",
      "        [[ 1.2508]],\n",
      "\n",
      "        [[ 0.3629]],\n",
      "\n",
      "        [[-0.1733]],\n",
      "\n",
      "        [[ 0.3680]],\n",
      "\n",
      "        [[ 0.1282]],\n",
      "\n",
      "        [[-0.9736]],\n",
      "\n",
      "        [[-1.2146]],\n",
      "\n",
      "        [[ 0.9664]],\n",
      "\n",
      "        [[-0.2552]],\n",
      "\n",
      "        [[ 0.3833]],\n",
      "\n",
      "        [[ 2.0916]],\n",
      "\n",
      "        [[-1.3787]],\n",
      "\n",
      "        [[-1.0934]],\n",
      "\n",
      "        [[-0.2071]],\n",
      "\n",
      "        [[ 0.3384]],\n",
      "\n",
      "        [[ 0.2203]],\n",
      "\n",
      "        [[-0.4584]],\n",
      "\n",
      "        [[ 0.5090]],\n",
      "\n",
      "        [[-0.3834]],\n",
      "\n",
      "        [[-1.7752]],\n",
      "\n",
      "        [[-0.2684]],\n",
      "\n",
      "        [[-0.4076]],\n",
      "\n",
      "        [[ 2.0690]],\n",
      "\n",
      "        [[ 0.4578]],\n",
      "\n",
      "        [[-0.5330]],\n",
      "\n",
      "        [[-0.0129]],\n",
      "\n",
      "        [[-1.0982]],\n",
      "\n",
      "        [[-0.3977]],\n",
      "\n",
      "        [[-0.0127]],\n",
      "\n",
      "        [[-0.3236]],\n",
      "\n",
      "        [[-0.9057]],\n",
      "\n",
      "        [[ 0.1033]],\n",
      "\n",
      "        [[-0.4480]],\n",
      "\n",
      "        [[-0.4189]],\n",
      "\n",
      "        [[ 1.7533]],\n",
      "\n",
      "        [[ 0.4960]],\n",
      "\n",
      "        [[-1.0902]],\n",
      "\n",
      "        [[ 0.7930]],\n",
      "\n",
      "        [[ 0.2888]],\n",
      "\n",
      "        [[ 0.1350]],\n",
      "\n",
      "        [[-0.2846]],\n",
      "\n",
      "        [[-2.2587]],\n",
      "\n",
      "        [[-0.4966]],\n",
      "\n",
      "        [[ 0.2498]],\n",
      "\n",
      "        [[-0.5925]],\n",
      "\n",
      "        [[-0.7855]],\n",
      "\n",
      "        [[ 0.7926]],\n",
      "\n",
      "        [[-0.3876]],\n",
      "\n",
      "        [[ 0.2595]],\n",
      "\n",
      "        [[ 0.0072]],\n",
      "\n",
      "        [[ 0.6202]],\n",
      "\n",
      "        [[ 2.4166]],\n",
      "\n",
      "        [[-0.7590]],\n",
      "\n",
      "        [[-0.0480]],\n",
      "\n",
      "        [[ 0.3641]],\n",
      "\n",
      "        [[ 0.7504]],\n",
      "\n",
      "        [[-0.5388]],\n",
      "\n",
      "        [[-1.0230]],\n",
      "\n",
      "        [[-1.3027]],\n",
      "\n",
      "        [[ 0.4209]],\n",
      "\n",
      "        [[-1.0605]],\n",
      "\n",
      "        [[-3.0438]],\n",
      "\n",
      "        [[ 0.1938]],\n",
      "\n",
      "        [[ 1.5021]],\n",
      "\n",
      "        [[ 1.0672]],\n",
      "\n",
      "        [[ 2.0727]],\n",
      "\n",
      "        [[ 0.4052]],\n",
      "\n",
      "        [[-0.9214]],\n",
      "\n",
      "        [[-2.5155]],\n",
      "\n",
      "        [[ 1.1721]],\n",
      "\n",
      "        [[-0.6295]],\n",
      "\n",
      "        [[ 0.4615]],\n",
      "\n",
      "        [[ 1.9429]],\n",
      "\n",
      "        [[ 0.5427]],\n",
      "\n",
      "        [[ 1.2626]],\n",
      "\n",
      "        [[-1.0673]],\n",
      "\n",
      "        [[ 2.1273]],\n",
      "\n",
      "        [[ 0.9283]],\n",
      "\n",
      "        [[-0.4536]],\n",
      "\n",
      "        [[-0.2721]],\n",
      "\n",
      "        [[-1.7657]],\n",
      "\n",
      "        [[-0.4696]],\n",
      "\n",
      "        [[ 0.8354]],\n",
      "\n",
      "        [[-0.3852]],\n",
      "\n",
      "        [[-0.3214]],\n",
      "\n",
      "        [[-0.4841]],\n",
      "\n",
      "        [[ 0.1275]],\n",
      "\n",
      "        [[ 2.1027]],\n",
      "\n",
      "        [[-0.5600]],\n",
      "\n",
      "        [[ 0.2706]],\n",
      "\n",
      "        [[-0.9443]],\n",
      "\n",
      "        [[ 0.7767]],\n",
      "\n",
      "        [[-0.2174]],\n",
      "\n",
      "        [[ 1.1683]],\n",
      "\n",
      "        [[ 0.1950]],\n",
      "\n",
      "        [[ 0.8266]],\n",
      "\n",
      "        [[-1.0658]],\n",
      "\n",
      "        [[ 1.1335]],\n",
      "\n",
      "        [[ 1.0780]],\n",
      "\n",
      "        [[ 1.6092]],\n",
      "\n",
      "        [[ 0.1657]],\n",
      "\n",
      "        [[-1.4903]],\n",
      "\n",
      "        [[-0.7287]],\n",
      "\n",
      "        [[-1.6775]],\n",
      "\n",
      "        [[-0.6416]],\n",
      "\n",
      "        [[-0.7986]],\n",
      "\n",
      "        [[ 0.7762]],\n",
      "\n",
      "        [[-2.4204]],\n",
      "\n",
      "        [[-0.0979]],\n",
      "\n",
      "        [[-0.3652]],\n",
      "\n",
      "        [[ 1.5851]],\n",
      "\n",
      "        [[ 0.1260]],\n",
      "\n",
      "        [[-0.1920]],\n",
      "\n",
      "        [[ 1.7466]],\n",
      "\n",
      "        [[ 0.8740]],\n",
      "\n",
      "        [[-1.0895]],\n",
      "\n",
      "        [[ 0.0458]],\n",
      "\n",
      "        [[ 0.7088]],\n",
      "\n",
      "        [[-1.1340]],\n",
      "\n",
      "        [[ 0.1880]],\n",
      "\n",
      "        [[-0.2581]],\n",
      "\n",
      "        [[-0.5297]],\n",
      "\n",
      "        [[ 1.4397]],\n",
      "\n",
      "        [[-0.8948]],\n",
      "\n",
      "        [[-0.1313]],\n",
      "\n",
      "        [[-0.9366]],\n",
      "\n",
      "        [[-0.7148]],\n",
      "\n",
      "        [[ 0.4898]],\n",
      "\n",
      "        [[-0.3594]]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor(1.00000e-03 *\n",
      "       [[[-8.7038]]], device='cuda:0')\n",
      "torch.Size([1, 448, 512])\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 1.9530,  1.9532,  1.9531,  ...,  1.9532,  1.9532,  1.9532],\n",
      "         [ 1.9530,  1.9531,  1.9529,  ...,  1.9530,  1.9529,  1.9530],\n",
      "         [ 1.9531,  1.9531,  1.9531,  ...,  1.9532,  1.9532,  1.9532],\n",
      "         ...,\n",
      "         [ 1.9533,  1.9531,  1.9532,  ...,  1.9531,  1.9531,  1.9532],\n",
      "         [ 1.9532,  1.9533,  1.9530,  ...,  1.9531,  1.9532,  1.9531],\n",
      "         [ 1.9530,  1.9532,  1.9532,  ...,  1.9530,  1.9531,  1.9531]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 63 [33280/50000 (74%)]\tLoss: 0.052333, Accuracy: 99.22\n",
      "Train Epoch: 63 [34560/50000 (77%)]\tLoss: 0.068207, Accuracy: 97.27\n",
      "Train Epoch: 63 [35840/50000 (80%)]\tLoss: 0.166953, Accuracy: 94.92\n",
      "Train Epoch: 63 [37120/50000 (82%)]\tLoss: 0.093734, Accuracy: 96.09\n",
      "Train Epoch: 63 [38400/50000 (85%)]\tLoss: 0.155399, Accuracy: 94.14\n",
      "Train Epoch: 63 [39680/50000 (88%)]\tLoss: 0.127341, Accuracy: 95.70\n",
      "Train Epoch: 63 [40960/50000 (91%)]\tLoss: 0.118067, Accuracy: 95.31\n",
      "Train Epoch: 63 [42240/50000 (94%)]\tLoss: 0.107744, Accuracy: 96.09\n",
      "Train Epoch: 63 [43520/50000 (97%)]\tLoss: 0.065747, Accuracy: 98.44\n",
      "Train Epoch: 63 [35000/50000 (99%)]\tLoss: 0.107672, Accuracy: 96.00\n",
      "\n",
      "Validation set: Average loss: 0.3000, Accuracy: 4548/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[41.076807498931885 s]\n",
      "Train Epoch: 64 [0/50000 (0%)]\tLoss: 0.050215, Accuracy: 98.05\n",
      "Train Epoch: 64 [1280/50000 (3%)]\tLoss: 0.059055, Accuracy: 98.44\n",
      "Train Epoch: 64 [2560/50000 (6%)]\tLoss: 0.086477, Accuracy: 97.66\n",
      "Train Epoch: 64 [3840/50000 (9%)]\tLoss: 0.102669, Accuracy: 95.31\n",
      "Train Epoch: 64 [5120/50000 (11%)]\tLoss: 0.070382, Accuracy: 97.27\n",
      "Train Epoch: 64 [6400/50000 (14%)]\tLoss: 0.064839, Accuracy: 98.05\n",
      "Train Epoch: 64 [7680/50000 (17%)]\tLoss: 0.065322, Accuracy: 97.66\n",
      "Train Epoch: 64 [8960/50000 (20%)]\tLoss: 0.136789, Accuracy: 95.31\n",
      "Train Epoch: 64 [10240/50000 (23%)]\tLoss: 0.091208, Accuracy: 97.27\n",
      "Train Epoch: 64 [11520/50000 (26%)]\tLoss: 0.118338, Accuracy: 96.09\n",
      "Train Epoch: 64 [12800/50000 (28%)]\tLoss: 0.129818, Accuracy: 94.92\n",
      "Train Epoch: 64 [14080/50000 (31%)]\tLoss: 0.073222, Accuracy: 97.27\n",
      "Train Epoch: 64 [15360/50000 (34%)]\tLoss: 0.105360, Accuracy: 96.88\n",
      "Train Epoch: 64 [16640/50000 (37%)]\tLoss: 0.074611, Accuracy: 97.66\n",
      "Train Epoch: 64 [17920/50000 (40%)]\tLoss: 0.082543, Accuracy: 97.27\n",
      "Train Epoch: 64 [19200/50000 (43%)]\tLoss: 0.081093, Accuracy: 96.88\n",
      "Train Epoch: 64 [20480/50000 (45%)]\tLoss: 0.063481, Accuracy: 98.05\n",
      "Train Epoch: 64 [21760/50000 (48%)]\tLoss: 0.114460, Accuracy: 97.27\n",
      "Train Epoch: 64 [23040/50000 (51%)]\tLoss: 0.060954, Accuracy: 98.44\n",
      "Train Epoch: 64 [24320/50000 (54%)]\tLoss: 0.083998, Accuracy: 96.48\n",
      "Train Epoch: 64 [25600/50000 (57%)]\tLoss: 0.073524, Accuracy: 98.05\n",
      "Train Epoch: 64 [26880/50000 (60%)]\tLoss: 0.062102, Accuracy: 98.44\n",
      "Train Epoch: 64 [28160/50000 (62%)]\tLoss: 0.054061, Accuracy: 98.44\n",
      "Train Epoch: 64 [29440/50000 (65%)]\tLoss: 0.108181, Accuracy: 96.09\n",
      "Train Epoch: 64 [30720/50000 (68%)]\tLoss: 0.147196, Accuracy: 94.14\n",
      "Train Epoch: 64 [32000/50000 (71%)]\tLoss: 0.114393, Accuracy: 95.31\n",
      "Train Epoch: 64 [33280/50000 (74%)]\tLoss: 0.135755, Accuracy: 94.53\n",
      "Train Epoch: 64 [34560/50000 (77%)]\tLoss: 0.117652, Accuracy: 96.09\n",
      "Train Epoch: 64 [35840/50000 (80%)]\tLoss: 0.107467, Accuracy: 96.48\n",
      "Train Epoch: 64 [37120/50000 (82%)]\tLoss: 0.154391, Accuracy: 94.53\n",
      "Train Epoch: 64 [38400/50000 (85%)]\tLoss: 0.083958, Accuracy: 96.88\n",
      "Train Epoch: 64 [39680/50000 (88%)]\tLoss: 0.088957, Accuracy: 98.05\n",
      "Train Epoch: 64 [40960/50000 (91%)]\tLoss: 0.053853, Accuracy: 98.44\n",
      "Train Epoch: 64 [42240/50000 (94%)]\tLoss: 0.120736, Accuracy: 95.31\n",
      "Train Epoch: 64 [43520/50000 (97%)]\tLoss: 0.066753, Accuracy: 98.05\n",
      "Train Epoch: 64 [35000/50000 (99%)]\tLoss: 0.148466, Accuracy: 94.00\n",
      "\n",
      "Validation set: Average loss: 0.3065, Accuracy: 4540/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[37.71840214729309 s]\n",
      "torch.Size([512, 1, 1])\n",
      "tensor([[[-0.6755]],\n",
      "\n",
      "        [[ 0.4826]],\n",
      "\n",
      "        [[-1.4379]],\n",
      "\n",
      "        [[-2.3934]],\n",
      "\n",
      "        [[ 1.7004]],\n",
      "\n",
      "        [[ 0.6115]],\n",
      "\n",
      "        [[ 0.1878]],\n",
      "\n",
      "        [[ 0.8958]],\n",
      "\n",
      "        [[ 1.0131]],\n",
      "\n",
      "        [[ 0.4638]],\n",
      "\n",
      "        [[-0.1783]],\n",
      "\n",
      "        [[ 0.4959]],\n",
      "\n",
      "        [[-0.0350]],\n",
      "\n",
      "        [[ 0.1713]],\n",
      "\n",
      "        [[-0.1504]],\n",
      "\n",
      "        [[ 0.4571]],\n",
      "\n",
      "        [[-0.1239]],\n",
      "\n",
      "        [[-0.0530]],\n",
      "\n",
      "        [[-0.7617]],\n",
      "\n",
      "        [[-1.6077]],\n",
      "\n",
      "        [[ 0.4337]],\n",
      "\n",
      "        [[ 0.4293]],\n",
      "\n",
      "        [[-0.5339]],\n",
      "\n",
      "        [[-0.8150]],\n",
      "\n",
      "        [[-1.7135]],\n",
      "\n",
      "        [[ 0.8759]],\n",
      "\n",
      "        [[ 0.1384]],\n",
      "\n",
      "        [[ 1.2089]],\n",
      "\n",
      "        [[ 0.3420]],\n",
      "\n",
      "        [[ 0.7945]],\n",
      "\n",
      "        [[-0.3453]],\n",
      "\n",
      "        [[-1.2674]],\n",
      "\n",
      "        [[ 0.6874]],\n",
      "\n",
      "        [[-0.5326]],\n",
      "\n",
      "        [[ 0.5471]],\n",
      "\n",
      "        [[-2.0300]],\n",
      "\n",
      "        [[-0.9528]],\n",
      "\n",
      "        [[ 1.3370]],\n",
      "\n",
      "        [[ 1.2124]],\n",
      "\n",
      "        [[ 0.5965]],\n",
      "\n",
      "        [[-0.3128]],\n",
      "\n",
      "        [[-0.2330]],\n",
      "\n",
      "        [[-0.3400]],\n",
      "\n",
      "        [[-0.1760]],\n",
      "\n",
      "        [[-0.1213]],\n",
      "\n",
      "        [[ 0.0449]],\n",
      "\n",
      "        [[-2.1599]],\n",
      "\n",
      "        [[ 0.6857]],\n",
      "\n",
      "        [[ 0.5501]],\n",
      "\n",
      "        [[ 0.1754]],\n",
      "\n",
      "        [[ 0.5417]],\n",
      "\n",
      "        [[ 0.7222]],\n",
      "\n",
      "        [[-1.1425]],\n",
      "\n",
      "        [[-0.0743]],\n",
      "\n",
      "        [[-1.4007]],\n",
      "\n",
      "        [[-0.2809]],\n",
      "\n",
      "        [[ 0.6423]],\n",
      "\n",
      "        [[ 0.4350]],\n",
      "\n",
      "        [[ 0.3549]],\n",
      "\n",
      "        [[-0.4556]],\n",
      "\n",
      "        [[ 1.4506]],\n",
      "\n",
      "        [[-1.4948]],\n",
      "\n",
      "        [[ 1.2207]],\n",
      "\n",
      "        [[ 0.1070]],\n",
      "\n",
      "        [[-1.3805]],\n",
      "\n",
      "        [[-0.2272]],\n",
      "\n",
      "        [[ 0.7749]],\n",
      "\n",
      "        [[ 1.6251]],\n",
      "\n",
      "        [[-0.5290]],\n",
      "\n",
      "        [[ 0.7406]],\n",
      "\n",
      "        [[ 0.3176]],\n",
      "\n",
      "        [[-0.2789]],\n",
      "\n",
      "        [[ 0.5049]],\n",
      "\n",
      "        [[ 0.3582]],\n",
      "\n",
      "        [[ 1.9678]],\n",
      "\n",
      "        [[-0.0525]],\n",
      "\n",
      "        [[-1.2534]],\n",
      "\n",
      "        [[ 0.0847]],\n",
      "\n",
      "        [[-0.7724]],\n",
      "\n",
      "        [[ 0.8327]],\n",
      "\n",
      "        [[ 0.6933]],\n",
      "\n",
      "        [[ 0.3902]],\n",
      "\n",
      "        [[ 0.0709]],\n",
      "\n",
      "        [[-1.5981]],\n",
      "\n",
      "        [[ 1.7009]],\n",
      "\n",
      "        [[-0.6539]],\n",
      "\n",
      "        [[-0.8979]],\n",
      "\n",
      "        [[-2.1582]],\n",
      "\n",
      "        [[-0.2083]],\n",
      "\n",
      "        [[-0.9245]],\n",
      "\n",
      "        [[ 0.5338]],\n",
      "\n",
      "        [[ 1.1644]],\n",
      "\n",
      "        [[-0.7916]],\n",
      "\n",
      "        [[-0.0281]],\n",
      "\n",
      "        [[-1.1832]],\n",
      "\n",
      "        [[-1.3782]],\n",
      "\n",
      "        [[-0.4267]],\n",
      "\n",
      "        [[-0.3385]],\n",
      "\n",
      "        [[-0.6590]],\n",
      "\n",
      "        [[-0.5084]],\n",
      "\n",
      "        [[-0.6532]],\n",
      "\n",
      "        [[-0.2189]],\n",
      "\n",
      "        [[-1.6142]],\n",
      "\n",
      "        [[ 0.9558]],\n",
      "\n",
      "        [[-1.7369]],\n",
      "\n",
      "        [[ 0.0741]],\n",
      "\n",
      "        [[ 1.7082]],\n",
      "\n",
      "        [[ 0.4645]],\n",
      "\n",
      "        [[-1.3083]],\n",
      "\n",
      "        [[ 0.1276]],\n",
      "\n",
      "        [[ 1.7654]],\n",
      "\n",
      "        [[ 0.1188]],\n",
      "\n",
      "        [[ 1.4144]],\n",
      "\n",
      "        [[ 0.1584]],\n",
      "\n",
      "        [[-0.2942]],\n",
      "\n",
      "        [[ 1.3122]],\n",
      "\n",
      "        [[ 0.3899]],\n",
      "\n",
      "        [[-0.7274]],\n",
      "\n",
      "        [[-1.1997]],\n",
      "\n",
      "        [[ 0.7397]],\n",
      "\n",
      "        [[ 0.0600]],\n",
      "\n",
      "        [[-0.1511]],\n",
      "\n",
      "        [[-0.9491]],\n",
      "\n",
      "        [[ 2.5208]],\n",
      "\n",
      "        [[ 1.8253]],\n",
      "\n",
      "        [[-0.6862]],\n",
      "\n",
      "        [[-0.2321]],\n",
      "\n",
      "        [[ 1.3471]],\n",
      "\n",
      "        [[-0.1563]],\n",
      "\n",
      "        [[ 0.1986]],\n",
      "\n",
      "        [[ 0.2622]],\n",
      "\n",
      "        [[ 0.7056]],\n",
      "\n",
      "        [[ 1.5851]],\n",
      "\n",
      "        [[-0.5234]],\n",
      "\n",
      "        [[-0.4601]],\n",
      "\n",
      "        [[-0.5747]],\n",
      "\n",
      "        [[-0.8070]],\n",
      "\n",
      "        [[-0.2538]],\n",
      "\n",
      "        [[-0.9121]],\n",
      "\n",
      "        [[ 0.5521]],\n",
      "\n",
      "        [[-0.2807]],\n",
      "\n",
      "        [[-0.1039]],\n",
      "\n",
      "        [[ 0.0134]],\n",
      "\n",
      "        [[ 1.8186]],\n",
      "\n",
      "        [[-0.5347]],\n",
      "\n",
      "        [[ 0.2408]],\n",
      "\n",
      "        [[ 1.0886]],\n",
      "\n",
      "        [[ 0.1422]],\n",
      "\n",
      "        [[-1.4346]],\n",
      "\n",
      "        [[-0.7704]],\n",
      "\n",
      "        [[-0.8236]],\n",
      "\n",
      "        [[-0.5525]],\n",
      "\n",
      "        [[ 0.5477]],\n",
      "\n",
      "        [[ 1.7990]],\n",
      "\n",
      "        [[ 0.5355]],\n",
      "\n",
      "        [[ 0.5418]],\n",
      "\n",
      "        [[ 1.8785]],\n",
      "\n",
      "        [[ 2.5458]],\n",
      "\n",
      "        [[ 0.2686]],\n",
      "\n",
      "        [[-0.6117]],\n",
      "\n",
      "        [[-0.4247]],\n",
      "\n",
      "        [[-0.4034]],\n",
      "\n",
      "        [[-2.8309]],\n",
      "\n",
      "        [[ 0.7510]],\n",
      "\n",
      "        [[-0.9186]],\n",
      "\n",
      "        [[-0.5500]],\n",
      "\n",
      "        [[-0.3193]],\n",
      "\n",
      "        [[-0.0887]],\n",
      "\n",
      "        [[ 0.1587]],\n",
      "\n",
      "        [[-0.3900]],\n",
      "\n",
      "        [[ 2.1701]],\n",
      "\n",
      "        [[-0.2101]],\n",
      "\n",
      "        [[ 0.5363]],\n",
      "\n",
      "        [[-2.4626]],\n",
      "\n",
      "        [[ 0.3389]],\n",
      "\n",
      "        [[ 1.2176]],\n",
      "\n",
      "        [[ 0.1046]],\n",
      "\n",
      "        [[ 1.6155]],\n",
      "\n",
      "        [[ 0.7327]],\n",
      "\n",
      "        [[-0.5634]],\n",
      "\n",
      "        [[ 0.1602]],\n",
      "\n",
      "        [[-1.5666]],\n",
      "\n",
      "        [[ 2.0263]],\n",
      "\n",
      "        [[-0.7699]],\n",
      "\n",
      "        [[-0.2847]],\n",
      "\n",
      "        [[ 1.1009]],\n",
      "\n",
      "        [[-1.1945]],\n",
      "\n",
      "        [[ 0.2758]],\n",
      "\n",
      "        [[-0.2477]],\n",
      "\n",
      "        [[ 1.2299]],\n",
      "\n",
      "        [[ 0.9621]],\n",
      "\n",
      "        [[ 0.3526]],\n",
      "\n",
      "        [[-0.2291]],\n",
      "\n",
      "        [[ 0.0091]],\n",
      "\n",
      "        [[-0.0352]],\n",
      "\n",
      "        [[-1.6015]],\n",
      "\n",
      "        [[-0.4311]],\n",
      "\n",
      "        [[-0.0488]],\n",
      "\n",
      "        [[ 0.1950]],\n",
      "\n",
      "        [[ 1.4934]],\n",
      "\n",
      "        [[-0.3763]],\n",
      "\n",
      "        [[-0.6032]],\n",
      "\n",
      "        [[ 1.6472]],\n",
      "\n",
      "        [[ 0.2071]],\n",
      "\n",
      "        [[-1.7497]],\n",
      "\n",
      "        [[ 1.0284]],\n",
      "\n",
      "        [[ 2.2694]],\n",
      "\n",
      "        [[-1.3129]],\n",
      "\n",
      "        [[ 1.7632]],\n",
      "\n",
      "        [[ 0.3679]],\n",
      "\n",
      "        [[-0.7206]],\n",
      "\n",
      "        [[ 0.1113]],\n",
      "\n",
      "        [[ 0.2435]],\n",
      "\n",
      "        [[-0.0325]],\n",
      "\n",
      "        [[ 0.0959]],\n",
      "\n",
      "        [[ 0.6277]],\n",
      "\n",
      "        [[ 1.0265]],\n",
      "\n",
      "        [[ 0.4303]],\n",
      "\n",
      "        [[-0.3211]],\n",
      "\n",
      "        [[-0.2615]],\n",
      "\n",
      "        [[-0.2581]],\n",
      "\n",
      "        [[ 1.2972]],\n",
      "\n",
      "        [[ 0.0898]],\n",
      "\n",
      "        [[ 0.6694]],\n",
      "\n",
      "        [[ 0.7196]],\n",
      "\n",
      "        [[-1.3242]],\n",
      "\n",
      "        [[-0.8871]],\n",
      "\n",
      "        [[ 0.5970]],\n",
      "\n",
      "        [[-1.0931]],\n",
      "\n",
      "        [[ 0.9623]],\n",
      "\n",
      "        [[ 0.5613]],\n",
      "\n",
      "        [[-0.9321]],\n",
      "\n",
      "        [[ 0.9105]],\n",
      "\n",
      "        [[-1.5978]],\n",
      "\n",
      "        [[ 1.1137]],\n",
      "\n",
      "        [[-0.5753]],\n",
      "\n",
      "        [[ 2.8655]],\n",
      "\n",
      "        [[-1.5136]],\n",
      "\n",
      "        [[-1.0355]],\n",
      "\n",
      "        [[ 0.5645]],\n",
      "\n",
      "        [[ 0.8408]],\n",
      "\n",
      "        [[ 2.2038]],\n",
      "\n",
      "        [[ 0.0730]],\n",
      "\n",
      "        [[-0.9537]],\n",
      "\n",
      "        [[-0.2826]],\n",
      "\n",
      "        [[ 1.0360]],\n",
      "\n",
      "        [[-0.5843]],\n",
      "\n",
      "        [[-0.8323]],\n",
      "\n",
      "        [[-2.1599]],\n",
      "\n",
      "        [[-0.8713]],\n",
      "\n",
      "        [[-0.1383]],\n",
      "\n",
      "        [[-0.3518]],\n",
      "\n",
      "        [[ 1.6613]],\n",
      "\n",
      "        [[ 0.0775]],\n",
      "\n",
      "        [[ 1.4342]],\n",
      "\n",
      "        [[-0.1384]],\n",
      "\n",
      "        [[-0.3473]],\n",
      "\n",
      "        [[-0.1692]],\n",
      "\n",
      "        [[ 1.6124]],\n",
      "\n",
      "        [[-0.1469]],\n",
      "\n",
      "        [[-1.2698]],\n",
      "\n",
      "        [[-2.3116]],\n",
      "\n",
      "        [[ 1.9465]],\n",
      "\n",
      "        [[-0.6774]],\n",
      "\n",
      "        [[ 0.1710]],\n",
      "\n",
      "        [[-0.2943]],\n",
      "\n",
      "        [[ 0.1864]],\n",
      "\n",
      "        [[ 1.1116]],\n",
      "\n",
      "        [[-0.9874]],\n",
      "\n",
      "        [[-1.1673]],\n",
      "\n",
      "        [[-0.6552]],\n",
      "\n",
      "        [[-1.6888]],\n",
      "\n",
      "        [[-1.7250]],\n",
      "\n",
      "        [[ 0.5054]],\n",
      "\n",
      "        [[ 0.1600]],\n",
      "\n",
      "        [[ 0.0208]],\n",
      "\n",
      "        [[ 0.0768]],\n",
      "\n",
      "        [[ 0.5587]],\n",
      "\n",
      "        [[ 0.9749]],\n",
      "\n",
      "        [[ 0.0122]],\n",
      "\n",
      "        [[ 0.2835]],\n",
      "\n",
      "        [[ 0.2096]],\n",
      "\n",
      "        [[-0.7842]],\n",
      "\n",
      "        [[-0.2391]],\n",
      "\n",
      "        [[ 0.3279]],\n",
      "\n",
      "        [[ 0.1005]],\n",
      "\n",
      "        [[-0.1505]],\n",
      "\n",
      "        [[ 0.9498]],\n",
      "\n",
      "        [[ 0.7658]],\n",
      "\n",
      "        [[ 1.5067]],\n",
      "\n",
      "        [[-0.7568]],\n",
      "\n",
      "        [[ 0.6960]],\n",
      "\n",
      "        [[ 0.6619]],\n",
      "\n",
      "        [[ 0.3947]],\n",
      "\n",
      "        [[ 1.6022]],\n",
      "\n",
      "        [[ 1.1398]],\n",
      "\n",
      "        [[-0.1244]],\n",
      "\n",
      "        [[ 0.8137]],\n",
      "\n",
      "        [[-2.1523]],\n",
      "\n",
      "        [[-0.6367]],\n",
      "\n",
      "        [[-0.5723]],\n",
      "\n",
      "        [[ 0.1470]],\n",
      "\n",
      "        [[ 1.0560]],\n",
      "\n",
      "        [[-2.5905]],\n",
      "\n",
      "        [[ 0.3376]],\n",
      "\n",
      "        [[ 0.0554]],\n",
      "\n",
      "        [[-0.4564]],\n",
      "\n",
      "        [[ 0.5108]],\n",
      "\n",
      "        [[-1.8516]],\n",
      "\n",
      "        [[-0.5297]],\n",
      "\n",
      "        [[ 0.7324]],\n",
      "\n",
      "        [[ 1.6206]],\n",
      "\n",
      "        [[ 0.6874]],\n",
      "\n",
      "        [[-0.0431]],\n",
      "\n",
      "        [[ 0.3806]],\n",
      "\n",
      "        [[ 0.3193]],\n",
      "\n",
      "        [[ 0.1373]],\n",
      "\n",
      "        [[-0.1568]],\n",
      "\n",
      "        [[ 2.5415]],\n",
      "\n",
      "        [[ 1.0572]],\n",
      "\n",
      "        [[-1.8479]],\n",
      "\n",
      "        [[-0.3502]],\n",
      "\n",
      "        [[-0.3377]],\n",
      "\n",
      "        [[ 0.1673]],\n",
      "\n",
      "        [[-0.4375]],\n",
      "\n",
      "        [[ 1.0916]],\n",
      "\n",
      "        [[ 0.2610]],\n",
      "\n",
      "        [[-1.3861]],\n",
      "\n",
      "        [[-1.1088]],\n",
      "\n",
      "        [[-0.8794]],\n",
      "\n",
      "        [[-1.0584]],\n",
      "\n",
      "        [[-1.5438]],\n",
      "\n",
      "        [[-1.0141]],\n",
      "\n",
      "        [[ 0.9155]],\n",
      "\n",
      "        [[ 0.9379]],\n",
      "\n",
      "        [[ 0.3032]],\n",
      "\n",
      "        [[ 0.0064]],\n",
      "\n",
      "        [[ 1.6511]],\n",
      "\n",
      "        [[ 0.7606]],\n",
      "\n",
      "        [[-0.0457]],\n",
      "\n",
      "        [[-0.0494]],\n",
      "\n",
      "        [[-0.9767]],\n",
      "\n",
      "        [[-0.6462]],\n",
      "\n",
      "        [[ 0.6929]],\n",
      "\n",
      "        [[ 0.4004]],\n",
      "\n",
      "        [[ 0.0002]],\n",
      "\n",
      "        [[-0.2858]],\n",
      "\n",
      "        [[-1.2306]],\n",
      "\n",
      "        [[ 0.6949]],\n",
      "\n",
      "        [[-0.3079]],\n",
      "\n",
      "        [[ 1.3267]],\n",
      "\n",
      "        [[ 0.2078]],\n",
      "\n",
      "        [[-0.7255]],\n",
      "\n",
      "        [[ 1.6288]],\n",
      "\n",
      "        [[ 0.1681]],\n",
      "\n",
      "        [[ 1.2722]],\n",
      "\n",
      "        [[-0.1149]],\n",
      "\n",
      "        [[ 1.4983]],\n",
      "\n",
      "        [[-0.5691]],\n",
      "\n",
      "        [[-1.0511]],\n",
      "\n",
      "        [[ 1.7588]],\n",
      "\n",
      "        [[-0.5464]],\n",
      "\n",
      "        [[ 1.3393]],\n",
      "\n",
      "        [[ 1.9181]],\n",
      "\n",
      "        [[ 0.4173]],\n",
      "\n",
      "        [[ 1.8943]],\n",
      "\n",
      "        [[ 0.3938]],\n",
      "\n",
      "        [[-0.9507]],\n",
      "\n",
      "        [[ 0.7896]],\n",
      "\n",
      "        [[ 0.4757]],\n",
      "\n",
      "        [[-0.4377]],\n",
      "\n",
      "        [[-1.5844]],\n",
      "\n",
      "        [[-0.6716]],\n",
      "\n",
      "        [[ 0.8972]],\n",
      "\n",
      "        [[-0.2044]],\n",
      "\n",
      "        [[ 0.2948]],\n",
      "\n",
      "        [[ 1.4698]],\n",
      "\n",
      "        [[-1.4816]],\n",
      "\n",
      "        [[ 0.1746]],\n",
      "\n",
      "        [[-1.6234]],\n",
      "\n",
      "        [[-0.9156]],\n",
      "\n",
      "        [[ 0.2043]],\n",
      "\n",
      "        [[ 1.1774]],\n",
      "\n",
      "        [[-2.5916]],\n",
      "\n",
      "        [[-0.3810]],\n",
      "\n",
      "        [[ 1.4343]],\n",
      "\n",
      "        [[ 0.1526]],\n",
      "\n",
      "        [[ 0.5302]],\n",
      "\n",
      "        [[ 0.7017]],\n",
      "\n",
      "        [[ 0.6716]],\n",
      "\n",
      "        [[ 0.0150]],\n",
      "\n",
      "        [[ 1.4760]],\n",
      "\n",
      "        [[ 0.2817]],\n",
      "\n",
      "        [[ 2.3185]],\n",
      "\n",
      "        [[ 0.9853]],\n",
      "\n",
      "        [[ 1.8842]],\n",
      "\n",
      "        [[ 1.1970]],\n",
      "\n",
      "        [[-0.5916]],\n",
      "\n",
      "        [[ 0.0339]],\n",
      "\n",
      "        [[-0.0693]],\n",
      "\n",
      "        [[-0.9237]],\n",
      "\n",
      "        [[-0.6597]],\n",
      "\n",
      "        [[ 0.6311]],\n",
      "\n",
      "        [[-0.0389]],\n",
      "\n",
      "        [[-0.7471]],\n",
      "\n",
      "        [[ 0.2866]],\n",
      "\n",
      "        [[-0.6778]],\n",
      "\n",
      "        [[ 1.3281]],\n",
      "\n",
      "        [[ 1.3326]],\n",
      "\n",
      "        [[-0.3795]],\n",
      "\n",
      "        [[-0.9991]],\n",
      "\n",
      "        [[-1.6166]],\n",
      "\n",
      "        [[ 0.3269]],\n",
      "\n",
      "        [[ 0.2378]],\n",
      "\n",
      "        [[-0.3574]],\n",
      "\n",
      "        [[-0.9457]],\n",
      "\n",
      "        [[-1.3871]],\n",
      "\n",
      "        [[-1.2835]],\n",
      "\n",
      "        [[-1.2614]],\n",
      "\n",
      "        [[ 1.4818]],\n",
      "\n",
      "        [[-1.3272]],\n",
      "\n",
      "        [[-0.1783]],\n",
      "\n",
      "        [[ 0.6123]],\n",
      "\n",
      "        [[-0.3328]],\n",
      "\n",
      "        [[ 1.7745]],\n",
      "\n",
      "        [[ 0.5700]],\n",
      "\n",
      "        [[ 0.2202]],\n",
      "\n",
      "        [[-0.6283]],\n",
      "\n",
      "        [[-0.5916]],\n",
      "\n",
      "        [[-0.7051]],\n",
      "\n",
      "        [[ 0.2173]],\n",
      "\n",
      "        [[ 1.0375]],\n",
      "\n",
      "        [[ 0.9137]],\n",
      "\n",
      "        [[-0.0448]],\n",
      "\n",
      "        [[-0.6379]],\n",
      "\n",
      "        [[-0.2449]],\n",
      "\n",
      "        [[ 0.5607]],\n",
      "\n",
      "        [[-0.4215]],\n",
      "\n",
      "        [[ 0.2084]],\n",
      "\n",
      "        [[-0.2161]],\n",
      "\n",
      "        [[ 0.0297]],\n",
      "\n",
      "        [[ 0.1969]],\n",
      "\n",
      "        [[ 0.4891]],\n",
      "\n",
      "        [[-0.3251]],\n",
      "\n",
      "        [[-1.6301]],\n",
      "\n",
      "        [[-0.6724]],\n",
      "\n",
      "        [[-1.2751]],\n",
      "\n",
      "        [[ 0.6898]],\n",
      "\n",
      "        [[-0.9662]],\n",
      "\n",
      "        [[ 1.0724]],\n",
      "\n",
      "        [[-0.7046]],\n",
      "\n",
      "        [[-0.4890]],\n",
      "\n",
      "        [[-0.8653]],\n",
      "\n",
      "        [[ 0.2637]],\n",
      "\n",
      "        [[ 0.9969]],\n",
      "\n",
      "        [[ 1.1068]],\n",
      "\n",
      "        [[-0.0825]],\n",
      "\n",
      "        [[ 0.2500]],\n",
      "\n",
      "        [[ 0.0600]],\n",
      "\n",
      "        [[-0.3598]],\n",
      "\n",
      "        [[ 1.0396]],\n",
      "\n",
      "        [[-1.6761]],\n",
      "\n",
      "        [[ 2.3764]],\n",
      "\n",
      "        [[ 0.1065]],\n",
      "\n",
      "        [[ 0.1097]],\n",
      "\n",
      "        [[-0.0282]],\n",
      "\n",
      "        [[ 1.2444]],\n",
      "\n",
      "        [[-1.3537]],\n",
      "\n",
      "        [[-0.8546]],\n",
      "\n",
      "        [[-1.4507]],\n",
      "\n",
      "        [[-1.2061]],\n",
      "\n",
      "        [[-2.2491]],\n",
      "\n",
      "        [[-1.1758]],\n",
      "\n",
      "        [[-2.2015]],\n",
      "\n",
      "        [[-2.0733]],\n",
      "\n",
      "        [[-0.1732]],\n",
      "\n",
      "        [[-0.2882]],\n",
      "\n",
      "        [[-0.6183]],\n",
      "\n",
      "        [[ 0.4097]],\n",
      "\n",
      "        [[ 0.6642]],\n",
      "\n",
      "        [[ 0.3725]],\n",
      "\n",
      "        [[ 1.2447]],\n",
      "\n",
      "        [[-0.2430]],\n",
      "\n",
      "        [[-0.3550]],\n",
      "\n",
      "        [[ 0.1222]],\n",
      "\n",
      "        [[ 0.9551]],\n",
      "\n",
      "        [[ 0.3912]],\n",
      "\n",
      "        [[ 1.3428]],\n",
      "\n",
      "        [[ 0.3762]],\n",
      "\n",
      "        [[ 0.4384]],\n",
      "\n",
      "        [[ 0.0543]],\n",
      "\n",
      "        [[ 0.5550]],\n",
      "\n",
      "        [[-0.3135]],\n",
      "\n",
      "        [[ 0.6294]],\n",
      "\n",
      "        [[-1.0187]],\n",
      "\n",
      "        [[ 2.2762]],\n",
      "\n",
      "        [[-1.6248]],\n",
      "\n",
      "        [[-0.6971]],\n",
      "\n",
      "        [[-0.4570]],\n",
      "\n",
      "        [[-0.7248]],\n",
      "\n",
      "        [[ 1.1785]],\n",
      "\n",
      "        [[ 1.0045]],\n",
      "\n",
      "        [[ 0.4206]],\n",
      "\n",
      "        [[-0.7895]],\n",
      "\n",
      "        [[-0.6327]],\n",
      "\n",
      "        [[ 0.1569]],\n",
      "\n",
      "        [[-0.5879]],\n",
      "\n",
      "        [[-0.0585]],\n",
      "\n",
      "        [[-0.1675]],\n",
      "\n",
      "        [[ 1.5657]],\n",
      "\n",
      "        [[-0.1441]],\n",
      "\n",
      "        [[ 0.2147]]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 9.4801]]], device='cuda:0')\n",
      "torch.Size([1, 896, 512])\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 1.9530,  1.9530,  1.9532,  ...,  1.9531,  1.9532,  1.9530],\n",
      "         [ 1.9530,  1.9531,  1.9533,  ...,  1.9530,  1.9530,  1.9531],\n",
      "         [ 1.9532,  1.9532,  1.9532,  ...,  1.9531,  1.9531,  1.9532],\n",
      "         ...,\n",
      "         [ 1.9531,  1.9533,  1.9533,  ...,  1.9531,  1.9531,  1.9531],\n",
      "         [ 1.9532,  1.9532,  1.9530,  ...,  1.9532,  1.9531,  1.9532],\n",
      "         [ 1.9531,  1.9532,  1.9531,  ...,  1.9531,  1.9531,  1.9531]]], device='cuda:0')\n",
      "\n",
      "Test set: Average loss: 0.3179, Accuracy: 9057/10000 (90.57%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 65 [0/50000 (0%)]\tLoss: 0.059503, Accuracy: 98.44\n",
      "Train Epoch: 65 [1280/50000 (3%)]\tLoss: 0.072632, Accuracy: 98.05\n",
      "Train Epoch: 65 [2560/50000 (6%)]\tLoss: 0.070190, Accuracy: 97.66\n",
      "Train Epoch: 65 [3840/50000 (9%)]\tLoss: 0.094657, Accuracy: 96.09\n",
      "Train Epoch: 65 [5120/50000 (11%)]\tLoss: 0.078786, Accuracy: 97.27\n",
      "Train Epoch: 65 [6400/50000 (14%)]\tLoss: 0.078618, Accuracy: 98.05\n",
      "Train Epoch: 65 [7680/50000 (17%)]\tLoss: 0.057047, Accuracy: 98.05\n",
      "Train Epoch: 65 [8960/50000 (20%)]\tLoss: 0.089300, Accuracy: 97.27\n",
      "Train Epoch: 65 [10240/50000 (23%)]\tLoss: 0.068224, Accuracy: 98.05\n",
      "Train Epoch: 65 [11520/50000 (26%)]\tLoss: 0.099252, Accuracy: 95.70\n",
      "Train Epoch: 65 [12800/50000 (28%)]\tLoss: 0.157451, Accuracy: 95.31\n",
      "Train Epoch: 65 [14080/50000 (31%)]\tLoss: 0.065127, Accuracy: 97.66\n",
      "Train Epoch: 65 [15360/50000 (34%)]\tLoss: 0.059215, Accuracy: 98.44\n",
      "Train Epoch: 65 [16640/50000 (37%)]\tLoss: 0.091037, Accuracy: 96.88\n",
      "Train Epoch: 65 [17920/50000 (40%)]\tLoss: 0.053158, Accuracy: 98.83\n",
      "Train Epoch: 65 [19200/50000 (43%)]\tLoss: 0.042922, Accuracy: 98.83\n",
      "Train Epoch: 65 [20480/50000 (45%)]\tLoss: 0.077684, Accuracy: 97.27\n",
      "Train Epoch: 65 [21760/50000 (48%)]\tLoss: 0.133855, Accuracy: 94.92\n",
      "Train Epoch: 65 [23040/50000 (51%)]\tLoss: 0.205079, Accuracy: 93.36\n",
      "Train Epoch: 65 [24320/50000 (54%)]\tLoss: 0.064522, Accuracy: 97.66\n",
      "Train Epoch: 65 [25600/50000 (57%)]\tLoss: 0.099495, Accuracy: 96.48\n",
      "Train Epoch: 65 [26880/50000 (60%)]\tLoss: 0.081849, Accuracy: 97.66\n",
      "Train Epoch: 65 [28160/50000 (62%)]\tLoss: 0.072145, Accuracy: 97.27\n",
      "Train Epoch: 65 [29440/50000 (65%)]\tLoss: 0.066789, Accuracy: 98.05\n",
      "Train Epoch: 65 [30720/50000 (68%)]\tLoss: 0.073531, Accuracy: 97.66\n",
      "Train Epoch: 65 [32000/50000 (71%)]\tLoss: 0.089864, Accuracy: 96.09\n",
      "Train Epoch: 65 [33280/50000 (74%)]\tLoss: 0.145131, Accuracy: 95.31\n",
      "Train Epoch: 65 [34560/50000 (77%)]\tLoss: 0.079557, Accuracy: 98.44\n",
      "Train Epoch: 65 [35840/50000 (80%)]\tLoss: 0.108398, Accuracy: 96.88\n",
      "Train Epoch: 65 [37120/50000 (82%)]\tLoss: 0.104935, Accuracy: 95.70\n",
      "Train Epoch: 65 [38400/50000 (85%)]\tLoss: 0.071720, Accuracy: 97.27\n",
      "Train Epoch: 65 [39680/50000 (88%)]\tLoss: 0.074103, Accuracy: 98.05\n",
      "Train Epoch: 65 [40960/50000 (91%)]\tLoss: 0.092514, Accuracy: 97.27\n",
      "Train Epoch: 65 [42240/50000 (94%)]\tLoss: 0.075148, Accuracy: 97.66\n",
      "Train Epoch: 65 [43520/50000 (97%)]\tLoss: 0.057696, Accuracy: 98.44\n",
      "Train Epoch: 65 [35000/50000 (99%)]\tLoss: 0.188000, Accuracy: 93.50\n",
      "\n",
      "Validation set: Average loss: 0.3149, Accuracy: 4543/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[40.999756813049316 s]\n",
      "Train Epoch: 66 [0/50000 (0%)]\tLoss: 0.062850, Accuracy: 98.05\n",
      "Train Epoch: 66 [1280/50000 (3%)]\tLoss: 0.130988, Accuracy: 95.70\n",
      "Train Epoch: 66 [2560/50000 (6%)]\tLoss: 0.090301, Accuracy: 97.27\n",
      "Train Epoch: 66 [3840/50000 (9%)]\tLoss: 0.089075, Accuracy: 96.48\n",
      "Train Epoch: 66 [5120/50000 (11%)]\tLoss: 0.057749, Accuracy: 98.05\n",
      "Train Epoch: 66 [6400/50000 (14%)]\tLoss: 0.066570, Accuracy: 96.88\n",
      "Train Epoch: 66 [7680/50000 (17%)]\tLoss: 0.071948, Accuracy: 97.66\n",
      "Train Epoch: 66 [8960/50000 (20%)]\tLoss: 0.076278, Accuracy: 97.27\n",
      "Train Epoch: 66 [10240/50000 (23%)]\tLoss: 0.096903, Accuracy: 96.88\n",
      "Train Epoch: 66 [11520/50000 (26%)]\tLoss: 0.083180, Accuracy: 97.66\n",
      "Train Epoch: 66 [12800/50000 (28%)]\tLoss: 0.082768, Accuracy: 97.66\n",
      "Train Epoch: 66 [14080/50000 (31%)]\tLoss: 0.105227, Accuracy: 96.48\n",
      "Train Epoch: 66 [15360/50000 (34%)]\tLoss: 0.068378, Accuracy: 97.27\n",
      "Train Epoch: 66 [16640/50000 (37%)]\tLoss: 0.143062, Accuracy: 96.09\n",
      "Train Epoch: 66 [17920/50000 (40%)]\tLoss: 0.081028, Accuracy: 96.88\n",
      "Train Epoch: 66 [19200/50000 (43%)]\tLoss: 0.107666, Accuracy: 96.09\n",
      "Train Epoch: 66 [20480/50000 (45%)]\tLoss: 0.092716, Accuracy: 97.66\n",
      "Train Epoch: 66 [21760/50000 (48%)]\tLoss: 0.077969, Accuracy: 96.88\n",
      "Train Epoch: 66 [23040/50000 (51%)]\tLoss: 0.054465, Accuracy: 98.05\n",
      "Train Epoch: 66 [24320/50000 (54%)]\tLoss: 0.059692, Accuracy: 98.05\n",
      "Train Epoch: 66 [25600/50000 (57%)]\tLoss: 0.070679, Accuracy: 97.66\n",
      "Train Epoch: 66 [26880/50000 (60%)]\tLoss: 0.081720, Accuracy: 96.88\n",
      "Train Epoch: 66 [28160/50000 (62%)]\tLoss: 0.077582, Accuracy: 97.66\n",
      "Train Epoch: 66 [29440/50000 (65%)]\tLoss: 0.103689, Accuracy: 95.31\n",
      "Train Epoch: 66 [30720/50000 (68%)]\tLoss: 0.061476, Accuracy: 98.44\n",
      "Train Epoch: 66 [32000/50000 (71%)]\tLoss: 0.110987, Accuracy: 96.09\n",
      "Train Epoch: 66 [33280/50000 (74%)]\tLoss: 0.160963, Accuracy: 96.09\n",
      "Train Epoch: 66 [34560/50000 (77%)]\tLoss: 0.094522, Accuracy: 97.66\n",
      "Train Epoch: 66 [35840/50000 (80%)]\tLoss: 0.090765, Accuracy: 96.88\n",
      "Train Epoch: 66 [37120/50000 (82%)]\tLoss: 0.094976, Accuracy: 96.88\n",
      "Train Epoch: 66 [38400/50000 (85%)]\tLoss: 0.096672, Accuracy: 96.48\n",
      "Train Epoch: 66 [39680/50000 (88%)]\tLoss: 0.038042, Accuracy: 98.44\n",
      "Train Epoch: 66 [40960/50000 (91%)]\tLoss: 0.124075, Accuracy: 95.70\n",
      "Train Epoch: 66 [42240/50000 (94%)]\tLoss: 0.060714, Accuracy: 97.27\n",
      "Train Epoch: 66 [43520/50000 (97%)]\tLoss: 0.139449, Accuracy: 94.92\n",
      "Train Epoch: 66 [35000/50000 (99%)]\tLoss: 0.108085, Accuracy: 96.00\n",
      "\n",
      "Validation set: Average loss: 0.2935, Accuracy: 4550/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[37.72866249084473 s]\n",
      "\n",
      "Test set: Average loss: 0.3121, Accuracy: 9078/10000 (90.78%)\n",
      "\n",
      "Train Epoch: 67 [0/50000 (0%)]\tLoss: 0.067303, Accuracy: 96.88\n",
      "Train Epoch: 67 [1280/50000 (3%)]\tLoss: 0.074313, Accuracy: 98.05\n",
      "Train Epoch: 67 [2560/50000 (6%)]\tLoss: 0.061249, Accuracy: 98.05\n",
      "Train Epoch: 67 [3840/50000 (9%)]\tLoss: 0.052896, Accuracy: 98.44\n",
      "Train Epoch: 67 [5120/50000 (11%)]\tLoss: 0.061840, Accuracy: 97.27\n",
      "Train Epoch: 67 [6400/50000 (14%)]\tLoss: 0.089855, Accuracy: 98.44\n",
      "Train Epoch: 67 [7680/50000 (17%)]\tLoss: 0.084081, Accuracy: 96.88\n",
      "Train Epoch: 67 [8960/50000 (20%)]\tLoss: 0.053690, Accuracy: 98.44\n",
      "Train Epoch: 67 [10240/50000 (23%)]\tLoss: 0.111836, Accuracy: 95.31\n",
      "Train Epoch: 67 [11520/50000 (26%)]\tLoss: 0.086089, Accuracy: 98.44\n",
      "Train Epoch: 67 [12800/50000 (28%)]\tLoss: 0.065408, Accuracy: 98.44\n",
      "Train Epoch: 67 [14080/50000 (31%)]\tLoss: 0.043339, Accuracy: 98.83\n",
      "Train Epoch: 67 [15360/50000 (34%)]\tLoss: 0.079578, Accuracy: 96.88\n",
      "Train Epoch: 67 [16640/50000 (37%)]\tLoss: 0.100441, Accuracy: 97.27\n",
      "Train Epoch: 67 [17920/50000 (40%)]\tLoss: 0.081459, Accuracy: 96.88\n",
      "Train Epoch: 67 [19200/50000 (43%)]\tLoss: 0.056834, Accuracy: 97.66\n",
      "Train Epoch: 67 [20480/50000 (45%)]\tLoss: 0.078197, Accuracy: 97.66\n",
      "Train Epoch: 67 [21760/50000 (48%)]\tLoss: 0.099701, Accuracy: 97.27\n",
      "Train Epoch: 67 [23040/50000 (51%)]\tLoss: 0.076582, Accuracy: 97.27\n",
      "Train Epoch: 67 [24320/50000 (54%)]\tLoss: 0.073320, Accuracy: 97.66\n",
      "Train Epoch: 67 [25600/50000 (57%)]\tLoss: 0.042609, Accuracy: 99.22\n",
      "Train Epoch: 67 [26880/50000 (60%)]\tLoss: 0.103014, Accuracy: 96.09\n",
      "Train Epoch: 67 [28160/50000 (62%)]\tLoss: 0.072613, Accuracy: 96.88\n",
      "Train Epoch: 67 [29440/50000 (65%)]\tLoss: 0.106649, Accuracy: 95.31\n",
      "Train Epoch: 67 [30720/50000 (68%)]\tLoss: 0.049269, Accuracy: 97.66\n",
      "torch.Size([512, 1, 1])\n",
      "tensor([[[-0.9294]],\n",
      "\n",
      "        [[ 0.3135]],\n",
      "\n",
      "        [[-1.3195]],\n",
      "\n",
      "        [[-0.3535]],\n",
      "\n",
      "        [[-1.2416]],\n",
      "\n",
      "        [[ 0.8039]],\n",
      "\n",
      "        [[-0.1204]],\n",
      "\n",
      "        [[ 0.2015]],\n",
      "\n",
      "        [[ 1.3135]],\n",
      "\n",
      "        [[-1.2615]],\n",
      "\n",
      "        [[-0.4742]],\n",
      "\n",
      "        [[ 0.8905]],\n",
      "\n",
      "        [[-1.0292]],\n",
      "\n",
      "        [[-1.0347]],\n",
      "\n",
      "        [[-0.9943]],\n",
      "\n",
      "        [[-0.9242]],\n",
      "\n",
      "        [[-0.2511]],\n",
      "\n",
      "        [[-0.1008]],\n",
      "\n",
      "        [[-0.1857]],\n",
      "\n",
      "        [[-1.5848]],\n",
      "\n",
      "        [[ 0.7182]],\n",
      "\n",
      "        [[-1.1268]],\n",
      "\n",
      "        [[-0.0158]],\n",
      "\n",
      "        [[ 0.4534]],\n",
      "\n",
      "        [[ 0.0869]],\n",
      "\n",
      "        [[-1.4297]],\n",
      "\n",
      "        [[ 0.1507]],\n",
      "\n",
      "        [[ 0.2920]],\n",
      "\n",
      "        [[-1.9559]],\n",
      "\n",
      "        [[-0.5590]],\n",
      "\n",
      "        [[-0.2593]],\n",
      "\n",
      "        [[-1.0297]],\n",
      "\n",
      "        [[ 0.1237]],\n",
      "\n",
      "        [[-0.2940]],\n",
      "\n",
      "        [[-0.6736]],\n",
      "\n",
      "        [[-1.2924]],\n",
      "\n",
      "        [[ 0.0800]],\n",
      "\n",
      "        [[-0.9020]],\n",
      "\n",
      "        [[-0.6178]],\n",
      "\n",
      "        [[-1.7273]],\n",
      "\n",
      "        [[ 0.2377]],\n",
      "\n",
      "        [[ 0.9648]],\n",
      "\n",
      "        [[ 0.1070]],\n",
      "\n",
      "        [[-2.9643]],\n",
      "\n",
      "        [[-0.7805]],\n",
      "\n",
      "        [[ 1.1309]],\n",
      "\n",
      "        [[ 0.3017]],\n",
      "\n",
      "        [[ 1.5273]],\n",
      "\n",
      "        [[ 2.0689]],\n",
      "\n",
      "        [[-1.0240]],\n",
      "\n",
      "        [[ 1.1848]],\n",
      "\n",
      "        [[ 0.0940]],\n",
      "\n",
      "        [[ 0.2201]],\n",
      "\n",
      "        [[ 0.4597]],\n",
      "\n",
      "        [[ 0.8178]],\n",
      "\n",
      "        [[ 1.3308]],\n",
      "\n",
      "        [[-0.3659]],\n",
      "\n",
      "        [[-0.7365]],\n",
      "\n",
      "        [[-0.3173]],\n",
      "\n",
      "        [[ 0.4271]],\n",
      "\n",
      "        [[-0.7613]],\n",
      "\n",
      "        [[ 0.8608]],\n",
      "\n",
      "        [[-1.4739]],\n",
      "\n",
      "        [[ 0.9185]],\n",
      "\n",
      "        [[-1.2190]],\n",
      "\n",
      "        [[ 0.2354]],\n",
      "\n",
      "        [[ 0.2399]],\n",
      "\n",
      "        [[-0.2175]],\n",
      "\n",
      "        [[-0.6564]],\n",
      "\n",
      "        [[ 0.9990]],\n",
      "\n",
      "        [[ 0.8402]],\n",
      "\n",
      "        [[ 0.3747]],\n",
      "\n",
      "        [[ 1.1112]],\n",
      "\n",
      "        [[-3.8299]],\n",
      "\n",
      "        [[ 0.5879]],\n",
      "\n",
      "        [[-0.2259]],\n",
      "\n",
      "        [[-2.3849]],\n",
      "\n",
      "        [[-0.0138]],\n",
      "\n",
      "        [[ 0.5953]],\n",
      "\n",
      "        [[ 1.1984]],\n",
      "\n",
      "        [[ 0.3115]],\n",
      "\n",
      "        [[-1.2510]],\n",
      "\n",
      "        [[ 0.7353]],\n",
      "\n",
      "        [[ 0.3661]],\n",
      "\n",
      "        [[ 0.7107]],\n",
      "\n",
      "        [[-1.7498]],\n",
      "\n",
      "        [[ 1.4751]],\n",
      "\n",
      "        [[ 0.2068]],\n",
      "\n",
      "        [[ 0.4294]],\n",
      "\n",
      "        [[-0.5891]],\n",
      "\n",
      "        [[ 0.4934]],\n",
      "\n",
      "        [[ 0.8528]],\n",
      "\n",
      "        [[ 1.2737]],\n",
      "\n",
      "        [[-0.4519]],\n",
      "\n",
      "        [[-0.5023]],\n",
      "\n",
      "        [[ 0.4860]],\n",
      "\n",
      "        [[-0.7749]],\n",
      "\n",
      "        [[ 1.3110]],\n",
      "\n",
      "        [[ 0.0214]],\n",
      "\n",
      "        [[-0.3610]],\n",
      "\n",
      "        [[-0.3449]],\n",
      "\n",
      "        [[-0.8170]],\n",
      "\n",
      "        [[-0.0332]],\n",
      "\n",
      "        [[ 1.3012]],\n",
      "\n",
      "        [[-0.5871]],\n",
      "\n",
      "        [[ 0.4834]],\n",
      "\n",
      "        [[-1.3379]],\n",
      "\n",
      "        [[ 1.1998]],\n",
      "\n",
      "        [[-0.1850]],\n",
      "\n",
      "        [[-1.4738]],\n",
      "\n",
      "        [[ 1.1197]],\n",
      "\n",
      "        [[ 0.0098]],\n",
      "\n",
      "        [[-1.1200]],\n",
      "\n",
      "        [[ 2.0093]],\n",
      "\n",
      "        [[-2.2173]],\n",
      "\n",
      "        [[ 0.7835]],\n",
      "\n",
      "        [[ 0.3570]],\n",
      "\n",
      "        [[ 0.2047]],\n",
      "\n",
      "        [[ 1.2217]],\n",
      "\n",
      "        [[ 1.3431]],\n",
      "\n",
      "        [[ 0.9181]],\n",
      "\n",
      "        [[-1.1439]],\n",
      "\n",
      "        [[-0.3018]],\n",
      "\n",
      "        [[ 0.5347]],\n",
      "\n",
      "        [[ 1.0048]],\n",
      "\n",
      "        [[ 0.4842]],\n",
      "\n",
      "        [[ 0.1778]],\n",
      "\n",
      "        [[ 0.3546]],\n",
      "\n",
      "        [[ 0.5171]],\n",
      "\n",
      "        [[-0.8321]],\n",
      "\n",
      "        [[-1.0642]],\n",
      "\n",
      "        [[-0.0199]],\n",
      "\n",
      "        [[-0.9817]],\n",
      "\n",
      "        [[-0.7464]],\n",
      "\n",
      "        [[-0.7081]],\n",
      "\n",
      "        [[ 0.3572]],\n",
      "\n",
      "        [[-0.7571]],\n",
      "\n",
      "        [[ 1.0564]],\n",
      "\n",
      "        [[ 0.6964]],\n",
      "\n",
      "        [[-0.6523]],\n",
      "\n",
      "        [[ 0.0197]],\n",
      "\n",
      "        [[-0.8341]],\n",
      "\n",
      "        [[-1.0384]],\n",
      "\n",
      "        [[ 1.3747]],\n",
      "\n",
      "        [[ 0.7915]],\n",
      "\n",
      "        [[ 0.5427]],\n",
      "\n",
      "        [[ 0.1854]],\n",
      "\n",
      "        [[-0.3869]],\n",
      "\n",
      "        [[-0.7305]],\n",
      "\n",
      "        [[-0.7508]],\n",
      "\n",
      "        [[ 0.2534]],\n",
      "\n",
      "        [[ 1.0957]],\n",
      "\n",
      "        [[ 0.3352]],\n",
      "\n",
      "        [[ 0.4030]],\n",
      "\n",
      "        [[ 0.9307]],\n",
      "\n",
      "        [[-0.4055]],\n",
      "\n",
      "        [[-1.2932]],\n",
      "\n",
      "        [[ 0.7148]],\n",
      "\n",
      "        [[-1.9447]],\n",
      "\n",
      "        [[-1.7001]],\n",
      "\n",
      "        [[ 0.4405]],\n",
      "\n",
      "        [[ 0.4359]],\n",
      "\n",
      "        [[ 0.4168]],\n",
      "\n",
      "        [[-0.6060]],\n",
      "\n",
      "        [[ 0.6708]],\n",
      "\n",
      "        [[-0.8869]],\n",
      "\n",
      "        [[ 1.4976]],\n",
      "\n",
      "        [[-1.2713]],\n",
      "\n",
      "        [[-2.1009]],\n",
      "\n",
      "        [[ 0.3627]],\n",
      "\n",
      "        [[ 1.8662]],\n",
      "\n",
      "        [[ 0.2216]],\n",
      "\n",
      "        [[-0.8106]],\n",
      "\n",
      "        [[ 0.1871]],\n",
      "\n",
      "        [[-0.1729]],\n",
      "\n",
      "        [[ 1.5490]],\n",
      "\n",
      "        [[ 0.7216]],\n",
      "\n",
      "        [[ 1.4164]],\n",
      "\n",
      "        [[ 1.5842]],\n",
      "\n",
      "        [[ 0.2401]],\n",
      "\n",
      "        [[-0.6770]],\n",
      "\n",
      "        [[-0.3713]],\n",
      "\n",
      "        [[-1.1242]],\n",
      "\n",
      "        [[ 0.7855]],\n",
      "\n",
      "        [[ 0.2037]],\n",
      "\n",
      "        [[ 0.9795]],\n",
      "\n",
      "        [[-0.9564]],\n",
      "\n",
      "        [[-0.5908]],\n",
      "\n",
      "        [[-1.1269]],\n",
      "\n",
      "        [[-0.1516]],\n",
      "\n",
      "        [[-0.8539]],\n",
      "\n",
      "        [[-0.3658]],\n",
      "\n",
      "        [[-0.3501]],\n",
      "\n",
      "        [[-0.7935]],\n",
      "\n",
      "        [[-0.5380]],\n",
      "\n",
      "        [[ 2.4192]],\n",
      "\n",
      "        [[-1.5686]],\n",
      "\n",
      "        [[ 0.1441]],\n",
      "\n",
      "        [[-1.4291]],\n",
      "\n",
      "        [[ 1.3862]],\n",
      "\n",
      "        [[-0.5306]],\n",
      "\n",
      "        [[ 0.0572]],\n",
      "\n",
      "        [[-2.4210]],\n",
      "\n",
      "        [[ 0.3096]],\n",
      "\n",
      "        [[ 1.7867]],\n",
      "\n",
      "        [[-0.7768]],\n",
      "\n",
      "        [[ 2.1550]],\n",
      "\n",
      "        [[ 1.0582]],\n",
      "\n",
      "        [[ 2.8947]],\n",
      "\n",
      "        [[-0.0905]],\n",
      "\n",
      "        [[-0.2759]],\n",
      "\n",
      "        [[ 1.2003]],\n",
      "\n",
      "        [[-0.9148]],\n",
      "\n",
      "        [[ 0.4848]],\n",
      "\n",
      "        [[-1.0548]],\n",
      "\n",
      "        [[ 0.9347]],\n",
      "\n",
      "        [[ 1.0731]],\n",
      "\n",
      "        [[ 1.0648]],\n",
      "\n",
      "        [[-1.7659]],\n",
      "\n",
      "        [[-0.7486]],\n",
      "\n",
      "        [[ 0.1435]],\n",
      "\n",
      "        [[ 0.4734]],\n",
      "\n",
      "        [[ 1.0738]],\n",
      "\n",
      "        [[ 0.1174]],\n",
      "\n",
      "        [[-0.1905]],\n",
      "\n",
      "        [[-2.0575]],\n",
      "\n",
      "        [[-1.3678]],\n",
      "\n",
      "        [[ 1.6007]],\n",
      "\n",
      "        [[-1.3601]],\n",
      "\n",
      "        [[-1.1098]],\n",
      "\n",
      "        [[ 1.5524]],\n",
      "\n",
      "        [[ 1.6500]],\n",
      "\n",
      "        [[-1.4290]],\n",
      "\n",
      "        [[-0.6337]],\n",
      "\n",
      "        [[ 0.0456]],\n",
      "\n",
      "        [[-0.0382]],\n",
      "\n",
      "        [[-3.1156]],\n",
      "\n",
      "        [[-1.0070]],\n",
      "\n",
      "        [[ 0.1318]],\n",
      "\n",
      "        [[ 0.8249]],\n",
      "\n",
      "        [[-2.4074]],\n",
      "\n",
      "        [[ 1.9613]],\n",
      "\n",
      "        [[-0.1630]],\n",
      "\n",
      "        [[-0.5265]],\n",
      "\n",
      "        [[-1.6593]],\n",
      "\n",
      "        [[-3.1305]],\n",
      "\n",
      "        [[-1.2694]],\n",
      "\n",
      "        [[-0.6653]],\n",
      "\n",
      "        [[ 0.9082]],\n",
      "\n",
      "        [[-1.0843]],\n",
      "\n",
      "        [[ 0.7420]],\n",
      "\n",
      "        [[ 1.1818]],\n",
      "\n",
      "        [[-0.2904]],\n",
      "\n",
      "        [[ 0.5507]],\n",
      "\n",
      "        [[-1.1386]],\n",
      "\n",
      "        [[ 0.0888]],\n",
      "\n",
      "        [[-1.0643]],\n",
      "\n",
      "        [[ 0.0573]],\n",
      "\n",
      "        [[ 1.0753]],\n",
      "\n",
      "        [[ 1.9248]],\n",
      "\n",
      "        [[-1.3331]],\n",
      "\n",
      "        [[ 1.1936]],\n",
      "\n",
      "        [[-1.9334]],\n",
      "\n",
      "        [[-0.1348]],\n",
      "\n",
      "        [[-0.3165]],\n",
      "\n",
      "        [[-0.9704]],\n",
      "\n",
      "        [[ 1.0138]],\n",
      "\n",
      "        [[ 0.8489]],\n",
      "\n",
      "        [[-0.2011]],\n",
      "\n",
      "        [[-0.6295]],\n",
      "\n",
      "        [[ 0.6746]],\n",
      "\n",
      "        [[ 0.7631]],\n",
      "\n",
      "        [[-0.9410]],\n",
      "\n",
      "        [[-0.5352]],\n",
      "\n",
      "        [[-0.2838]],\n",
      "\n",
      "        [[ 1.9300]],\n",
      "\n",
      "        [[-1.4540]],\n",
      "\n",
      "        [[-1.1722]],\n",
      "\n",
      "        [[ 0.3506]],\n",
      "\n",
      "        [[ 0.2870]],\n",
      "\n",
      "        [[-1.0580]],\n",
      "\n",
      "        [[-0.4097]],\n",
      "\n",
      "        [[-0.1454]],\n",
      "\n",
      "        [[-0.6816]],\n",
      "\n",
      "        [[-0.8780]],\n",
      "\n",
      "        [[ 1.1901]],\n",
      "\n",
      "        [[-1.5114]],\n",
      "\n",
      "        [[-1.0211]],\n",
      "\n",
      "        [[ 0.6232]],\n",
      "\n",
      "        [[ 0.1937]],\n",
      "\n",
      "        [[ 1.2685]],\n",
      "\n",
      "        [[-0.3408]],\n",
      "\n",
      "        [[ 0.3201]],\n",
      "\n",
      "        [[-1.7911]],\n",
      "\n",
      "        [[ 0.1506]],\n",
      "\n",
      "        [[-0.1569]],\n",
      "\n",
      "        [[ 0.1017]],\n",
      "\n",
      "        [[ 2.2129]],\n",
      "\n",
      "        [[-1.0891]],\n",
      "\n",
      "        [[ 1.5418]],\n",
      "\n",
      "        [[-0.5315]],\n",
      "\n",
      "        [[ 1.0620]],\n",
      "\n",
      "        [[ 0.7584]],\n",
      "\n",
      "        [[-0.0058]],\n",
      "\n",
      "        [[-0.3285]],\n",
      "\n",
      "        [[ 1.0854]],\n",
      "\n",
      "        [[ 0.3614]],\n",
      "\n",
      "        [[ 0.3990]],\n",
      "\n",
      "        [[ 2.2810]],\n",
      "\n",
      "        [[ 0.0857]],\n",
      "\n",
      "        [[ 0.5028]],\n",
      "\n",
      "        [[ 0.4326]],\n",
      "\n",
      "        [[ 0.1949]],\n",
      "\n",
      "        [[ 0.8030]],\n",
      "\n",
      "        [[ 0.9238]],\n",
      "\n",
      "        [[ 0.5071]],\n",
      "\n",
      "        [[ 0.3153]],\n",
      "\n",
      "        [[-0.5146]],\n",
      "\n",
      "        [[-1.4598]],\n",
      "\n",
      "        [[ 0.2293]],\n",
      "\n",
      "        [[-0.2828]],\n",
      "\n",
      "        [[-1.1878]],\n",
      "\n",
      "        [[-0.4782]],\n",
      "\n",
      "        [[-0.3759]],\n",
      "\n",
      "        [[-0.4480]],\n",
      "\n",
      "        [[ 0.1808]],\n",
      "\n",
      "        [[ 0.3901]],\n",
      "\n",
      "        [[ 0.1102]],\n",
      "\n",
      "        [[-0.3291]],\n",
      "\n",
      "        [[ 1.7059]],\n",
      "\n",
      "        [[ 1.9635]],\n",
      "\n",
      "        [[ 0.7974]],\n",
      "\n",
      "        [[ 0.0333]],\n",
      "\n",
      "        [[-0.4941]],\n",
      "\n",
      "        [[ 0.2565]],\n",
      "\n",
      "        [[ 1.1728]],\n",
      "\n",
      "        [[-1.2404]],\n",
      "\n",
      "        [[-0.0299]],\n",
      "\n",
      "        [[-0.8802]],\n",
      "\n",
      "        [[-0.8582]],\n",
      "\n",
      "        [[-0.7418]],\n",
      "\n",
      "        [[-1.4736]],\n",
      "\n",
      "        [[ 0.5489]],\n",
      "\n",
      "        [[-0.3581]],\n",
      "\n",
      "        [[ 0.1774]],\n",
      "\n",
      "        [[-1.0770]],\n",
      "\n",
      "        [[-1.4472]],\n",
      "\n",
      "        [[-0.3728]],\n",
      "\n",
      "        [[ 0.3624]],\n",
      "\n",
      "        [[ 1.2429]],\n",
      "\n",
      "        [[-0.9102]],\n",
      "\n",
      "        [[ 1.5909]],\n",
      "\n",
      "        [[-0.3057]],\n",
      "\n",
      "        [[ 2.2264]],\n",
      "\n",
      "        [[-0.0775]],\n",
      "\n",
      "        [[-0.5459]],\n",
      "\n",
      "        [[ 0.3876]],\n",
      "\n",
      "        [[-0.2978]],\n",
      "\n",
      "        [[-0.3187]],\n",
      "\n",
      "        [[-0.7158]],\n",
      "\n",
      "        [[ 0.1246]],\n",
      "\n",
      "        [[-2.7202]],\n",
      "\n",
      "        [[ 0.4569]],\n",
      "\n",
      "        [[-1.1755]],\n",
      "\n",
      "        [[ 0.2137]],\n",
      "\n",
      "        [[-0.0232]],\n",
      "\n",
      "        [[-2.6688]],\n",
      "\n",
      "        [[-0.0523]],\n",
      "\n",
      "        [[-0.5011]],\n",
      "\n",
      "        [[-0.9068]],\n",
      "\n",
      "        [[ 1.0476]],\n",
      "\n",
      "        [[-0.0955]],\n",
      "\n",
      "        [[-0.1785]],\n",
      "\n",
      "        [[-0.2548]],\n",
      "\n",
      "        [[ 0.3267]],\n",
      "\n",
      "        [[-0.4660]],\n",
      "\n",
      "        [[ 0.5636]],\n",
      "\n",
      "        [[-0.7137]],\n",
      "\n",
      "        [[-0.8973]],\n",
      "\n",
      "        [[ 1.7357]],\n",
      "\n",
      "        [[ 0.2180]],\n",
      "\n",
      "        [[-0.5257]],\n",
      "\n",
      "        [[-0.3500]],\n",
      "\n",
      "        [[ 0.3123]],\n",
      "\n",
      "        [[ 1.6677]],\n",
      "\n",
      "        [[ 1.4564]],\n",
      "\n",
      "        [[ 1.0257]],\n",
      "\n",
      "        [[-0.4906]],\n",
      "\n",
      "        [[ 0.0736]],\n",
      "\n",
      "        [[-0.3710]],\n",
      "\n",
      "        [[-0.3563]],\n",
      "\n",
      "        [[ 0.3829]],\n",
      "\n",
      "        [[ 1.3841]],\n",
      "\n",
      "        [[-2.1979]],\n",
      "\n",
      "        [[ 1.1973]],\n",
      "\n",
      "        [[-0.6268]],\n",
      "\n",
      "        [[-0.4434]],\n",
      "\n",
      "        [[-0.5213]],\n",
      "\n",
      "        [[ 0.9700]],\n",
      "\n",
      "        [[-0.4389]],\n",
      "\n",
      "        [[ 0.8407]],\n",
      "\n",
      "        [[-0.1952]],\n",
      "\n",
      "        [[-0.7459]],\n",
      "\n",
      "        [[ 0.5043]],\n",
      "\n",
      "        [[ 0.2280]],\n",
      "\n",
      "        [[-1.6419]],\n",
      "\n",
      "        [[-0.5778]],\n",
      "\n",
      "        [[ 1.6417]],\n",
      "\n",
      "        [[ 0.5192]],\n",
      "\n",
      "        [[-0.1139]],\n",
      "\n",
      "        [[-1.0905]],\n",
      "\n",
      "        [[-0.4008]],\n",
      "\n",
      "        [[ 0.3283]],\n",
      "\n",
      "        [[ 0.3679]],\n",
      "\n",
      "        [[ 0.1152]],\n",
      "\n",
      "        [[ 0.3266]],\n",
      "\n",
      "        [[ 0.1014]],\n",
      "\n",
      "        [[-1.1282]],\n",
      "\n",
      "        [[ 0.4708]],\n",
      "\n",
      "        [[-1.3058]],\n",
      "\n",
      "        [[-0.4012]],\n",
      "\n",
      "        [[-1.7848]],\n",
      "\n",
      "        [[ 0.0802]],\n",
      "\n",
      "        [[-0.2429]],\n",
      "\n",
      "        [[ 0.3660]],\n",
      "\n",
      "        [[ 1.0616]],\n",
      "\n",
      "        [[-1.3392]],\n",
      "\n",
      "        [[-0.2683]],\n",
      "\n",
      "        [[ 0.8557]],\n",
      "\n",
      "        [[ 1.4560]],\n",
      "\n",
      "        [[-2.0670]],\n",
      "\n",
      "        [[ 1.2335]],\n",
      "\n",
      "        [[-0.2837]],\n",
      "\n",
      "        [[ 1.7251]],\n",
      "\n",
      "        [[-1.3437]],\n",
      "\n",
      "        [[-0.3945]],\n",
      "\n",
      "        [[-0.1597]],\n",
      "\n",
      "        [[ 1.0198]],\n",
      "\n",
      "        [[-1.3408]],\n",
      "\n",
      "        [[ 2.1279]],\n",
      "\n",
      "        [[ 0.2295]],\n",
      "\n",
      "        [[ 2.5890]],\n",
      "\n",
      "        [[ 0.5932]],\n",
      "\n",
      "        [[-0.5474]],\n",
      "\n",
      "        [[ 1.5099]],\n",
      "\n",
      "        [[-0.1864]],\n",
      "\n",
      "        [[-0.9868]],\n",
      "\n",
      "        [[ 0.1988]],\n",
      "\n",
      "        [[-1.2710]],\n",
      "\n",
      "        [[ 1.0040]],\n",
      "\n",
      "        [[-1.1851]],\n",
      "\n",
      "        [[ 0.2942]],\n",
      "\n",
      "        [[ 0.5981]],\n",
      "\n",
      "        [[-1.2399]],\n",
      "\n",
      "        [[-0.7681]],\n",
      "\n",
      "        [[ 0.2959]],\n",
      "\n",
      "        [[ 0.4418]],\n",
      "\n",
      "        [[ 0.1657]],\n",
      "\n",
      "        [[-0.4524]],\n",
      "\n",
      "        [[ 0.3280]],\n",
      "\n",
      "        [[-2.4654]],\n",
      "\n",
      "        [[-0.2988]],\n",
      "\n",
      "        [[ 0.3507]],\n",
      "\n",
      "        [[-0.9002]],\n",
      "\n",
      "        [[-0.0427]],\n",
      "\n",
      "        [[-1.8228]],\n",
      "\n",
      "        [[-1.0089]],\n",
      "\n",
      "        [[-0.0642]],\n",
      "\n",
      "        [[-0.0580]],\n",
      "\n",
      "        [[ 0.3033]],\n",
      "\n",
      "        [[ 0.4594]],\n",
      "\n",
      "        [[ 0.3455]],\n",
      "\n",
      "        [[-0.7818]],\n",
      "\n",
      "        [[-1.8765]],\n",
      "\n",
      "        [[ 1.0026]],\n",
      "\n",
      "        [[ 0.6982]],\n",
      "\n",
      "        [[-0.6174]],\n",
      "\n",
      "        [[-0.0642]],\n",
      "\n",
      "        [[-0.9728]],\n",
      "\n",
      "        [[-0.4313]],\n",
      "\n",
      "        [[-0.4384]],\n",
      "\n",
      "        [[-0.6679]],\n",
      "\n",
      "        [[ 0.4699]],\n",
      "\n",
      "        [[-1.0694]],\n",
      "\n",
      "        [[ 1.1693]],\n",
      "\n",
      "        [[ 0.2925]],\n",
      "\n",
      "        [[ 0.4186]],\n",
      "\n",
      "        [[ 0.9244]],\n",
      "\n",
      "        [[-3.1661]],\n",
      "\n",
      "        [[-0.2212]],\n",
      "\n",
      "        [[ 0.3658]],\n",
      "\n",
      "        [[ 1.5136]],\n",
      "\n",
      "        [[ 1.3681]],\n",
      "\n",
      "        [[ 0.0927]],\n",
      "\n",
      "        [[ 1.1863]],\n",
      "\n",
      "        [[-0.3965]],\n",
      "\n",
      "        [[ 0.4592]],\n",
      "\n",
      "        [[ 0.0538]],\n",
      "\n",
      "        [[-0.0964]],\n",
      "\n",
      "        [[ 0.8340]],\n",
      "\n",
      "        [[ 1.4769]],\n",
      "\n",
      "        [[ 2.3247]],\n",
      "\n",
      "        [[ 1.5743]],\n",
      "\n",
      "        [[-1.0640]],\n",
      "\n",
      "        [[ 0.9653]],\n",
      "\n",
      "        [[ 1.0076]],\n",
      "\n",
      "        [[ 0.3442]],\n",
      "\n",
      "        [[-0.9666]],\n",
      "\n",
      "        [[-0.9019]],\n",
      "\n",
      "        [[-0.1406]],\n",
      "\n",
      "        [[-0.1001]],\n",
      "\n",
      "        [[ 0.1160]]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 3.9264]]], device='cuda:0')\n",
      "torch.Size([1, 448, 512])\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 1.9532,  1.9532,  1.9531,  ...,  1.9532,  1.9531,  1.9531],\n",
      "         [ 1.9531,  1.9531,  1.9531,  ...,  1.9531,  1.9531,  1.9531],\n",
      "         [ 1.9531,  1.9531,  1.9531,  ...,  1.9531,  1.9532,  1.9532],\n",
      "         ...,\n",
      "         [ 1.9532,  1.9531,  1.9531,  ...,  1.9531,  1.9531,  1.9532],\n",
      "         [ 1.9531,  1.9531,  1.9531,  ...,  1.9532,  1.9531,  1.9531],\n",
      "         [ 1.9531,  1.9530,  1.9531,  ...,  1.9531,  1.9532,  1.9532]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 67 [32000/50000 (71%)]\tLoss: 0.064802, Accuracy: 97.27\n",
      "Train Epoch: 67 [33280/50000 (74%)]\tLoss: 0.085034, Accuracy: 96.88\n",
      "Train Epoch: 67 [34560/50000 (77%)]\tLoss: 0.100435, Accuracy: 97.27\n",
      "Train Epoch: 67 [35840/50000 (80%)]\tLoss: 0.064899, Accuracy: 97.27\n",
      "Train Epoch: 67 [37120/50000 (82%)]\tLoss: 0.083318, Accuracy: 97.66\n",
      "Train Epoch: 67 [38400/50000 (85%)]\tLoss: 0.075165, Accuracy: 96.88\n",
      "Train Epoch: 67 [39680/50000 (88%)]\tLoss: 0.096417, Accuracy: 95.70\n",
      "Train Epoch: 67 [40960/50000 (91%)]\tLoss: 0.131046, Accuracy: 94.53\n",
      "Train Epoch: 67 [42240/50000 (94%)]\tLoss: 0.086685, Accuracy: 96.88\n",
      "Train Epoch: 67 [43520/50000 (97%)]\tLoss: 0.076940, Accuracy: 96.88\n",
      "Train Epoch: 67 [35000/50000 (99%)]\tLoss: 0.045658, Accuracy: 98.50\n",
      "\n",
      "Validation set: Average loss: 0.3248, Accuracy: 4539/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[41.252866983413696 s]\n",
      "Train Epoch: 68 [0/50000 (0%)]\tLoss: 0.120961, Accuracy: 96.09\n",
      "Train Epoch: 68 [1280/50000 (3%)]\tLoss: 0.076387, Accuracy: 98.44\n",
      "Train Epoch: 68 [2560/50000 (6%)]\tLoss: 0.090238, Accuracy: 97.66\n",
      "Train Epoch: 68 [3840/50000 (9%)]\tLoss: 0.065847, Accuracy: 97.66\n",
      "Train Epoch: 68 [5120/50000 (11%)]\tLoss: 0.090325, Accuracy: 96.48\n",
      "Train Epoch: 68 [6400/50000 (14%)]\tLoss: 0.091759, Accuracy: 98.05\n",
      "Train Epoch: 68 [7680/50000 (17%)]\tLoss: 0.056460, Accuracy: 98.44\n",
      "Train Epoch: 68 [8960/50000 (20%)]\tLoss: 0.086111, Accuracy: 97.27\n",
      "Train Epoch: 68 [10240/50000 (23%)]\tLoss: 0.079444, Accuracy: 96.48\n",
      "Train Epoch: 68 [11520/50000 (26%)]\tLoss: 0.073029, Accuracy: 97.66\n",
      "Train Epoch: 68 [12800/50000 (28%)]\tLoss: 0.109297, Accuracy: 96.88\n",
      "Train Epoch: 68 [14080/50000 (31%)]\tLoss: 0.089189, Accuracy: 98.05\n",
      "Train Epoch: 68 [15360/50000 (34%)]\tLoss: 0.081528, Accuracy: 97.66\n",
      "Train Epoch: 68 [16640/50000 (37%)]\tLoss: 0.097555, Accuracy: 96.09\n",
      "Train Epoch: 68 [17920/50000 (40%)]\tLoss: 0.057768, Accuracy: 97.66\n",
      "Train Epoch: 68 [19200/50000 (43%)]\tLoss: 0.087841, Accuracy: 96.48\n",
      "Train Epoch: 68 [20480/50000 (45%)]\tLoss: 0.083031, Accuracy: 96.09\n",
      "Train Epoch: 68 [21760/50000 (48%)]\tLoss: 0.054419, Accuracy: 98.83\n",
      "Train Epoch: 68 [23040/50000 (51%)]\tLoss: 0.064243, Accuracy: 98.05\n",
      "Train Epoch: 68 [24320/50000 (54%)]\tLoss: 0.087051, Accuracy: 97.27\n",
      "Train Epoch: 68 [25600/50000 (57%)]\tLoss: 0.044627, Accuracy: 98.44\n",
      "Train Epoch: 68 [26880/50000 (60%)]\tLoss: 0.059233, Accuracy: 98.44\n",
      "Train Epoch: 68 [28160/50000 (62%)]\tLoss: 0.046862, Accuracy: 98.44\n",
      "Train Epoch: 68 [29440/50000 (65%)]\tLoss: 0.115871, Accuracy: 97.66\n",
      "Train Epoch: 68 [30720/50000 (68%)]\tLoss: 0.111618, Accuracy: 95.31\n",
      "Train Epoch: 68 [32000/50000 (71%)]\tLoss: 0.088582, Accuracy: 96.48\n",
      "Train Epoch: 68 [33280/50000 (74%)]\tLoss: 0.051391, Accuracy: 99.22\n",
      "Train Epoch: 68 [34560/50000 (77%)]\tLoss: 0.067850, Accuracy: 98.05\n",
      "Train Epoch: 68 [35840/50000 (80%)]\tLoss: 0.072712, Accuracy: 97.66\n",
      "Train Epoch: 68 [37120/50000 (82%)]\tLoss: 0.078292, Accuracy: 96.88\n",
      "Train Epoch: 68 [38400/50000 (85%)]\tLoss: 0.078103, Accuracy: 98.05\n",
      "Train Epoch: 68 [39680/50000 (88%)]\tLoss: 0.092301, Accuracy: 96.88\n",
      "Train Epoch: 68 [40960/50000 (91%)]\tLoss: 0.106262, Accuracy: 96.88\n",
      "Train Epoch: 68 [42240/50000 (94%)]\tLoss: 0.086295, Accuracy: 96.88\n",
      "Train Epoch: 68 [43520/50000 (97%)]\tLoss: 0.131944, Accuracy: 96.48\n",
      "Train Epoch: 68 [35000/50000 (99%)]\tLoss: 0.115264, Accuracy: 95.00\n",
      "\n",
      "Validation set: Average loss: 0.3184, Accuracy: 4554/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[37.476699113845825 s]\n",
      "\n",
      "Test set: Average loss: 0.3331, Accuracy: 9105/10000 (91.05%)\n",
      "\n",
      "Train Epoch: 69 [0/50000 (0%)]\tLoss: 0.106773, Accuracy: 95.70\n",
      "Train Epoch: 69 [1280/50000 (3%)]\tLoss: 0.087541, Accuracy: 98.05\n",
      "Train Epoch: 69 [2560/50000 (6%)]\tLoss: 0.131389, Accuracy: 96.48\n",
      "Train Epoch: 69 [3840/50000 (9%)]\tLoss: 0.057047, Accuracy: 98.83\n",
      "Train Epoch: 69 [5120/50000 (11%)]\tLoss: 0.099987, Accuracy: 96.48\n",
      "Train Epoch: 69 [6400/50000 (14%)]\tLoss: 0.083913, Accuracy: 96.09\n",
      "Train Epoch: 69 [7680/50000 (17%)]\tLoss: 0.064184, Accuracy: 98.05\n",
      "Train Epoch: 69 [8960/50000 (20%)]\tLoss: 0.067194, Accuracy: 98.44\n",
      "Train Epoch: 69 [10240/50000 (23%)]\tLoss: 0.072694, Accuracy: 97.66\n",
      "Train Epoch: 69 [11520/50000 (26%)]\tLoss: 0.070346, Accuracy: 96.88\n",
      "Train Epoch: 69 [12800/50000 (28%)]\tLoss: 0.072374, Accuracy: 96.48\n",
      "Train Epoch: 69 [14080/50000 (31%)]\tLoss: 0.052524, Accuracy: 98.83\n",
      "Train Epoch: 69 [15360/50000 (34%)]\tLoss: 0.078121, Accuracy: 97.66\n",
      "Train Epoch: 69 [16640/50000 (37%)]\tLoss: 0.072487, Accuracy: 96.88\n",
      "Train Epoch: 69 [17920/50000 (40%)]\tLoss: 0.135496, Accuracy: 95.70\n",
      "Train Epoch: 69 [19200/50000 (43%)]\tLoss: 0.036051, Accuracy: 98.83\n",
      "Train Epoch: 69 [20480/50000 (45%)]\tLoss: 0.058573, Accuracy: 98.05\n",
      "Train Epoch: 69 [21760/50000 (48%)]\tLoss: 0.113880, Accuracy: 95.31\n",
      "Train Epoch: 69 [23040/50000 (51%)]\tLoss: 0.093791, Accuracy: 96.88\n",
      "Train Epoch: 69 [24320/50000 (54%)]\tLoss: 0.098867, Accuracy: 96.48\n",
      "Train Epoch: 69 [25600/50000 (57%)]\tLoss: 0.099326, Accuracy: 96.88\n",
      "Train Epoch: 69 [26880/50000 (60%)]\tLoss: 0.066562, Accuracy: 98.44\n",
      "Train Epoch: 69 [28160/50000 (62%)]\tLoss: 0.088141, Accuracy: 97.27\n",
      "Train Epoch: 69 [29440/50000 (65%)]\tLoss: 0.079005, Accuracy: 96.09\n",
      "Train Epoch: 69 [30720/50000 (68%)]\tLoss: 0.077513, Accuracy: 96.09\n",
      "Train Epoch: 69 [32000/50000 (71%)]\tLoss: 0.069524, Accuracy: 98.05\n",
      "Train Epoch: 69 [33280/50000 (74%)]\tLoss: 0.089888, Accuracy: 97.27\n",
      "Train Epoch: 69 [34560/50000 (77%)]\tLoss: 0.116798, Accuracy: 96.88\n",
      "Train Epoch: 69 [35840/50000 (80%)]\tLoss: 0.096351, Accuracy: 96.88\n",
      "Train Epoch: 69 [37120/50000 (82%)]\tLoss: 0.094050, Accuracy: 96.88\n",
      "Train Epoch: 69 [38400/50000 (85%)]\tLoss: 0.073003, Accuracy: 97.27\n",
      "Train Epoch: 69 [39680/50000 (88%)]\tLoss: 0.093372, Accuracy: 96.88\n",
      "Train Epoch: 69 [40960/50000 (91%)]\tLoss: 0.085052, Accuracy: 96.88\n",
      "Train Epoch: 69 [42240/50000 (94%)]\tLoss: 0.105838, Accuracy: 95.70\n",
      "Train Epoch: 69 [43520/50000 (97%)]\tLoss: 0.057297, Accuracy: 98.05\n",
      "Train Epoch: 69 [35000/50000 (99%)]\tLoss: 0.121879, Accuracy: 95.00\n",
      "\n",
      "Validation set: Average loss: 0.3355, Accuracy: 4543/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[40.638103723526 s]\n",
      "Train Epoch: 70 [0/50000 (0%)]\tLoss: 0.098911, Accuracy: 96.48\n",
      "Train Epoch: 70 [1280/50000 (3%)]\tLoss: 0.047870, Accuracy: 98.44\n",
      "Train Epoch: 70 [2560/50000 (6%)]\tLoss: 0.054132, Accuracy: 98.44\n",
      "Train Epoch: 70 [3840/50000 (9%)]\tLoss: 0.094477, Accuracy: 96.88\n",
      "Train Epoch: 70 [5120/50000 (11%)]\tLoss: 0.091015, Accuracy: 96.48\n",
      "Train Epoch: 70 [6400/50000 (14%)]\tLoss: 0.061101, Accuracy: 99.22\n",
      "Train Epoch: 70 [7680/50000 (17%)]\tLoss: 0.101039, Accuracy: 96.88\n",
      "Train Epoch: 70 [8960/50000 (20%)]\tLoss: 0.078048, Accuracy: 96.88\n",
      "Train Epoch: 70 [10240/50000 (23%)]\tLoss: 0.095497, Accuracy: 96.48\n",
      "Train Epoch: 70 [11520/50000 (26%)]\tLoss: 0.061261, Accuracy: 98.05\n",
      "Train Epoch: 70 [12800/50000 (28%)]\tLoss: 0.086229, Accuracy: 96.48\n",
      "Train Epoch: 70 [14080/50000 (31%)]\tLoss: 0.084113, Accuracy: 97.66\n",
      "Train Epoch: 70 [15360/50000 (34%)]\tLoss: 0.065511, Accuracy: 97.66\n",
      "Train Epoch: 70 [16640/50000 (37%)]\tLoss: 0.081390, Accuracy: 98.05\n",
      "Train Epoch: 70 [17920/50000 (40%)]\tLoss: 0.079787, Accuracy: 96.88\n",
      "Train Epoch: 70 [19200/50000 (43%)]\tLoss: 0.064927, Accuracy: 98.44\n",
      "Train Epoch: 70 [20480/50000 (45%)]\tLoss: 0.090347, Accuracy: 96.48\n",
      "Train Epoch: 70 [21760/50000 (48%)]\tLoss: 0.036243, Accuracy: 99.61\n",
      "Train Epoch: 70 [23040/50000 (51%)]\tLoss: 0.065393, Accuracy: 98.44\n",
      "Train Epoch: 70 [24320/50000 (54%)]\tLoss: 0.122678, Accuracy: 95.70\n",
      "Train Epoch: 70 [25600/50000 (57%)]\tLoss: 0.058100, Accuracy: 98.44\n",
      "Train Epoch: 70 [26880/50000 (60%)]\tLoss: 0.092276, Accuracy: 97.27\n",
      "Train Epoch: 70 [28160/50000 (62%)]\tLoss: 0.102796, Accuracy: 97.27\n",
      "Train Epoch: 70 [29440/50000 (65%)]\tLoss: 0.056884, Accuracy: 98.44\n",
      "Train Epoch: 70 [30720/50000 (68%)]\tLoss: 0.087181, Accuracy: 96.88\n",
      "Train Epoch: 70 [32000/50000 (71%)]\tLoss: 0.067545, Accuracy: 98.05\n",
      "Train Epoch: 70 [33280/50000 (74%)]\tLoss: 0.071716, Accuracy: 97.27\n",
      "Train Epoch: 70 [34560/50000 (77%)]\tLoss: 0.075059, Accuracy: 97.27\n",
      "Train Epoch: 70 [35840/50000 (80%)]\tLoss: 0.093430, Accuracy: 97.27\n",
      "Train Epoch: 70 [37120/50000 (82%)]\tLoss: 0.102140, Accuracy: 95.31\n",
      "Train Epoch: 70 [38400/50000 (85%)]\tLoss: 0.103354, Accuracy: 96.48\n",
      "Train Epoch: 70 [39680/50000 (88%)]\tLoss: 0.085900, Accuracy: 97.27\n",
      "Train Epoch: 70 [40960/50000 (91%)]\tLoss: 0.060040, Accuracy: 98.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 70 [42240/50000 (94%)]\tLoss: 0.067042, Accuracy: 97.66\n",
      "Train Epoch: 70 [43520/50000 (97%)]\tLoss: 0.065837, Accuracy: 96.88\n",
      "Train Epoch: 70 [35000/50000 (99%)]\tLoss: 0.064102, Accuracy: 98.50\n",
      "\n",
      "Validation set: Average loss: 0.3169, Accuracy: 4553/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[37.53821086883545 s]\n",
      "\n",
      "Test set: Average loss: 0.3254, Accuracy: 9116/10000 (91.16%)\n",
      "\n",
      "Train Epoch: 71 [0/50000 (0%)]\tLoss: 0.041767, Accuracy: 98.83\n",
      "Train Epoch: 71 [1280/50000 (3%)]\tLoss: 0.099012, Accuracy: 97.27\n",
      "Train Epoch: 71 [2560/50000 (6%)]\tLoss: 0.050840, Accuracy: 97.66\n",
      "Train Epoch: 71 [3840/50000 (9%)]\tLoss: 0.049556, Accuracy: 98.44\n",
      "Train Epoch: 71 [5120/50000 (11%)]\tLoss: 0.114204, Accuracy: 95.70\n",
      "Train Epoch: 71 [6400/50000 (14%)]\tLoss: 0.070067, Accuracy: 98.05\n",
      "Train Epoch: 71 [7680/50000 (17%)]\tLoss: 0.053762, Accuracy: 98.05\n",
      "Train Epoch: 71 [8960/50000 (20%)]\tLoss: 0.081655, Accuracy: 96.48\n",
      "Train Epoch: 71 [10240/50000 (23%)]\tLoss: 0.077562, Accuracy: 97.27\n",
      "Train Epoch: 71 [11520/50000 (26%)]\tLoss: 0.052384, Accuracy: 98.05\n",
      "Train Epoch: 71 [12800/50000 (28%)]\tLoss: 0.089171, Accuracy: 96.88\n",
      "Train Epoch: 71 [14080/50000 (31%)]\tLoss: 0.051813, Accuracy: 98.05\n",
      "Train Epoch: 71 [15360/50000 (34%)]\tLoss: 0.081403, Accuracy: 96.48\n",
      "Train Epoch: 71 [16640/50000 (37%)]\tLoss: 0.057506, Accuracy: 98.05\n",
      "Train Epoch: 71 [17920/50000 (40%)]\tLoss: 0.045282, Accuracy: 98.44\n",
      "Train Epoch: 71 [19200/50000 (43%)]\tLoss: 0.044897, Accuracy: 98.83\n",
      "Train Epoch: 71 [20480/50000 (45%)]\tLoss: 0.083644, Accuracy: 96.09\n",
      "Train Epoch: 71 [21760/50000 (48%)]\tLoss: 0.085885, Accuracy: 97.66\n",
      "Train Epoch: 71 [23040/50000 (51%)]\tLoss: 0.072668, Accuracy: 96.88\n",
      "Train Epoch: 71 [24320/50000 (54%)]\tLoss: 0.081258, Accuracy: 97.27\n",
      "Train Epoch: 71 [25600/50000 (57%)]\tLoss: 0.042536, Accuracy: 98.44\n",
      "Train Epoch: 71 [26880/50000 (60%)]\tLoss: 0.044242, Accuracy: 99.22\n",
      "Train Epoch: 71 [28160/50000 (62%)]\tLoss: 0.132941, Accuracy: 95.31\n",
      "Train Epoch: 71 [29440/50000 (65%)]\tLoss: 0.078794, Accuracy: 97.27\n",
      "Train Epoch: 71 [30720/50000 (68%)]\tLoss: 0.040028, Accuracy: 98.83\n",
      "torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.5587]],\n",
      "\n",
      "        [[ 0.2867]],\n",
      "\n",
      "        [[ 0.2308]],\n",
      "\n",
      "        [[ 0.0065]],\n",
      "\n",
      "        [[-0.0045]],\n",
      "\n",
      "        [[ 0.6361]],\n",
      "\n",
      "        [[-2.7878]],\n",
      "\n",
      "        [[ 1.5986]],\n",
      "\n",
      "        [[-0.7316]],\n",
      "\n",
      "        [[ 2.6199]],\n",
      "\n",
      "        [[ 1.1821]],\n",
      "\n",
      "        [[ 0.5620]],\n",
      "\n",
      "        [[ 1.8686]],\n",
      "\n",
      "        [[ 0.1070]],\n",
      "\n",
      "        [[ 0.3342]],\n",
      "\n",
      "        [[-1.2860]],\n",
      "\n",
      "        [[-0.9743]],\n",
      "\n",
      "        [[-0.6662]],\n",
      "\n",
      "        [[-2.3561]],\n",
      "\n",
      "        [[-1.8254]],\n",
      "\n",
      "        [[-0.5019]],\n",
      "\n",
      "        [[-0.5212]],\n",
      "\n",
      "        [[ 2.1648]],\n",
      "\n",
      "        [[ 0.1440]],\n",
      "\n",
      "        [[ 0.8610]],\n",
      "\n",
      "        [[-0.1786]],\n",
      "\n",
      "        [[-0.6988]],\n",
      "\n",
      "        [[ 0.4208]],\n",
      "\n",
      "        [[ 0.0844]],\n",
      "\n",
      "        [[ 0.2307]],\n",
      "\n",
      "        [[ 1.4191]],\n",
      "\n",
      "        [[-1.2140]],\n",
      "\n",
      "        [[-1.6583]],\n",
      "\n",
      "        [[ 1.0259]],\n",
      "\n",
      "        [[ 1.0342]],\n",
      "\n",
      "        [[-0.6824]],\n",
      "\n",
      "        [[-0.9492]],\n",
      "\n",
      "        [[ 0.0627]],\n",
      "\n",
      "        [[ 3.7741]],\n",
      "\n",
      "        [[-0.0242]],\n",
      "\n",
      "        [[-0.0732]],\n",
      "\n",
      "        [[-0.7946]],\n",
      "\n",
      "        [[-0.7460]],\n",
      "\n",
      "        [[-0.8106]],\n",
      "\n",
      "        [[-0.6603]],\n",
      "\n",
      "        [[-0.0552]],\n",
      "\n",
      "        [[-0.8405]],\n",
      "\n",
      "        [[ 0.5656]],\n",
      "\n",
      "        [[-2.4524]],\n",
      "\n",
      "        [[-1.5528]],\n",
      "\n",
      "        [[ 0.5649]],\n",
      "\n",
      "        [[-0.7359]],\n",
      "\n",
      "        [[ 0.3731]],\n",
      "\n",
      "        [[ 0.4829]],\n",
      "\n",
      "        [[ 0.6117]],\n",
      "\n",
      "        [[ 1.7038]],\n",
      "\n",
      "        [[-1.5124]],\n",
      "\n",
      "        [[ 0.4451]],\n",
      "\n",
      "        [[ 0.1981]],\n",
      "\n",
      "        [[ 0.2307]],\n",
      "\n",
      "        [[-0.8124]],\n",
      "\n",
      "        [[-0.1870]],\n",
      "\n",
      "        [[-0.2327]],\n",
      "\n",
      "        [[-0.8500]],\n",
      "\n",
      "        [[ 0.4744]],\n",
      "\n",
      "        [[ 1.5582]],\n",
      "\n",
      "        [[-0.5509]],\n",
      "\n",
      "        [[-1.7329]],\n",
      "\n",
      "        [[-0.7344]],\n",
      "\n",
      "        [[ 0.5176]],\n",
      "\n",
      "        [[-0.2238]],\n",
      "\n",
      "        [[-0.4463]],\n",
      "\n",
      "        [[ 0.2339]],\n",
      "\n",
      "        [[ 0.4991]],\n",
      "\n",
      "        [[ 1.7359]],\n",
      "\n",
      "        [[ 1.5229]],\n",
      "\n",
      "        [[-0.0310]],\n",
      "\n",
      "        [[ 1.6859]],\n",
      "\n",
      "        [[ 0.7711]],\n",
      "\n",
      "        [[-0.5787]],\n",
      "\n",
      "        [[ 1.1344]],\n",
      "\n",
      "        [[ 0.5911]],\n",
      "\n",
      "        [[ 0.6339]],\n",
      "\n",
      "        [[-0.0083]],\n",
      "\n",
      "        [[-2.0300]],\n",
      "\n",
      "        [[ 1.1726]],\n",
      "\n",
      "        [[-0.4866]],\n",
      "\n",
      "        [[ 0.4214]],\n",
      "\n",
      "        [[ 0.4143]],\n",
      "\n",
      "        [[ 0.8056]],\n",
      "\n",
      "        [[ 0.8520]],\n",
      "\n",
      "        [[ 1.1015]],\n",
      "\n",
      "        [[ 0.0916]],\n",
      "\n",
      "        [[ 0.7224]],\n",
      "\n",
      "        [[ 0.4467]],\n",
      "\n",
      "        [[ 0.9880]],\n",
      "\n",
      "        [[ 1.3270]],\n",
      "\n",
      "        [[-0.3468]],\n",
      "\n",
      "        [[ 0.9437]],\n",
      "\n",
      "        [[ 1.2771]],\n",
      "\n",
      "        [[-0.2916]],\n",
      "\n",
      "        [[-1.4147]],\n",
      "\n",
      "        [[-0.8635]],\n",
      "\n",
      "        [[-2.4762]],\n",
      "\n",
      "        [[-0.1246]],\n",
      "\n",
      "        [[ 0.2409]],\n",
      "\n",
      "        [[ 0.4145]],\n",
      "\n",
      "        [[ 1.4538]],\n",
      "\n",
      "        [[ 0.4949]],\n",
      "\n",
      "        [[-0.2954]],\n",
      "\n",
      "        [[-0.7091]],\n",
      "\n",
      "        [[-0.9141]],\n",
      "\n",
      "        [[ 0.4832]],\n",
      "\n",
      "        [[ 1.3654]],\n",
      "\n",
      "        [[-0.5683]],\n",
      "\n",
      "        [[-2.4534]],\n",
      "\n",
      "        [[ 0.1785]],\n",
      "\n",
      "        [[ 0.4035]],\n",
      "\n",
      "        [[-1.0864]],\n",
      "\n",
      "        [[ 0.0083]],\n",
      "\n",
      "        [[ 0.4249]],\n",
      "\n",
      "        [[-1.2330]],\n",
      "\n",
      "        [[-0.2455]],\n",
      "\n",
      "        [[ 0.9326]],\n",
      "\n",
      "        [[ 0.1896]],\n",
      "\n",
      "        [[-0.0941]],\n",
      "\n",
      "        [[ 0.8940]],\n",
      "\n",
      "        [[-0.6802]],\n",
      "\n",
      "        [[-1.8365]],\n",
      "\n",
      "        [[-0.4199]],\n",
      "\n",
      "        [[-0.6602]],\n",
      "\n",
      "        [[-0.3293]],\n",
      "\n",
      "        [[-1.1834]],\n",
      "\n",
      "        [[ 0.4489]],\n",
      "\n",
      "        [[-0.8621]],\n",
      "\n",
      "        [[-0.6044]],\n",
      "\n",
      "        [[-0.0753]],\n",
      "\n",
      "        [[-0.9396]],\n",
      "\n",
      "        [[-0.5699]],\n",
      "\n",
      "        [[-0.8403]],\n",
      "\n",
      "        [[-2.0260]],\n",
      "\n",
      "        [[-0.0809]],\n",
      "\n",
      "        [[-0.7055]],\n",
      "\n",
      "        [[-2.8347]],\n",
      "\n",
      "        [[-1.3573]],\n",
      "\n",
      "        [[-1.1334]],\n",
      "\n",
      "        [[ 1.4192]],\n",
      "\n",
      "        [[-1.0548]],\n",
      "\n",
      "        [[-0.6131]],\n",
      "\n",
      "        [[ 0.5264]],\n",
      "\n",
      "        [[ 0.2238]],\n",
      "\n",
      "        [[ 0.1052]],\n",
      "\n",
      "        [[-0.4150]],\n",
      "\n",
      "        [[-1.2860]],\n",
      "\n",
      "        [[ 0.4233]],\n",
      "\n",
      "        [[ 0.5888]],\n",
      "\n",
      "        [[ 0.4328]],\n",
      "\n",
      "        [[ 2.3003]],\n",
      "\n",
      "        [[ 1.1446]],\n",
      "\n",
      "        [[-1.9279]],\n",
      "\n",
      "        [[ 1.0834]],\n",
      "\n",
      "        [[-0.1771]],\n",
      "\n",
      "        [[ 0.2632]],\n",
      "\n",
      "        [[ 0.4089]],\n",
      "\n",
      "        [[ 0.4541]],\n",
      "\n",
      "        [[-0.6135]],\n",
      "\n",
      "        [[-0.5138]],\n",
      "\n",
      "        [[-0.3926]],\n",
      "\n",
      "        [[-0.1035]],\n",
      "\n",
      "        [[-0.1801]],\n",
      "\n",
      "        [[-0.2948]],\n",
      "\n",
      "        [[-0.7487]],\n",
      "\n",
      "        [[-0.7619]],\n",
      "\n",
      "        [[-0.2420]],\n",
      "\n",
      "        [[ 1.0267]],\n",
      "\n",
      "        [[ 0.2248]],\n",
      "\n",
      "        [[ 0.1442]],\n",
      "\n",
      "        [[-0.9958]],\n",
      "\n",
      "        [[ 1.8948]],\n",
      "\n",
      "        [[ 1.4804]],\n",
      "\n",
      "        [[ 2.3655]],\n",
      "\n",
      "        [[-0.5437]],\n",
      "\n",
      "        [[-0.1826]],\n",
      "\n",
      "        [[-0.0397]],\n",
      "\n",
      "        [[-0.3506]],\n",
      "\n",
      "        [[-0.7479]],\n",
      "\n",
      "        [[ 1.5595]],\n",
      "\n",
      "        [[-2.2599]],\n",
      "\n",
      "        [[ 0.7880]],\n",
      "\n",
      "        [[ 1.6999]],\n",
      "\n",
      "        [[-2.0649]],\n",
      "\n",
      "        [[ 0.8701]],\n",
      "\n",
      "        [[-0.0465]],\n",
      "\n",
      "        [[-1.2839]],\n",
      "\n",
      "        [[ 1.3713]],\n",
      "\n",
      "        [[-0.0322]],\n",
      "\n",
      "        [[ 0.7814]],\n",
      "\n",
      "        [[-2.8630]],\n",
      "\n",
      "        [[ 0.0404]],\n",
      "\n",
      "        [[-0.0027]],\n",
      "\n",
      "        [[ 0.8803]],\n",
      "\n",
      "        [[-0.4984]],\n",
      "\n",
      "        [[-1.4352]],\n",
      "\n",
      "        [[ 0.5506]],\n",
      "\n",
      "        [[-0.8683]],\n",
      "\n",
      "        [[ 0.7473]],\n",
      "\n",
      "        [[ 0.9415]],\n",
      "\n",
      "        [[-0.1417]],\n",
      "\n",
      "        [[-1.5592]],\n",
      "\n",
      "        [[ 0.3087]],\n",
      "\n",
      "        [[-0.2850]],\n",
      "\n",
      "        [[-0.5159]],\n",
      "\n",
      "        [[-1.2095]],\n",
      "\n",
      "        [[ 0.7148]],\n",
      "\n",
      "        [[-0.2408]],\n",
      "\n",
      "        [[-0.8583]],\n",
      "\n",
      "        [[ 0.9078]],\n",
      "\n",
      "        [[-1.6086]],\n",
      "\n",
      "        [[ 1.0900]],\n",
      "\n",
      "        [[-0.2874]],\n",
      "\n",
      "        [[-2.3934]],\n",
      "\n",
      "        [[ 0.3591]],\n",
      "\n",
      "        [[ 0.6348]],\n",
      "\n",
      "        [[-0.7813]],\n",
      "\n",
      "        [[-0.4655]],\n",
      "\n",
      "        [[-1.1439]],\n",
      "\n",
      "        [[-1.4129]],\n",
      "\n",
      "        [[-0.3962]],\n",
      "\n",
      "        [[-0.9182]],\n",
      "\n",
      "        [[-0.2874]],\n",
      "\n",
      "        [[ 0.2769]],\n",
      "\n",
      "        [[ 1.4331]],\n",
      "\n",
      "        [[ 0.8966]],\n",
      "\n",
      "        [[ 0.8447]],\n",
      "\n",
      "        [[-0.2429]],\n",
      "\n",
      "        [[ 1.5650]],\n",
      "\n",
      "        [[ 1.8604]],\n",
      "\n",
      "        [[ 1.3158]],\n",
      "\n",
      "        [[ 0.0008]],\n",
      "\n",
      "        [[-1.1573]],\n",
      "\n",
      "        [[ 1.2884]],\n",
      "\n",
      "        [[-0.2218]],\n",
      "\n",
      "        [[-1.0318]],\n",
      "\n",
      "        [[ 0.1315]],\n",
      "\n",
      "        [[-0.4052]],\n",
      "\n",
      "        [[ 0.5718]],\n",
      "\n",
      "        [[-0.3129]],\n",
      "\n",
      "        [[ 1.3258]],\n",
      "\n",
      "        [[-0.0696]],\n",
      "\n",
      "        [[-0.0435]],\n",
      "\n",
      "        [[-0.8931]],\n",
      "\n",
      "        [[-2.0812]],\n",
      "\n",
      "        [[ 0.2819]],\n",
      "\n",
      "        [[ 1.8173]],\n",
      "\n",
      "        [[-1.9038]],\n",
      "\n",
      "        [[ 0.0422]],\n",
      "\n",
      "        [[ 0.6850]],\n",
      "\n",
      "        [[ 0.7871]],\n",
      "\n",
      "        [[-0.6065]],\n",
      "\n",
      "        [[ 0.3480]],\n",
      "\n",
      "        [[ 0.0635]],\n",
      "\n",
      "        [[ 1.8142]],\n",
      "\n",
      "        [[-0.4579]],\n",
      "\n",
      "        [[-0.1512]],\n",
      "\n",
      "        [[ 2.2066]],\n",
      "\n",
      "        [[-0.7199]],\n",
      "\n",
      "        [[ 0.0557]],\n",
      "\n",
      "        [[ 0.0863]],\n",
      "\n",
      "        [[-0.8021]],\n",
      "\n",
      "        [[ 0.5118]],\n",
      "\n",
      "        [[ 0.6495]],\n",
      "\n",
      "        [[ 0.0367]],\n",
      "\n",
      "        [[-0.0099]],\n",
      "\n",
      "        [[-1.9002]],\n",
      "\n",
      "        [[-1.4530]],\n",
      "\n",
      "        [[ 0.3510]],\n",
      "\n",
      "        [[ 1.0753]],\n",
      "\n",
      "        [[-0.4603]],\n",
      "\n",
      "        [[ 0.8931]],\n",
      "\n",
      "        [[ 1.2543]],\n",
      "\n",
      "        [[-1.4241]],\n",
      "\n",
      "        [[ 0.2691]],\n",
      "\n",
      "        [[ 0.3885]],\n",
      "\n",
      "        [[ 0.7065]],\n",
      "\n",
      "        [[ 0.2452]],\n",
      "\n",
      "        [[ 0.2857]],\n",
      "\n",
      "        [[-1.5459]],\n",
      "\n",
      "        [[-0.7581]],\n",
      "\n",
      "        [[-0.2866]],\n",
      "\n",
      "        [[-0.1746]],\n",
      "\n",
      "        [[-0.0703]],\n",
      "\n",
      "        [[ 0.6084]],\n",
      "\n",
      "        [[ 0.1271]],\n",
      "\n",
      "        [[ 1.0930]],\n",
      "\n",
      "        [[ 0.6722]],\n",
      "\n",
      "        [[-1.4833]],\n",
      "\n",
      "        [[ 1.0190]],\n",
      "\n",
      "        [[-1.1216]],\n",
      "\n",
      "        [[ 1.2932]],\n",
      "\n",
      "        [[ 0.9050]],\n",
      "\n",
      "        [[-2.0083]],\n",
      "\n",
      "        [[ 2.2318]],\n",
      "\n",
      "        [[ 0.0890]],\n",
      "\n",
      "        [[-1.4967]],\n",
      "\n",
      "        [[ 1.4830]],\n",
      "\n",
      "        [[ 1.2638]],\n",
      "\n",
      "        [[-1.1422]],\n",
      "\n",
      "        [[-0.6408]],\n",
      "\n",
      "        [[ 0.3894]],\n",
      "\n",
      "        [[-0.4024]],\n",
      "\n",
      "        [[-0.3992]],\n",
      "\n",
      "        [[-0.7513]],\n",
      "\n",
      "        [[-1.1597]],\n",
      "\n",
      "        [[ 0.2228]],\n",
      "\n",
      "        [[-2.3575]],\n",
      "\n",
      "        [[ 2.0414]],\n",
      "\n",
      "        [[ 0.5278]],\n",
      "\n",
      "        [[ 0.7280]],\n",
      "\n",
      "        [[ 0.9956]],\n",
      "\n",
      "        [[ 1.1991]],\n",
      "\n",
      "        [[-1.4614]],\n",
      "\n",
      "        [[ 0.2195]],\n",
      "\n",
      "        [[-0.3668]],\n",
      "\n",
      "        [[ 1.5428]],\n",
      "\n",
      "        [[ 0.9903]],\n",
      "\n",
      "        [[-1.2951]],\n",
      "\n",
      "        [[-1.1279]],\n",
      "\n",
      "        [[-0.0866]],\n",
      "\n",
      "        [[-0.7741]],\n",
      "\n",
      "        [[-0.4348]],\n",
      "\n",
      "        [[ 0.5763]],\n",
      "\n",
      "        [[ 0.6641]],\n",
      "\n",
      "        [[ 0.2524]],\n",
      "\n",
      "        [[-0.0888]],\n",
      "\n",
      "        [[-1.5267]],\n",
      "\n",
      "        [[-0.6411]],\n",
      "\n",
      "        [[ 0.2000]],\n",
      "\n",
      "        [[-0.7383]],\n",
      "\n",
      "        [[-0.1226]],\n",
      "\n",
      "        [[-0.8981]],\n",
      "\n",
      "        [[ 1.6547]],\n",
      "\n",
      "        [[ 1.0504]],\n",
      "\n",
      "        [[ 0.9639]],\n",
      "\n",
      "        [[ 0.1922]],\n",
      "\n",
      "        [[-1.5750]],\n",
      "\n",
      "        [[ 1.8213]],\n",
      "\n",
      "        [[ 1.8140]],\n",
      "\n",
      "        [[-1.3095]],\n",
      "\n",
      "        [[-1.6606]],\n",
      "\n",
      "        [[ 0.2924]],\n",
      "\n",
      "        [[-0.1570]],\n",
      "\n",
      "        [[-0.3170]],\n",
      "\n",
      "        [[ 0.2853]],\n",
      "\n",
      "        [[ 0.1818]],\n",
      "\n",
      "        [[-1.3680]],\n",
      "\n",
      "        [[-1.1209]],\n",
      "\n",
      "        [[-1.2969]],\n",
      "\n",
      "        [[-0.6391]],\n",
      "\n",
      "        [[ 0.1117]],\n",
      "\n",
      "        [[ 1.8628]],\n",
      "\n",
      "        [[-0.8781]],\n",
      "\n",
      "        [[ 0.7813]],\n",
      "\n",
      "        [[-0.6602]],\n",
      "\n",
      "        [[ 0.0814]],\n",
      "\n",
      "        [[-0.3621]],\n",
      "\n",
      "        [[ 0.4805]],\n",
      "\n",
      "        [[-1.3474]],\n",
      "\n",
      "        [[-0.4828]],\n",
      "\n",
      "        [[-0.3903]],\n",
      "\n",
      "        [[ 0.1679]],\n",
      "\n",
      "        [[ 0.2670]],\n",
      "\n",
      "        [[ 0.3332]],\n",
      "\n",
      "        [[ 0.9137]],\n",
      "\n",
      "        [[-0.4227]],\n",
      "\n",
      "        [[ 0.3582]],\n",
      "\n",
      "        [[-1.0586]],\n",
      "\n",
      "        [[ 0.5341]],\n",
      "\n",
      "        [[-0.3715]],\n",
      "\n",
      "        [[ 0.3688]],\n",
      "\n",
      "        [[ 1.4638]],\n",
      "\n",
      "        [[-0.4131]],\n",
      "\n",
      "        [[ 2.5203]],\n",
      "\n",
      "        [[ 1.3752]],\n",
      "\n",
      "        [[ 0.5380]],\n",
      "\n",
      "        [[ 0.9595]],\n",
      "\n",
      "        [[-1.5019]],\n",
      "\n",
      "        [[ 1.0910]],\n",
      "\n",
      "        [[ 0.0369]],\n",
      "\n",
      "        [[ 0.1461]],\n",
      "\n",
      "        [[-0.4929]],\n",
      "\n",
      "        [[ 0.9965]],\n",
      "\n",
      "        [[-0.0539]],\n",
      "\n",
      "        [[-0.5947]],\n",
      "\n",
      "        [[ 2.5580]],\n",
      "\n",
      "        [[ 0.2207]],\n",
      "\n",
      "        [[-0.0540]],\n",
      "\n",
      "        [[-0.6746]],\n",
      "\n",
      "        [[-0.1960]],\n",
      "\n",
      "        [[-0.5455]],\n",
      "\n",
      "        [[ 0.5480]],\n",
      "\n",
      "        [[-0.6915]],\n",
      "\n",
      "        [[ 0.2815]],\n",
      "\n",
      "        [[-1.1132]],\n",
      "\n",
      "        [[-0.7138]],\n",
      "\n",
      "        [[-1.0430]],\n",
      "\n",
      "        [[ 1.0653]],\n",
      "\n",
      "        [[ 0.1533]],\n",
      "\n",
      "        [[ 0.5442]],\n",
      "\n",
      "        [[ 0.4407]],\n",
      "\n",
      "        [[-1.1574]],\n",
      "\n",
      "        [[ 1.1459]],\n",
      "\n",
      "        [[-0.8486]],\n",
      "\n",
      "        [[ 1.9933]],\n",
      "\n",
      "        [[ 0.6505]],\n",
      "\n",
      "        [[ 0.2936]],\n",
      "\n",
      "        [[-1.8991]],\n",
      "\n",
      "        [[-0.2798]],\n",
      "\n",
      "        [[ 0.1532]],\n",
      "\n",
      "        [[-0.7672]],\n",
      "\n",
      "        [[ 0.8512]],\n",
      "\n",
      "        [[ 0.7551]],\n",
      "\n",
      "        [[-0.1565]],\n",
      "\n",
      "        [[ 1.4436]],\n",
      "\n",
      "        [[ 1.2758]],\n",
      "\n",
      "        [[-2.3603]],\n",
      "\n",
      "        [[-0.3756]],\n",
      "\n",
      "        [[ 0.9290]],\n",
      "\n",
      "        [[-0.2739]],\n",
      "\n",
      "        [[-0.1331]],\n",
      "\n",
      "        [[-1.4220]],\n",
      "\n",
      "        [[-0.8156]],\n",
      "\n",
      "        [[ 0.5239]],\n",
      "\n",
      "        [[ 0.1355]],\n",
      "\n",
      "        [[ 0.9848]],\n",
      "\n",
      "        [[-1.5653]],\n",
      "\n",
      "        [[ 1.5859]],\n",
      "\n",
      "        [[ 0.1023]],\n",
      "\n",
      "        [[ 1.0068]],\n",
      "\n",
      "        [[ 0.4592]],\n",
      "\n",
      "        [[ 0.8780]],\n",
      "\n",
      "        [[-0.6328]],\n",
      "\n",
      "        [[ 0.6777]],\n",
      "\n",
      "        [[ 0.6371]],\n",
      "\n",
      "        [[-0.9766]],\n",
      "\n",
      "        [[-0.1955]],\n",
      "\n",
      "        [[ 0.7650]],\n",
      "\n",
      "        [[ 0.7158]],\n",
      "\n",
      "        [[ 0.3010]],\n",
      "\n",
      "        [[ 0.7323]],\n",
      "\n",
      "        [[-0.0157]],\n",
      "\n",
      "        [[ 0.8626]],\n",
      "\n",
      "        [[-0.5559]],\n",
      "\n",
      "        [[ 1.7622]],\n",
      "\n",
      "        [[ 2.7205]],\n",
      "\n",
      "        [[ 0.0738]],\n",
      "\n",
      "        [[-0.2943]],\n",
      "\n",
      "        [[ 0.5915]],\n",
      "\n",
      "        [[-0.6071]],\n",
      "\n",
      "        [[-1.7464]],\n",
      "\n",
      "        [[-0.8683]],\n",
      "\n",
      "        [[ 0.4477]],\n",
      "\n",
      "        [[-0.2425]],\n",
      "\n",
      "        [[ 0.1411]],\n",
      "\n",
      "        [[-0.8715]],\n",
      "\n",
      "        [[-1.0058]],\n",
      "\n",
      "        [[-0.5105]],\n",
      "\n",
      "        [[ 0.1560]],\n",
      "\n",
      "        [[ 1.7083]],\n",
      "\n",
      "        [[ 0.5474]],\n",
      "\n",
      "        [[ 0.5676]],\n",
      "\n",
      "        [[ 0.4127]],\n",
      "\n",
      "        [[-0.0103]],\n",
      "\n",
      "        [[-0.7822]],\n",
      "\n",
      "        [[-0.2367]],\n",
      "\n",
      "        [[-0.4893]],\n",
      "\n",
      "        [[-0.3689]],\n",
      "\n",
      "        [[-1.2789]],\n",
      "\n",
      "        [[ 0.8009]],\n",
      "\n",
      "        [[ 0.9853]],\n",
      "\n",
      "        [[ 1.8712]],\n",
      "\n",
      "        [[ 0.9456]],\n",
      "\n",
      "        [[ 0.1456]],\n",
      "\n",
      "        [[ 0.7795]],\n",
      "\n",
      "        [[-0.0943]],\n",
      "\n",
      "        [[-0.3136]],\n",
      "\n",
      "        [[-0.1290]],\n",
      "\n",
      "        [[ 1.2009]],\n",
      "\n",
      "        [[ 0.9052]],\n",
      "\n",
      "        [[-1.2085]],\n",
      "\n",
      "        [[ 0.6199]],\n",
      "\n",
      "        [[-0.2879]],\n",
      "\n",
      "        [[-1.1220]],\n",
      "\n",
      "        [[-0.7267]],\n",
      "\n",
      "        [[ 1.1655]],\n",
      "\n",
      "        [[-0.6000]],\n",
      "\n",
      "        [[ 0.6211]],\n",
      "\n",
      "        [[-1.7544]],\n",
      "\n",
      "        [[-1.1322]],\n",
      "\n",
      "        [[-1.0657]],\n",
      "\n",
      "        [[ 1.0963]],\n",
      "\n",
      "        [[ 0.7470]],\n",
      "\n",
      "        [[ 1.6210]],\n",
      "\n",
      "        [[-0.3836]],\n",
      "\n",
      "        [[ 0.4402]],\n",
      "\n",
      "        [[ 0.5512]],\n",
      "\n",
      "        [[ 0.9857]],\n",
      "\n",
      "        [[-0.3054]],\n",
      "\n",
      "        [[-1.0912]],\n",
      "\n",
      "        [[ 0.9348]],\n",
      "\n",
      "        [[-2.1152]],\n",
      "\n",
      "        [[-0.4283]],\n",
      "\n",
      "        [[-0.6196]]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 8.9861]]], device='cuda:0')\n",
      "torch.Size([1, 896, 512])\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 1.9531,  1.9532,  1.9529,  ...,  1.9533,  1.9531,  1.9531],\n",
      "         [ 1.9530,  1.9531,  1.9529,  ...,  1.9531,  1.9532,  1.9531],\n",
      "         [ 1.9531,  1.9531,  1.9531,  ...,  1.9530,  1.9532,  1.9531],\n",
      "         ...,\n",
      "         [ 1.9530,  1.9533,  1.9532,  ...,  1.9532,  1.9531,  1.9531],\n",
      "         [ 1.9531,  1.9532,  1.9530,  ...,  1.9530,  1.9532,  1.9531],\n",
      "         [ 1.9533,  1.9531,  1.9532,  ...,  1.9531,  1.9532,  1.9531]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 71 [32000/50000 (71%)]\tLoss: 0.085920, Accuracy: 96.88\n",
      "Train Epoch: 71 [33280/50000 (74%)]\tLoss: 0.073686, Accuracy: 97.66\n",
      "Train Epoch: 71 [34560/50000 (77%)]\tLoss: 0.053334, Accuracy: 98.05\n",
      "Train Epoch: 71 [35840/50000 (80%)]\tLoss: 0.035969, Accuracy: 98.83\n",
      "Train Epoch: 71 [37120/50000 (82%)]\tLoss: 0.046294, Accuracy: 98.83\n",
      "Train Epoch: 71 [38400/50000 (85%)]\tLoss: 0.034558, Accuracy: 98.44\n",
      "Train Epoch: 71 [39680/50000 (88%)]\tLoss: 0.059352, Accuracy: 97.27\n",
      "Train Epoch: 71 [40960/50000 (91%)]\tLoss: 0.042200, Accuracy: 98.83\n",
      "Train Epoch: 71 [42240/50000 (94%)]\tLoss: 0.064464, Accuracy: 98.83\n",
      "Train Epoch: 71 [43520/50000 (97%)]\tLoss: 0.094121, Accuracy: 96.88\n",
      "Train Epoch: 71 [35000/50000 (99%)]\tLoss: 0.032720, Accuracy: 99.00\n",
      "\n",
      "Validation set: Average loss: 0.2955, Accuracy: 4579/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[40.77070498466492 s]\n",
      "Train Epoch: 72 [0/50000 (0%)]\tLoss: 0.077659, Accuracy: 98.05\n",
      "Train Epoch: 72 [1280/50000 (3%)]\tLoss: 0.079310, Accuracy: 98.05\n",
      "Train Epoch: 72 [2560/50000 (6%)]\tLoss: 0.063300, Accuracy: 97.27\n",
      "Train Epoch: 72 [3840/50000 (9%)]\tLoss: 0.082658, Accuracy: 96.88\n",
      "Train Epoch: 72 [5120/50000 (11%)]\tLoss: 0.081929, Accuracy: 98.05\n",
      "Train Epoch: 72 [6400/50000 (14%)]\tLoss: 0.042635, Accuracy: 98.83\n",
      "Train Epoch: 72 [7680/50000 (17%)]\tLoss: 0.045292, Accuracy: 98.83\n",
      "Train Epoch: 72 [8960/50000 (20%)]\tLoss: 0.027441, Accuracy: 99.61\n",
      "Train Epoch: 72 [10240/50000 (23%)]\tLoss: 0.043693, Accuracy: 98.83\n",
      "Train Epoch: 72 [11520/50000 (26%)]\tLoss: 0.058535, Accuracy: 98.44\n",
      "Train Epoch: 72 [12800/50000 (28%)]\tLoss: 0.024362, Accuracy: 99.22\n",
      "Train Epoch: 72 [14080/50000 (31%)]\tLoss: 0.060359, Accuracy: 98.44\n",
      "Train Epoch: 72 [15360/50000 (34%)]\tLoss: 0.045431, Accuracy: 98.44\n",
      "Train Epoch: 72 [16640/50000 (37%)]\tLoss: 0.031039, Accuracy: 98.83\n",
      "Train Epoch: 72 [17920/50000 (40%)]\tLoss: 0.114552, Accuracy: 95.70\n",
      "Train Epoch: 72 [19200/50000 (43%)]\tLoss: 0.025844, Accuracy: 99.22\n",
      "Train Epoch: 72 [20480/50000 (45%)]\tLoss: 0.055436, Accuracy: 98.05\n",
      "Train Epoch: 72 [21760/50000 (48%)]\tLoss: 0.061496, Accuracy: 98.05\n",
      "Train Epoch: 72 [23040/50000 (51%)]\tLoss: 0.031000, Accuracy: 99.22\n",
      "Train Epoch: 72 [24320/50000 (54%)]\tLoss: 0.021287, Accuracy: 99.61\n",
      "Train Epoch: 72 [25600/50000 (57%)]\tLoss: 0.068965, Accuracy: 97.27\n",
      "Train Epoch: 72 [26880/50000 (60%)]\tLoss: 0.035732, Accuracy: 98.83\n",
      "Train Epoch: 72 [28160/50000 (62%)]\tLoss: 0.078940, Accuracy: 97.66\n",
      "Train Epoch: 72 [29440/50000 (65%)]\tLoss: 0.076518, Accuracy: 97.27\n",
      "Train Epoch: 72 [30720/50000 (68%)]\tLoss: 0.069049, Accuracy: 97.27\n",
      "Train Epoch: 72 [32000/50000 (71%)]\tLoss: 0.050521, Accuracy: 99.22\n",
      "Train Epoch: 72 [33280/50000 (74%)]\tLoss: 0.057880, Accuracy: 97.66\n",
      "Train Epoch: 72 [34560/50000 (77%)]\tLoss: 0.032937, Accuracy: 99.22\n",
      "Train Epoch: 72 [35840/50000 (80%)]\tLoss: 0.072852, Accuracy: 97.27\n",
      "Train Epoch: 72 [37120/50000 (82%)]\tLoss: 0.066723, Accuracy: 98.05\n",
      "Train Epoch: 72 [38400/50000 (85%)]\tLoss: 0.042936, Accuracy: 98.83\n",
      "Train Epoch: 72 [39680/50000 (88%)]\tLoss: 0.061763, Accuracy: 97.27\n",
      "Train Epoch: 72 [40960/50000 (91%)]\tLoss: 0.041687, Accuracy: 98.44\n",
      "Train Epoch: 72 [42240/50000 (94%)]\tLoss: 0.039776, Accuracy: 98.05\n",
      "Train Epoch: 72 [43520/50000 (97%)]\tLoss: 0.066177, Accuracy: 98.05\n",
      "Train Epoch: 72 [35000/50000 (99%)]\tLoss: 0.052300, Accuracy: 98.50\n",
      "\n",
      "Validation set: Average loss: 0.2981, Accuracy: 4583/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[37.66337251663208 s]\n",
      "\n",
      "Test set: Average loss: 0.3043, Accuracy: 9164/10000 (91.64%)\n",
      "\n",
      "Train Epoch: 73 [0/50000 (0%)]\tLoss: 0.059740, Accuracy: 98.05\n",
      "Train Epoch: 73 [1280/50000 (3%)]\tLoss: 0.032449, Accuracy: 99.61\n",
      "Train Epoch: 73 [2560/50000 (6%)]\tLoss: 0.051038, Accuracy: 98.44\n",
      "Train Epoch: 73 [3840/50000 (9%)]\tLoss: 0.079022, Accuracy: 97.27\n",
      "Train Epoch: 73 [5120/50000 (11%)]\tLoss: 0.055728, Accuracy: 97.66\n",
      "Train Epoch: 73 [6400/50000 (14%)]\tLoss: 0.041416, Accuracy: 98.83\n",
      "Train Epoch: 73 [7680/50000 (17%)]\tLoss: 0.034875, Accuracy: 98.83\n",
      "Train Epoch: 73 [8960/50000 (20%)]\tLoss: 0.039202, Accuracy: 99.22\n",
      "Train Epoch: 73 [10240/50000 (23%)]\tLoss: 0.024895, Accuracy: 99.22\n",
      "Train Epoch: 73 [11520/50000 (26%)]\tLoss: 0.048688, Accuracy: 97.66\n",
      "Train Epoch: 73 [12800/50000 (28%)]\tLoss: 0.075352, Accuracy: 97.66\n",
      "Train Epoch: 73 [14080/50000 (31%)]\tLoss: 0.066639, Accuracy: 96.48\n",
      "Train Epoch: 73 [15360/50000 (34%)]\tLoss: 0.045110, Accuracy: 99.22\n",
      "Train Epoch: 73 [16640/50000 (37%)]\tLoss: 0.068950, Accuracy: 98.05\n",
      "Train Epoch: 73 [17920/50000 (40%)]\tLoss: 0.073738, Accuracy: 97.27\n",
      "Train Epoch: 73 [19200/50000 (43%)]\tLoss: 0.036093, Accuracy: 99.22\n",
      "Train Epoch: 73 [20480/50000 (45%)]\tLoss: 0.039237, Accuracy: 98.44\n",
      "Train Epoch: 73 [21760/50000 (48%)]\tLoss: 0.052761, Accuracy: 98.05\n",
      "Train Epoch: 73 [23040/50000 (51%)]\tLoss: 0.051898, Accuracy: 98.83\n",
      "Train Epoch: 73 [24320/50000 (54%)]\tLoss: 0.058349, Accuracy: 98.83\n",
      "Train Epoch: 73 [25600/50000 (57%)]\tLoss: 0.050022, Accuracy: 98.05\n",
      "Train Epoch: 73 [26880/50000 (60%)]\tLoss: 0.065476, Accuracy: 98.05\n",
      "Train Epoch: 73 [28160/50000 (62%)]\tLoss: 0.041606, Accuracy: 99.22\n",
      "Train Epoch: 73 [29440/50000 (65%)]\tLoss: 0.054089, Accuracy: 98.44\n",
      "Train Epoch: 73 [30720/50000 (68%)]\tLoss: 0.063920, Accuracy: 99.22\n",
      "Train Epoch: 73 [32000/50000 (71%)]\tLoss: 0.057589, Accuracy: 98.44\n",
      "Train Epoch: 73 [33280/50000 (74%)]\tLoss: 0.053303, Accuracy: 98.44\n",
      "Train Epoch: 73 [34560/50000 (77%)]\tLoss: 0.027414, Accuracy: 99.61\n",
      "Train Epoch: 73 [35840/50000 (80%)]\tLoss: 0.078086, Accuracy: 96.48\n",
      "Train Epoch: 73 [37120/50000 (82%)]\tLoss: 0.077851, Accuracy: 96.48\n",
      "Train Epoch: 73 [38400/50000 (85%)]\tLoss: 0.063048, Accuracy: 97.66\n",
      "Train Epoch: 73 [39680/50000 (88%)]\tLoss: 0.031326, Accuracy: 99.61\n",
      "Train Epoch: 73 [40960/50000 (91%)]\tLoss: 0.080525, Accuracy: 96.09\n",
      "Train Epoch: 73 [42240/50000 (94%)]\tLoss: 0.049837, Accuracy: 98.05\n",
      "Train Epoch: 73 [43520/50000 (97%)]\tLoss: 0.043187, Accuracy: 99.22\n",
      "Train Epoch: 73 [35000/50000 (99%)]\tLoss: 0.072076, Accuracy: 98.50\n",
      "\n",
      "Validation set: Average loss: 0.2991, Accuracy: 4586/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[40.83463001251221 s]\n",
      "Train Epoch: 74 [0/50000 (0%)]\tLoss: 0.068585, Accuracy: 97.66\n",
      "Train Epoch: 74 [1280/50000 (3%)]\tLoss: 0.044895, Accuracy: 98.83\n",
      "Train Epoch: 74 [2560/50000 (6%)]\tLoss: 0.052517, Accuracy: 98.05\n",
      "Train Epoch: 74 [3840/50000 (9%)]\tLoss: 0.075565, Accuracy: 97.66\n",
      "Train Epoch: 74 [5120/50000 (11%)]\tLoss: 0.063131, Accuracy: 98.05\n",
      "Train Epoch: 74 [6400/50000 (14%)]\tLoss: 0.104457, Accuracy: 97.27\n",
      "Train Epoch: 74 [7680/50000 (17%)]\tLoss: 0.087247, Accuracy: 97.27\n",
      "Train Epoch: 74 [8960/50000 (20%)]\tLoss: 0.056858, Accuracy: 98.05\n",
      "Train Epoch: 74 [10240/50000 (23%)]\tLoss: 0.046071, Accuracy: 98.83\n",
      "Train Epoch: 74 [11520/50000 (26%)]\tLoss: 0.054075, Accuracy: 98.05\n",
      "Train Epoch: 74 [12800/50000 (28%)]\tLoss: 0.032895, Accuracy: 98.44\n",
      "Train Epoch: 74 [14080/50000 (31%)]\tLoss: 0.024615, Accuracy: 100.00\n",
      "Train Epoch: 74 [15360/50000 (34%)]\tLoss: 0.047090, Accuracy: 99.22\n",
      "Train Epoch: 74 [16640/50000 (37%)]\tLoss: 0.038258, Accuracy: 98.44\n",
      "Train Epoch: 74 [17920/50000 (40%)]\tLoss: 0.047834, Accuracy: 97.66\n",
      "Train Epoch: 74 [19200/50000 (43%)]\tLoss: 0.042654, Accuracy: 99.22\n",
      "Train Epoch: 74 [20480/50000 (45%)]\tLoss: 0.064656, Accuracy: 98.05\n",
      "Train Epoch: 74 [21760/50000 (48%)]\tLoss: 0.054488, Accuracy: 98.83\n",
      "Train Epoch: 74 [23040/50000 (51%)]\tLoss: 0.055714, Accuracy: 98.05\n",
      "Train Epoch: 74 [24320/50000 (54%)]\tLoss: 0.075828, Accuracy: 96.88\n",
      "Train Epoch: 74 [25600/50000 (57%)]\tLoss: 0.040084, Accuracy: 98.83\n",
      "Train Epoch: 74 [26880/50000 (60%)]\tLoss: 0.035842, Accuracy: 99.22\n",
      "Train Epoch: 74 [28160/50000 (62%)]\tLoss: 0.026442, Accuracy: 99.61\n",
      "Train Epoch: 74 [29440/50000 (65%)]\tLoss: 0.045017, Accuracy: 98.83\n",
      "Train Epoch: 74 [30720/50000 (68%)]\tLoss: 0.036688, Accuracy: 99.22\n",
      "Train Epoch: 74 [32000/50000 (71%)]\tLoss: 0.036521, Accuracy: 99.22\n",
      "Train Epoch: 74 [33280/50000 (74%)]\tLoss: 0.060200, Accuracy: 96.88\n",
      "Train Epoch: 74 [34560/50000 (77%)]\tLoss: 0.019191, Accuracy: 99.61\n",
      "Train Epoch: 74 [35840/50000 (80%)]\tLoss: 0.057812, Accuracy: 97.66\n",
      "Train Epoch: 74 [37120/50000 (82%)]\tLoss: 0.083112, Accuracy: 97.27\n",
      "Train Epoch: 74 [38400/50000 (85%)]\tLoss: 0.040898, Accuracy: 98.83\n",
      "Train Epoch: 74 [39680/50000 (88%)]\tLoss: 0.057971, Accuracy: 96.88\n",
      "Train Epoch: 74 [40960/50000 (91%)]\tLoss: 0.024938, Accuracy: 99.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 74 [42240/50000 (94%)]\tLoss: 0.034655, Accuracy: 98.44\n",
      "Train Epoch: 74 [43520/50000 (97%)]\tLoss: 0.058030, Accuracy: 98.44\n",
      "Train Epoch: 74 [35000/50000 (99%)]\tLoss: 0.073755, Accuracy: 97.00\n",
      "\n",
      "Validation set: Average loss: 0.3024, Accuracy: 4592/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[37.51292610168457 s]\n",
      "\n",
      "Test set: Average loss: 0.3045, Accuracy: 9151/10000 (91.51%)\n",
      "\n",
      "Train Epoch: 75 [0/50000 (0%)]\tLoss: 0.073673, Accuracy: 98.05\n",
      "Train Epoch: 75 [1280/50000 (3%)]\tLoss: 0.034917, Accuracy: 98.44\n",
      "Train Epoch: 75 [2560/50000 (6%)]\tLoss: 0.078251, Accuracy: 97.27\n",
      "Train Epoch: 75 [3840/50000 (9%)]\tLoss: 0.077623, Accuracy: 97.66\n",
      "Train Epoch: 75 [5120/50000 (11%)]\tLoss: 0.060417, Accuracy: 98.83\n",
      "Train Epoch: 75 [6400/50000 (14%)]\tLoss: 0.044535, Accuracy: 98.44\n",
      "Train Epoch: 75 [7680/50000 (17%)]\tLoss: 0.027196, Accuracy: 99.22\n",
      "Train Epoch: 75 [8960/50000 (20%)]\tLoss: 0.030118, Accuracy: 98.44\n",
      "Train Epoch: 75 [10240/50000 (23%)]\tLoss: 0.055334, Accuracy: 98.05\n",
      "Train Epoch: 75 [11520/50000 (26%)]\tLoss: 0.041277, Accuracy: 98.44\n",
      "Train Epoch: 75 [12800/50000 (28%)]\tLoss: 0.072527, Accuracy: 98.44\n",
      "Train Epoch: 75 [14080/50000 (31%)]\tLoss: 0.045310, Accuracy: 99.22\n",
      "Train Epoch: 75 [15360/50000 (34%)]\tLoss: 0.023645, Accuracy: 99.22\n",
      "Train Epoch: 75 [16640/50000 (37%)]\tLoss: 0.056386, Accuracy: 98.44\n",
      "Train Epoch: 75 [17920/50000 (40%)]\tLoss: 0.056414, Accuracy: 97.27\n",
      "Train Epoch: 75 [19200/50000 (43%)]\tLoss: 0.040165, Accuracy: 98.83\n",
      "Train Epoch: 75 [20480/50000 (45%)]\tLoss: 0.056837, Accuracy: 98.05\n",
      "Train Epoch: 75 [21760/50000 (48%)]\tLoss: 0.045328, Accuracy: 98.44\n",
      "Train Epoch: 75 [23040/50000 (51%)]\tLoss: 0.045053, Accuracy: 98.44\n",
      "Train Epoch: 75 [24320/50000 (54%)]\tLoss: 0.062438, Accuracy: 97.66\n",
      "Train Epoch: 75 [25600/50000 (57%)]\tLoss: 0.038502, Accuracy: 98.83\n",
      "torch.Size([512, 1, 1])\n",
      "tensor([[[ 1.4312]],\n",
      "\n",
      "        [[ 0.9851]],\n",
      "\n",
      "        [[ 1.1009]],\n",
      "\n",
      "        [[-1.2354]],\n",
      "\n",
      "        [[-0.7207]],\n",
      "\n",
      "        [[ 0.4547]],\n",
      "\n",
      "        [[-0.0517]],\n",
      "\n",
      "        [[ 0.2695]],\n",
      "\n",
      "        [[-0.0517]],\n",
      "\n",
      "        [[-0.3663]],\n",
      "\n",
      "        [[ 1.4806]],\n",
      "\n",
      "        [[-0.2570]],\n",
      "\n",
      "        [[-0.9534]],\n",
      "\n",
      "        [[ 0.8894]],\n",
      "\n",
      "        [[-0.1210]],\n",
      "\n",
      "        [[-1.1890]],\n",
      "\n",
      "        [[ 1.2565]],\n",
      "\n",
      "        [[ 0.0247]],\n",
      "\n",
      "        [[ 0.4064]],\n",
      "\n",
      "        [[ 0.9059]],\n",
      "\n",
      "        [[ 1.0566]],\n",
      "\n",
      "        [[ 0.3310]],\n",
      "\n",
      "        [[-0.7589]],\n",
      "\n",
      "        [[ 1.1343]],\n",
      "\n",
      "        [[ 0.5594]],\n",
      "\n",
      "        [[ 1.4278]],\n",
      "\n",
      "        [[ 2.8384]],\n",
      "\n",
      "        [[-0.8617]],\n",
      "\n",
      "        [[ 0.7889]],\n",
      "\n",
      "        [[-0.6549]],\n",
      "\n",
      "        [[-0.0816]],\n",
      "\n",
      "        [[-1.4060]],\n",
      "\n",
      "        [[-0.6154]],\n",
      "\n",
      "        [[-0.0076]],\n",
      "\n",
      "        [[ 0.2682]],\n",
      "\n",
      "        [[-1.4458]],\n",
      "\n",
      "        [[ 0.2553]],\n",
      "\n",
      "        [[ 0.2216]],\n",
      "\n",
      "        [[-0.5163]],\n",
      "\n",
      "        [[-0.1819]],\n",
      "\n",
      "        [[-1.2613]],\n",
      "\n",
      "        [[-0.4874]],\n",
      "\n",
      "        [[ 0.9991]],\n",
      "\n",
      "        [[-2.7452]],\n",
      "\n",
      "        [[-1.9628]],\n",
      "\n",
      "        [[ 1.4271]],\n",
      "\n",
      "        [[ 0.1674]],\n",
      "\n",
      "        [[-1.1345]],\n",
      "\n",
      "        [[ 0.4074]],\n",
      "\n",
      "        [[ 0.3283]],\n",
      "\n",
      "        [[-0.3810]],\n",
      "\n",
      "        [[ 0.7810]],\n",
      "\n",
      "        [[-0.8708]],\n",
      "\n",
      "        [[-0.8032]],\n",
      "\n",
      "        [[ 1.8544]],\n",
      "\n",
      "        [[ 0.2765]],\n",
      "\n",
      "        [[ 0.7911]],\n",
      "\n",
      "        [[ 0.1424]],\n",
      "\n",
      "        [[ 0.6922]],\n",
      "\n",
      "        [[ 0.8162]],\n",
      "\n",
      "        [[ 0.4942]],\n",
      "\n",
      "        [[-0.0638]],\n",
      "\n",
      "        [[-1.3842]],\n",
      "\n",
      "        [[-0.2261]],\n",
      "\n",
      "        [[-0.2158]],\n",
      "\n",
      "        [[ 0.0407]],\n",
      "\n",
      "        [[ 1.7457]],\n",
      "\n",
      "        [[ 0.4018]],\n",
      "\n",
      "        [[-1.5179]],\n",
      "\n",
      "        [[-0.2908]],\n",
      "\n",
      "        [[ 0.8250]],\n",
      "\n",
      "        [[ 1.0147]],\n",
      "\n",
      "        [[ 0.9119]],\n",
      "\n",
      "        [[ 0.3679]],\n",
      "\n",
      "        [[-0.7484]],\n",
      "\n",
      "        [[ 1.5629]],\n",
      "\n",
      "        [[-0.8149]],\n",
      "\n",
      "        [[-1.3603]],\n",
      "\n",
      "        [[ 1.1659]],\n",
      "\n",
      "        [[ 0.2179]],\n",
      "\n",
      "        [[ 0.0460]],\n",
      "\n",
      "        [[-0.8070]],\n",
      "\n",
      "        [[-0.5858]],\n",
      "\n",
      "        [[ 0.2367]],\n",
      "\n",
      "        [[-0.4788]],\n",
      "\n",
      "        [[ 1.0188]],\n",
      "\n",
      "        [[-0.6917]],\n",
      "\n",
      "        [[-0.3179]],\n",
      "\n",
      "        [[-0.7777]],\n",
      "\n",
      "        [[ 2.3350]],\n",
      "\n",
      "        [[ 0.0213]],\n",
      "\n",
      "        [[-0.6630]],\n",
      "\n",
      "        [[ 0.4088]],\n",
      "\n",
      "        [[-0.0753]],\n",
      "\n",
      "        [[ 1.1511]],\n",
      "\n",
      "        [[-0.6538]],\n",
      "\n",
      "        [[ 0.1317]],\n",
      "\n",
      "        [[-1.2708]],\n",
      "\n",
      "        [[-0.1439]],\n",
      "\n",
      "        [[-1.3401]],\n",
      "\n",
      "        [[ 0.8148]],\n",
      "\n",
      "        [[-0.2044]],\n",
      "\n",
      "        [[-0.3216]],\n",
      "\n",
      "        [[ 1.4914]],\n",
      "\n",
      "        [[-0.3368]],\n",
      "\n",
      "        [[ 0.5480]],\n",
      "\n",
      "        [[ 1.0762]],\n",
      "\n",
      "        [[ 0.4874]],\n",
      "\n",
      "        [[ 0.4514]],\n",
      "\n",
      "        [[-1.4052]],\n",
      "\n",
      "        [[ 0.1240]],\n",
      "\n",
      "        [[ 0.5763]],\n",
      "\n",
      "        [[-0.7972]],\n",
      "\n",
      "        [[-0.5418]],\n",
      "\n",
      "        [[ 1.3501]],\n",
      "\n",
      "        [[-1.8506]],\n",
      "\n",
      "        [[-0.3033]],\n",
      "\n",
      "        [[ 1.2244]],\n",
      "\n",
      "        [[ 0.4666]],\n",
      "\n",
      "        [[ 0.4665]],\n",
      "\n",
      "        [[ 1.4125]],\n",
      "\n",
      "        [[-0.6895]],\n",
      "\n",
      "        [[ 0.4066]],\n",
      "\n",
      "        [[ 0.0759]],\n",
      "\n",
      "        [[-0.6243]],\n",
      "\n",
      "        [[ 1.1181]],\n",
      "\n",
      "        [[-0.5166]],\n",
      "\n",
      "        [[-1.2496]],\n",
      "\n",
      "        [[-0.0536]],\n",
      "\n",
      "        [[-0.6861]],\n",
      "\n",
      "        [[ 0.0556]],\n",
      "\n",
      "        [[-0.9654]],\n",
      "\n",
      "        [[-0.0060]],\n",
      "\n",
      "        [[ 0.2394]],\n",
      "\n",
      "        [[ 0.5983]],\n",
      "\n",
      "        [[-2.1466]],\n",
      "\n",
      "        [[-0.7471]],\n",
      "\n",
      "        [[-0.4970]],\n",
      "\n",
      "        [[-0.0100]],\n",
      "\n",
      "        [[-2.7510]],\n",
      "\n",
      "        [[-0.3364]],\n",
      "\n",
      "        [[ 0.9498]],\n",
      "\n",
      "        [[ 0.2247]],\n",
      "\n",
      "        [[-1.1504]],\n",
      "\n",
      "        [[ 0.7201]],\n",
      "\n",
      "        [[ 1.3978]],\n",
      "\n",
      "        [[-0.2413]],\n",
      "\n",
      "        [[-0.5878]],\n",
      "\n",
      "        [[-1.9975]],\n",
      "\n",
      "        [[ 0.9109]],\n",
      "\n",
      "        [[ 0.7369]],\n",
      "\n",
      "        [[ 0.0051]],\n",
      "\n",
      "        [[ 0.7248]],\n",
      "\n",
      "        [[-2.1740]],\n",
      "\n",
      "        [[ 0.8771]],\n",
      "\n",
      "        [[ 0.2629]],\n",
      "\n",
      "        [[-0.1576]],\n",
      "\n",
      "        [[-0.1939]],\n",
      "\n",
      "        [[-0.5389]],\n",
      "\n",
      "        [[ 0.7007]],\n",
      "\n",
      "        [[ 0.4672]],\n",
      "\n",
      "        [[-0.3905]],\n",
      "\n",
      "        [[ 0.3166]],\n",
      "\n",
      "        [[-1.7058]],\n",
      "\n",
      "        [[ 0.5292]],\n",
      "\n",
      "        [[ 0.6325]],\n",
      "\n",
      "        [[-0.4335]],\n",
      "\n",
      "        [[-1.5142]],\n",
      "\n",
      "        [[-0.8103]],\n",
      "\n",
      "        [[ 0.5797]],\n",
      "\n",
      "        [[ 0.3835]],\n",
      "\n",
      "        [[-1.6974]],\n",
      "\n",
      "        [[-0.2038]],\n",
      "\n",
      "        [[-0.6105]],\n",
      "\n",
      "        [[-0.6404]],\n",
      "\n",
      "        [[ 0.3757]],\n",
      "\n",
      "        [[ 0.5348]],\n",
      "\n",
      "        [[-0.7139]],\n",
      "\n",
      "        [[ 0.4489]],\n",
      "\n",
      "        [[-0.5506]],\n",
      "\n",
      "        [[ 0.0231]],\n",
      "\n",
      "        [[ 0.4850]],\n",
      "\n",
      "        [[ 0.7461]],\n",
      "\n",
      "        [[-0.1943]],\n",
      "\n",
      "        [[-0.1457]],\n",
      "\n",
      "        [[ 0.9425]],\n",
      "\n",
      "        [[-1.3038]],\n",
      "\n",
      "        [[-0.9257]],\n",
      "\n",
      "        [[ 0.1684]],\n",
      "\n",
      "        [[-0.4068]],\n",
      "\n",
      "        [[ 0.6574]],\n",
      "\n",
      "        [[-1.5837]],\n",
      "\n",
      "        [[-0.4146]],\n",
      "\n",
      "        [[-0.1236]],\n",
      "\n",
      "        [[ 0.2319]],\n",
      "\n",
      "        [[ 0.5124]],\n",
      "\n",
      "        [[ 0.9646]],\n",
      "\n",
      "        [[-1.1319]],\n",
      "\n",
      "        [[-1.1730]],\n",
      "\n",
      "        [[-0.6926]],\n",
      "\n",
      "        [[-0.1611]],\n",
      "\n",
      "        [[-0.3789]],\n",
      "\n",
      "        [[ 0.4424]],\n",
      "\n",
      "        [[-0.4834]],\n",
      "\n",
      "        [[-0.9341]],\n",
      "\n",
      "        [[ 1.3700]],\n",
      "\n",
      "        [[ 1.5516]],\n",
      "\n",
      "        [[ 0.4788]],\n",
      "\n",
      "        [[-0.6621]],\n",
      "\n",
      "        [[-0.6599]],\n",
      "\n",
      "        [[-0.4197]],\n",
      "\n",
      "        [[-0.3073]],\n",
      "\n",
      "        [[ 0.7828]],\n",
      "\n",
      "        [[ 0.8602]],\n",
      "\n",
      "        [[-0.2463]],\n",
      "\n",
      "        [[ 0.7962]],\n",
      "\n",
      "        [[-0.2995]],\n",
      "\n",
      "        [[-0.5943]],\n",
      "\n",
      "        [[ 0.8916]],\n",
      "\n",
      "        [[-0.9430]],\n",
      "\n",
      "        [[-0.5649]],\n",
      "\n",
      "        [[-0.3786]],\n",
      "\n",
      "        [[-0.2786]],\n",
      "\n",
      "        [[-1.4786]],\n",
      "\n",
      "        [[-1.7410]],\n",
      "\n",
      "        [[-0.5947]],\n",
      "\n",
      "        [[-0.7043]],\n",
      "\n",
      "        [[ 1.5843]],\n",
      "\n",
      "        [[-0.7904]],\n",
      "\n",
      "        [[ 0.1858]],\n",
      "\n",
      "        [[-0.0705]],\n",
      "\n",
      "        [[ 1.5205]],\n",
      "\n",
      "        [[-0.3958]],\n",
      "\n",
      "        [[ 0.7998]],\n",
      "\n",
      "        [[-0.6928]],\n",
      "\n",
      "        [[-0.1570]],\n",
      "\n",
      "        [[ 0.2768]],\n",
      "\n",
      "        [[-0.3645]],\n",
      "\n",
      "        [[ 0.4226]],\n",
      "\n",
      "        [[-0.8609]],\n",
      "\n",
      "        [[-1.1080]],\n",
      "\n",
      "        [[ 1.3349]],\n",
      "\n",
      "        [[-0.0961]],\n",
      "\n",
      "        [[-0.1924]],\n",
      "\n",
      "        [[-0.1638]],\n",
      "\n",
      "        [[-1.2514]],\n",
      "\n",
      "        [[-0.4033]],\n",
      "\n",
      "        [[ 0.1299]],\n",
      "\n",
      "        [[-1.3728]],\n",
      "\n",
      "        [[ 0.2707]],\n",
      "\n",
      "        [[ 0.3995]],\n",
      "\n",
      "        [[ 0.9791]],\n",
      "\n",
      "        [[ 1.1569]],\n",
      "\n",
      "        [[ 1.2317]],\n",
      "\n",
      "        [[ 0.0877]],\n",
      "\n",
      "        [[-1.0517]],\n",
      "\n",
      "        [[ 1.5777]],\n",
      "\n",
      "        [[-1.2346]],\n",
      "\n",
      "        [[ 0.4736]],\n",
      "\n",
      "        [[ 0.5826]],\n",
      "\n",
      "        [[-0.0813]],\n",
      "\n",
      "        [[-0.6987]],\n",
      "\n",
      "        [[-0.5922]],\n",
      "\n",
      "        [[-0.3953]],\n",
      "\n",
      "        [[-0.6598]],\n",
      "\n",
      "        [[ 1.6719]],\n",
      "\n",
      "        [[-0.0613]],\n",
      "\n",
      "        [[-0.9513]],\n",
      "\n",
      "        [[-0.4149]],\n",
      "\n",
      "        [[-2.2226]],\n",
      "\n",
      "        [[ 0.4551]],\n",
      "\n",
      "        [[-0.6672]],\n",
      "\n",
      "        [[-0.0552]],\n",
      "\n",
      "        [[-2.0635]],\n",
      "\n",
      "        [[-0.4890]],\n",
      "\n",
      "        [[ 0.9464]],\n",
      "\n",
      "        [[ 0.2580]],\n",
      "\n",
      "        [[-0.3239]],\n",
      "\n",
      "        [[ 1.2319]],\n",
      "\n",
      "        [[-1.2913]],\n",
      "\n",
      "        [[ 0.2910]],\n",
      "\n",
      "        [[-0.6566]],\n",
      "\n",
      "        [[ 0.6283]],\n",
      "\n",
      "        [[-0.1123]],\n",
      "\n",
      "        [[ 0.4801]],\n",
      "\n",
      "        [[-0.2085]],\n",
      "\n",
      "        [[-0.5951]],\n",
      "\n",
      "        [[ 1.2944]],\n",
      "\n",
      "        [[ 1.5754]],\n",
      "\n",
      "        [[-0.7817]],\n",
      "\n",
      "        [[ 1.0455]],\n",
      "\n",
      "        [[-0.1578]],\n",
      "\n",
      "        [[ 0.4243]],\n",
      "\n",
      "        [[-1.1626]],\n",
      "\n",
      "        [[-0.7319]],\n",
      "\n",
      "        [[ 0.0894]],\n",
      "\n",
      "        [[ 0.4579]],\n",
      "\n",
      "        [[-0.0816]],\n",
      "\n",
      "        [[-1.1781]],\n",
      "\n",
      "        [[ 0.4968]],\n",
      "\n",
      "        [[ 2.2587]],\n",
      "\n",
      "        [[-0.3421]],\n",
      "\n",
      "        [[ 1.1443]],\n",
      "\n",
      "        [[ 0.3059]],\n",
      "\n",
      "        [[-0.1172]],\n",
      "\n",
      "        [[ 0.9188]],\n",
      "\n",
      "        [[ 0.7016]],\n",
      "\n",
      "        [[ 0.4606]],\n",
      "\n",
      "        [[-0.7694]],\n",
      "\n",
      "        [[-1.2000]],\n",
      "\n",
      "        [[-0.2467]],\n",
      "\n",
      "        [[ 1.2335]],\n",
      "\n",
      "        [[-0.2793]],\n",
      "\n",
      "        [[-0.0611]],\n",
      "\n",
      "        [[ 0.4267]],\n",
      "\n",
      "        [[ 0.9425]],\n",
      "\n",
      "        [[ 0.3148]],\n",
      "\n",
      "        [[-0.6422]],\n",
      "\n",
      "        [[ 0.8542]],\n",
      "\n",
      "        [[ 0.1824]],\n",
      "\n",
      "        [[-1.0032]],\n",
      "\n",
      "        [[-0.9673]],\n",
      "\n",
      "        [[-0.0711]],\n",
      "\n",
      "        [[-0.2592]],\n",
      "\n",
      "        [[-1.3221]],\n",
      "\n",
      "        [[-0.1439]],\n",
      "\n",
      "        [[ 1.6287]],\n",
      "\n",
      "        [[-0.5169]],\n",
      "\n",
      "        [[ 2.1592]],\n",
      "\n",
      "        [[-0.7325]],\n",
      "\n",
      "        [[-0.8216]],\n",
      "\n",
      "        [[ 0.1464]],\n",
      "\n",
      "        [[-0.1471]],\n",
      "\n",
      "        [[ 0.9659]],\n",
      "\n",
      "        [[-0.4794]],\n",
      "\n",
      "        [[-1.0574]],\n",
      "\n",
      "        [[-0.4374]],\n",
      "\n",
      "        [[-0.2283]],\n",
      "\n",
      "        [[-1.8243]],\n",
      "\n",
      "        [[ 1.1034]],\n",
      "\n",
      "        [[ 0.0236]],\n",
      "\n",
      "        [[-0.0566]],\n",
      "\n",
      "        [[ 0.6567]],\n",
      "\n",
      "        [[-0.0606]],\n",
      "\n",
      "        [[ 0.0498]],\n",
      "\n",
      "        [[-1.5496]],\n",
      "\n",
      "        [[ 1.0329]],\n",
      "\n",
      "        [[ 1.6175]],\n",
      "\n",
      "        [[ 0.2771]],\n",
      "\n",
      "        [[-1.1928]],\n",
      "\n",
      "        [[-2.1336]],\n",
      "\n",
      "        [[ 0.8170]],\n",
      "\n",
      "        [[-0.1649]],\n",
      "\n",
      "        [[ 0.9490]],\n",
      "\n",
      "        [[-1.5573]],\n",
      "\n",
      "        [[-0.3033]],\n",
      "\n",
      "        [[-0.7977]],\n",
      "\n",
      "        [[ 1.7801]],\n",
      "\n",
      "        [[ 2.2861]],\n",
      "\n",
      "        [[-1.0971]],\n",
      "\n",
      "        [[ 0.1227]],\n",
      "\n",
      "        [[-0.3392]],\n",
      "\n",
      "        [[-1.6248]],\n",
      "\n",
      "        [[ 1.2373]],\n",
      "\n",
      "        [[ 2.0693]],\n",
      "\n",
      "        [[-1.9087]],\n",
      "\n",
      "        [[ 0.1479]],\n",
      "\n",
      "        [[ 0.8242]],\n",
      "\n",
      "        [[-0.0262]],\n",
      "\n",
      "        [[-0.0718]],\n",
      "\n",
      "        [[ 0.3418]],\n",
      "\n",
      "        [[-0.2877]],\n",
      "\n",
      "        [[ 0.4941]],\n",
      "\n",
      "        [[-0.0870]],\n",
      "\n",
      "        [[ 2.1553]],\n",
      "\n",
      "        [[-0.4336]],\n",
      "\n",
      "        [[-1.0138]],\n",
      "\n",
      "        [[-0.5305]],\n",
      "\n",
      "        [[ 1.7270]],\n",
      "\n",
      "        [[ 1.2785]],\n",
      "\n",
      "        [[ 0.1950]],\n",
      "\n",
      "        [[-0.1192]],\n",
      "\n",
      "        [[-1.2879]],\n",
      "\n",
      "        [[-0.4161]],\n",
      "\n",
      "        [[-0.6918]],\n",
      "\n",
      "        [[ 1.8594]],\n",
      "\n",
      "        [[ 0.1421]],\n",
      "\n",
      "        [[ 0.7283]],\n",
      "\n",
      "        [[ 0.1108]],\n",
      "\n",
      "        [[ 0.4959]],\n",
      "\n",
      "        [[-0.3976]],\n",
      "\n",
      "        [[ 0.6705]],\n",
      "\n",
      "        [[-0.7848]],\n",
      "\n",
      "        [[-0.3537]],\n",
      "\n",
      "        [[-0.6793]],\n",
      "\n",
      "        [[ 0.2845]],\n",
      "\n",
      "        [[-0.5097]],\n",
      "\n",
      "        [[-0.5447]],\n",
      "\n",
      "        [[-0.4842]],\n",
      "\n",
      "        [[ 0.6864]],\n",
      "\n",
      "        [[ 0.0635]],\n",
      "\n",
      "        [[-0.2787]],\n",
      "\n",
      "        [[ 0.0341]],\n",
      "\n",
      "        [[-0.8431]],\n",
      "\n",
      "        [[-1.6074]],\n",
      "\n",
      "        [[-0.9273]],\n",
      "\n",
      "        [[-0.6789]],\n",
      "\n",
      "        [[-1.9300]],\n",
      "\n",
      "        [[ 1.0358]],\n",
      "\n",
      "        [[ 1.2947]],\n",
      "\n",
      "        [[ 1.7568]],\n",
      "\n",
      "        [[-1.6297]],\n",
      "\n",
      "        [[-0.4305]],\n",
      "\n",
      "        [[-0.0495]],\n",
      "\n",
      "        [[ 2.8060]],\n",
      "\n",
      "        [[-1.7159]],\n",
      "\n",
      "        [[ 0.7129]],\n",
      "\n",
      "        [[ 0.4772]],\n",
      "\n",
      "        [[ 1.6212]],\n",
      "\n",
      "        [[-1.1893]],\n",
      "\n",
      "        [[-0.3983]],\n",
      "\n",
      "        [[-0.5161]],\n",
      "\n",
      "        [[-1.0501]],\n",
      "\n",
      "        [[-1.0073]],\n",
      "\n",
      "        [[ 0.6384]],\n",
      "\n",
      "        [[ 0.0440]],\n",
      "\n",
      "        [[-0.4511]],\n",
      "\n",
      "        [[ 1.6014]],\n",
      "\n",
      "        [[ 0.6605]],\n",
      "\n",
      "        [[-0.9765]],\n",
      "\n",
      "        [[ 1.0036]],\n",
      "\n",
      "        [[-0.6886]],\n",
      "\n",
      "        [[ 0.8022]],\n",
      "\n",
      "        [[-0.7536]],\n",
      "\n",
      "        [[ 1.3316]],\n",
      "\n",
      "        [[ 0.0221]],\n",
      "\n",
      "        [[-0.4774]],\n",
      "\n",
      "        [[-2.0777]],\n",
      "\n",
      "        [[-1.5491]],\n",
      "\n",
      "        [[-0.9696]],\n",
      "\n",
      "        [[-0.4432]],\n",
      "\n",
      "        [[ 0.0803]],\n",
      "\n",
      "        [[ 0.4366]],\n",
      "\n",
      "        [[ 0.6102]],\n",
      "\n",
      "        [[ 0.5435]],\n",
      "\n",
      "        [[-0.0322]],\n",
      "\n",
      "        [[-1.4657]],\n",
      "\n",
      "        [[ 0.2580]],\n",
      "\n",
      "        [[-0.0248]],\n",
      "\n",
      "        [[-1.0036]],\n",
      "\n",
      "        [[ 0.8215]],\n",
      "\n",
      "        [[ 1.1061]],\n",
      "\n",
      "        [[ 0.7737]],\n",
      "\n",
      "        [[-0.6774]],\n",
      "\n",
      "        [[-2.0424]],\n",
      "\n",
      "        [[-0.5066]],\n",
      "\n",
      "        [[ 1.3211]],\n",
      "\n",
      "        [[ 0.2981]],\n",
      "\n",
      "        [[-0.4309]],\n",
      "\n",
      "        [[-0.3081]],\n",
      "\n",
      "        [[-0.4921]],\n",
      "\n",
      "        [[-1.7828]],\n",
      "\n",
      "        [[ 0.0370]],\n",
      "\n",
      "        [[-1.1966]],\n",
      "\n",
      "        [[-1.2526]],\n",
      "\n",
      "        [[-0.5314]],\n",
      "\n",
      "        [[ 0.9523]],\n",
      "\n",
      "        [[-0.1483]],\n",
      "\n",
      "        [[-1.1825]],\n",
      "\n",
      "        [[-0.6704]],\n",
      "\n",
      "        [[ 0.1695]],\n",
      "\n",
      "        [[-1.2112]],\n",
      "\n",
      "        [[-0.9990]],\n",
      "\n",
      "        [[ 0.3161]],\n",
      "\n",
      "        [[-0.1925]],\n",
      "\n",
      "        [[-0.1261]],\n",
      "\n",
      "        [[-0.2965]],\n",
      "\n",
      "        [[-2.0338]],\n",
      "\n",
      "        [[-0.2680]],\n",
      "\n",
      "        [[ 0.8395]],\n",
      "\n",
      "        [[-0.5491]],\n",
      "\n",
      "        [[ 0.7151]],\n",
      "\n",
      "        [[ 0.3202]],\n",
      "\n",
      "        [[ 0.1791]],\n",
      "\n",
      "        [[ 1.2884]],\n",
      "\n",
      "        [[ 0.1390]],\n",
      "\n",
      "        [[ 0.3427]],\n",
      "\n",
      "        [[ 0.6258]],\n",
      "\n",
      "        [[-0.2004]],\n",
      "\n",
      "        [[-0.7535]],\n",
      "\n",
      "        [[ 1.7798]],\n",
      "\n",
      "        [[-1.4377]],\n",
      "\n",
      "        [[-1.3858]],\n",
      "\n",
      "        [[-1.7636]],\n",
      "\n",
      "        [[-0.2014]],\n",
      "\n",
      "        [[ 1.6585]],\n",
      "\n",
      "        [[-0.3516]],\n",
      "\n",
      "        [[-0.3005]],\n",
      "\n",
      "        [[-0.1495]],\n",
      "\n",
      "        [[ 1.1841]],\n",
      "\n",
      "        [[-0.1607]],\n",
      "\n",
      "        [[ 0.1286]],\n",
      "\n",
      "        [[-0.1819]],\n",
      "\n",
      "        [[ 1.7175]],\n",
      "\n",
      "        [[-0.0106]],\n",
      "\n",
      "        [[ 2.0243]],\n",
      "\n",
      "        [[ 0.8830]],\n",
      "\n",
      "        [[ 1.0233]],\n",
      "\n",
      "        [[ 1.7388]],\n",
      "\n",
      "        [[-0.4028]],\n",
      "\n",
      "        [[ 0.4116]],\n",
      "\n",
      "        [[-2.6921]]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor(1.00000e-03 *\n",
      "       [[[-6.2503]]], device='cuda:0')\n",
      "torch.Size([1, 448, 512])\n",
      "tensor(1.00000e-03 *\n",
      "       [[[ 1.9531,  1.9531,  1.9532,  ...,  1.9532,  1.9532,  1.9530],\n",
      "         [ 1.9531,  1.9531,  1.9531,  ...,  1.9531,  1.9530,  1.9530],\n",
      "         [ 1.9531,  1.9531,  1.9530,  ...,  1.9530,  1.9530,  1.9531],\n",
      "         ...,\n",
      "         [ 1.9532,  1.9531,  1.9531,  ...,  1.9531,  1.9531,  1.9531],\n",
      "         [ 1.9532,  1.9531,  1.9532,  ...,  1.9531,  1.9532,  1.9531],\n",
      "         [ 1.9531,  1.9531,  1.9531,  ...,  1.9531,  1.9531,  1.9531]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 75 [26880/50000 (60%)]\tLoss: 0.077257, Accuracy: 97.27\n",
      "Train Epoch: 75 [28160/50000 (62%)]\tLoss: 0.041480, Accuracy: 98.83\n",
      "Train Epoch: 75 [29440/50000 (65%)]\tLoss: 0.049549, Accuracy: 98.05\n",
      "Train Epoch: 75 [30720/50000 (68%)]\tLoss: 0.031848, Accuracy: 99.22\n",
      "Train Epoch: 75 [32000/50000 (71%)]\tLoss: 0.082747, Accuracy: 97.66\n",
      "Train Epoch: 75 [33280/50000 (74%)]\tLoss: 0.040581, Accuracy: 98.83\n",
      "Train Epoch: 75 [34560/50000 (77%)]\tLoss: 0.033949, Accuracy: 99.22\n",
      "Train Epoch: 75 [35840/50000 (80%)]\tLoss: 0.059890, Accuracy: 98.44\n",
      "Train Epoch: 75 [37120/50000 (82%)]\tLoss: 0.038777, Accuracy: 98.83\n",
      "Train Epoch: 75 [38400/50000 (85%)]\tLoss: 0.049129, Accuracy: 97.66\n",
      "Train Epoch: 75 [39680/50000 (88%)]\tLoss: 0.040946, Accuracy: 98.44\n",
      "Train Epoch: 75 [40960/50000 (91%)]\tLoss: 0.021580, Accuracy: 100.00\n",
      "Train Epoch: 75 [42240/50000 (94%)]\tLoss: 0.042389, Accuracy: 98.44\n",
      "Train Epoch: 75 [43520/50000 (97%)]\tLoss: 0.025947, Accuracy: 99.61\n",
      "Train Epoch: 75 [35000/50000 (99%)]\tLoss: 0.072023, Accuracy: 98.00\n",
      "\n",
      "Validation set: Average loss: 0.3033, Accuracy: 4587/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[41.13075017929077 s]\n",
      "Train Epoch: 76 [0/50000 (0%)]\tLoss: 0.084351, Accuracy: 97.66\n",
      "Train Epoch: 76 [1280/50000 (3%)]\tLoss: 0.030836, Accuracy: 99.22\n",
      "Train Epoch: 76 [2560/50000 (6%)]\tLoss: 0.050391, Accuracy: 98.05\n",
      "Train Epoch: 76 [3840/50000 (9%)]\tLoss: 0.030157, Accuracy: 98.83\n",
      "Train Epoch: 76 [5120/50000 (11%)]\tLoss: 0.077281, Accuracy: 97.27\n",
      "Train Epoch: 76 [6400/50000 (14%)]\tLoss: 0.044849, Accuracy: 99.22\n",
      "Train Epoch: 76 [7680/50000 (17%)]\tLoss: 0.046497, Accuracy: 98.83\n",
      "Train Epoch: 76 [8960/50000 (20%)]\tLoss: 0.027840, Accuracy: 99.61\n",
      "Train Epoch: 76 [10240/50000 (23%)]\tLoss: 0.029508, Accuracy: 98.83\n",
      "Train Epoch: 76 [11520/50000 (26%)]\tLoss: 0.062352, Accuracy: 96.48\n",
      "Train Epoch: 76 [12800/50000 (28%)]\tLoss: 0.054170, Accuracy: 96.88\n",
      "Train Epoch: 76 [14080/50000 (31%)]\tLoss: 0.058025, Accuracy: 98.05\n",
      "Train Epoch: 76 [15360/50000 (34%)]\tLoss: 0.038012, Accuracy: 98.05\n",
      "Train Epoch: 76 [16640/50000 (37%)]\tLoss: 0.047245, Accuracy: 98.05\n",
      "Train Epoch: 76 [17920/50000 (40%)]\tLoss: 0.057290, Accuracy: 98.05\n",
      "Train Epoch: 76 [19200/50000 (43%)]\tLoss: 0.031575, Accuracy: 98.44\n",
      "Train Epoch: 76 [20480/50000 (45%)]\tLoss: 0.035301, Accuracy: 99.22\n",
      "Train Epoch: 76 [21760/50000 (48%)]\tLoss: 0.032417, Accuracy: 99.22\n",
      "Train Epoch: 76 [23040/50000 (51%)]\tLoss: 0.056028, Accuracy: 98.44\n",
      "Train Epoch: 76 [24320/50000 (54%)]\tLoss: 0.046972, Accuracy: 98.05\n",
      "Train Epoch: 76 [25600/50000 (57%)]\tLoss: 0.042147, Accuracy: 98.83\n",
      "Train Epoch: 76 [26880/50000 (60%)]\tLoss: 0.051304, Accuracy: 99.22\n",
      "Train Epoch: 76 [28160/50000 (62%)]\tLoss: 0.073916, Accuracy: 97.27\n",
      "Train Epoch: 76 [29440/50000 (65%)]\tLoss: 0.037895, Accuracy: 98.44\n",
      "Train Epoch: 76 [30720/50000 (68%)]\tLoss: 0.080175, Accuracy: 96.48\n",
      "Train Epoch: 76 [32000/50000 (71%)]\tLoss: 0.031255, Accuracy: 99.22\n",
      "Train Epoch: 76 [33280/50000 (74%)]\tLoss: 0.049852, Accuracy: 98.44\n",
      "Train Epoch: 76 [34560/50000 (77%)]\tLoss: 0.019810, Accuracy: 99.61\n",
      "Train Epoch: 76 [35840/50000 (80%)]\tLoss: 0.069848, Accuracy: 98.05\n",
      "Train Epoch: 76 [37120/50000 (82%)]\tLoss: 0.035395, Accuracy: 99.22\n",
      "Train Epoch: 76 [38400/50000 (85%)]\tLoss: 0.024043, Accuracy: 100.00\n",
      "Train Epoch: 76 [39680/50000 (88%)]\tLoss: 0.023383, Accuracy: 99.61\n",
      "Train Epoch: 76 [40960/50000 (91%)]\tLoss: 0.042905, Accuracy: 98.44\n",
      "Train Epoch: 76 [42240/50000 (94%)]\tLoss: 0.027509, Accuracy: 99.22\n",
      "Train Epoch: 76 [43520/50000 (97%)]\tLoss: 0.027491, Accuracy: 100.00\n",
      "Train Epoch: 76 [35000/50000 (99%)]\tLoss: 0.035109, Accuracy: 99.50\n",
      "\n",
      "Validation set: Average loss: 0.3047, Accuracy: 4585/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[37.34636950492859 s]\n",
      "\n",
      "Test set: Average loss: 0.3084, Accuracy: 9142/10000 (91.42%)\n",
      "\n",
      "Train Epoch: 77 [0/50000 (0%)]\tLoss: 0.044259, Accuracy: 98.44\n",
      "Train Epoch: 77 [1280/50000 (3%)]\tLoss: 0.074753, Accuracy: 98.83\n",
      "Train Epoch: 77 [2560/50000 (6%)]\tLoss: 0.041304, Accuracy: 97.66\n",
      "Train Epoch: 77 [3840/50000 (9%)]\tLoss: 0.077163, Accuracy: 97.66\n",
      "Train Epoch: 77 [5120/50000 (11%)]\tLoss: 0.079996, Accuracy: 97.27\n",
      "Train Epoch: 77 [6400/50000 (14%)]\tLoss: 0.029782, Accuracy: 98.83\n",
      "Train Epoch: 77 [7680/50000 (17%)]\tLoss: 0.016874, Accuracy: 100.00\n",
      "Train Epoch: 77 [8960/50000 (20%)]\tLoss: 0.089816, Accuracy: 97.66\n",
      "Train Epoch: 77 [10240/50000 (23%)]\tLoss: 0.072219, Accuracy: 98.05\n",
      "Train Epoch: 77 [11520/50000 (26%)]\tLoss: 0.020954, Accuracy: 100.00\n",
      "Train Epoch: 77 [12800/50000 (28%)]\tLoss: 0.054865, Accuracy: 97.66\n",
      "Train Epoch: 77 [14080/50000 (31%)]\tLoss: 0.043329, Accuracy: 98.83\n",
      "Train Epoch: 77 [15360/50000 (34%)]\tLoss: 0.023874, Accuracy: 99.61\n",
      "Train Epoch: 77 [16640/50000 (37%)]\tLoss: 0.073122, Accuracy: 98.05\n",
      "Train Epoch: 77 [17920/50000 (40%)]\tLoss: 0.104316, Accuracy: 97.27\n",
      "Train Epoch: 77 [19200/50000 (43%)]\tLoss: 0.037906, Accuracy: 99.22\n",
      "Train Epoch: 77 [20480/50000 (45%)]\tLoss: 0.019818, Accuracy: 99.61\n",
      "Train Epoch: 77 [21760/50000 (48%)]\tLoss: 0.086368, Accuracy: 96.88\n",
      "Train Epoch: 77 [23040/50000 (51%)]\tLoss: 0.057183, Accuracy: 98.44\n",
      "Train Epoch: 77 [24320/50000 (54%)]\tLoss: 0.032481, Accuracy: 99.61\n",
      "Train Epoch: 77 [25600/50000 (57%)]\tLoss: 0.034322, Accuracy: 99.61\n",
      "Train Epoch: 77 [26880/50000 (60%)]\tLoss: 0.049938, Accuracy: 98.44\n",
      "Train Epoch: 77 [28160/50000 (62%)]\tLoss: 0.025709, Accuracy: 99.61\n",
      "Train Epoch: 77 [29440/50000 (65%)]\tLoss: 0.019036, Accuracy: 100.00\n",
      "Train Epoch: 77 [30720/50000 (68%)]\tLoss: 0.055021, Accuracy: 98.05\n",
      "Train Epoch: 77 [32000/50000 (71%)]\tLoss: 0.044998, Accuracy: 98.83\n",
      "Train Epoch: 77 [33280/50000 (74%)]\tLoss: 0.037647, Accuracy: 98.83\n",
      "Train Epoch: 77 [34560/50000 (77%)]\tLoss: 0.023178, Accuracy: 99.22\n",
      "Train Epoch: 77 [35840/50000 (80%)]\tLoss: 0.028144, Accuracy: 99.61\n",
      "Train Epoch: 77 [37120/50000 (82%)]\tLoss: 0.059951, Accuracy: 97.66\n",
      "Train Epoch: 77 [38400/50000 (85%)]\tLoss: 0.036210, Accuracy: 98.83\n",
      "Train Epoch: 77 [39680/50000 (88%)]\tLoss: 0.043336, Accuracy: 98.44\n",
      "Train Epoch: 77 [40960/50000 (91%)]\tLoss: 0.034746, Accuracy: 99.61\n",
      "Train Epoch: 77 [42240/50000 (94%)]\tLoss: 0.047533, Accuracy: 98.44\n",
      "Train Epoch: 77 [43520/50000 (97%)]\tLoss: 0.050007, Accuracy: 99.22\n",
      "Train Epoch: 77 [35000/50000 (99%)]\tLoss: 0.030596, Accuracy: 99.00\n",
      "\n",
      "Validation set: Average loss: 0.3011, Accuracy: 4590/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[40.98675537109375 s]\n",
      "Train Epoch: 78 [0/50000 (0%)]\tLoss: 0.035547, Accuracy: 98.44\n",
      "Train Epoch: 78 [1280/50000 (3%)]\tLoss: 0.042801, Accuracy: 98.83\n",
      "Train Epoch: 78 [2560/50000 (6%)]\tLoss: 0.044793, Accuracy: 98.44\n",
      "Train Epoch: 78 [3840/50000 (9%)]\tLoss: 0.081069, Accuracy: 97.27\n",
      "Train Epoch: 78 [5120/50000 (11%)]\tLoss: 0.038078, Accuracy: 98.44\n",
      "Train Epoch: 78 [6400/50000 (14%)]\tLoss: 0.040881, Accuracy: 98.83\n",
      "Train Epoch: 78 [7680/50000 (17%)]\tLoss: 0.026194, Accuracy: 99.22\n",
      "Train Epoch: 78 [8960/50000 (20%)]\tLoss: 0.036295, Accuracy: 98.83\n",
      "Train Epoch: 78 [10240/50000 (23%)]\tLoss: 0.035186, Accuracy: 99.61\n",
      "Train Epoch: 78 [11520/50000 (26%)]\tLoss: 0.038870, Accuracy: 98.83\n",
      "Train Epoch: 78 [12800/50000 (28%)]\tLoss: 0.058953, Accuracy: 98.05\n",
      "Train Epoch: 78 [14080/50000 (31%)]\tLoss: 0.062226, Accuracy: 97.66\n",
      "Train Epoch: 78 [15360/50000 (34%)]\tLoss: 0.050805, Accuracy: 98.83\n",
      "Train Epoch: 78 [16640/50000 (37%)]\tLoss: 0.029431, Accuracy: 99.22\n",
      "Train Epoch: 78 [17920/50000 (40%)]\tLoss: 0.056666, Accuracy: 98.05\n",
      "Train Epoch: 78 [19200/50000 (43%)]\tLoss: 0.056431, Accuracy: 98.05\n",
      "Train Epoch: 78 [20480/50000 (45%)]\tLoss: 0.033857, Accuracy: 98.83\n",
      "Train Epoch: 78 [21760/50000 (48%)]\tLoss: 0.020815, Accuracy: 100.00\n",
      "Train Epoch: 78 [23040/50000 (51%)]\tLoss: 0.030410, Accuracy: 99.61\n",
      "Train Epoch: 78 [24320/50000 (54%)]\tLoss: 0.094453, Accuracy: 98.05\n",
      "Train Epoch: 78 [25600/50000 (57%)]\tLoss: 0.033342, Accuracy: 98.83\n",
      "Train Epoch: 78 [26880/50000 (60%)]\tLoss: 0.024838, Accuracy: 98.83\n",
      "Train Epoch: 78 [28160/50000 (62%)]\tLoss: 0.035927, Accuracy: 99.22\n",
      "Train Epoch: 78 [29440/50000 (65%)]\tLoss: 0.033670, Accuracy: 99.22\n",
      "Train Epoch: 78 [30720/50000 (68%)]\tLoss: 0.031973, Accuracy: 98.83\n",
      "Train Epoch: 78 [32000/50000 (71%)]\tLoss: 0.042315, Accuracy: 98.05\n",
      "Train Epoch: 78 [33280/50000 (74%)]\tLoss: 0.071863, Accuracy: 97.27\n",
      "Train Epoch: 78 [34560/50000 (77%)]\tLoss: 0.030660, Accuracy: 99.22\n",
      "Train Epoch: 78 [35840/50000 (80%)]\tLoss: 0.058334, Accuracy: 98.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 78 [37120/50000 (82%)]\tLoss: 0.050279, Accuracy: 98.05\n",
      "Train Epoch: 78 [38400/50000 (85%)]\tLoss: 0.029474, Accuracy: 99.22\n",
      "Train Epoch: 78 [39680/50000 (88%)]\tLoss: 0.024220, Accuracy: 99.22\n",
      "Train Epoch: 78 [40960/50000 (91%)]\tLoss: 0.059048, Accuracy: 98.44\n",
      "Train Epoch: 78 [42240/50000 (94%)]\tLoss: 0.062650, Accuracy: 97.27\n",
      "Train Epoch: 78 [43520/50000 (97%)]\tLoss: 0.020212, Accuracy: 99.61\n",
      "Train Epoch: 78 [35000/50000 (99%)]\tLoss: 0.040496, Accuracy: 98.50\n",
      "\n",
      "Validation set: Average loss: 0.3040, Accuracy: 4589/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[37.71013426780701 s]\n",
      "torch.Size([1024, 1, 1])\n",
      "tensor([[[ 0.2561]],\n",
      "\n",
      "        [[ 0.6075]],\n",
      "\n",
      "        [[ 0.4023]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5824]],\n",
      "\n",
      "        [[-0.4619]],\n",
      "\n",
      "        [[-0.2801]]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor(1.00000e-03 *\n",
      "       [[[-7.4211]]], device='cuda:0')\n",
      "torch.Size([1, 896, 1024])\n",
      "tensor(1.00000e-04 *\n",
      "       [[[ 9.7656,  9.7654,  9.7656,  ...,  9.7656,  9.7657,  9.7656],\n",
      "         [ 9.7657,  9.7657,  9.7652,  ...,  9.7652,  9.7655,  9.7654],\n",
      "         [ 9.7659,  9.7659,  9.7657,  ...,  9.7658,  9.7650,  9.7658],\n",
      "         ...,\n",
      "         [ 9.7657,  9.7656,  9.7659,  ...,  9.7657,  9.7663,  9.7662],\n",
      "         [ 9.7655,  9.7657,  9.7657,  ...,  9.7654,  9.7653,  9.7655],\n",
      "         [ 9.7657,  9.7657,  9.7657,  ...,  9.7657,  9.7657,  9.7655]]], device='cuda:0')\n",
      "\n",
      "Test set: Average loss: 0.3085, Accuracy: 9167/10000 (91.67%)\n",
      "\n",
      "Train Epoch: 79 [0/50000 (0%)]\tLoss: 0.047813, Accuracy: 98.44\n",
      "Train Epoch: 79 [1280/50000 (3%)]\tLoss: 0.024315, Accuracy: 100.00\n",
      "Train Epoch: 79 [2560/50000 (6%)]\tLoss: 0.031218, Accuracy: 99.22\n",
      "Train Epoch: 79 [3840/50000 (9%)]\tLoss: 0.030730, Accuracy: 99.61\n",
      "Train Epoch: 79 [5120/50000 (11%)]\tLoss: 0.036990, Accuracy: 99.22\n",
      "Train Epoch: 79 [6400/50000 (14%)]\tLoss: 0.070427, Accuracy: 97.27\n",
      "Train Epoch: 79 [7680/50000 (17%)]\tLoss: 0.036737, Accuracy: 98.83\n",
      "Train Epoch: 79 [8960/50000 (20%)]\tLoss: 0.039082, Accuracy: 98.44\n",
      "Train Epoch: 79 [10240/50000 (23%)]\tLoss: 0.061921, Accuracy: 97.27\n",
      "Train Epoch: 79 [11520/50000 (26%)]\tLoss: 0.048846, Accuracy: 98.44\n",
      "Train Epoch: 79 [12800/50000 (28%)]\tLoss: 0.041895, Accuracy: 99.22\n",
      "Train Epoch: 79 [14080/50000 (31%)]\tLoss: 0.028611, Accuracy: 98.83\n",
      "Train Epoch: 79 [15360/50000 (34%)]\tLoss: 0.026757, Accuracy: 99.61\n",
      "Train Epoch: 79 [16640/50000 (37%)]\tLoss: 0.047057, Accuracy: 99.22\n",
      "Train Epoch: 79 [17920/50000 (40%)]\tLoss: 0.064657, Accuracy: 97.66\n",
      "Train Epoch: 79 [19200/50000 (43%)]\tLoss: 0.041092, Accuracy: 98.83\n",
      "Train Epoch: 79 [20480/50000 (45%)]\tLoss: 0.104631, Accuracy: 96.48\n",
      "Train Epoch: 79 [21760/50000 (48%)]\tLoss: 0.057096, Accuracy: 98.05\n",
      "Train Epoch: 79 [23040/50000 (51%)]\tLoss: 0.028866, Accuracy: 99.22\n",
      "Train Epoch: 79 [24320/50000 (54%)]\tLoss: 0.058255, Accuracy: 98.44\n",
      "Train Epoch: 79 [25600/50000 (57%)]\tLoss: 0.045428, Accuracy: 98.83\n",
      "Train Epoch: 79 [26880/50000 (60%)]\tLoss: 0.042564, Accuracy: 98.44\n",
      "Train Epoch: 79 [28160/50000 (62%)]\tLoss: 0.058968, Accuracy: 96.88\n",
      "Train Epoch: 79 [29440/50000 (65%)]\tLoss: 0.074634, Accuracy: 98.05\n",
      "Train Epoch: 79 [30720/50000 (68%)]\tLoss: 0.041506, Accuracy: 98.83\n",
      "Train Epoch: 79 [32000/50000 (71%)]\tLoss: 0.058991, Accuracy: 97.66\n",
      "Train Epoch: 79 [33280/50000 (74%)]\tLoss: 0.044953, Accuracy: 98.05\n",
      "Train Epoch: 79 [34560/50000 (77%)]\tLoss: 0.031652, Accuracy: 98.44\n",
      "Train Epoch: 79 [35840/50000 (80%)]\tLoss: 0.079061, Accuracy: 97.27\n",
      "Train Epoch: 79 [37120/50000 (82%)]\tLoss: 0.037136, Accuracy: 98.44\n",
      "Train Epoch: 79 [38400/50000 (85%)]\tLoss: 0.054483, Accuracy: 97.66\n",
      "Train Epoch: 79 [39680/50000 (88%)]\tLoss: 0.087593, Accuracy: 97.27\n",
      "Train Epoch: 79 [40960/50000 (91%)]\tLoss: 0.022643, Accuracy: 99.61\n",
      "Train Epoch: 79 [42240/50000 (94%)]\tLoss: 0.030638, Accuracy: 99.22\n",
      "Train Epoch: 79 [43520/50000 (97%)]\tLoss: 0.046054, Accuracy: 98.44\n",
      "Train Epoch: 79 [35000/50000 (99%)]\tLoss: 0.078491, Accuracy: 96.50\n",
      "\n",
      "Validation set: Average loss: 0.3053, Accuracy: 4589/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[40.89432168006897 s]\n",
      "\n",
      "Test set: Average loss: 0.3079, Accuracy: 9147/10000 (91.47%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fantastic logger for tensorboard and pytorch, \n",
    "# run tensorboard by opening a new terminal and run \"tensorboard --logdir runs\"\n",
    "# open tensorboard at http://localhost:6006/\n",
    "from tensorboardX import SummaryWriter\n",
    "best_loss = None\n",
    "best_acc = None\n",
    "\n",
    "import time \n",
    "SINCE=time.time()\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    train(epoch)\n",
    "    \n",
    "    loss, accuracy = validate(epoch)\n",
    "    best_loss, best_acc = save_best(loss, accuracy, best_loss, best_acc)\n",
    "    \n",
    "    NOW=time.time() \n",
    "    DURINGS=NOW-SINCE\n",
    "    SINCE=NOW\n",
    "    print(\"the time of this epoch:[{} s]\".format(DURINGS))\n",
    "    \n",
    "    if epoch>=10 and (epoch-10)%2==0:\n",
    "        test(epoch)\n",
    "    \n",
    "# writer = SummaryWriter() \n",
    "# writer.export_scalars_to_json(\"./all_scalars.json\")\n",
    "\n",
    "# writer.close()\n",
    "\n",
    "#---------------------------- Test ------------------------------\n",
    "test(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6902, Accuracy: 8877/10000 (88.77%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一次 scale 位于[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](http://op4a94iq8.bkt.clouddn.com/18-7-14/70206949.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x9BnCF17x72RAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhLQQijshhLQQijshhLQQijshhLSQ/w9isHt8TVxEXQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 查看训练过程的信息\n",
    "import  matplotlib.pyplot as plt\n",
    "\n",
    "def parse(in_file,flag):\n",
    "    num=-1\n",
    "    ys=list()\n",
    "    xs=list()\n",
    "    losses=list()\n",
    "    with open(in_file,\"r\") as reader:\n",
    "        for aLine in reader:\n",
    "            #print(aLine)\n",
    "\n",
    "            res=[e for e in aLine.strip('\\n').split(\" \")]\n",
    "            if res[0]==\"Train\" and flag==\"Train\":\n",
    "                num=num+1\n",
    "                ys.append(float(res[-1]))\n",
    "                xs.append(int(num))\n",
    "                losses.append(float(res[-3].split(',')[0]))\n",
    "            if res[0]==\"Validation\" and flag==\"Validation\":\n",
    "                num=num+1\n",
    "                xs.append(int(num))\n",
    "                tmp=[float(e) for e in res[-2].split('/')]\n",
    "                ys.append(100*float(tmp[0]/tmp[1]))\n",
    "                losses.append(float(res[-4].split(',')[0]))\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot(xs,ys,'ro')\n",
    "\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.plot(xs, losses, 'ro')\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    in_file=\"D://INFO.txt\"\n",
    "    # 显示训练阶段的正确率和Loss信息\n",
    "    parse(in_file,\"Train\") # \"Validation\"\n",
    "    # 显示验证阶段的正确率和Loss信息\n",
    "    #parse(in_file,\"Validation\") # \"Validation\"\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naRBY0BmGYRqE/w/U/zxNDJVCvAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngFDcCSGkAaG4E0JIA0JxJ4SQBuT/AHC9SchdaANwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XecVPXV+PHPoSkCCuiqdIhi7IBZ\niRErIiAu9oItFBVbokYx0cefRk2eaIIIiR1iIT5ENhFXYVF0KRsrZekiKEgslFAERSzU8/vj3AnL\nMrN7d3f6nPfrNa+Znbnl7DCcuXvu956vqCrOOedyR51UB+Cccy65PPE751yO8cTvnHM5xhO/c87l\nGE/8zjmXYzzxO+dcjvHE75xzOcYTv3PO5RhP/M45l2PqpTqAaA444ABt3759qsNwzrmMMXv27PWq\nmhdm2bRM/O3bt6esrCzVYTjnXMYQkc/CLuulHuecyzGe+J1zLsd44nfOuRzjid8553KMJ37nnMsx\nnvidcy7HeOJ3zrkc44nfOefSwbvvwp/+lJRdeeJ3zrlU2rYN7rkHTjkFnn4aNm9O+C498TvnXKp8\n9BGceCL8/vfQvz/MnQuNGyd8t574nXMu2VThySehSxdYvhxeegmefRb23Tcpu68y8YvI3iIyU0Tm\ni8giEbk/eP55Efm3iMwLbp1jrN9fRJYGt/7x/gWccy6jrFkDffvCjTfCySfDwoVw4YVJDSFMk7Yt\nQHdV3Swi9YF3ROT14LU7VPWlWCuKSHPgt0A+oMBsERmvqhtrG7hzzmWc8ePhmmvgm2/gL3+Bm26C\nOskvvFS5RzWRsw31g5uG3H4voERVNwTJvgToXaNInXMuU23eDIMHw7nnQqtWUFYGv/xlSpI+hKzx\ni0hdEZkHrMUS+Yzgpf8VkQUiMlxE9oqyaivgi3I/rwiec8653DBjhtXy//pX+M1vYPp0OOqolIYU\nKvGr6g5V7Qy0BrqKyNHAXcDhwPFAc+A3UVaVaJuLtg8RGSwiZSJStm7dulDBO+dc2tq+HR54ALp1\ng61bYdo0eOgh2CvaMXJyVevvDFX9CigFeqvq6qAMtAV4DugaZZUVQJtyP7cGVsXY9khVzVfV/Ly8\nUJPIOOdcelq2zE7c/va3cNllsGABnHpqqqP6rzCjevJEpGnwuCHQA1giIi2C5wQ4D/ggyupvAD1F\npJmINAN6Bs8551z2UYVnnoHOnWHJEnjxRXjhBdhvv1RHtpswo3paAKNFpC72RfEPVS0WkakikoeV\nc+YB1wOISD5wvapeo6obROR3wKxgWw+o6ob4/xrOOZdi69bZCdxXXoHu3eH556FNmypXSwVRDTtA\nJ3ny8/PV59x1zmWMOXOgTx/YuBEefBBuvTXpI3ZEZLaq5odZNi0nW3fOuYzy4IN2MnfWLDj22FRH\nUyVv2eCcc7Xx/ffw+ut29W0GJH3wxO+cc7UzeTJ8+y2cf36qIwnNE79zztVGUZE1V+vePdWRhOaJ\n3znnamr7duu/U1AADRqkOprQPPE751xNvfMOfPllRpV5wEf1OOdSZdo0G+u+337Qrt3ut7w8kGgd\nX9JMUZG1YOidWb0nPfE755Lr7bfh3nuhtBSaNYMdO2DTpt2XadgQ2rbd8wsh8lyrVlAvxelL1S7W\n6tkzKbNmxZMnfudccrz/viX8yZPh4IOtH/2118Lee8NXX8Fnn0W/zZsHa9fuvq26dS35t2sHRx4J\nw4fbl0UyzZkDn38O992X3P3GgSd+51xizZxpzcomTYIDD4RHHoHrr989UTdtardOnaJv4/vvLclW\n/FL45BOboPyEE2DAgKT8Ov9VVGRX5/btm9z9xoG3bHDOJcbcuZbwJ0yA/fe3XvQ33giNGsVvH6pw\nxBH2hfLWW/HbbhhHHWX7nTYtufuNoTotG3xUj3MuvhYsgAsugOOOs1Evf/gD/PvfcMcd8U36YCeA\nBwyw8wZLl8Z325X5+GP48MOMG80T4YnfORcfixbBJZdYuWbqVLj/fkv4d90FTZokbr8//7mVXJ5/\nPnH7qKioyO7POy95+4wjT/zOudr56CO4/HI45hir499zjyX8e+9NTh/6li1tOOXo0TZCKBmKiuAn\nP7FRRhnIE79zrmaWLYP+/W1UzfjxcOedlvAfeMCGaSbToEGwciWUlCR+XytX2jy6GVrmAR/V45yr\niY8/tpKOCNx2G/z613bRVar07WsnkJ97LvEXU736qt174nfO5ZRHHrERNYsXQ/v2qY7G+uRceSU8\n+SRs2ADNmyduX0VFcNhhNpooQ4WZc3dvEZkpIvNFZJGI3B88P0ZEPhKRD0TkWRGpH2P9HSIyL7iN\nj/cv4JxLsvXrrZ5+5ZXpkfQjBg6ErVvh739P3D42brQrjs8/PzNaSsQQpsa/Beiuqp2AzkBvETkB\nGAMcDhwDNASuibH+96raObidE4+gnXMp9OST8MMPVuJJJ5062RDSZ59N3D6Ki60jZwaXeSBE4lez\nOfixfnBTVX0teE2BmUDrBMbpnEsHP/wAjz0GZ51lJ3XTzcCBduHYvHmJ2X5RkY0iOv74xGw/SUKN\n6hGRuiIyD1gLlKjqjHKv1QeuAibFWH1vESkTkekikpmDXp1zZswY65tz++2pjiS6yy+3ev9zz8V/\n2999Z8NVzzsv6ROpx1uo6FV1h6p2xo7qu4rI0eVefgJ4S1XfjrF62+Ay4suBESJySLSFRGRw8AVR\ntm7dumr8Cs65pFC1k7qdOqXvbFPNm1tiHjMGtmyJ77bfeMN6BmV4mQeqOY5fVb8CSoHeACLyWyAP\niFnsU9VVwf3yYN0uMZYbqar5qpqfl8phYc656CZNsjYFt9+e3ic2Bw2yyVEmTIjvdouK7PqEU0+N\n73ZTIMyonjwRaRo8bgj0AJaIyDVAL+AyVd0ZY91mIrJX8PgAoBvwYbyCd84l0bBhVt++9NJUR1K5\nHj2gdev4lnu2bbMvkr59oX7UAYwZJcwRfwtgmogsAGZhNf5i4CngIOD9YKjmvQAiki8ifw3WPQIo\nE5H5wDTgIVX1xO9cppk3D6ZMgZtvTv+5ZevWtSuKJ02yq2zj4V//sjkDsqDMA96W2TkXxs9/Di+/\nDF98kfx2DDWxbBl07AgPPmitJGrrppvsL4j162GffWq/vQTwtszOufhZuRJefBGuvjozkj7AoYfC\nySfbmP7aHtzu3GlTLPbunbZJv7o88TvnKvfoo5b8br011ZFUz6BB1qP/vfdqt51Zs2DVqqwp84An\nfudcZTZvtqkNL7gAOnRIdTTVc9FFNvFLba/kLSqyid0LCuITVxrwxO+ci+3ZZ+2kZrpesFWZxo1t\nBNI//mFfYDWhaon/tNMyp8wVgid+51x0O3bAiBFw4ok2mXkmGjjQkv5LL9Vs/cWLrQV1FpV5wBO/\ncy6WoiKbWCUTj/YjunWz0T01HdMfmWLx3HPjF1Ma8MTvnItu2DA45JDMTnoidtT/1ls2xLO6iorg\npz+FVq3iH1sKeeJ3zu3pvfdg+nQbyVO3bqqjqZ2aTsb++ecwe3bWlXnAE79zLpphw6BpUxgwINWR\n1F6rVtCrlyX+6kzG/sordu+J3zmX9T75xEoc119vI2OyQWQy9smTw69TVGRzDhx2WOLiShFP/M65\n3f35zzZu/Ze/THUk8dO3r7VsDjumf/16Oy+QhUf74InfOVfexo2WHC+7zDpxZou99rI5gl95xSZj\nr8qECXa1sid+51zWe/pp+Pbb9JtPNx6qMxl7URG0bWtz+GYhT/zOObN1q/Xl6dHDZtnKNp07Q5cu\nVY/p37wZ3nzTZvJK5wlnasETv3POjB1rzcgy+YKtqgwcCHPmwPz5sZeZNMmmbczSMg944nfOgfWk\nGTYMjjrKhj5mqzCTsRcVwf77w0knJS+uJAsz9eLeIjJTROaLyCIRuT94voOIzBCRpSJSKCJRp+UR\nkbtEZJmIfCQiWfyJci6DTZkCCxZYbT9LyxuAJfRzz4X/+z8rbVW0dSsUF9sy9eolP74kCXPEvwXo\nrqqdgM5AbxE5AfgjMFxVOwIbgasrrigiRwL9gKOwCdqfEJEMvwzQuSw0bBgcdBBccUWqI0m8gQNj\nT8Y+dSps2pTVZR4IkfjVRHqa1g9uCnQHIi3vRgPnRVn9XGCsqm5R1X8Dy4CutY7aORc/ixZZXfsX\nv7Bhj9muZ0+7mjdauaeoyC5a69Ej+XElUagav4jUFZF5wFqgBPgE+EpVtweLrACidTFqBXxR7udY\nyznnUuWRR6BhQ7jhhlRHkhx161r/ntdft5PZETt2wKuvwllnwd57py6+JAiV+FV1h6p2BlpjR+xH\nRFssynPRioVRJ8AUkcEiUiYiZevWrQsTlnOutv7zH6t3Dxhg9e9cMXCgXaD1wgu7nps+Hdasyfoy\nD1RzVI+qfgWUAicATUUkcvajNbAqyiorgDblfo61HKo6UlXzVTU/Ly+vOmE552rq8cdh2zb41a9S\nHUlydexoo3bKT8ZeVAT160OfPqmNLQnCjOrJE5GmweOGQA9gMTANuChYrD/wapTVxwP9RGQvEekA\ndARmxiNw51wtffcdPPkknHOOJcJcM2iQza71/vu7plg84wzYb79UR5ZwYY74WwDTRGQBMAsoUdVi\n4DfAbSKyDNgfeAZARM4RkQcAVHUR8A/gQ2AScJOqVqMvqnMuYUaPttEt2XzBVmUuvnjXZOwLF8Ly\n5TlR5gEQ1agl95TKz8/XsrKyVIfhXPbauRMOP9x67s+Ykd1j9yszaBD88592Yvvhh2H1ahvWmoFE\nZLaq5odZ1q/cdS4XTZgAS5fa0X6uJn3YNRn78OE2qXyGJv3q8sTvXK6JtGdo1w4uvDDV0aTWSSfB\noYfC9u05U+YBT/zO5RZV+J//gbffhiFDsrotQSgicO21NrbfE79zLis98AA89BBcdx3cdFOqo0kP\nt90GH3wAP/pRqiNJGk/8zuWKhx6C++6zuvYTT+R2bb+8evXsRHcO8cTvXC4YPhzuusuasI0aBXX8\nv34u839957Ld449bOePii+H5562e7XKaJ37nstmoUdZ189xzYcwYP5nrAE/8zmWv0aPtJG6fPlBY\naH1onMMTv3PZaexYuyr1jDNg3Ljc6LPvQvPE71y2GTcOrrzSLk569dWs7y3vqs8Tv3PZZMIE6NcP\nuna1uWP32SfVEbk05InfuWzxxhtw0UXQpYvNLtWkSaojcmnKE79z2WDqVDjvPDjySPsCyIGe8q7m\nPPE7l+nefhv69rVmYyUl0KxZqiNyac4Tv3OZbPp0G67Zti1MngwHHJDqiFwG8MTvXKaaPRt694aD\nD4YpU3Kml7yrvSov4xORNsDfgIOBncBIVf2ziBQCPw4Wawp8paqdo6z/KfANsAPYHnaGGOdcJebP\nhzPPtLLO1KnQsmWqI3IZJMz129uB21V1jog0AWaLSImqXhpZQESGAV9Xso3TVXV9LWN1zgEsWgQ9\neth8sVOnQps2qY7IZZgqE7+qrgZWB4+/EZHFQCtsAnVERIBLgO4JjNM5BzZTVJ8+1n5h6lTo0CHV\nEbkMVK0av4i0B7oAM8o9fTKwRlWXxlhNgTdFZLaIDK5JkM65wNSp8Pnn8Nhj0LFjqqNxGSp0qz4R\naQyMA25V1U3lXroMeLGSVbup6ioRORAoEZElqvpWlO0PBgYDtG3bNmxYzuWWwkK7MKtPn1RH4jJY\nqCN+EamPJf0xqvpyuefrARcAhbHWVdVVwf1aoAjoGmO5kaqar6r5eXl54X8D53LF1q3w8svWYtn7\n77haqDLxBzX8Z4DFqvpIhZd7AEtUdUWMdRsFJ4QRkUZAT+CD2oXsXI4qKYGvvoJLL616WecqEeaI\nvxtwFdBdROYFt8jfmf2oUOYRkZYi8lrw40HAOyIyH5gJTFTVSXGK3bncUlgITZtCz56pjsRluDCj\net4Bos7KrKoDojy3CugTPF4OdKpdiM45fvgBXnnFmrA1aJDqaFyG8yt3ncsEkybBN994mcfFhSd+\n5zJBYSHsvz9098tlXO154ncu3X33nU2wcuGFPm+uiwtP/M6lu4kT4dtvbWYt5+LAE79z6a6w0Dpw\nnnJKqiNxWcITv3Pp7Jtv7Ij/oougbt1UR+OyhCd+59LZhAk2lNNH87g48sTvXDorLIRWreDEE1Md\nicsinvidS1dffWXj9y+5BOr4f1UXP/5pci5dvfqqNWbzMo+LM0/8zqWrsWOhfXvoGrWhrXM15onf\n5Q7VVEcQ3pdfwuTJVuaRqK2ynKsxT/wu+6nCwIE2T+3WramOJpyXX7ZpFr3M4xLAE7/Lfi+8AM8/\nb9MW3nlnqqMJp7AQDj0UunRJdSQuC3nid9nt88/hl7+0q15vugmGD4fi4lRHVbk1a2DaNDva9zKP\nS4DQc+46l3F27oQBA+z++eehRQt4913o3x/mz4fWrVMdYXTjxlnMXuZxCeJH/C57PfqoHTn/+c/Q\noYPNU1tYCFu2wOWXWw09HRUWwhFHwNFHpzoSl6XCzLnbRkSmichiEVkkIrcEz98nIiujTMdYcf3e\nIvKRiCwTkQwpsLqMt3ix1fP79rUTuxGHHQZPPQVvvw0PPJC6+GJZtcpi8zKPS6AwpZ7twO2qOieY\nOH22iJQErw1X1YdjrSgidYHHgTOBFcAsERmvqh/WNnDnYtq2Da66Cho3hlGj9kygV14JU6bA738P\np52WXpOb/POfNgrJyzwugao84lfV1ao6J3j8DbAYaBVy+12BZaq6XFW3AmOBc2sarHOh/O//wuzZ\n8PTTcNBB0Zd57DH48Y/hiitg7drkxleZwkI49lg4/PBUR+KyWLVq/CLSHugCzAie+oWILBCRZ0Wk\nWZRVWgFflPt5BTG+NERksIiUiUjZunXrqhOWS6RMuugJYOZMO5L/+c/hggtiL9eokSXZjRtt2Z07\nkxdjLJ9/Du+/70f7LuFCj+oRkcbAOOBWVd0kIk8CvwM0uB8GDKq4WpRNRc0kqjoSGAmQn5+fYdkm\nS02YABdfDPvuCwceaLe8vOiPIz83bZq62vR331kSb9nSTuhW5dhjYcQIuOEGePhh+PWvEx9jZf7x\nD7v3xO8SLFTiF5H6WNIfo6ovA6jqmnKvjwKiDY5eAbQp93NrYFWNo3XJNW4cNGxoR85r19pt3jy7\n/+qr6OvUr29fAOW/FI45Bm67LfHzxd51F3z0kbU6aNo03DrXXWf1/rvvtrH+J5yQ2BgrU1gI+flw\nyCGpi8HlhCoTv4gI8AywWFUfKfd8C1VdHfx4PvBBlNVnAR1FpAOwEugHXF7rqF3iqdpQyB49bBRM\nRVu3wvr1u74Q1q3b/T7yeNkyGDMG3nzTTlw2b56YeCdPhr/8BW6+Gc44I/x6InYCuKwMLrsM5s4N\n/6URT598YjEMHZr8fbvco6qV3oCTsPLMAmBecOsDvAAsDJ4fD7QIlm8JvFZu/T7Ax8AnwN1V7U9V\n+clPfqIuxZYvVwXVxx6r/bZGj1Zt0EC1Y0fVJUtqv72KNm5Ubd1a9fDDVb/7rmbbmD5dtV491Qsv\nVN25M77xhfGHP9j7/dlnyd+3ywpAmYbIr2qftHALJvPmiT8NPPOMfTwWLYrP9t59VzUvT7VpU9U3\n34zPNiOuukq1bl3VmTNrt50//cl+5yeeiE9c1dGpk+rPfpb8/bqsUZ3E71fuuuhKS60+f8QR8dne\niSfCrFnQpg2cdRY88UR8tjtunDVh+3//D44/vnbbuv12i+1Xv7KWDsny0Ue2Pz+p65LEE7/bU6S+\nf9pp8R2h066d9crp08capv3iF7Vrm/Cf/9jJ2fx8OzlbW3XqwOjRdh7i0kth8+babzOMwkJ7ny++\nODn7cznPE7/b0/LlsGKFJf54a9IEiorgjjvg8cftCHvjxupvRxWuvRa+/Rb+9rf4jRjKy7OT0R9/\nbF9MyVBYCCefbMNQnUsCT/xuT9Om2f3ppydm+3Xrwp/+BM89B//6lw2hXLq0ett45hlrr/zQQ/Er\nR0Wcfjrcc48d/b/wQny3XdEHH8CHH3qZxyWVJ363p9JSOPhga2mQSAMG2OQoGzbAT39qj8NYvtzq\n8N27W6/9RLjnHjsKv+EGq8EnytixVmK68MLE7cO5Cjzxu90lqr4fy0knWZuFli2hZ0/rr1OZHTvs\nC6NOHfuLoU6CPsL16sHf/26tnC+9FH74If77ULUyz+mnx+4p5FwCeOJ3u1u2zFoDJ6K+H0uHDvDe\ne9CrF1x/vV2EFeuk7yOPWNviRx+Ftm0TG1fr1jaBy/z5MGRI/Lc/d669317mcUnmid/tLtH1/Vj2\n3RfGj7fWDo8+CmefvWdbiIULbdjm+edb2+VkKCiwstLjj9sE6PFUWGh/WVTWTM65BPDE73ZXWmpT\nFHbsmPx9160Lw4bBX/9q9f6f/cyOiMFaRFx1lbVTePrp5DaCe+ghGzJ69dXw2Wfx2aaqNWXr0QP2\n3z8+23QuJE/8bpdIff/001M7+9PVV1vvnXXr7KTvtGlw331Wchk1yoZcJlODBnYSdscOG4H00EOx\nm9SFNXMmfPqpl3lcSnjid7t8/LFdFJXM+n4sp54KM2bYSc+ePeGPf4RBg+Ccc1ITzyGH2JfRMcdY\nF9A2bazuv2JFzbZXWGhfKOedF984nQvBE7/bJVX1/VgOOcQmJund24aWDh+e2ni6drUuo3Pm2BfQ\niBF2Yrp/fxuPH9bOnVbm6dUrNZ1AXc7zxO92KS2FVq3Sqx/8fvvZhDCLFtkJ4HTQpYtd3btsGdx4\nI7z0kv0lcPbZdkFaVbOWvfcerFzpZR6XMp74nVG1xJ/q+n4s6RhT+/Y209fnn8PvfmdN6E47zc5L\nvPSSnROIprDQrg9IVdnK5TxP/M4sWQJr1qRHfT/T7L+/DTP97DN48knrPXTxxVaeevJJ+P77Xcvu\n2GFfCmefbX2LnEsBT/zOpFt9PxM1bGgXoC1ZYsm9eXMrBbVrZ38RfPklvPWWnUD3Mo9LoSoTv4i0\nEZFpIrJYRBaJyC3B80NFZImILBCRIhGJepZKRD4VkYUiMk9EyuL9C7g4KS21kSodOqQ6ksxXt671\n3pkxw97Xrl3h3nvtSuMbb4RGjeyI37kUCXPEvx24XVWPAE4AbhKRI4ES4GhVPRabWvGuSrZxuqp2\nVtX8Wkfs4i/d6/uZSsSGpRYX21XHF19sJ4Qvugj22SfV0bkcVmXiV9XVqjonePwNsBhopapvqmqk\nocp0oHXiwnQJ9eGHdrGU1/cT5+ijre/P2rXRJ693LomqVeMXkfZAF2BGhZcGAa/HWE2BN0VktogM\nrm6ALgm8vp88zZrZiB7nUqhe2AVFpDEwDrhVVTeVe/5urBw0Jsaq3VR1lYgcCJSIyBJVfSvK9gcD\ngwHaJrrrottdaamdgGzfPtWROOeSINQRv4jUx5L+GFV9udzz/YEC4Ipglvc9qOqq4H4tUAR0jbHc\nSFXNV9X8vGT3YsllO3fuqu8753JCmFE9AjwDLFbVR8o93xv4DXCOqn4XY91GItIk8hjoCVTj2naX\ncIsW2TBDr+87lzPCHPF3A64CugdDMueJSB/gMaAJVr6ZJyJPAYhISxF5LVj3IOAdEZkPzAQmquqk\n+P8arsYi9X1P/M7ljCpr/Kr6DhBtjN9rUZ6LlHb6BI+XA51qE2DO2rwZGjdO/H5KS23sfrt2id+X\ncy4t+JW75W3fbpN3z52b2jjmzLGujSUlid3Pzp3WVMzr+87lFE/85Y0bB489Zo23UinS4OvBBxO7\nn4ULYcMGL/M4l2M88UeowtCh9vi112J3VkyG4mKbi3XaNJg9O3H78fq+cznJE39Eaakl2TPOsKtY\nZ81KTRyff25H4nfdZd0bH344cfsqLbXe+23aJG4fzrm044k/YuhQOPBAeOEFa7JVXJyaOCZOtPsr\nroDBg+Gf/7S5WeNtxw6v7zuXozzxg02b9/rrdmK3RQvo1i11ib+42I7CDzsMbrnFGn0l4pzDggU2\nYbiXeZzLOZ74wcop++wDN9xgP/ftC/PnwxdfJDeO776DqVOhoMASfps20K8fjBplk3vEk9f3nctZ\nnvhXroS//x0GDbKZlMASL+wquyTL1Knwww+792q//Xb49lsYOTK++yothY4dbY5d51xO8cT/l79Y\nvfu223Y99+MfW7kl2eWeiRPtoq1TTtn1XOfO0KOHlXu2bInPfnbssJmgvL7vXE7K7cS/aZP1Rr/o\not1nnhKxo/4pU6z8kgyq9kVz5pmw1167v3bHHbB6Nbz4Ynz2NW8efP21l3mcy1G5nfhHjbLkf8cd\ne75WUGBll6lTkxPLwoWwYsWuMlN5Z54Jxxxj5yKiN0GtHq/vO5fTcjfxb9sGI0ZY8suPMiPkKadY\n2WXChOTEEykr9emz52siMGSIddJ8443a76u01MpZLVrUflvOuYyTu4l/7Fg7wo52tA/QoAH06mUJ\nOR5H2VWZONG+gA4+OPrr/frZidjI1cU1tX271/edy3G5mfgj7RmOPBLOOiv2cgUFsGqV1cQTaf16\neP/93UfzVNSggY3rnzrVmrjV1Ny58M03XuZxLoflZuIvKbGa+pAhVkaJ5ayz7PVEj+6ZNMm+jKLV\n98sbPNjaOAwbVvN9eX3fuZyXm4l/6FCrb19+eeXLHXQQdO2a+MRfXGz7Ou64ypfbbz+49looLLSe\nPjVRWgpHHGH7c87lpNxL/HPnwuTJVjapOGwymoICmDkT1qxJTDzbttkR/9lnQ50Q/xy33GL3NWnj\nsG0bvP221/edy3Fh5txtIyLTRGSxiCwSkVuC55uLSImILA3um8VYv3+wzNJgcvbUevhhG61z3XXh\nlo+UX16LOuFY7b33no2pr6y+X17btnaid+RI67VTHXPm2MxeXuZxLqeFOeLfDtyuqkcAJwA3iciR\nwJ3AFFXtCEwJft6NiDQHfgv8FOgK/DbWF0RSfPaZlUkGD7YZrsLo1Alat05cuae4GOrXt7H6Yd1+\nuyXw6rZxiNT3Tz21eus557JKlYlfVVer6pzg8TfAYqAVcC4wOlhsNHBelNV7ASWqukFVNwIlQO94\nBF4jI0bYydpbbw2/TuQq3jffjF/LhPImTrQj8CZNwq/TpYvNG/DnP8PWreHXKy2Fo46y9tPOuZxV\nrRq/iLQHugAzgINUdTXYlwPbOtNHAAAMy0lEQVQQLZu0Asq3uFwRPBdt24NFpExEytatW1edsMLZ\nuNGu1O3Xr/oTjxQU2BH2W2/FN6bly2Hx4vBlnvKGDLGhpmPHhlt+2zZ45x2v7zvnwid+EWkMjANu\nVdVNYVeL8lzUq6FUdaSq5qtqfl5eXtiwwnvqKetyOWRI9dft3h0aNoz/VbyR7p9VDeOMplcvOPro\n8G0cysrs9/f6vnM5L1TiF5H6WNIfo6ovB0+vEZEWwestgLVRVl0BlD+8bg2sqnm4NbRli3XhPPNM\nq9lXV8OGVlqJ91W8xcW7OoFWV6SNw8KFVoaqitf3nXOBMKN6BHgGWKyqj5R7aTwQGaXTH3g1yupv\nAD1FpFlwUrdn8FxyjRkD//lP7PYMYRQUwL//baWZeNi82WruNTnaj7jsMmjZMty8vKWl1ujtgANq\nvj/nXFYIc8TfDbgK6C4i84JbH+Ah4EwRWQqcGfyMiOSLyF8BVHUD8DtgVnB7IHgueXbutMQY6Wtf\nU5E6fLxG90yebCdma1Lfj2jQAG6+2bZVWVuJrVvh3Xe9vu+cA8KN6nlHVUVVj1XVzsHtNVX9UlXP\nUNWOwf2GYPkyVb2m3PrPquqhwe25RP4yUb32mh2lV9WeoSqtW9uXR7wS/8SJsO++cNJJtdvOddfZ\ndQmVHfXPmmXzCnh93zlHLly5O3SojeK55JLab6ugwI6cN9Tyj5adOy3x9+plY/hro2lTa+Mwdmzs\nOYKnTbMvPa/vO+fI9sQ/c6YNwfzVr2qfYMES/86d1mKhNubOtRm1alPfL6+qNg6lpXDssdC8eXz2\n55zLaNmd+IcOtcZm11xT9bJhHH885OXVvtwzcaIdgVfWEro62rWzv2hGjrT2D+Vt2eL1fefcbrI3\n8X/yCbz8Mlx/ffWuiq1MnTp2Mvb1121Ck5oqLoaf/tS+ROJlyBDrsz9q1O7Pz5xpU0h6fd85F8je\nxD98ONSta6Ne4qmgwJqjvfdezdZfs8ZOttZmNE80xx1nF5qNGLF7G4dIff+UU+K7P+dcxsrOxL9+\nPTz7LFx5pY1zj6eePe18QU3LPZEun/Gq75c3ZAisXGmN6CJKS200UrPU9cZzzqWX7Ez8TzwB339f\ns/YMVWnSxMomNW3fMHGizZ1bkyuIq9K7t00nGWnj8MMP9peJl3mcc+VkX+L//nt47DErpRx5ZGL2\nUVAAS5bAsmXVW2/rVmuvcPbZtbumIJZIG4cFC+yirhkz7OSun9h1zpWTfYl/9GhYt6527RmqEqnP\nR5qshfX223YCNhFlnojLL7dpJYcOtfp+nTpw8smJ259zLuNkV+LfscMmIj/++MSezDzkEJu3trp1\n/uJim+6xe/fExAW2/Ztvtgnln3vOeveHnXTGOZcTsivxv/qqlV/uuCMxpZTyCgrgX/+CTWE7VGN/\nIXTvDo0aJS4usDYOjRrZhOxe33fOVZBdif/hh6FDBzj//MTvq6DAJjcpKQm3/Mcfw9Kl8R/GGU2z\nZrsuWvP6vnOugnqpDiBuNm2CevXgttvsPtFOPNFKKMXFcOGFVS8fKQslI/ED3H23XbVcnbl8nXM5\nIXsS/777Wl+enTuTs7969azlwsSJts86VfzxNHGizXfbvn1SwiMvD+6/Pzn7cs5llOwq9UDVCTie\nCgpsBNGsWZUv9/XX9qWUyNE8zjkXUvYl/mTq3du+aKoa3VNSYr19klXmcc65SoSZevFZEVkrIh+U\ne66w3Gxcn4pI1OmfgtcWBsuVxTPwtNC8OXTrVvVVvMXFdsL1Zz9LTlzOOVeJMEf8zwO9yz+hqpdG\nZuPCJmF/OdqKgdODZfNrHmYaKyiA+fNjT4Kyc6f15+ndOzknnZ1zrgphpl58C4g65VQwEfslwItx\njitz9O1r97Gu4p01y84DeH3fOZcmalvjPxlYo6pLY7yuwJsiMltEBtdyX+np8MPhRz+KXeefONHO\nA/TuHf1155xLstom/suo/Gi/m6oeB5wF3CQiMfsoiMhgESkTkbJ169bVMqwkErGj+SlTbELzioqL\nbcy/T3vonEsTNU78IlIPuAAojLWMqq4K7tcCRUDXSpYdqar5qpqfF8+ZqZKhoMBaIE+duvvzK1fa\n/Lo+msc5l0Zqc8TfA1iiqiuivSgijUSkSeQx0BP4INqyGe+UU6Bx4z3LPYmcdMU552oozHDOF4H3\ngR+LyAoRuTp4qR8Vyjwi0lJEgmzHQcA7IjIfmAlMVNVJ8Qs9jey1l83MVVxsE6BEFBfbROhHHZW6\n2JxzroIqxxeq6mUxnh8Q5blVQJ/g8XIgAdNMpamCApvcff58m+rwhx9sMpQBAxLfKdQ556rBr9yN\nlz597D5S7ikttZO9XuZxzqUZT/zxctBB0LXrrsQ/cSI0bOj98J1zaccTfzwVFMDMmbBmjX0B9Ohh\nyd8559KIJ/54Kiiwk7sPPwyffurDOJ1zackTfzx17gytWsGIEfazJ37nXBryxB9Pkat4t2+HTp2g\ndetUR+Scc3vwxB9vkVE8PprHOZemPPHH25lnwpAhcP31qY7EOeei8gbx8bbXXjB0aKqjcM65mPyI\n3znncownfuecyzGe+J1zLsd44nfOuRzjid8553KMJ37nnMsxnvidcy7HeOJ3zrkcI1p+qsA0ISLr\ngM9quPoBwPo4hpMoHmf8ZUqsHmd8ZUqckNhY26lqXpgF0zLx14aIlKlqfqrjqIrHGX+ZEqvHGV+Z\nEiekT6xe6nHOuRzjid8553JMNib+kakOICSPM/4yJVaPM74yJU5Ik1izrsbvnHOuctl4xO+cc64S\nGZv4RaS3iHwkIstE5M4or+8lIoXB6zNEpH0KYmwjItNEZLGILBKRW6Isc5qIfC0i84LbvcmOM4jj\nUxFZGMRQFuV1EZG/BO/nAhE5LgUx/rjc+zRPRDaJyK0VlknZ+ykiz4rIWhH5oNxzzUWkRESWBvfN\nYqzbP1hmqYj0T0GcQ0VkSfBvWyQiTWOsW+nnJAlx3iciK8v9+/aJsW6l+SFJsRaWi/NTEZkXY92k\nvaf/paoZdwPqAp8APwIaAPOBIysscyPwVPC4H1CYgjhbAMcFj5sAH0eJ8zSgOA3e00+BAyp5vQ/w\nOiDACcCMNPgM/Acbu5wW7ydwCnAc8EG55/4E3Bk8vhP4Y5T1mgPLg/tmweNmSY6zJ1AvePzHaHGG\n+ZwkIc77gCEhPhuV5odkxFrh9WHAval+TyO3TD3i7wosU9XlqroVGAucW2GZc4HRweOXgDNERJIY\nI6q6WlXnBI+/ARYDrZIZQxydC/xNzXSgqYi0SGE8ZwCfqGpNL/SLO1V9C9hQ4enyn8PRwHlRVu0F\nlKjqBlXdCJQAvZMZp6q+qarbgx+nA60Ttf+wYryfYYTJD3FVWaxB3rkEeDGRMVRHpib+VsAX5X5e\nwZ4J9b/LBB/or4H9kxJdFEGpqQswI8rLPxOR+SLyuogcldTAdlHgTRGZLSKDo7we5j1Ppn7E/o+U\nDu9nxEGquhrsQAA4MMoy6fbeDsL+uoumqs9JMvwiKEk9G6N0lm7v58nAGlVdGuP1pL+nmZr4ox25\nVxyeFGaZpBCRxsA44FZV3VTh5TlYuaIT8CjwSrLjC3RT1eOAs4CbROSUCq+n0/vZADgH+GeUl9Pl\n/ayOdHpv7wa2A2NiLFLV5yTRngQOAToDq7ESSkVp834GLqPyo/2kv6eZmvhXAG3K/dwaWBVrGRGp\nB+xHzf5srBURqY8l/TGq+nLF11V1k6puDh6/BtQXkQOSHCaquiq4XwsUYX8ulxfmPU+Ws4A5qrqm\n4gvp8n6WsyZSEgvu10ZZJi3e2+CkcgFwhQbF54pCfE4SSlXXqOoOVd0JjIqx/7R4P+G/uecCoDDW\nMql4TzM18c8COopIh+Dorx8wvsIy44HI6IiLgKmxPsyJEtT2ngEWq+ojMZY5OHLuQUS6Yv8mXyYv\nShCRRiLSJPIYO9H3QYXFxgM/D0b3nAB8HSlhpEDMI6h0eD8rKP857A+8GmWZN4CeItIsKF30DJ5L\nGhHpDfwGOEdVv4uxTJjPSUJVOK90foz9h8kPydIDWKKqK6K9mLL3NJlnkuN5w0aZfIydvb87eO4B\n7IMLsDdWClgGzAR+lIIYT8L+xFwAzAtufYDrgeuDZX4BLMJGHkwHTkxBnD8K9j8/iCXyfpaPU4DH\ng/d7IZCfon/3fbBEvl+559Li/cS+jFYD27Cjzqux80pTgKXBffNg2Xzgr+XWHRR8VpcBA1MQ5zKs\nLh75nEZGxLUEXqvsc5LkOF8IPn8LsGTeomKcwc975Idkxxo8/3zks1lu2ZS9p5GbX7nrnHM5JlNL\nPc4552rIE79zzuUYT/zOOZdjPPE751yO8cTvnHM5xhO/c87lGE/8zjmXYzzxO+dcjvn/QKMdOnl8\nDuAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wPtS+GMghk59AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 查看训练过程的信息\n",
    "import  matplotlib.pyplot as plt\n",
    "\n",
    "def parse(in_file,flag):\n",
    "    num=-1\n",
    "    ys=list()\n",
    "    xs=list()\n",
    "    losses=list()\n",
    "    with open(in_file,\"r\") as reader:\n",
    "        for aLine in reader:\n",
    "            #print(aLine)\n",
    "\n",
    "            res=[e for e in aLine.strip('\\n').split(\" \")]\n",
    "            if res[0]==\"Train\" and flag==\"Train\":\n",
    "                num=num+1\n",
    "                ys.append(float(res[-1]))\n",
    "                xs.append(int(num))\n",
    "                losses.append(float(res[-3].split(',')[0]))\n",
    "            if res[0]==\"Validation\" and flag==\"Validation\":\n",
    "                num=num+1\n",
    "                xs.append(int(num))\n",
    "                tmp=[float(e) for e in res[-2].split('/')]\n",
    "                ys.append(100*float(tmp[0]/tmp[1]))\n",
    "                losses.append(float(res[-4].split(',')[0]))\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot(xs,ys,'r-')\n",
    "\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.plot(xs, losses, 'r-')\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    in_file=\"D://INFO.txt\"\n",
    "    # 显示训练阶段的正确率和Loss信息\n",
    "    parse(in_file,\"Train\") # \"Validation\"\n",
    "    # 显示验证阶段的正确率和Loss信息\n",
    "    parse(in_file,\"Validation\") # \"Validation\"\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
