{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>MobileNet - Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step 1: Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MobileNet-Pytorch\n",
    "import argparse \n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from mobilenets import mobilenet\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cudause_cud  = torch.cuda.is_available()\n",
    "dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Train, Validate, Test. Heavily inspired by Kevinzakka https://github.com/kevinzakka/DenseNet/blob/master/data_loader.py\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "valid_size=0.1\n",
    "\n",
    "# define transforms\n",
    "valid_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "\n",
    "# load the dataset\n",
    "train_dataset = datasets.CIFAR10(root=\"data\", train=True, \n",
    "            download=True, transform=train_transform)\n",
    "\n",
    "valid_dataset = datasets.CIFAR10(root=\"data\", train=True, \n",
    "            download=True, transform=valid_transform)\n",
    "\n",
    "num_train = len(train_dataset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train)) #5w张图片的10%用来当做验证集\n",
    "\n",
    "\n",
    "np.random.seed(42)# 42\n",
    "np.random.shuffle(indices) # 随机乱序[0,1,...,49999]\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx) # 这个很有意思\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "###################################################################################\n",
    "# ------------------------- 使用不同的批次大小 ------------------------------------\n",
    "###################################################################################\n",
    "\n",
    "show_step=2  # 批次大，show_step就小点\n",
    "max_epoch=250  # 训练最大epoch数目\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                batch_size=512, sampler=train_sampler)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, \n",
    "                batch_size=64, sampler=valid_sampler)\n",
    "\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), normalize\n",
    "])\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root=\"data\", \n",
    "                                train=False, \n",
    "                                download=True,transform=test_transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                          batch_size=64, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Model Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 32  缩放5次到 1x1@1024 \n",
    "# From https://github.com/kuangliu/pytorch-cifar \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    '''Depthwise conv + Pointwise conv'''\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        \n",
    "        # 分组卷积数=输入通道数\n",
    "        self.conv1 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=in_planes, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        \n",
    "        \n",
    "        #self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "        one_conv_kernel_size = 3\n",
    "        self.conv1D= nn.Conv1d(1, out_planes, one_conv_kernel_size, stride=1,padding=1,groups=1,dilation=1,bias=False) # 在__init__初始化        \n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        # -------------------------- Attention -----------------------\n",
    "        w = F.avg_pool2d(x,x.shape[-1])  #最好在初始化层定义好\n",
    "        #print(w.shape)\n",
    "        # [bs,in_Channel,1,1]\n",
    "        w = w.view(w.shape[0],1,w.shape[1])\n",
    "        # [bs,1,in_Channel]\n",
    "        # one_conv_filter = nn.Conv1d(1, out_channel, one_conv_kernel_size, stride=1,padding=1,groups=1,dilation=1) # 在__init__初始化\n",
    "        # [bs,out_channel,in_Channel]\n",
    "        w = self.conv1D(w)\n",
    "        w = 0.5*F.tanh(w) # [-0.5,+0.5]\n",
    "        # -------------- softmax ---------------------------\n",
    "        #print(w.shape)\n",
    "        w = w.view(w.shape[0],w.shape[1],w.shape[2],1,1)\n",
    "        #print(w.shape)\n",
    "        \n",
    "        # ------------------------- fusion --------------------------\n",
    "        out=out.view(out.shape[0],1,out.shape[1],out.shape[2],out.shape[3])\n",
    "        #print(\"x size:\",out.shape)\n",
    "        \n",
    "        out=out*w\n",
    "        #print(\"after fusion x size:\",out.shape)\n",
    "        out=out.sum(dim=2)\n",
    "        \n",
    "        out = F.relu(self.bn2(out))\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    # (128,2) means conv planes=128, conv stride=2, by default conv stride=1\n",
    "    cfg = [64, (128,2), 128, (256,2), 256, (512,2), 512, 512, 512, 512, 512, (1024,2), 1024]\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layers = self._make_layers(in_planes=32) # 自动化构建层\n",
    "        self.linear = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        layers = []\n",
    "        for x in self.cfg:\n",
    "            out_planes = x if isinstance(x, int) else x[0]\n",
    "            stride = 1 if isinstance(x, int) else x[1]\n",
    "            layers.append(Block(in_planes, out_planes, stride))\n",
    "            in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 32  缩放5次到 1x1@1024 \n",
    "# From https://github.com/kuangliu/pytorch-cifar \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Block_Attention_HALF(nn.Module):\n",
    "    '''Depthwise conv + Pointwise conv'''\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(Block_Attention_HALF, self).__init__()\n",
    "        \n",
    "        # 分组卷积数=输入通道数\n",
    "        self.conv1 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=in_planes, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        \n",
    "        #------------------------ 一半 ------------------------------\n",
    "        self.conv2 = nn.Conv2d(in_planes, int(out_planes*0.125), kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "        #------------------------ 另一半 ----------------------------\n",
    "        self.scaleLayer= nn.Conv1d(1, 1, 1, stride=1,padding=0,groups=1,dilation=1,bias=False)\n",
    "        \n",
    "        one_conv_kernel_size = 9 # [3,7,9]\n",
    "        self.conv1D= nn.Conv1d(1, int(out_planes*0.875), one_conv_kernel_size, stride=1,padding=4,groups=1,dilation=1,bias=False) # 在__init__初始化        \n",
    "        \n",
    "        #------------------------------------------------------------\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # 【bs,c_in,h,w】\n",
    "        out = F.relu6(self.bn1(self.conv1(x)))\n",
    "        # 【bs,c_in,h,w】,if stride==1,else 【bs,c_in,h/2,w/2】\n",
    "        \n",
    "        # -------------------------- Attention -----------------------\n",
    "        w = F.avg_pool2d(out,out.shape[-1])  #最好在初始化层定义好\n",
    "        # 【bs,c_in,1,1】\n",
    "        \n",
    "        \n",
    "        in_channel=w.shape[1]\n",
    "        #w = w.view(w.shape[0],1,w.shape[1])\n",
    "        # [bs,1,in_Channel]\n",
    "\n",
    "        \n",
    "        #---------------------------- 种子向量策略 -----------------------\n",
    "        # 随机产生一个标量值\n",
    "        a=torch.randn(1)*0.1\n",
    "        print_prob=0.38  # 控制显示tensor信息的概率\n",
    "        \n",
    "        # 策略1: 最简单直接的策略\n",
    "        w=w[0]\n",
    "    \n",
    "    \n",
    "        # 策略2: 在小范围内随机挑选\n",
    "#         b=int(a*10)\n",
    "#         if b>0:\n",
    "#             w=w[b]\n",
    "#         else:\n",
    "#             w=w[0]\n",
    "        \n",
    "    \n",
    "        # 策略3：减去均值\n",
    "        #w=w[0]-torch.mean(w[0])\n",
    "        \n",
    "        \n",
    "        # 策略4: 做标准化或者softmax归一化\n",
    "        #\n",
    "        \n",
    "        # 策略5:对这批数据取平均 且保留第0维\n",
    "        #w= w.mean(dim=0,keepdim=True)\n",
    "        \n",
    "        \n",
    "        # 策略6：随机产生w值\n",
    "        #w=torch.randn(w[0].shape).cuda()*1\n",
    "        \n",
    "        \n",
    "        # 策略7: 使用固定种子向量\n",
    "        #\n",
    "        \n",
    "        if a>print_prob:\n",
    "            print(\"---\"*10)\n",
    "            print(\"before autoscale:\",w.shape)\n",
    "            print(w[0:10])\n",
    "            \n",
    "        \n",
    "        w=w.view(1,1,in_channel) # 改变格式\n",
    "        \n",
    "        w=self.scaleLayer(w)  #自动缩放层 可以激活或者不激活 甚至采用多级缩放\n",
    "        \n",
    "        if a>print_prob:\n",
    "            print(\"autoScale weight:\",self.scaleLayer.weight)\n",
    "            print(\"autoScale bias:\",self.scaleLayer.bias)\n",
    "            \n",
    "            print(\"after autoscale w[0]:\",w.shape)\n",
    "            print(w[0:10])\n",
    "            print(\"---\"*10)\n",
    "        \n",
    "        \n",
    "        # [bs=1,1,in_Channel]\n",
    "        # one_conv_filter = nn.Conv1d(1, out_channel, one_conv_kernel_size, stride=1,padding=1,groups=1,dilation=1) # 在__init__初始化\n",
    "        # [bs=1,out_channel,in_Channel]\n",
    "        if a>print_prob:\n",
    "            print(\"===\"*10)\n",
    "            print(\"conv1D weight[0]:\",self.conv1D.weight[0])\n",
    "            print(\"conv1D bias[0]:\",self.conv1D.bias)\n",
    "        \n",
    "        w = self.conv1D(w)\n",
    "        # [bs=1,out_channel,in_Channel]\n",
    "        \n",
    "        if a>print_prob:\n",
    "            print(\"after conv1D w[0]:\",w.shape)\n",
    "            print(w[0][0:15])\n",
    "            print(\"===\"*10)\n",
    "        \n",
    "        #--------------------通过非线性激活函数-----------------\n",
    "        w = 0.1*F.tanh(w) # [-0.5,+0.5]\n",
    "        #w=F.softmax(w,dim=2)\n",
    "        \n",
    "        if a>print_prob:\n",
    "            print(w.shape)\n",
    "            print(w[0][0:20])\n",
    "            \n",
    "        # [bs=1,out_channel,in_Channel]\n",
    "        w=w.view(w.shape[1],w.shape[2],1,1)\n",
    "        # [out_channel,in_Channel,1,1]\n",
    "        \n",
    "        # -------------- softmax ---------------------------\n",
    "        #print(w.shape)\n",
    "        \n",
    "        # ------------------------- fusion --------------------------\n",
    "       \n",
    "        # conv 1x1\n",
    "        out_1=self.conv2(out)\n",
    "        out_2=F.conv2d(out,w,bias=None,stride=1,groups=1,dilation=1)\n",
    "        out=torch.cat([out_1,out_2],1)\n",
    "        \n",
    "        # ----------------------- 试一试不要用relu -------------------------------\n",
    "        out = F.relu6(self.bn2(out))\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    '''Depthwise conv + Pointwise conv'''\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        \n",
    "        # 分组卷积数=输入通道数\n",
    "        self.conv1 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=in_planes, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        return out\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    # (128,2) means conv planes=128, conv stride=2, by default conv stride=1\n",
    "    #cfg = [64, (128,2), 128, (256,2), 256, (512,2), 512, 512, 512, 512, 512, (1024,2), 1024]\n",
    "    \n",
    "    #cfg = [64, (128,2), 128, (256,2), 256, (512,2), 512, 512, 512, 512, 512, (1024,2), [1024,1]]\n",
    "    cfg = [64, (128,2), 128, 256, 256, (512,2), 512, [512,1], [512,1],[512,1], [512,1], [1024,1], [1024,1]]\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layers = self._make_layers(in_planes=32) # 自动化构建层\n",
    "        self.linear = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        layers = []\n",
    "        for x in self.cfg:\n",
    "            if isinstance(x, int):\n",
    "                out_planes = x\n",
    "                stride = 1 \n",
    "                layers.append(Block(in_planes, out_planes, stride))\n",
    "            elif isinstance(x, tuple):\n",
    "                out_planes = x[0]\n",
    "                stride = x[1]\n",
    "                layers.append(Block(in_planes, out_planes, stride))\n",
    "            # AC层通过list存放设置参数\n",
    "            elif isinstance(x, list):\n",
    "                out_planes= x[0]\n",
    "                stride = x[1] if len(x)==2 else 1\n",
    "                layers.append(Block_Attention_HALF(in_planes, out_planes, stride))   \n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            in_planes = out_planes\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From https://github.com/Z0m6ie/CIFAR-10_PyTorch\n",
    "#model = mobilenet(num_classes=10, large_img=False)\n",
    "\n",
    "# From https://github.com/kuangliu/pytorch-cifar \n",
    "if torch.cuda.is_available():\n",
    "    model=MobileNet(10).cuda()\n",
    "else:\n",
    "    model=MobileNet(10)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "#scheduler = StepLR(optimizer, step_size=70, gamma=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150,200,230,250], gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement validation\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    #writer = SummaryWriter()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        correct = 0\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        accuracy = 100. * (correct.cpu().numpy()/ len(output))\n",
    "        optimizer.step()\n",
    "        if batch_idx % 5*show_step == 0:\n",
    "#             if batch_idx % 2*show_step == 0:\n",
    "#                 print(model.layers[1].conv1D.weight.shape)\n",
    "#                 print(model.layers[1].conv1D.weight[0:2][0:2])\n",
    "            \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accuracy: {:.2f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(), accuracy))\n",
    "#             f1=open(\"Cifar10_INFO.txt\",\"a+\")\n",
    "#             f1.write(\"\\n\"+'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accuracy: {:.2f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), loss.item(), accuracy))\n",
    "#             f1.close()\n",
    "            \n",
    "            #writer.add_scalar('Loss/Loss', loss.item(), epoch)\n",
    "            #writer.add_scalar('Accuracy/Accuracy', accuracy, epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(epoch):\n",
    "    model.eval()\n",
    "    #writer = SummaryWriter()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in valid_loader:\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        valid_loss += F.cross_entropy(output, target, size_average=False).item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "    valid_loss /= len(valid_idx)\n",
    "    accuracy = 100. * correct.cpu().numpy() / len(valid_idx)\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        valid_loss, correct, len(valid_idx),\n",
    "        100. * correct / len(valid_idx)))\n",
    "    \n",
    "#     f1=open(\"Cifar10_INFO.txt\",\"a+\")\n",
    "#     f1.write('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "#         valid_loss, correct, len(valid_idx),\n",
    "#         100. * correct / len(valid_idx)))\n",
    "#     f1.close()\n",
    "    #writer.add_scalar('Loss/Validation_Loss', valid_loss, epoch)\n",
    "    #writer.add_scalar('Accuracy/Validation_Accuracy', accuracy, epoch)\n",
    "    return valid_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fix best model\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target, size_average=False).item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct.cpu().numpy() / len(test_loader.dataset)))\n",
    "    \n",
    "#     f1=open(\"Cifar10_INFO.txt\",\"a+\")\n",
    "#     f1.write('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "#         test_loss, correct, len(test_loader.dataset),\n",
    "#         100. * correct.cpu().numpy() / len(test_loader.dataset)))\n",
    "#     f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_best(loss, accuracy, best_loss, best_acc):\n",
    "    if best_loss == None:\n",
    "        best_loss = loss\n",
    "        best_acc = accuracy\n",
    "        file = 'saved_models/best_save_model.p'\n",
    "        torch.save(model.state_dict(), file)\n",
    "        \n",
    "    elif loss < best_loss and accuracy > best_acc:\n",
    "        best_loss = loss\n",
    "        best_acc = accuracy\n",
    "        file = 'saved_models/best_save_model.p'\n",
    "        torch.save(model.state_dict(), file)\n",
    "    return best_loss, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 2.336344, Accuracy: 8.98\n",
      "Train Epoch: 0 [2560/50000 (6%)]\tLoss: 2.376990, Accuracy: 10.55\n",
      "Train Epoch: 0 [5120/50000 (11%)]\tLoss: 2.319052, Accuracy: 14.65\n",
      "Train Epoch: 0 [7680/50000 (17%)]\tLoss: 2.350706, Accuracy: 10.55\n",
      "Train Epoch: 0 [10240/50000 (23%)]\tLoss: 2.360566, Accuracy: 10.35\n",
      "Train Epoch: 0 [12800/50000 (28%)]\tLoss: 2.316635, Accuracy: 10.74\n",
      "Train Epoch: 0 [15360/50000 (34%)]\tLoss: 2.235941, Accuracy: 14.45\n",
      "Train Epoch: 0 [17920/50000 (40%)]\tLoss: 2.179312, Accuracy: 18.55\n",
      "Train Epoch: 0 [20480/50000 (45%)]\tLoss: 2.301983, Accuracy: 14.65\n",
      "Train Epoch: 0 [23040/50000 (51%)]\tLoss: 2.202751, Accuracy: 14.65\n",
      "Train Epoch: 0 [25600/50000 (57%)]\tLoss: 2.071144, Accuracy: 19.14\n",
      "Train Epoch: 0 [28160/50000 (62%)]\tLoss: 2.379745, Accuracy: 11.33\n",
      "Train Epoch: 0 [30720/50000 (68%)]\tLoss: 2.077622, Accuracy: 18.36\n",
      "Train Epoch: 0 [33280/50000 (74%)]\tLoss: 2.047662, Accuracy: 20.12\n",
      "Train Epoch: 0 [35840/50000 (80%)]\tLoss: 2.011800, Accuracy: 24.22\n",
      "Train Epoch: 0 [38400/50000 (85%)]\tLoss: 2.006403, Accuracy: 24.41\n",
      "Train Epoch: 0 [40960/50000 (91%)]\tLoss: 1.994746, Accuracy: 22.46\n",
      "------------------------------\n",
      "before autoscale: torch.Size([1024, 1, 1])\n",
      "tensor([[[ 0.0047]],\n",
      "\n",
      "        [[ 0.0332]],\n",
      "\n",
      "        [[ 0.4424]],\n",
      "\n",
      "        [[ 0.0605]],\n",
      "\n",
      "        [[ 0.5440]],\n",
      "\n",
      "        [[ 0.0482]],\n",
      "\n",
      "        [[ 0.0007]],\n",
      "\n",
      "        [[ 0.0945]],\n",
      "\n",
      "        [[ 0.0539]],\n",
      "\n",
      "        [[ 0.0581]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[ 0.5175]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 1024])\n",
      "tensor([[[ 0.0024,  0.0172,  0.2290,  ...,  0.0136,  0.0005,  0.0195]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor([[ 0.0127, -0.0774,  0.1260, -0.1559, -0.0904, -0.1089, -0.2222,\n",
      "          0.2228,  0.1858]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 896, 1024])\n",
      "tensor([[ 0.0063,  0.0335, -0.0834,  ...,  0.0073, -0.0304,  0.0036],\n",
      "        [ 0.0499, -0.0152,  0.0178,  ..., -0.0096,  0.0305, -0.0601],\n",
      "        [-0.0013,  0.0088, -0.0400,  ..., -0.1459,  0.0156,  0.0079],\n",
      "        ...,\n",
      "        [ 0.0333, -0.0088, -0.0598,  ...,  0.1051,  0.2848,  0.1459],\n",
      "        [ 0.0741,  0.0639, -0.0214,  ...,  0.0900,  0.2590,  0.1307],\n",
      "        [-0.0816, -0.0285, -0.0743,  ...,  0.1004, -0.0775, -0.1291]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 896, 1024])\n",
      "tensor([[ 6.3222e-04,  3.3529e-03, -8.3213e-03,  ...,  7.3494e-04,\n",
      "         -3.0361e-03,  3.6382e-04],\n",
      "        [ 4.9872e-03, -1.5207e-03,  1.7779e-03,  ..., -9.5950e-04,\n",
      "          3.0523e-03, -6.0025e-03],\n",
      "        [-1.3029e-04,  8.7680e-04, -4.0012e-03,  ..., -1.4491e-02,\n",
      "          1.5637e-03,  7.8787e-04],\n",
      "        ...,\n",
      "        [ 2.4798e-03,  3.5139e-03,  3.2819e-03,  ..., -2.3331e-02,\n",
      "         -2.4110e-02, -1.0235e-02],\n",
      "        [-7.3921e-03,  6.3632e-04, -7.0863e-04,  ...,  3.7224e-03,\n",
      "         -6.9271e-03, -9.9798e-03],\n",
      "        [-1.5403e-03,  1.1052e-02, -7.7143e-03,  ..., -3.3420e-03,\n",
      "         -8.7159e-03, -7.0991e-03]], device='cuda:0')\n",
      "Train Epoch: 0 [43520/50000 (97%)]\tLoss: 1.907468, Accuracy: 24.80\n",
      "\n",
      "Validation set: Average loss: 3.1434, Accuracy: 692/5000 (13.00%)\n",
      "\n",
      "the time of this epoch:[35.969911098480225 s]\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 1.894563, Accuracy: 25.78\n",
      "Train Epoch: 1 [2560/50000 (6%)]\tLoss: 1.865774, Accuracy: 25.59\n",
      "Train Epoch: 1 [5120/50000 (11%)]\tLoss: 1.894018, Accuracy: 23.63\n",
      "Train Epoch: 1 [7680/50000 (17%)]\tLoss: 1.888678, Accuracy: 24.80\n",
      "Train Epoch: 1 [10240/50000 (23%)]\tLoss: 1.902079, Accuracy: 26.95\n",
      "Train Epoch: 1 [12800/50000 (28%)]\tLoss: 1.838552, Accuracy: 30.08\n",
      "Train Epoch: 1 [15360/50000 (34%)]\tLoss: 1.792894, Accuracy: 31.64\n",
      "Train Epoch: 1 [17920/50000 (40%)]\tLoss: 1.815708, Accuracy: 28.32\n",
      "Train Epoch: 1 [20480/50000 (45%)]\tLoss: 1.823207, Accuracy: 26.17\n",
      "Train Epoch: 1 [23040/50000 (51%)]\tLoss: 1.826809, Accuracy: 25.98\n",
      "Train Epoch: 1 [25600/50000 (57%)]\tLoss: 1.717941, Accuracy: 31.45\n",
      "Train Epoch: 1 [28160/50000 (62%)]\tLoss: 1.722958, Accuracy: 30.08\n",
      "Train Epoch: 1 [30720/50000 (68%)]\tLoss: 1.872928, Accuracy: 27.34\n",
      "Train Epoch: 1 [33280/50000 (74%)]\tLoss: 1.761870, Accuracy: 30.08\n",
      "Train Epoch: 1 [35840/50000 (80%)]\tLoss: 1.723474, Accuracy: 31.45\n",
      "Train Epoch: 1 [38400/50000 (85%)]\tLoss: 1.705302, Accuracy: 35.35\n",
      "Train Epoch: 1 [40960/50000 (91%)]\tLoss: 1.795320, Accuracy: 31.45\n",
      "Train Epoch: 1 [43520/50000 (97%)]\tLoss: 1.775766, Accuracy: 33.01\n",
      "\n",
      "Validation set: Average loss: 6.0214, Accuracy: 630/5000 (12.00%)\n",
      "\n",
      "the time of this epoch:[36.01089382171631 s]\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.714607, Accuracy: 31.05\n",
      "Train Epoch: 2 [2560/50000 (6%)]\tLoss: 1.730575, Accuracy: 29.88\n",
      "Train Epoch: 2 [5120/50000 (11%)]\tLoss: 1.659417, Accuracy: 33.79\n",
      "Train Epoch: 2 [7680/50000 (17%)]\tLoss: 1.727102, Accuracy: 38.09\n",
      "Train Epoch: 2 [10240/50000 (23%)]\tLoss: 1.690311, Accuracy: 32.42\n",
      "Train Epoch: 2 [12800/50000 (28%)]\tLoss: 1.744818, Accuracy: 33.20\n",
      "Train Epoch: 2 [15360/50000 (34%)]\tLoss: 1.720765, Accuracy: 33.01\n",
      "Train Epoch: 2 [17920/50000 (40%)]\tLoss: 1.652923, Accuracy: 34.96\n",
      "Train Epoch: 2 [20480/50000 (45%)]\tLoss: 1.660897, Accuracy: 38.09\n",
      "Train Epoch: 2 [23040/50000 (51%)]\tLoss: 1.705413, Accuracy: 34.77\n",
      "Train Epoch: 2 [25600/50000 (57%)]\tLoss: 1.603867, Accuracy: 39.26\n",
      "Train Epoch: 2 [28160/50000 (62%)]\tLoss: 1.679187, Accuracy: 31.84\n",
      "Train Epoch: 2 [30720/50000 (68%)]\tLoss: 1.647164, Accuracy: 34.96\n",
      "Train Epoch: 2 [33280/50000 (74%)]\tLoss: 1.540511, Accuracy: 38.87\n",
      "Train Epoch: 2 [35840/50000 (80%)]\tLoss: 1.499881, Accuracy: 42.77\n",
      "Train Epoch: 2 [38400/50000 (85%)]\tLoss: 1.649921, Accuracy: 36.13\n",
      "Train Epoch: 2 [40960/50000 (91%)]\tLoss: 1.573862, Accuracy: 38.87\n",
      "Train Epoch: 2 [43520/50000 (97%)]\tLoss: 1.534265, Accuracy: 42.77\n",
      "\n",
      "Validation set: Average loss: 4.2083, Accuracy: 815/5000 (16.00%)\n",
      "\n",
      "the time of this epoch:[36.08232402801514 s]\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.433187, Accuracy: 42.58\n",
      "Train Epoch: 3 [2560/50000 (6%)]\tLoss: 1.577062, Accuracy: 43.36\n",
      "Train Epoch: 3 [5120/50000 (11%)]\tLoss: 1.508832, Accuracy: 41.60\n",
      "Train Epoch: 3 [7680/50000 (17%)]\tLoss: 1.460748, Accuracy: 43.16\n",
      "Train Epoch: 3 [10240/50000 (23%)]\tLoss: 1.615993, Accuracy: 42.77\n",
      "Train Epoch: 3 [12800/50000 (28%)]\tLoss: 1.430413, Accuracy: 45.31\n",
      "Train Epoch: 3 [15360/50000 (34%)]\tLoss: 1.453101, Accuracy: 44.73\n",
      "Train Epoch: 3 [17920/50000 (40%)]\tLoss: 1.403648, Accuracy: 48.24\n",
      "Train Epoch: 3 [20480/50000 (45%)]\tLoss: 1.397435, Accuracy: 45.70\n",
      "Train Epoch: 3 [23040/50000 (51%)]\tLoss: 1.459432, Accuracy: 43.36\n",
      "Train Epoch: 3 [25600/50000 (57%)]\tLoss: 1.345951, Accuracy: 51.56\n",
      "Train Epoch: 3 [28160/50000 (62%)]\tLoss: 1.441650, Accuracy: 44.34\n",
      "Train Epoch: 3 [30720/50000 (68%)]\tLoss: 1.399909, Accuracy: 48.83\n",
      "Train Epoch: 3 [33280/50000 (74%)]\tLoss: 1.431791, Accuracy: 45.12\n",
      "Train Epoch: 3 [35840/50000 (80%)]\tLoss: 1.408785, Accuracy: 48.24\n",
      "Train Epoch: 3 [38400/50000 (85%)]\tLoss: 1.413707, Accuracy: 52.15\n",
      "Train Epoch: 3 [40960/50000 (91%)]\tLoss: 1.418181, Accuracy: 47.85\n",
      "Train Epoch: 3 [43520/50000 (97%)]\tLoss: 1.347422, Accuracy: 52.15\n",
      "\n",
      "Validation set: Average loss: 4.0480, Accuracy: 918/5000 (18.00%)\n",
      "\n",
      "the time of this epoch:[36.118653297424316 s]\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.229206, Accuracy: 54.88\n",
      "Train Epoch: 4 [2560/50000 (6%)]\tLoss: 1.355597, Accuracy: 49.02\n",
      "Train Epoch: 4 [5120/50000 (11%)]\tLoss: 1.294270, Accuracy: 53.91\n",
      "Train Epoch: 4 [7680/50000 (17%)]\tLoss: 1.315720, Accuracy: 50.78\n",
      "Train Epoch: 4 [10240/50000 (23%)]\tLoss: 1.259027, Accuracy: 55.86\n",
      "Train Epoch: 4 [12800/50000 (28%)]\tLoss: 1.307165, Accuracy: 53.12\n",
      "Train Epoch: 4 [15360/50000 (34%)]\tLoss: 1.344758, Accuracy: 51.76\n",
      "Train Epoch: 4 [17920/50000 (40%)]\tLoss: 1.213431, Accuracy: 56.05\n",
      "Train Epoch: 4 [20480/50000 (45%)]\tLoss: 1.279434, Accuracy: 53.12\n",
      "Train Epoch: 4 [23040/50000 (51%)]\tLoss: 1.210208, Accuracy: 54.88\n",
      "Train Epoch: 4 [25600/50000 (57%)]\tLoss: 1.235122, Accuracy: 55.47\n",
      "Train Epoch: 4 [28160/50000 (62%)]\tLoss: 1.139084, Accuracy: 57.81\n",
      "Train Epoch: 4 [30720/50000 (68%)]\tLoss: 1.152023, Accuracy: 60.35\n",
      "Train Epoch: 4 [33280/50000 (74%)]\tLoss: 1.194037, Accuracy: 54.69\n",
      "Train Epoch: 4 [35840/50000 (80%)]\tLoss: 1.199572, Accuracy: 55.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [38400/50000 (85%)]\tLoss: 1.237639, Accuracy: 58.20\n",
      "Train Epoch: 4 [40960/50000 (91%)]\tLoss: 1.247834, Accuracy: 56.45\n",
      "Train Epoch: 4 [43520/50000 (97%)]\tLoss: 1.152496, Accuracy: 57.23\n",
      "\n",
      "Validation set: Average loss: 3.9470, Accuracy: 978/5000 (19.00%)\n",
      "\n",
      "the time of this epoch:[37.43326783180237 s]\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.138427, Accuracy: 59.57\n",
      "Train Epoch: 5 [2560/50000 (6%)]\tLoss: 1.098218, Accuracy: 59.77\n",
      "Train Epoch: 5 [5120/50000 (11%)]\tLoss: 1.125679, Accuracy: 59.38\n",
      "Train Epoch: 5 [7680/50000 (17%)]\tLoss: 1.112314, Accuracy: 60.74\n",
      "Train Epoch: 5 [10240/50000 (23%)]\tLoss: 1.134493, Accuracy: 59.57\n",
      "Train Epoch: 5 [12800/50000 (28%)]\tLoss: 1.157100, Accuracy: 58.98\n",
      "Train Epoch: 5 [15360/50000 (34%)]\tLoss: 1.164323, Accuracy: 58.20\n",
      "Train Epoch: 5 [17920/50000 (40%)]\tLoss: 1.110806, Accuracy: 61.91\n",
      "Train Epoch: 5 [20480/50000 (45%)]\tLoss: 1.088003, Accuracy: 62.50\n",
      "Train Epoch: 5 [23040/50000 (51%)]\tLoss: 1.115650, Accuracy: 61.33\n",
      "Train Epoch: 5 [25600/50000 (57%)]\tLoss: 0.973989, Accuracy: 65.04\n",
      "Train Epoch: 5 [28160/50000 (62%)]\tLoss: 1.939761, Accuracy: 32.62\n",
      "Train Epoch: 5 [30720/50000 (68%)]\tLoss: 1.101563, Accuracy: 62.70\n",
      "Train Epoch: 5 [33280/50000 (74%)]\tLoss: 1.086612, Accuracy: 62.70\n",
      "Train Epoch: 5 [35840/50000 (80%)]\tLoss: 1.003680, Accuracy: 63.48\n",
      "Train Epoch: 5 [38400/50000 (85%)]\tLoss: 1.101776, Accuracy: 62.30\n",
      "Train Epoch: 5 [40960/50000 (91%)]\tLoss: 1.052925, Accuracy: 63.09\n",
      "Train Epoch: 5 [43520/50000 (97%)]\tLoss: 1.157058, Accuracy: 58.98\n",
      "\n",
      "Validation set: Average loss: 3.6578, Accuracy: 1269/5000 (25.00%)\n",
      "\n",
      "the time of this epoch:[36.38123679161072 s]\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.020036, Accuracy: 63.28\n",
      "Train Epoch: 6 [2560/50000 (6%)]\tLoss: 0.964024, Accuracy: 66.21\n",
      "Train Epoch: 6 [5120/50000 (11%)]\tLoss: 0.979472, Accuracy: 63.87\n",
      "Train Epoch: 6 [7680/50000 (17%)]\tLoss: 0.937270, Accuracy: 66.60\n",
      "Train Epoch: 6 [10240/50000 (23%)]\tLoss: 1.067423, Accuracy: 64.26\n",
      "Train Epoch: 6 [12800/50000 (28%)]\tLoss: 1.005030, Accuracy: 65.62\n",
      "Train Epoch: 6 [15360/50000 (34%)]\tLoss: 0.960327, Accuracy: 65.04\n",
      "Train Epoch: 6 [17920/50000 (40%)]\tLoss: 1.071222, Accuracy: 60.35\n",
      "Train Epoch: 6 [20480/50000 (45%)]\tLoss: 0.994129, Accuracy: 64.26\n",
      "Train Epoch: 6 [23040/50000 (51%)]\tLoss: 1.108368, Accuracy: 63.67\n",
      "Train Epoch: 6 [25600/50000 (57%)]\tLoss: 0.994946, Accuracy: 64.45\n",
      "Train Epoch: 6 [28160/50000 (62%)]\tLoss: 1.051082, Accuracy: 64.45\n",
      "Train Epoch: 6 [30720/50000 (68%)]\tLoss: 1.018074, Accuracy: 66.21\n",
      "Train Epoch: 6 [33280/50000 (74%)]\tLoss: 0.959566, Accuracy: 66.41\n",
      "Train Epoch: 6 [35840/50000 (80%)]\tLoss: 0.974773, Accuracy: 63.87\n",
      "Train Epoch: 6 [38400/50000 (85%)]\tLoss: 0.878702, Accuracy: 68.55\n",
      "Train Epoch: 6 [40960/50000 (91%)]\tLoss: 0.893056, Accuracy: 66.80\n",
      "Train Epoch: 6 [43520/50000 (97%)]\tLoss: 0.927684, Accuracy: 68.55\n",
      "\n",
      "Validation set: Average loss: 2.9656, Accuracy: 1599/5000 (31.00%)\n",
      "\n",
      "the time of this epoch:[35.680564641952515 s]\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.909596, Accuracy: 64.65\n",
      "Train Epoch: 7 [2560/50000 (6%)]\tLoss: 0.840325, Accuracy: 70.90\n",
      "Train Epoch: 7 [5120/50000 (11%)]\tLoss: 0.929260, Accuracy: 66.99\n",
      "Train Epoch: 7 [7680/50000 (17%)]\tLoss: 0.919019, Accuracy: 71.88\n",
      "Train Epoch: 7 [10240/50000 (23%)]\tLoss: 0.863270, Accuracy: 69.34\n",
      "Train Epoch: 7 [12800/50000 (28%)]\tLoss: 0.891175, Accuracy: 67.19\n",
      "Train Epoch: 7 [15360/50000 (34%)]\tLoss: 0.874287, Accuracy: 68.16\n",
      "Train Epoch: 7 [17920/50000 (40%)]\tLoss: 0.947649, Accuracy: 64.65\n",
      "Train Epoch: 7 [20480/50000 (45%)]\tLoss: 0.866524, Accuracy: 71.09\n",
      "Train Epoch: 7 [23040/50000 (51%)]\tLoss: 0.940871, Accuracy: 66.02\n",
      "Train Epoch: 7 [25600/50000 (57%)]\tLoss: 0.840993, Accuracy: 70.12\n",
      "Train Epoch: 7 [28160/50000 (62%)]\tLoss: 0.902377, Accuracy: 69.34\n",
      "Train Epoch: 7 [30720/50000 (68%)]\tLoss: 0.914790, Accuracy: 65.82\n",
      "Train Epoch: 7 [33280/50000 (74%)]\tLoss: 0.965170, Accuracy: 66.60\n",
      "Train Epoch: 7 [35840/50000 (80%)]\tLoss: 0.925872, Accuracy: 69.14\n",
      "Train Epoch: 7 [38400/50000 (85%)]\tLoss: 0.818481, Accuracy: 71.29\n",
      "Train Epoch: 7 [40960/50000 (91%)]\tLoss: 0.864420, Accuracy: 68.75\n",
      "Train Epoch: 7 [43520/50000 (97%)]\tLoss: 0.937748, Accuracy: 66.99\n",
      "\n",
      "Validation set: Average loss: 3.3387, Accuracy: 1739/5000 (34.00%)\n",
      "\n",
      "the time of this epoch:[35.822662115097046 s]\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.900078, Accuracy: 66.80\n",
      "Train Epoch: 8 [2560/50000 (6%)]\tLoss: 0.945762, Accuracy: 66.99\n",
      "Train Epoch: 8 [5120/50000 (11%)]\tLoss: 0.821296, Accuracy: 71.48\n",
      "Train Epoch: 8 [7680/50000 (17%)]\tLoss: 0.762055, Accuracy: 73.05\n",
      "Train Epoch: 8 [10240/50000 (23%)]\tLoss: 0.873921, Accuracy: 70.51\n",
      "Train Epoch: 8 [12800/50000 (28%)]\tLoss: 0.823446, Accuracy: 73.24\n",
      "Train Epoch: 8 [15360/50000 (34%)]\tLoss: 0.812970, Accuracy: 70.90\n",
      "Train Epoch: 8 [17920/50000 (40%)]\tLoss: 0.819180, Accuracy: 71.29\n",
      "Train Epoch: 8 [20480/50000 (45%)]\tLoss: 0.809010, Accuracy: 72.66\n",
      "Train Epoch: 8 [23040/50000 (51%)]\tLoss: 0.829047, Accuracy: 70.31\n",
      "Train Epoch: 8 [25600/50000 (57%)]\tLoss: 0.879185, Accuracy: 68.16\n",
      "Train Epoch: 8 [28160/50000 (62%)]\tLoss: 0.827365, Accuracy: 72.07\n",
      "Train Epoch: 8 [30720/50000 (68%)]\tLoss: 0.746150, Accuracy: 73.83\n",
      "Train Epoch: 8 [33280/50000 (74%)]\tLoss: 0.802674, Accuracy: 72.66\n",
      "Train Epoch: 8 [35840/50000 (80%)]\tLoss: 0.832602, Accuracy: 69.73\n",
      "Train Epoch: 8 [38400/50000 (85%)]\tLoss: 0.805107, Accuracy: 70.31\n",
      "Train Epoch: 8 [40960/50000 (91%)]\tLoss: 0.805620, Accuracy: 73.63\n",
      "Train Epoch: 8 [43520/50000 (97%)]\tLoss: 0.786616, Accuracy: 72.85\n",
      "\n",
      "Validation set: Average loss: 2.6848, Accuracy: 1297/5000 (25.00%)\n",
      "\n",
      "the time of this epoch:[37.07985186576843 s]\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.737000, Accuracy: 74.61\n",
      "Train Epoch: 9 [2560/50000 (6%)]\tLoss: 0.829060, Accuracy: 70.31\n",
      "Train Epoch: 9 [5120/50000 (11%)]\tLoss: 0.707564, Accuracy: 75.00\n",
      "Train Epoch: 9 [7680/50000 (17%)]\tLoss: 0.754825, Accuracy: 74.41\n",
      "Train Epoch: 9 [10240/50000 (23%)]\tLoss: 0.707878, Accuracy: 74.41\n",
      "Train Epoch: 9 [12800/50000 (28%)]\tLoss: 0.692068, Accuracy: 74.41\n",
      "Train Epoch: 9 [15360/50000 (34%)]\tLoss: 0.826564, Accuracy: 72.66\n",
      "Train Epoch: 9 [17920/50000 (40%)]\tLoss: 0.743970, Accuracy: 75.98\n",
      "Train Epoch: 9 [20480/50000 (45%)]\tLoss: 0.796091, Accuracy: 74.61\n",
      "Train Epoch: 9 [23040/50000 (51%)]\tLoss: 0.824996, Accuracy: 70.51\n",
      "Train Epoch: 9 [25600/50000 (57%)]\tLoss: 0.819067, Accuracy: 71.48\n",
      "Train Epoch: 9 [28160/50000 (62%)]\tLoss: 0.705806, Accuracy: 73.44\n",
      "Train Epoch: 9 [30720/50000 (68%)]\tLoss: 0.812282, Accuracy: 71.09\n",
      "Train Epoch: 9 [33280/50000 (74%)]\tLoss: 0.708772, Accuracy: 74.80\n",
      "Train Epoch: 9 [35840/50000 (80%)]\tLoss: 0.695935, Accuracy: 74.80\n",
      "Train Epoch: 9 [38400/50000 (85%)]\tLoss: 0.739942, Accuracy: 71.29\n",
      "Train Epoch: 9 [40960/50000 (91%)]\tLoss: 0.828011, Accuracy: 71.29\n",
      "Train Epoch: 9 [43520/50000 (97%)]\tLoss: 0.820686, Accuracy: 71.88\n",
      "\n",
      "Validation set: Average loss: 3.0000, Accuracy: 1664/5000 (33.00%)\n",
      "\n",
      "the time of this epoch:[35.783409118652344 s]\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.741383, Accuracy: 74.41\n",
      "Train Epoch: 10 [2560/50000 (6%)]\tLoss: 0.762712, Accuracy: 73.83\n",
      "Train Epoch: 10 [5120/50000 (11%)]\tLoss: 0.671837, Accuracy: 78.32\n",
      "Train Epoch: 10 [7680/50000 (17%)]\tLoss: 0.728978, Accuracy: 74.80\n",
      "Train Epoch: 10 [10240/50000 (23%)]\tLoss: 0.658276, Accuracy: 75.78\n",
      "Train Epoch: 10 [12800/50000 (28%)]\tLoss: 0.697750, Accuracy: 75.20\n",
      "Train Epoch: 10 [15360/50000 (34%)]\tLoss: 0.637958, Accuracy: 77.54\n",
      "Train Epoch: 10 [17920/50000 (40%)]\tLoss: 0.658241, Accuracy: 76.95\n",
      "Train Epoch: 10 [20480/50000 (45%)]\tLoss: 0.696296, Accuracy: 77.15\n",
      "Train Epoch: 10 [23040/50000 (51%)]\tLoss: 0.693997, Accuracy: 75.98\n",
      "Train Epoch: 10 [25600/50000 (57%)]\tLoss: 0.665832, Accuracy: 76.56\n",
      "Train Epoch: 10 [28160/50000 (62%)]\tLoss: 0.773573, Accuracy: 75.78\n",
      "Train Epoch: 10 [30720/50000 (68%)]\tLoss: 0.681471, Accuracy: 76.37\n",
      "Train Epoch: 10 [33280/50000 (74%)]\tLoss: 0.700110, Accuracy: 75.59\n",
      "Train Epoch: 10 [35840/50000 (80%)]\tLoss: 0.664181, Accuracy: 76.37\n",
      "Train Epoch: 10 [38400/50000 (85%)]\tLoss: 0.617092, Accuracy: 78.52\n",
      "Train Epoch: 10 [40960/50000 (91%)]\tLoss: 0.661866, Accuracy: 75.98\n",
      "Train Epoch: 10 [43520/50000 (97%)]\tLoss: 0.696016, Accuracy: 77.15\n",
      "\n",
      "Validation set: Average loss: 4.1977, Accuracy: 1798/5000 (35.00%)\n",
      "\n",
      "the time of this epoch:[35.70158386230469 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 4.6254, Accuracy: 3420/10000 (34.20%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.652714, Accuracy: 77.34\n",
      "Train Epoch: 11 [2560/50000 (6%)]\tLoss: 0.664620, Accuracy: 79.10\n",
      "Train Epoch: 11 [5120/50000 (11%)]\tLoss: 0.684365, Accuracy: 73.05\n",
      "Train Epoch: 11 [7680/50000 (17%)]\tLoss: 0.709286, Accuracy: 73.44\n",
      "Train Epoch: 11 [10240/50000 (23%)]\tLoss: 0.695239, Accuracy: 76.17\n",
      "Train Epoch: 11 [12800/50000 (28%)]\tLoss: 0.710593, Accuracy: 75.59\n",
      "Train Epoch: 11 [15360/50000 (34%)]\tLoss: 0.660761, Accuracy: 79.10\n",
      "Train Epoch: 11 [17920/50000 (40%)]\tLoss: 0.645172, Accuracy: 77.93\n",
      "Train Epoch: 11 [20480/50000 (45%)]\tLoss: 0.732022, Accuracy: 74.41\n",
      "Train Epoch: 11 [23040/50000 (51%)]\tLoss: 0.638008, Accuracy: 76.95\n",
      "Train Epoch: 11 [25600/50000 (57%)]\tLoss: 0.712096, Accuracy: 74.22\n",
      "Train Epoch: 11 [28160/50000 (62%)]\tLoss: 0.688273, Accuracy: 74.80\n",
      "Train Epoch: 11 [30720/50000 (68%)]\tLoss: 0.629035, Accuracy: 78.52\n",
      "Train Epoch: 11 [33280/50000 (74%)]\tLoss: 0.617063, Accuracy: 80.86\n",
      "Train Epoch: 11 [35840/50000 (80%)]\tLoss: 0.625286, Accuracy: 79.49\n",
      "Train Epoch: 11 [38400/50000 (85%)]\tLoss: 0.608344, Accuracy: 77.73\n",
      "Train Epoch: 11 [40960/50000 (91%)]\tLoss: 0.614022, Accuracy: 78.32\n",
      "Train Epoch: 11 [43520/50000 (97%)]\tLoss: 0.673327, Accuracy: 76.76\n",
      "\n",
      "Validation set: Average loss: 3.1160, Accuracy: 1862/5000 (37.00%)\n",
      "\n",
      "the time of this epoch:[59.07277965545654 s]\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.562409, Accuracy: 82.23\n",
      "Train Epoch: 12 [2560/50000 (6%)]\tLoss: 0.576930, Accuracy: 79.30\n",
      "Train Epoch: 12 [5120/50000 (11%)]\tLoss: 0.585227, Accuracy: 81.25\n",
      "Train Epoch: 12 [7680/50000 (17%)]\tLoss: 0.632259, Accuracy: 77.93\n",
      "Train Epoch: 12 [10240/50000 (23%)]\tLoss: 0.599626, Accuracy: 79.10\n",
      "Train Epoch: 12 [12800/50000 (28%)]\tLoss: 0.545111, Accuracy: 81.84\n",
      "Train Epoch: 12 [15360/50000 (34%)]\tLoss: 0.588227, Accuracy: 79.49\n",
      "Train Epoch: 12 [17920/50000 (40%)]\tLoss: 0.542668, Accuracy: 79.88\n",
      "Train Epoch: 12 [20480/50000 (45%)]\tLoss: 0.644257, Accuracy: 78.71\n",
      "Train Epoch: 12 [23040/50000 (51%)]\tLoss: 0.573530, Accuracy: 78.91\n",
      "Train Epoch: 12 [25600/50000 (57%)]\tLoss: 0.569739, Accuracy: 79.88\n",
      "Train Epoch: 12 [28160/50000 (62%)]\tLoss: 0.545618, Accuracy: 81.25\n",
      "Train Epoch: 12 [30720/50000 (68%)]\tLoss: 0.668502, Accuracy: 75.98\n",
      "Train Epoch: 12 [33280/50000 (74%)]\tLoss: 0.510123, Accuracy: 82.03\n",
      "Train Epoch: 12 [35840/50000 (80%)]\tLoss: 0.541604, Accuracy: 83.01\n",
      "Train Epoch: 12 [38400/50000 (85%)]\tLoss: 0.629416, Accuracy: 78.12\n",
      "Train Epoch: 12 [40960/50000 (91%)]\tLoss: 0.588612, Accuracy: 78.71\n",
      "Train Epoch: 12 [43520/50000 (97%)]\tLoss: 0.595909, Accuracy: 78.52\n",
      "\n",
      "Validation set: Average loss: 2.7681, Accuracy: 1957/5000 (39.00%)\n",
      "\n",
      "the time of this epoch:[35.59827709197998 s]\n",
      "\n",
      "Test set: Average loss: 2.9071, Accuracy: 3959/10000 (39.59%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.543570, Accuracy: 82.23\n",
      "Train Epoch: 13 [2560/50000 (6%)]\tLoss: 0.472786, Accuracy: 83.20\n",
      "Train Epoch: 13 [5120/50000 (11%)]\tLoss: 0.563332, Accuracy: 81.05\n",
      "Train Epoch: 13 [7680/50000 (17%)]\tLoss: 0.526354, Accuracy: 81.84\n",
      "Train Epoch: 13 [10240/50000 (23%)]\tLoss: 0.651037, Accuracy: 78.32\n",
      "Train Epoch: 13 [12800/50000 (28%)]\tLoss: 0.508045, Accuracy: 83.01\n",
      "Train Epoch: 13 [15360/50000 (34%)]\tLoss: 0.534781, Accuracy: 82.03\n",
      "Train Epoch: 13 [17920/50000 (40%)]\tLoss: 0.580942, Accuracy: 78.52\n",
      "Train Epoch: 13 [20480/50000 (45%)]\tLoss: 0.484384, Accuracy: 80.86\n",
      "Train Epoch: 13 [23040/50000 (51%)]\tLoss: 0.547462, Accuracy: 81.05\n",
      "Train Epoch: 13 [25600/50000 (57%)]\tLoss: 0.540489, Accuracy: 82.23\n",
      "Train Epoch: 13 [28160/50000 (62%)]\tLoss: 0.606333, Accuracy: 79.69\n",
      "Train Epoch: 13 [30720/50000 (68%)]\tLoss: 0.651134, Accuracy: 76.17\n",
      "Train Epoch: 13 [33280/50000 (74%)]\tLoss: 0.514133, Accuracy: 83.98\n",
      "Train Epoch: 13 [35840/50000 (80%)]\tLoss: 0.561459, Accuracy: 79.88\n",
      "Train Epoch: 13 [38400/50000 (85%)]\tLoss: 0.537948, Accuracy: 82.03\n",
      "Train Epoch: 13 [40960/50000 (91%)]\tLoss: 0.529509, Accuracy: 83.79\n",
      "Train Epoch: 13 [43520/50000 (97%)]\tLoss: 0.526577, Accuracy: 80.86\n",
      "\n",
      "Validation set: Average loss: 3.0901, Accuracy: 1930/5000 (38.00%)\n",
      "\n",
      "the time of this epoch:[39.223954916000366 s]\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.533255, Accuracy: 83.20\n",
      "Train Epoch: 14 [2560/50000 (6%)]\tLoss: 0.518097, Accuracy: 83.98\n",
      "Train Epoch: 14 [5120/50000 (11%)]\tLoss: 0.538955, Accuracy: 81.64\n",
      "Train Epoch: 14 [7680/50000 (17%)]\tLoss: 0.580341, Accuracy: 80.86\n",
      "Train Epoch: 14 [10240/50000 (23%)]\tLoss: 0.552755, Accuracy: 81.64\n",
      "Train Epoch: 14 [12800/50000 (28%)]\tLoss: 0.525879, Accuracy: 82.62\n",
      "Train Epoch: 14 [15360/50000 (34%)]\tLoss: 0.578221, Accuracy: 78.52\n",
      "Train Epoch: 14 [17920/50000 (40%)]\tLoss: 0.521696, Accuracy: 81.05\n",
      "Train Epoch: 14 [20480/50000 (45%)]\tLoss: 0.538756, Accuracy: 81.45\n",
      "Train Epoch: 14 [23040/50000 (51%)]\tLoss: 0.535654, Accuracy: 80.47\n",
      "Train Epoch: 14 [25600/50000 (57%)]\tLoss: 0.520527, Accuracy: 81.84\n",
      "Train Epoch: 14 [28160/50000 (62%)]\tLoss: 0.584185, Accuracy: 79.30\n",
      "Train Epoch: 14 [30720/50000 (68%)]\tLoss: 0.561283, Accuracy: 81.25\n",
      "Train Epoch: 14 [33280/50000 (74%)]\tLoss: 0.488259, Accuracy: 83.20\n",
      "Train Epoch: 14 [35840/50000 (80%)]\tLoss: 0.541576, Accuracy: 81.84\n",
      "Train Epoch: 14 [38400/50000 (85%)]\tLoss: 0.519785, Accuracy: 82.42\n",
      "Train Epoch: 14 [40960/50000 (91%)]\tLoss: 0.511971, Accuracy: 82.81\n",
      "Train Epoch: 14 [43520/50000 (97%)]\tLoss: 0.449221, Accuracy: 84.57\n",
      "\n",
      "Validation set: Average loss: 1.7299, Accuracy: 2690/5000 (53.00%)\n",
      "\n",
      "the time of this epoch:[35.5958514213562 s]\n",
      "\n",
      "Test set: Average loss: 1.8753, Accuracy: 5187/10000 (51.87%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.421439, Accuracy: 86.52\n",
      "Train Epoch: 15 [2560/50000 (6%)]\tLoss: 0.459833, Accuracy: 84.96\n",
      "Train Epoch: 15 [5120/50000 (11%)]\tLoss: 0.482549, Accuracy: 82.81\n",
      "Train Epoch: 15 [7680/50000 (17%)]\tLoss: 0.513209, Accuracy: 84.57\n",
      "Train Epoch: 15 [10240/50000 (23%)]\tLoss: 0.499904, Accuracy: 83.01\n",
      "Train Epoch: 15 [12800/50000 (28%)]\tLoss: 0.448967, Accuracy: 86.33\n",
      "Train Epoch: 15 [15360/50000 (34%)]\tLoss: 0.565133, Accuracy: 78.52\n",
      "Train Epoch: 15 [17920/50000 (40%)]\tLoss: 0.601322, Accuracy: 80.47\n",
      "Train Epoch: 15 [20480/50000 (45%)]\tLoss: 0.513125, Accuracy: 81.84\n",
      "Train Epoch: 15 [23040/50000 (51%)]\tLoss: 0.462041, Accuracy: 86.52\n",
      "Train Epoch: 15 [25600/50000 (57%)]\tLoss: 0.447270, Accuracy: 84.18\n",
      "Train Epoch: 15 [28160/50000 (62%)]\tLoss: 0.475586, Accuracy: 83.40\n",
      "Train Epoch: 15 [30720/50000 (68%)]\tLoss: 0.497293, Accuracy: 82.42\n",
      "Train Epoch: 15 [33280/50000 (74%)]\tLoss: 0.557484, Accuracy: 79.88\n",
      "Train Epoch: 15 [35840/50000 (80%)]\tLoss: 0.482734, Accuracy: 82.42\n",
      "Train Epoch: 15 [38400/50000 (85%)]\tLoss: 0.513499, Accuracy: 83.01\n",
      "Train Epoch: 15 [40960/50000 (91%)]\tLoss: 0.554696, Accuracy: 80.47\n",
      "Train Epoch: 15 [43520/50000 (97%)]\tLoss: 0.481772, Accuracy: 83.20\n",
      "\n",
      "Validation set: Average loss: 4.7433, Accuracy: 1730/5000 (34.00%)\n",
      "\n",
      "the time of this epoch:[39.785627365112305 s]\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.448913, Accuracy: 85.35\n",
      "Train Epoch: 16 [2560/50000 (6%)]\tLoss: 0.510358, Accuracy: 84.18\n",
      "Train Epoch: 16 [5120/50000 (11%)]\tLoss: 0.366750, Accuracy: 89.06\n",
      "Train Epoch: 16 [7680/50000 (17%)]\tLoss: 0.509294, Accuracy: 84.18\n",
      "Train Epoch: 16 [10240/50000 (23%)]\tLoss: 0.522481, Accuracy: 82.03\n",
      "Train Epoch: 16 [12800/50000 (28%)]\tLoss: 0.472855, Accuracy: 83.01\n",
      "Train Epoch: 16 [15360/50000 (34%)]\tLoss: 0.488643, Accuracy: 82.03\n",
      "Train Epoch: 16 [17920/50000 (40%)]\tLoss: 0.548546, Accuracy: 82.23\n",
      "Train Epoch: 16 [20480/50000 (45%)]\tLoss: 0.511039, Accuracy: 82.81\n",
      "Train Epoch: 16 [23040/50000 (51%)]\tLoss: 0.403589, Accuracy: 87.30\n",
      "Train Epoch: 16 [25600/50000 (57%)]\tLoss: 0.484229, Accuracy: 84.96\n",
      "Train Epoch: 16 [28160/50000 (62%)]\tLoss: 0.449522, Accuracy: 85.55\n",
      "Train Epoch: 16 [30720/50000 (68%)]\tLoss: 0.419054, Accuracy: 84.77\n",
      "Train Epoch: 16 [33280/50000 (74%)]\tLoss: 0.522186, Accuracy: 83.79\n",
      "Train Epoch: 16 [35840/50000 (80%)]\tLoss: 0.467161, Accuracy: 83.59\n",
      "Train Epoch: 16 [38400/50000 (85%)]\tLoss: 0.464147, Accuracy: 84.38\n",
      "Train Epoch: 16 [40960/50000 (91%)]\tLoss: 0.543049, Accuracy: 83.01\n",
      "Train Epoch: 16 [43520/50000 (97%)]\tLoss: 0.464845, Accuracy: 82.62\n",
      "\n",
      "Validation set: Average loss: 2.4199, Accuracy: 2531/5000 (50.00%)\n",
      "\n",
      "the time of this epoch:[35.89907789230347 s]\n",
      "\n",
      "Test set: Average loss: 2.2947, Accuracy: 5141/10000 (51.41%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.429182, Accuracy: 84.77\n",
      "Train Epoch: 17 [2560/50000 (6%)]\tLoss: 0.477021, Accuracy: 83.40\n",
      "Train Epoch: 17 [5120/50000 (11%)]\tLoss: 0.439409, Accuracy: 85.16\n",
      "Train Epoch: 17 [7680/50000 (17%)]\tLoss: 0.418902, Accuracy: 85.94\n",
      "Train Epoch: 17 [10240/50000 (23%)]\tLoss: 0.418751, Accuracy: 85.35\n",
      "Train Epoch: 17 [12800/50000 (28%)]\tLoss: 0.491937, Accuracy: 82.23\n",
      "Train Epoch: 17 [15360/50000 (34%)]\tLoss: 0.527079, Accuracy: 82.62\n",
      "Train Epoch: 17 [17920/50000 (40%)]\tLoss: 0.459881, Accuracy: 84.38\n",
      "Train Epoch: 17 [20480/50000 (45%)]\tLoss: 0.424927, Accuracy: 84.57\n",
      "Train Epoch: 17 [23040/50000 (51%)]\tLoss: 0.485190, Accuracy: 82.81\n",
      "Train Epoch: 17 [25600/50000 (57%)]\tLoss: 0.430929, Accuracy: 85.94\n",
      "Train Epoch: 17 [28160/50000 (62%)]\tLoss: 0.479006, Accuracy: 84.96\n",
      "Train Epoch: 17 [30720/50000 (68%)]\tLoss: 0.387846, Accuracy: 86.33\n",
      "Train Epoch: 17 [33280/50000 (74%)]\tLoss: 0.481013, Accuracy: 83.98\n",
      "Train Epoch: 17 [35840/50000 (80%)]\tLoss: 0.442207, Accuracy: 86.33\n",
      "Train Epoch: 17 [38400/50000 (85%)]\tLoss: 0.587753, Accuracy: 80.27\n",
      "Train Epoch: 17 [40960/50000 (91%)]\tLoss: 0.433935, Accuracy: 84.96\n",
      "Train Epoch: 17 [43520/50000 (97%)]\tLoss: 0.493508, Accuracy: 83.01\n",
      "\n",
      "Validation set: Average loss: 1.8403, Accuracy: 2355/5000 (47.00%)\n",
      "\n",
      "the time of this epoch:[40.405940771102905 s]\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.391050, Accuracy: 85.94\n",
      "Train Epoch: 18 [2560/50000 (6%)]\tLoss: 0.456427, Accuracy: 85.16\n",
      "Train Epoch: 18 [5120/50000 (11%)]\tLoss: 0.399831, Accuracy: 87.11\n",
      "Train Epoch: 18 [7680/50000 (17%)]\tLoss: 0.456663, Accuracy: 84.77\n",
      "Train Epoch: 18 [10240/50000 (23%)]\tLoss: 0.363986, Accuracy: 87.70\n",
      "Train Epoch: 18 [12800/50000 (28%)]\tLoss: 0.449631, Accuracy: 86.72\n",
      "Train Epoch: 18 [15360/50000 (34%)]\tLoss: 0.400155, Accuracy: 85.55\n",
      "Train Epoch: 18 [17920/50000 (40%)]\tLoss: 0.439849, Accuracy: 85.55\n",
      "Train Epoch: 18 [20480/50000 (45%)]\tLoss: 0.396632, Accuracy: 85.74\n",
      "Train Epoch: 18 [23040/50000 (51%)]\tLoss: 0.452028, Accuracy: 84.38\n",
      "Train Epoch: 18 [25600/50000 (57%)]\tLoss: 0.466172, Accuracy: 84.38\n",
      "Train Epoch: 18 [28160/50000 (62%)]\tLoss: 0.518179, Accuracy: 82.23\n",
      "Train Epoch: 18 [30720/50000 (68%)]\tLoss: 0.401646, Accuracy: 85.55\n",
      "Train Epoch: 18 [33280/50000 (74%)]\tLoss: 0.523464, Accuracy: 82.42\n",
      "Train Epoch: 18 [35840/50000 (80%)]\tLoss: 0.430337, Accuracy: 86.33\n",
      "Train Epoch: 18 [38400/50000 (85%)]\tLoss: 0.422367, Accuracy: 85.35\n",
      "Train Epoch: 18 [40960/50000 (91%)]\tLoss: 0.497107, Accuracy: 83.98\n",
      "Train Epoch: 18 [43520/50000 (97%)]\tLoss: 0.491130, Accuracy: 84.57\n",
      "\n",
      "Validation set: Average loss: 1.8448, Accuracy: 2439/5000 (48.00%)\n",
      "\n",
      "the time of this epoch:[36.09813380241394 s]\n",
      "\n",
      "Test set: Average loss: 2.0837, Accuracy: 4464/10000 (44.64%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.430055, Accuracy: 85.16\n",
      "Train Epoch: 19 [2560/50000 (6%)]\tLoss: 0.413005, Accuracy: 86.13\n",
      "Train Epoch: 19 [5120/50000 (11%)]\tLoss: 0.441262, Accuracy: 85.16\n",
      "Train Epoch: 19 [7680/50000 (17%)]\tLoss: 0.346999, Accuracy: 87.70\n",
      "Train Epoch: 19 [10240/50000 (23%)]\tLoss: 0.488764, Accuracy: 84.18\n",
      "Train Epoch: 19 [12800/50000 (28%)]\tLoss: 0.418195, Accuracy: 85.74\n",
      "Train Epoch: 19 [15360/50000 (34%)]\tLoss: 0.436881, Accuracy: 85.35\n",
      "Train Epoch: 19 [17920/50000 (40%)]\tLoss: 0.417429, Accuracy: 83.59\n",
      "Train Epoch: 19 [20480/50000 (45%)]\tLoss: 0.408792, Accuracy: 85.35\n",
      "Train Epoch: 19 [23040/50000 (51%)]\tLoss: 0.434671, Accuracy: 86.13\n",
      "Train Epoch: 19 [25600/50000 (57%)]\tLoss: 0.394921, Accuracy: 87.30\n",
      "Train Epoch: 19 [28160/50000 (62%)]\tLoss: 0.407652, Accuracy: 86.91\n",
      "Train Epoch: 19 [30720/50000 (68%)]\tLoss: 0.398107, Accuracy: 87.30\n",
      "Train Epoch: 19 [33280/50000 (74%)]\tLoss: 0.460110, Accuracy: 84.77\n",
      "Train Epoch: 19 [35840/50000 (80%)]\tLoss: 0.408023, Accuracy: 85.55\n",
      "Train Epoch: 19 [38400/50000 (85%)]\tLoss: 0.393726, Accuracy: 86.13\n",
      "Train Epoch: 19 [40960/50000 (91%)]\tLoss: 0.417528, Accuracy: 85.35\n",
      "Train Epoch: 19 [43520/50000 (97%)]\tLoss: 0.388550, Accuracy: 86.91\n",
      "\n",
      "Validation set: Average loss: 2.2569, Accuracy: 2942/5000 (58.00%)\n",
      "\n",
      "the time of this epoch:[39.3971221446991 s]\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.424401, Accuracy: 85.74\n",
      "Train Epoch: 20 [2560/50000 (6%)]\tLoss: 0.418692, Accuracy: 85.74\n",
      "Train Epoch: 20 [5120/50000 (11%)]\tLoss: 0.372614, Accuracy: 87.30\n",
      "Train Epoch: 20 [7680/50000 (17%)]\tLoss: 0.360093, Accuracy: 87.70\n",
      "Train Epoch: 20 [10240/50000 (23%)]\tLoss: 0.442019, Accuracy: 84.57\n",
      "Train Epoch: 20 [12800/50000 (28%)]\tLoss: 0.400107, Accuracy: 86.33\n",
      "Train Epoch: 20 [15360/50000 (34%)]\tLoss: 0.440842, Accuracy: 85.55\n",
      "Train Epoch: 20 [17920/50000 (40%)]\tLoss: 0.444437, Accuracy: 84.96\n",
      "Train Epoch: 20 [20480/50000 (45%)]\tLoss: 0.409938, Accuracy: 87.50\n",
      "Train Epoch: 20 [23040/50000 (51%)]\tLoss: 0.426415, Accuracy: 84.38\n",
      "Train Epoch: 20 [25600/50000 (57%)]\tLoss: 0.388335, Accuracy: 88.67\n",
      "Train Epoch: 20 [28160/50000 (62%)]\tLoss: 0.491691, Accuracy: 83.40\n",
      "Train Epoch: 20 [30720/50000 (68%)]\tLoss: 0.412495, Accuracy: 85.74\n",
      "Train Epoch: 20 [33280/50000 (74%)]\tLoss: 0.425252, Accuracy: 86.13\n",
      "Train Epoch: 20 [35840/50000 (80%)]\tLoss: 0.417227, Accuracy: 85.74\n",
      "Train Epoch: 20 [38400/50000 (85%)]\tLoss: 0.385748, Accuracy: 87.50\n",
      "Train Epoch: 20 [40960/50000 (91%)]\tLoss: 0.393924, Accuracy: 86.72\n",
      "Train Epoch: 20 [43520/50000 (97%)]\tLoss: 0.386956, Accuracy: 86.52\n",
      "\n",
      "Validation set: Average loss: 1.4996, Accuracy: 2994/5000 (59.00%)\n",
      "\n",
      "the time of this epoch:[36.27726936340332 s]\n",
      "------------------------------\n",
      "before autoscale: torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.5091]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0900]],\n",
      "\n",
      "        [[ 0.0251]],\n",
      "\n",
      "        [[ 0.0228]],\n",
      "\n",
      "        [[ 0.1615]],\n",
      "\n",
      "        [[ 0.0004]],\n",
      "\n",
      "        [[ 0.1253]],\n",
      "\n",
      "        [[ 0.2863]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[-0.2931]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 512])\n",
      "tensor([[[-0.1492,  0.0000,  0.0000, -0.0264, -0.0073, -0.0067, -0.0473,\n",
      "          -0.0001, -0.0367, -0.0839, -0.0240, -0.0470, -0.1120, -0.0221,\n",
      "           0.0000, -0.0177, -0.0042, -0.0165, -0.0766, -0.0357, -0.0086,\n",
      "          -0.0238, -0.0143, -0.1342, -0.0311,  0.0000, -0.0436, -0.0011,\n",
      "          -0.0100, -0.0106, -0.0150, -0.0176,  0.0000, -0.0449, -0.0076,\n",
      "          -0.0349, -0.0042, -0.0042, -0.0201, -0.0087,  0.0000,  0.0000,\n",
      "          -0.0018, -0.0269, -0.1963, -0.0527, -0.0532,  0.0000, -0.0153,\n",
      "          -0.0271,  0.0000, -0.0449, -0.0688, -0.0557, -0.0366, -0.0614,\n",
      "          -0.1416, -0.0610, -0.1016, -0.0243, -0.0096, -0.0058,  0.0000,\n",
      "          -0.0295, -0.0005,  0.0000, -0.0655, -0.0008, -0.0134, -0.0116,\n",
      "          -0.0011, -0.0022, -0.0015, -0.0316, -0.0004,  0.0000, -0.0041,\n",
      "          -0.0065,  0.0000, -0.0000, -0.0012,  0.0000, -0.0236, -0.0201,\n",
      "          -0.0259, -0.0021, -0.0165,  0.0000, -0.0028, -0.0010, -0.0184,\n",
      "           0.0000,  0.0000, -0.0120, -0.0144, -0.0001,  0.0000, -0.0011,\n",
      "           0.0000, -0.0004, -0.0165,  0.0000,  0.0000, -0.0001, -0.0000,\n",
      "           0.0000,  0.0000, -0.0586, -0.0070, -0.0010, -0.0091,  0.0000,\n",
      "          -0.0678, -0.0019, -0.0195, -0.0076, -0.0041,  0.0000, -0.0320,\n",
      "          -0.0050, -0.0170, -0.0184, -0.0001, -0.0037, -0.0000, -0.0134,\n",
      "          -0.0033, -0.0188, -0.0118, -0.0000, -0.0460,  0.0000, -0.0058,\n",
      "          -0.0019, -0.0012, -0.0184, -0.0119, -0.0021, -0.0005, -0.0157,\n",
      "          -0.0000, -0.0661, -0.0000,  0.0000, -0.0106,  0.0000, -0.0223,\n",
      "          -0.0060, -0.0071, -0.0349, -0.0077, -0.0195, -0.0236, -0.0188,\n",
      "           0.0000, -0.0280, -0.0031, -0.0138, -0.0113, -0.0090, -0.0044,\n",
      "          -0.0013, -0.0031,  0.0000, -0.0028, -0.0149, -0.0050, -0.0116,\n",
      "          -0.0391, -0.0034, -0.0195, -0.0219, -0.0114,  0.0000, -0.0081,\n",
      "          -0.0090,  0.0000, -0.0243, -0.0229,  0.0000,  0.0000, -0.0402,\n",
      "          -0.0046,  0.0000,  0.0000,  0.0000, -0.0366, -0.0001, -0.0053,\n",
      "          -0.0444, -0.0148, -0.0021, -0.0037,  0.0000,  0.0000, -0.0523,\n",
      "          -0.0128, -0.0007, -0.0104, -0.0035, -0.0038, -0.0075,  0.0000,\n",
      "          -0.0345, -0.0015, -0.0011, -0.0340, -0.0150, -0.0195, -0.0457,\n",
      "           0.0000, -0.0333, -0.0010, -0.0041, -0.0092, -0.0193, -0.0297,\n",
      "           0.0000, -0.0164,  0.0000, -0.0109, -0.0058, -0.0047, -0.0333,\n",
      "          -0.0126, -0.0099,  0.0000, -0.0001, -0.0036, -0.0235,  0.0000,\n",
      "          -0.0032, -0.0471, -0.0090, -0.0251,  0.0000, -0.0072, -0.0352,\n",
      "           0.0000,  0.0000, -0.0084, -0.0272, -0.0406, -0.0206,  0.0000,\n",
      "          -0.0025, -0.0194, -0.0075, -0.0032, -0.0022,  0.0000, -0.0086,\n",
      "          -0.0009, -0.0346, -0.0066,  0.0000, -0.0077,  0.0000,  0.0000,\n",
      "           0.0000, -0.0098, -0.0140, -0.0085,  0.0000, -0.0293, -0.0152,\n",
      "          -0.0172, -0.0005, -0.0024,  0.0000, -0.0306, -0.0046,  0.0000,\n",
      "          -0.0376, -0.0019, -0.0503, -0.0090,  0.0000, -0.0106, -0.0231,\n",
      "          -0.0012, -0.0624,  0.0000, -0.0048, -0.0039,  0.0000, -0.0299,\n",
      "          -0.0129, -0.0146, -0.0008, -0.0022, -0.0047, -0.0102, -0.0258,\n",
      "          -0.0007, -0.0202, -0.0038, -0.0216,  0.0000,  0.0000, -0.0144,\n",
      "          -0.0164, -0.0450, -0.0004, -0.0000, -0.0212,  0.0000, -0.0037,\n",
      "          -0.0004, -0.0118, -0.0007, -0.0044, -0.0016,  0.0000, -0.0237,\n",
      "          -0.0079, -0.0015,  0.0000,  0.0000, -0.0039, -0.0061, -0.0319,\n",
      "          -0.0074, -0.0102, -0.0091, -0.0034, -0.0214, -0.0257, -0.0218,\n",
      "          -0.0233, -0.0104,  0.0000,  0.0000,  0.0000, -0.0206, -0.0122,\n",
      "           0.0000, -0.0040, -0.0021, -0.0002, -0.0049, -0.0025, -0.0024,\n",
      "          -0.0018, -0.0051, -0.0544, -0.0002, -0.0462, -0.0200,  0.0000,\n",
      "           0.0000, -0.0016, -0.0105, -0.0103, -0.0097, -0.0002, -0.0069,\n",
      "          -0.0045, -0.0039, -0.0012, -0.0174, -0.0148, -0.0182, -0.0023,\n",
      "          -0.0081, -0.0252, -0.0045, -0.0159, -0.0158, -0.0152, -0.0378,\n",
      "          -0.0482, -0.0059, -0.0015, -0.0291, -0.0112, -0.0036, -0.0054,\n",
      "           0.0000, -0.0155, -0.0232, -0.0124, -0.0086, -0.0014,  0.0000,\n",
      "          -0.0143, -0.0290, -0.0013, -0.0357, -0.0214, -0.0001, -0.0027,\n",
      "           0.0000, -0.0035,  0.0000, -0.0049, -0.0070, -0.0131, -0.0085,\n",
      "          -0.0020, -0.0630, -0.0140, -0.0307, -0.0309, -0.0052, -0.0048,\n",
      "           0.0000, -0.0011,  0.0000,  0.0000,  0.0000, -0.0087, -0.0091,\n",
      "           0.0000, -0.0019, -0.0220, -0.0048,  0.0000,  0.0000, -0.0045,\n",
      "          -0.0277, -0.0008, -0.0334, -0.0008,  0.0000, -0.0435, -0.0130,\n",
      "          -0.0119, -0.0047,  0.0000,  0.0000, -0.0145,  0.0000, -0.0107,\n",
      "          -0.0037, -0.0044,  0.0000, -0.0003,  0.0000, -0.0094, -0.0101,\n",
      "          -0.0738, -0.0047, -0.0064,  0.0000, -0.0008, -0.0442, -0.0103,\n",
      "          -0.0050, -0.0038,  0.0000, -0.0128, -0.0249,  0.0000, -0.0577,\n",
      "           0.0000,  0.0000, -0.0026,  0.0000, -0.0078, -0.0146, -0.0291,\n",
      "          -0.0052, -0.0258,  0.0000, -0.0396, -0.0030, -0.0335, -0.0001,\n",
      "          -0.0015,  0.0000, -0.0045,  0.0000, -0.0122, -0.0186, -0.0193,\n",
      "           0.0000, -0.0388,  0.0000, -0.0000,  0.0000, -0.0131, -0.0017,\n",
      "          -0.0199, -0.0193, -0.0200, -0.0069,  0.0000,  0.0000, -0.0213,\n",
      "          -0.0018, -0.0051,  0.0000, -0.0288,  0.0000, -0.0042, -0.0028,\n",
      "          -0.0147, -0.0039,  0.0000, -0.0009, -0.0085, -0.0576, -0.0013,\n",
      "          -0.0173,  0.0000, -0.0000, -0.0355, -0.0115, -0.0148, -0.0242,\n",
      "           0.0000]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor([[-0.0303,  0.0705, -0.0561,  0.1562, -0.0470, -0.0439,  0.0529,\n",
      "         -0.0402,  0.0633]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 448, 512])\n",
      "tensor([[ 7.6045e-03, -2.4830e-02,  6.4145e-03,  ...,  1.9589e-03,\n",
      "         -3.0289e-03, -2.6905e-03],\n",
      "        [ 5.1075e-03,  3.7577e-03, -6.3173e-03,  ...,  1.0251e-03,\n",
      "          1.5275e-03, -2.6352e-03],\n",
      "        [ 1.1699e-02,  2.8905e-03,  7.9163e-03,  ...,  4.7845e-03,\n",
      "          7.0154e-03, -8.2190e-05],\n",
      "        ...,\n",
      "        [ 1.5682e-03, -1.5444e-02, -4.6944e-03,  ..., -2.2525e-05,\n",
      "          3.4266e-03, -3.4392e-03],\n",
      "        [ 1.0690e-02,  4.7517e-03, -1.9395e-02,  ..., -2.2519e-03,\n",
      "          2.7197e-04, -9.7692e-04],\n",
      "        [-1.2963e-02, -1.6541e-02, -1.3728e-02,  ..., -6.2585e-03,\n",
      "         -2.3019e-03, -5.5156e-04]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 448, 512])\n",
      "tensor([[ 7.6044e-04, -2.4825e-03,  6.4145e-04,  ...,  1.9588e-04,\n",
      "         -3.0289e-04, -2.6904e-04],\n",
      "        [ 5.1075e-04,  3.7577e-04, -6.3172e-04,  ...,  1.0251e-04,\n",
      "          1.5275e-04, -2.6352e-04],\n",
      "        [ 1.1698e-03,  2.8905e-04,  7.9161e-04,  ...,  4.7844e-04,\n",
      "          7.0153e-04, -8.2190e-06],\n",
      "        ...,\n",
      "        [-1.1451e-03, -1.2323e-03, -9.6746e-04,  ..., -2.7994e-04,\n",
      "         -9.0985e-04, -4.3122e-04],\n",
      "        [ 8.1252e-04,  8.6193e-04, -1.0590e-04,  ..., -1.5215e-04,\n",
      "          2.5460e-04,  1.0569e-04],\n",
      "        [-1.5547e-03, -4.0477e-04,  1.3230e-03,  ..., -1.0610e-04,\n",
      "          2.4540e-04,  1.8313e-04]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.7798, Accuracy: 5444/10000 (54.44%)\n",
      "\n",
      "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.390903, Accuracy: 86.52\n",
      "Train Epoch: 21 [2560/50000 (6%)]\tLoss: 0.355655, Accuracy: 87.11\n",
      "Train Epoch: 21 [5120/50000 (11%)]\tLoss: 0.400784, Accuracy: 88.09\n",
      "Train Epoch: 21 [7680/50000 (17%)]\tLoss: 0.377369, Accuracy: 85.55\n",
      "Train Epoch: 21 [10240/50000 (23%)]\tLoss: 0.384346, Accuracy: 87.11\n",
      "Train Epoch: 21 [12800/50000 (28%)]\tLoss: 0.407466, Accuracy: 85.94\n",
      "Train Epoch: 21 [15360/50000 (34%)]\tLoss: 0.333182, Accuracy: 88.09\n",
      "Train Epoch: 21 [17920/50000 (40%)]\tLoss: 0.352597, Accuracy: 89.06\n",
      "Train Epoch: 21 [20480/50000 (45%)]\tLoss: 0.315494, Accuracy: 89.26\n",
      "Train Epoch: 21 [23040/50000 (51%)]\tLoss: 0.340737, Accuracy: 90.04\n",
      "Train Epoch: 21 [25600/50000 (57%)]\tLoss: 0.377643, Accuracy: 86.33\n",
      "Train Epoch: 21 [28160/50000 (62%)]\tLoss: 0.438331, Accuracy: 84.77\n",
      "Train Epoch: 21 [30720/50000 (68%)]\tLoss: 0.389150, Accuracy: 88.48\n",
      "Train Epoch: 21 [33280/50000 (74%)]\tLoss: 0.352487, Accuracy: 87.70\n",
      "Train Epoch: 21 [35840/50000 (80%)]\tLoss: 0.449967, Accuracy: 84.57\n",
      "Train Epoch: 21 [38400/50000 (85%)]\tLoss: 0.401377, Accuracy: 86.72\n",
      "Train Epoch: 21 [40960/50000 (91%)]\tLoss: 0.354354, Accuracy: 87.50\n",
      "Train Epoch: 21 [43520/50000 (97%)]\tLoss: 0.391353, Accuracy: 86.52\n",
      "\n",
      "Validation set: Average loss: 1.8190, Accuracy: 2306/5000 (46.00%)\n",
      "\n",
      "the time of this epoch:[39.55825161933899 s]\n",
      "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.346240, Accuracy: 88.09\n",
      "Train Epoch: 22 [2560/50000 (6%)]\tLoss: 0.418836, Accuracy: 84.96\n",
      "Train Epoch: 22 [5120/50000 (11%)]\tLoss: 0.334366, Accuracy: 88.67\n",
      "Train Epoch: 22 [7680/50000 (17%)]\tLoss: 0.342929, Accuracy: 87.89\n",
      "Train Epoch: 22 [10240/50000 (23%)]\tLoss: 0.321926, Accuracy: 90.62\n",
      "Train Epoch: 22 [12800/50000 (28%)]\tLoss: 0.411332, Accuracy: 85.16\n",
      "Train Epoch: 22 [15360/50000 (34%)]\tLoss: 0.325811, Accuracy: 88.48\n",
      "Train Epoch: 22 [17920/50000 (40%)]\tLoss: 0.387013, Accuracy: 86.91\n",
      "Train Epoch: 22 [20480/50000 (45%)]\tLoss: 0.420946, Accuracy: 86.52\n",
      "Train Epoch: 22 [23040/50000 (51%)]\tLoss: 0.381071, Accuracy: 87.70\n",
      "Train Epoch: 22 [25600/50000 (57%)]\tLoss: 0.388329, Accuracy: 86.52\n",
      "Train Epoch: 22 [28160/50000 (62%)]\tLoss: 0.413617, Accuracy: 85.94\n",
      "Train Epoch: 22 [30720/50000 (68%)]\tLoss: 0.349279, Accuracy: 87.89\n",
      "Train Epoch: 22 [33280/50000 (74%)]\tLoss: 0.381567, Accuracy: 88.67\n",
      "Train Epoch: 22 [35840/50000 (80%)]\tLoss: 0.480332, Accuracy: 83.20\n",
      "Train Epoch: 22 [38400/50000 (85%)]\tLoss: 0.419992, Accuracy: 87.89\n",
      "Train Epoch: 22 [40960/50000 (91%)]\tLoss: 0.399918, Accuracy: 85.16\n",
      "Train Epoch: 22 [43520/50000 (97%)]\tLoss: 0.390840, Accuracy: 87.50\n",
      "\n",
      "Validation set: Average loss: 1.5770, Accuracy: 3002/5000 (60.00%)\n",
      "\n",
      "the time of this epoch:[36.16579222679138 s]\n",
      "\n",
      "Test set: Average loss: 1.5610, Accuracy: 5859/10000 (58.59%)\n",
      "\n",
      "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.319384, Accuracy: 89.26\n",
      "Train Epoch: 23 [2560/50000 (6%)]\tLoss: 0.348127, Accuracy: 88.87\n",
      "Train Epoch: 23 [5120/50000 (11%)]\tLoss: 0.356936, Accuracy: 87.30\n",
      "Train Epoch: 23 [7680/50000 (17%)]\tLoss: 0.345160, Accuracy: 89.06\n",
      "Train Epoch: 23 [10240/50000 (23%)]\tLoss: 0.431963, Accuracy: 84.96\n",
      "Train Epoch: 23 [12800/50000 (28%)]\tLoss: 0.401059, Accuracy: 86.72\n",
      "Train Epoch: 23 [15360/50000 (34%)]\tLoss: 0.429695, Accuracy: 83.40\n",
      "Train Epoch: 23 [17920/50000 (40%)]\tLoss: 0.370991, Accuracy: 89.65\n",
      "Train Epoch: 23 [20480/50000 (45%)]\tLoss: 0.353075, Accuracy: 86.72\n",
      "Train Epoch: 23 [23040/50000 (51%)]\tLoss: 0.413582, Accuracy: 85.94\n",
      "Train Epoch: 23 [25600/50000 (57%)]\tLoss: 0.482501, Accuracy: 83.59\n",
      "Train Epoch: 23 [28160/50000 (62%)]\tLoss: 0.400327, Accuracy: 86.13\n",
      "Train Epoch: 23 [30720/50000 (68%)]\tLoss: 0.322252, Accuracy: 88.87\n",
      "Train Epoch: 23 [33280/50000 (74%)]\tLoss: 0.400867, Accuracy: 85.55\n",
      "Train Epoch: 23 [35840/50000 (80%)]\tLoss: 0.440958, Accuracy: 84.96\n",
      "Train Epoch: 23 [38400/50000 (85%)]\tLoss: 0.398743, Accuracy: 86.13\n",
      "Train Epoch: 23 [40960/50000 (91%)]\tLoss: 0.358429, Accuracy: 86.72\n",
      "Train Epoch: 23 [43520/50000 (97%)]\tLoss: 0.414011, Accuracy: 85.55\n",
      "\n",
      "Validation set: Average loss: 2.0800, Accuracy: 2773/5000 (55.00%)\n",
      "\n",
      "the time of this epoch:[39.70086717605591 s]\n",
      "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.327832, Accuracy: 90.62\n",
      "Train Epoch: 24 [2560/50000 (6%)]\tLoss: 0.403800, Accuracy: 86.13\n",
      "Train Epoch: 24 [5120/50000 (11%)]\tLoss: 0.315070, Accuracy: 88.09\n",
      "Train Epoch: 24 [7680/50000 (17%)]\tLoss: 0.474796, Accuracy: 83.40\n",
      "Train Epoch: 24 [10240/50000 (23%)]\tLoss: 0.316148, Accuracy: 89.84\n",
      "Train Epoch: 24 [12800/50000 (28%)]\tLoss: 0.359439, Accuracy: 87.11\n",
      "Train Epoch: 24 [15360/50000 (34%)]\tLoss: 0.358470, Accuracy: 87.70\n",
      "Train Epoch: 24 [17920/50000 (40%)]\tLoss: 0.340190, Accuracy: 88.28\n",
      "Train Epoch: 24 [20480/50000 (45%)]\tLoss: 0.387725, Accuracy: 87.50\n",
      "Train Epoch: 24 [23040/50000 (51%)]\tLoss: 0.353672, Accuracy: 87.89\n",
      "Train Epoch: 24 [25600/50000 (57%)]\tLoss: 0.336652, Accuracy: 89.26\n",
      "Train Epoch: 24 [28160/50000 (62%)]\tLoss: 0.363330, Accuracy: 87.30\n",
      "Train Epoch: 24 [30720/50000 (68%)]\tLoss: 0.331165, Accuracy: 87.70\n",
      "Train Epoch: 24 [33280/50000 (74%)]\tLoss: 0.340075, Accuracy: 87.50\n",
      "Train Epoch: 24 [35840/50000 (80%)]\tLoss: 0.434323, Accuracy: 86.13\n",
      "Train Epoch: 24 [38400/50000 (85%)]\tLoss: 0.359922, Accuracy: 86.52\n",
      "Train Epoch: 24 [40960/50000 (91%)]\tLoss: 0.385133, Accuracy: 87.11\n",
      "Train Epoch: 24 [43520/50000 (97%)]\tLoss: 0.370979, Accuracy: 87.30\n",
      "\n",
      "Validation set: Average loss: 1.7915, Accuracy: 2885/5000 (57.00%)\n",
      "\n",
      "the time of this epoch:[36.25419068336487 s]\n",
      "\n",
      "Test set: Average loss: 1.5297, Accuracy: 5920/10000 (59.20%)\n",
      "\n",
      "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.334735, Accuracy: 89.84\n",
      "Train Epoch: 25 [2560/50000 (6%)]\tLoss: 0.383776, Accuracy: 85.74\n",
      "Train Epoch: 25 [5120/50000 (11%)]\tLoss: 0.308866, Accuracy: 89.84\n",
      "Train Epoch: 25 [7680/50000 (17%)]\tLoss: 0.331196, Accuracy: 88.28\n",
      "Train Epoch: 25 [10240/50000 (23%)]\tLoss: 0.318584, Accuracy: 88.87\n",
      "Train Epoch: 25 [12800/50000 (28%)]\tLoss: 0.461677, Accuracy: 84.96\n",
      "Train Epoch: 25 [15360/50000 (34%)]\tLoss: 0.383758, Accuracy: 85.74\n",
      "Train Epoch: 25 [17920/50000 (40%)]\tLoss: 0.353978, Accuracy: 87.89\n",
      "Train Epoch: 25 [20480/50000 (45%)]\tLoss: 0.414531, Accuracy: 86.52\n",
      "Train Epoch: 25 [23040/50000 (51%)]\tLoss: 0.319804, Accuracy: 89.84\n",
      "Train Epoch: 25 [25600/50000 (57%)]\tLoss: 0.367204, Accuracy: 86.91\n",
      "Train Epoch: 25 [28160/50000 (62%)]\tLoss: 0.420774, Accuracy: 85.74\n",
      "Train Epoch: 25 [30720/50000 (68%)]\tLoss: 0.375633, Accuracy: 87.11\n",
      "Train Epoch: 25 [33280/50000 (74%)]\tLoss: 0.350212, Accuracy: 87.89\n",
      "Train Epoch: 25 [35840/50000 (80%)]\tLoss: 0.367293, Accuracy: 88.48\n",
      "Train Epoch: 25 [38400/50000 (85%)]\tLoss: 0.347315, Accuracy: 87.89\n",
      "Train Epoch: 25 [40960/50000 (91%)]\tLoss: 0.337154, Accuracy: 86.91\n",
      "Train Epoch: 25 [43520/50000 (97%)]\tLoss: 0.376426, Accuracy: 87.11\n",
      "\n",
      "Validation set: Average loss: 1.8428, Accuracy: 2419/5000 (48.00%)\n",
      "\n",
      "the time of this epoch:[39.387202978134155 s]\n",
      "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.291720, Accuracy: 89.06\n",
      "Train Epoch: 26 [2560/50000 (6%)]\tLoss: 0.374960, Accuracy: 87.50\n",
      "Train Epoch: 26 [5120/50000 (11%)]\tLoss: 0.351442, Accuracy: 86.52\n",
      "Train Epoch: 26 [7680/50000 (17%)]\tLoss: 0.386238, Accuracy: 86.72\n",
      "Train Epoch: 26 [10240/50000 (23%)]\tLoss: 0.331494, Accuracy: 89.06\n",
      "Train Epoch: 26 [12800/50000 (28%)]\tLoss: 0.361123, Accuracy: 87.89\n",
      "Train Epoch: 26 [15360/50000 (34%)]\tLoss: 0.302767, Accuracy: 89.84\n",
      "Train Epoch: 26 [17920/50000 (40%)]\tLoss: 0.351084, Accuracy: 87.89\n",
      "Train Epoch: 26 [20480/50000 (45%)]\tLoss: 0.315930, Accuracy: 90.82\n",
      "Train Epoch: 26 [23040/50000 (51%)]\tLoss: 0.370664, Accuracy: 86.52\n",
      "Train Epoch: 26 [25600/50000 (57%)]\tLoss: 0.359537, Accuracy: 85.94\n",
      "Train Epoch: 26 [28160/50000 (62%)]\tLoss: 0.351661, Accuracy: 88.28\n",
      "Train Epoch: 26 [30720/50000 (68%)]\tLoss: 0.389582, Accuracy: 86.13\n",
      "Train Epoch: 26 [33280/50000 (74%)]\tLoss: 0.363544, Accuracy: 86.72\n",
      "Train Epoch: 26 [35840/50000 (80%)]\tLoss: 0.419416, Accuracy: 87.30\n",
      "Train Epoch: 26 [38400/50000 (85%)]\tLoss: 0.308458, Accuracy: 89.06\n",
      "Train Epoch: 26 [40960/50000 (91%)]\tLoss: 0.406952, Accuracy: 87.30\n",
      "Train Epoch: 26 [43520/50000 (97%)]\tLoss: 0.395459, Accuracy: 86.33\n",
      "\n",
      "Validation set: Average loss: 3.9392, Accuracy: 1966/5000 (39.00%)\n",
      "\n",
      "the time of this epoch:[36.08651781082153 s]\n",
      "\n",
      "Test set: Average loss: 3.3251, Accuracy: 4596/10000 (45.96%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.297656, Accuracy: 89.84\n",
      "Train Epoch: 27 [2560/50000 (6%)]\tLoss: 0.270648, Accuracy: 91.80\n",
      "Train Epoch: 27 [5120/50000 (11%)]\tLoss: 0.337377, Accuracy: 88.28\n",
      "Train Epoch: 27 [7680/50000 (17%)]\tLoss: 0.341374, Accuracy: 88.09\n",
      "Train Epoch: 27 [10240/50000 (23%)]\tLoss: 0.265822, Accuracy: 91.60\n",
      "Train Epoch: 27 [12800/50000 (28%)]\tLoss: 0.287002, Accuracy: 90.04\n",
      "Train Epoch: 27 [15360/50000 (34%)]\tLoss: 0.339891, Accuracy: 88.87\n",
      "Train Epoch: 27 [17920/50000 (40%)]\tLoss: 0.336777, Accuracy: 88.09\n",
      "Train Epoch: 27 [20480/50000 (45%)]\tLoss: 0.389714, Accuracy: 85.74\n",
      "Train Epoch: 27 [23040/50000 (51%)]\tLoss: 0.301421, Accuracy: 89.84\n",
      "Train Epoch: 27 [25600/50000 (57%)]\tLoss: 0.314185, Accuracy: 89.45\n",
      "Train Epoch: 27 [28160/50000 (62%)]\tLoss: 0.364305, Accuracy: 87.11\n",
      "Train Epoch: 27 [30720/50000 (68%)]\tLoss: 0.371844, Accuracy: 87.70\n",
      "Train Epoch: 27 [33280/50000 (74%)]\tLoss: 0.414499, Accuracy: 84.38\n",
      "Train Epoch: 27 [35840/50000 (80%)]\tLoss: 0.380776, Accuracy: 86.52\n",
      "Train Epoch: 27 [38400/50000 (85%)]\tLoss: 0.315638, Accuracy: 90.43\n",
      "Train Epoch: 27 [40960/50000 (91%)]\tLoss: 0.403974, Accuracy: 87.11\n",
      "Train Epoch: 27 [43520/50000 (97%)]\tLoss: 0.409367, Accuracy: 84.96\n",
      "\n",
      "Validation set: Average loss: 1.1501, Accuracy: 3405/5000 (68.00%)\n",
      "\n",
      "the time of this epoch:[39.83205842971802 s]\n",
      "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.280013, Accuracy: 89.26\n",
      "Train Epoch: 28 [2560/50000 (6%)]\tLoss: 0.272690, Accuracy: 91.21\n",
      "Train Epoch: 28 [5120/50000 (11%)]\tLoss: 0.315890, Accuracy: 87.89\n",
      "Train Epoch: 28 [7680/50000 (17%)]\tLoss: 0.327980, Accuracy: 89.06\n",
      "Train Epoch: 28 [10240/50000 (23%)]\tLoss: 0.277171, Accuracy: 90.43\n",
      "Train Epoch: 28 [12800/50000 (28%)]\tLoss: 0.313379, Accuracy: 91.21\n",
      "Train Epoch: 28 [15360/50000 (34%)]\tLoss: 0.344729, Accuracy: 88.09\n",
      "Train Epoch: 28 [17920/50000 (40%)]\tLoss: 0.307191, Accuracy: 88.09\n",
      "Train Epoch: 28 [20480/50000 (45%)]\tLoss: 0.363889, Accuracy: 87.11\n",
      "Train Epoch: 28 [23040/50000 (51%)]\tLoss: 0.421798, Accuracy: 86.91\n",
      "Train Epoch: 28 [25600/50000 (57%)]\tLoss: 0.431673, Accuracy: 86.91\n",
      "Train Epoch: 28 [28160/50000 (62%)]\tLoss: 0.272498, Accuracy: 90.62\n",
      "Train Epoch: 28 [30720/50000 (68%)]\tLoss: 0.327219, Accuracy: 88.67\n",
      "Train Epoch: 28 [33280/50000 (74%)]\tLoss: 0.342555, Accuracy: 86.91\n",
      "Train Epoch: 28 [35840/50000 (80%)]\tLoss: 0.394097, Accuracy: 84.77\n",
      "Train Epoch: 28 [38400/50000 (85%)]\tLoss: 0.365161, Accuracy: 88.09\n",
      "Train Epoch: 28 [40960/50000 (91%)]\tLoss: 0.297581, Accuracy: 89.26\n",
      "Train Epoch: 28 [43520/50000 (97%)]\tLoss: 0.390705, Accuracy: 85.94\n",
      "\n",
      "Validation set: Average loss: 1.5270, Accuracy: 3020/5000 (60.00%)\n",
      "\n",
      "the time of this epoch:[37.49835729598999 s]\n",
      "\n",
      "Test set: Average loss: 1.4005, Accuracy: 6124/10000 (61.24%)\n",
      "\n",
      "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.375251, Accuracy: 86.52\n",
      "Train Epoch: 29 [2560/50000 (6%)]\tLoss: 0.312208, Accuracy: 89.45\n",
      "Train Epoch: 29 [5120/50000 (11%)]\tLoss: 0.315772, Accuracy: 89.84\n",
      "Train Epoch: 29 [7680/50000 (17%)]\tLoss: 0.336677, Accuracy: 88.87\n",
      "Train Epoch: 29 [10240/50000 (23%)]\tLoss: 0.369816, Accuracy: 87.89\n",
      "Train Epoch: 29 [12800/50000 (28%)]\tLoss: 0.367532, Accuracy: 87.70\n",
      "Train Epoch: 29 [15360/50000 (34%)]\tLoss: 0.370611, Accuracy: 88.09\n",
      "Train Epoch: 29 [17920/50000 (40%)]\tLoss: 0.371358, Accuracy: 87.50\n",
      "Train Epoch: 29 [20480/50000 (45%)]\tLoss: 0.341811, Accuracy: 87.50\n",
      "Train Epoch: 29 [23040/50000 (51%)]\tLoss: 0.258226, Accuracy: 90.43\n",
      "Train Epoch: 29 [25600/50000 (57%)]\tLoss: 0.379480, Accuracy: 88.28\n",
      "Train Epoch: 29 [28160/50000 (62%)]\tLoss: 0.345994, Accuracy: 87.89\n",
      "Train Epoch: 29 [30720/50000 (68%)]\tLoss: 0.355440, Accuracy: 88.28\n",
      "Train Epoch: 29 [33280/50000 (74%)]\tLoss: 0.352963, Accuracy: 87.89\n",
      "Train Epoch: 29 [35840/50000 (80%)]\tLoss: 0.336612, Accuracy: 87.11\n",
      "Train Epoch: 29 [38400/50000 (85%)]\tLoss: 0.348362, Accuracy: 87.30\n",
      "Train Epoch: 29 [40960/50000 (91%)]\tLoss: 0.428769, Accuracy: 87.11\n",
      "Train Epoch: 29 [43520/50000 (97%)]\tLoss: 0.361004, Accuracy: 87.30\n",
      "\n",
      "Validation set: Average loss: 1.7651, Accuracy: 2683/5000 (53.00%)\n",
      "\n",
      "the time of this epoch:[39.68299102783203 s]\n",
      "Train Epoch: 30 [0/50000 (0%)]\tLoss: 0.280656, Accuracy: 90.43\n",
      "Train Epoch: 30 [2560/50000 (6%)]\tLoss: 0.314299, Accuracy: 89.06\n",
      "Train Epoch: 30 [5120/50000 (11%)]\tLoss: 0.306032, Accuracy: 91.02\n",
      "Train Epoch: 30 [7680/50000 (17%)]\tLoss: 0.299096, Accuracy: 89.26\n",
      "Train Epoch: 30 [10240/50000 (23%)]\tLoss: 0.354048, Accuracy: 88.48\n",
      "Train Epoch: 30 [12800/50000 (28%)]\tLoss: 0.324803, Accuracy: 87.70\n",
      "Train Epoch: 30 [15360/50000 (34%)]\tLoss: 0.297012, Accuracy: 89.26\n",
      "Train Epoch: 30 [17920/50000 (40%)]\tLoss: 0.243153, Accuracy: 92.19\n",
      "Train Epoch: 30 [20480/50000 (45%)]\tLoss: 0.375398, Accuracy: 87.30\n",
      "Train Epoch: 30 [23040/50000 (51%)]\tLoss: 0.322785, Accuracy: 89.06\n",
      "Train Epoch: 30 [25600/50000 (57%)]\tLoss: 0.267730, Accuracy: 90.23\n",
      "Train Epoch: 30 [28160/50000 (62%)]\tLoss: 0.286770, Accuracy: 90.04\n",
      "Train Epoch: 30 [30720/50000 (68%)]\tLoss: 0.338900, Accuracy: 89.84\n",
      "Train Epoch: 30 [33280/50000 (74%)]\tLoss: 0.291232, Accuracy: 90.23\n",
      "Train Epoch: 30 [35840/50000 (80%)]\tLoss: 0.354159, Accuracy: 88.28\n",
      "Train Epoch: 30 [38400/50000 (85%)]\tLoss: 0.308152, Accuracy: 89.06\n",
      "Train Epoch: 30 [40960/50000 (91%)]\tLoss: 0.385141, Accuracy: 86.33\n",
      "Train Epoch: 30 [43520/50000 (97%)]\tLoss: 0.337845, Accuracy: 88.48\n",
      "\n",
      "Validation set: Average loss: 1.6900, Accuracy: 2830/5000 (56.00%)\n",
      "\n",
      "the time of this epoch:[36.149433612823486 s]\n",
      "\n",
      "Test set: Average loss: 1.6993, Accuracy: 5463/10000 (54.63%)\n",
      "\n",
      "Train Epoch: 31 [0/50000 (0%)]\tLoss: 0.310461, Accuracy: 90.04\n",
      "Train Epoch: 31 [2560/50000 (6%)]\tLoss: 0.302144, Accuracy: 89.65\n",
      "Train Epoch: 31 [5120/50000 (11%)]\tLoss: 0.348181, Accuracy: 88.87\n",
      "Train Epoch: 31 [7680/50000 (17%)]\tLoss: 0.353314, Accuracy: 88.48\n",
      "Train Epoch: 31 [10240/50000 (23%)]\tLoss: 0.249403, Accuracy: 91.41\n",
      "Train Epoch: 31 [12800/50000 (28%)]\tLoss: 0.317420, Accuracy: 88.67\n",
      "Train Epoch: 31 [15360/50000 (34%)]\tLoss: 0.336732, Accuracy: 87.50\n",
      "Train Epoch: 31 [17920/50000 (40%)]\tLoss: 0.312611, Accuracy: 89.45\n",
      "Train Epoch: 31 [20480/50000 (45%)]\tLoss: 0.321519, Accuracy: 89.06\n",
      "Train Epoch: 31 [23040/50000 (51%)]\tLoss: 0.269871, Accuracy: 91.02\n",
      "Train Epoch: 31 [25600/50000 (57%)]\tLoss: 0.268135, Accuracy: 90.04\n",
      "Train Epoch: 31 [28160/50000 (62%)]\tLoss: 0.304671, Accuracy: 89.84\n",
      "Train Epoch: 31 [30720/50000 (68%)]\tLoss: 0.383790, Accuracy: 86.91\n",
      "Train Epoch: 31 [33280/50000 (74%)]\tLoss: 0.344960, Accuracy: 88.67\n",
      "Train Epoch: 31 [35840/50000 (80%)]\tLoss: 0.314561, Accuracy: 89.84\n",
      "Train Epoch: 31 [38400/50000 (85%)]\tLoss: 0.314092, Accuracy: 89.65\n",
      "Train Epoch: 31 [40960/50000 (91%)]\tLoss: 0.349318, Accuracy: 88.48\n",
      "Train Epoch: 31 [43520/50000 (97%)]\tLoss: 0.396858, Accuracy: 86.33\n",
      "\n",
      "Validation set: Average loss: 1.8132, Accuracy: 2998/5000 (59.00%)\n",
      "\n",
      "the time of this epoch:[40.537805795669556 s]\n",
      "Train Epoch: 32 [0/50000 (0%)]\tLoss: 0.279415, Accuracy: 90.43\n",
      "Train Epoch: 32 [2560/50000 (6%)]\tLoss: 0.335248, Accuracy: 87.70\n",
      "Train Epoch: 32 [5120/50000 (11%)]\tLoss: 0.348978, Accuracy: 88.09\n",
      "Train Epoch: 32 [7680/50000 (17%)]\tLoss: 0.277950, Accuracy: 91.41\n",
      "Train Epoch: 32 [10240/50000 (23%)]\tLoss: 0.246597, Accuracy: 91.80\n",
      "Train Epoch: 32 [12800/50000 (28%)]\tLoss: 0.277175, Accuracy: 91.02\n",
      "Train Epoch: 32 [15360/50000 (34%)]\tLoss: 0.282740, Accuracy: 90.23\n",
      "Train Epoch: 32 [17920/50000 (40%)]\tLoss: 0.295031, Accuracy: 89.84\n",
      "Train Epoch: 32 [20480/50000 (45%)]\tLoss: 0.340442, Accuracy: 88.09\n",
      "Train Epoch: 32 [23040/50000 (51%)]\tLoss: 0.310227, Accuracy: 90.82\n",
      "Train Epoch: 32 [25600/50000 (57%)]\tLoss: 0.319493, Accuracy: 89.84\n",
      "Train Epoch: 32 [28160/50000 (62%)]\tLoss: 0.311672, Accuracy: 89.06\n",
      "Train Epoch: 32 [30720/50000 (68%)]\tLoss: 0.294784, Accuracy: 89.26\n",
      "Train Epoch: 32 [33280/50000 (74%)]\tLoss: 0.255403, Accuracy: 91.80\n",
      "Train Epoch: 32 [35840/50000 (80%)]\tLoss: 0.293726, Accuracy: 89.45\n",
      "Train Epoch: 32 [38400/50000 (85%)]\tLoss: 0.318224, Accuracy: 89.26\n",
      "Train Epoch: 32 [40960/50000 (91%)]\tLoss: 0.332230, Accuracy: 89.45\n",
      "Train Epoch: 32 [43520/50000 (97%)]\tLoss: 0.354919, Accuracy: 86.13\n",
      "\n",
      "Validation set: Average loss: 1.2686, Accuracy: 3316/5000 (66.00%)\n",
      "\n",
      "the time of this epoch:[37.48253273963928 s]\n",
      "\n",
      "Test set: Average loss: 1.4492, Accuracy: 6314/10000 (63.14%)\n",
      "\n",
      "Train Epoch: 33 [0/50000 (0%)]\tLoss: 0.310994, Accuracy: 88.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 33 [2560/50000 (6%)]\tLoss: 0.309581, Accuracy: 89.84\n",
      "Train Epoch: 33 [5120/50000 (11%)]\tLoss: 0.296906, Accuracy: 89.06\n",
      "Train Epoch: 33 [7680/50000 (17%)]\tLoss: 0.292935, Accuracy: 89.06\n",
      "Train Epoch: 33 [10240/50000 (23%)]\tLoss: 0.274679, Accuracy: 90.43\n",
      "Train Epoch: 33 [12800/50000 (28%)]\tLoss: 0.284844, Accuracy: 89.45\n",
      "Train Epoch: 33 [15360/50000 (34%)]\tLoss: 0.322446, Accuracy: 88.87\n",
      "Train Epoch: 33 [17920/50000 (40%)]\tLoss: 0.260226, Accuracy: 92.19\n",
      "Train Epoch: 33 [20480/50000 (45%)]\tLoss: 0.273169, Accuracy: 90.43\n",
      "Train Epoch: 33 [23040/50000 (51%)]\tLoss: 0.380678, Accuracy: 87.50\n",
      "Train Epoch: 33 [25600/50000 (57%)]\tLoss: 0.293741, Accuracy: 89.45\n",
      "Train Epoch: 33 [28160/50000 (62%)]\tLoss: 0.345073, Accuracy: 88.28\n",
      "Train Epoch: 33 [30720/50000 (68%)]\tLoss: 0.333730, Accuracy: 89.26\n",
      "Train Epoch: 33 [33280/50000 (74%)]\tLoss: 0.314881, Accuracy: 89.84\n",
      "Train Epoch: 33 [35840/50000 (80%)]\tLoss: 0.269047, Accuracy: 91.21\n",
      "Train Epoch: 33 [38400/50000 (85%)]\tLoss: 0.291617, Accuracy: 89.06\n",
      "Train Epoch: 33 [40960/50000 (91%)]\tLoss: 0.315646, Accuracy: 89.45\n",
      "Train Epoch: 33 [43520/50000 (97%)]\tLoss: 0.276928, Accuracy: 89.45\n",
      "\n",
      "Validation set: Average loss: 2.9388, Accuracy: 2615/5000 (52.00%)\n",
      "\n",
      "the time of this epoch:[40.13881301879883 s]\n",
      "Train Epoch: 34 [0/50000 (0%)]\tLoss: 0.248062, Accuracy: 92.77\n",
      "Train Epoch: 34 [2560/50000 (6%)]\tLoss: 0.325010, Accuracy: 89.45\n",
      "Train Epoch: 34 [5120/50000 (11%)]\tLoss: 0.309371, Accuracy: 88.48\n",
      "Train Epoch: 34 [7680/50000 (17%)]\tLoss: 0.309977, Accuracy: 89.26\n",
      "Train Epoch: 34 [10240/50000 (23%)]\tLoss: 0.313620, Accuracy: 89.65\n",
      "Train Epoch: 34 [12800/50000 (28%)]\tLoss: 0.255091, Accuracy: 90.82\n",
      "Train Epoch: 34 [15360/50000 (34%)]\tLoss: 0.289757, Accuracy: 90.04\n",
      "Train Epoch: 34 [17920/50000 (40%)]\tLoss: 0.343354, Accuracy: 89.26\n",
      "Train Epoch: 34 [20480/50000 (45%)]\tLoss: 0.314422, Accuracy: 89.84\n",
      "Train Epoch: 34 [23040/50000 (51%)]\tLoss: 0.337601, Accuracy: 87.50\n",
      "Train Epoch: 34 [25600/50000 (57%)]\tLoss: 0.352358, Accuracy: 86.72\n",
      "Train Epoch: 34 [28160/50000 (62%)]\tLoss: 0.288296, Accuracy: 89.84\n",
      "Train Epoch: 34 [30720/50000 (68%)]\tLoss: 0.332306, Accuracy: 88.09\n",
      "Train Epoch: 34 [33280/50000 (74%)]\tLoss: 0.299904, Accuracy: 89.45\n",
      "Train Epoch: 34 [35840/50000 (80%)]\tLoss: 0.324654, Accuracy: 88.48\n",
      "Train Epoch: 34 [38400/50000 (85%)]\tLoss: 0.302661, Accuracy: 89.06\n",
      "Train Epoch: 34 [40960/50000 (91%)]\tLoss: 0.385803, Accuracy: 86.33\n",
      "Train Epoch: 34 [43520/50000 (97%)]\tLoss: 0.383672, Accuracy: 87.70\n",
      "\n",
      "Validation set: Average loss: 11.8237, Accuracy: 500/5000 (10.00%)\n",
      "\n",
      "the time of this epoch:[36.20388579368591 s]\n",
      "\n",
      "Test set: Average loss: 11.8782, Accuracy: 1036/10000 (10.36%)\n",
      "\n",
      "Train Epoch: 35 [0/50000 (0%)]\tLoss: 0.284153, Accuracy: 90.23\n",
      "Train Epoch: 35 [2560/50000 (6%)]\tLoss: 0.294587, Accuracy: 91.21\n",
      "Train Epoch: 35 [5120/50000 (11%)]\tLoss: 0.273912, Accuracy: 90.62\n",
      "Train Epoch: 35 [7680/50000 (17%)]\tLoss: 0.330230, Accuracy: 88.48\n",
      "Train Epoch: 35 [10240/50000 (23%)]\tLoss: 0.281285, Accuracy: 91.02\n",
      "Train Epoch: 35 [12800/50000 (28%)]\tLoss: 0.383611, Accuracy: 86.33\n",
      "Train Epoch: 35 [15360/50000 (34%)]\tLoss: 0.318094, Accuracy: 88.67\n",
      "Train Epoch: 35 [17920/50000 (40%)]\tLoss: 0.259774, Accuracy: 90.23\n",
      "Train Epoch: 35 [20480/50000 (45%)]\tLoss: 0.277829, Accuracy: 92.58\n",
      "Train Epoch: 35 [23040/50000 (51%)]\tLoss: 0.287194, Accuracy: 90.82\n",
      "Train Epoch: 35 [25600/50000 (57%)]\tLoss: 0.377099, Accuracy: 87.70\n",
      "Train Epoch: 35 [28160/50000 (62%)]\tLoss: 0.286955, Accuracy: 90.23\n",
      "Train Epoch: 35 [30720/50000 (68%)]\tLoss: 0.263772, Accuracy: 92.19\n",
      "Train Epoch: 35 [33280/50000 (74%)]\tLoss: 0.322704, Accuracy: 87.89\n",
      "Train Epoch: 35 [35840/50000 (80%)]\tLoss: 0.351392, Accuracy: 88.09\n",
      "Train Epoch: 35 [38400/50000 (85%)]\tLoss: 0.269877, Accuracy: 91.80\n",
      "Train Epoch: 35 [40960/50000 (91%)]\tLoss: 0.294539, Accuracy: 91.02\n",
      "Train Epoch: 35 [43520/50000 (97%)]\tLoss: 0.322083, Accuracy: 88.09\n",
      "------------------------------\n",
      "before autoscale: torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.0954]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0009]],\n",
      "\n",
      "        [[ 0.1069]],\n",
      "\n",
      "        [[ 0.0277]],\n",
      "\n",
      "        [[ 0.0470]],\n",
      "\n",
      "        [[ 0.2410]],\n",
      "\n",
      "        [[ 0.1364]],\n",
      "\n",
      "        [[ 0.2324]],\n",
      "\n",
      "        [[ 0.1889]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[-0.3743]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 512])\n",
      "tensor([[[-0.0357,  0.0000, -0.0003, -0.0400, -0.0104, -0.0176, -0.0902,\n",
      "          -0.0510, -0.0870, -0.0707, -0.0299, -0.0538, -0.1220, -0.1374,\n",
      "           0.0000, -0.0355, -0.0032, -0.0309, -0.0371, -0.0654, -0.0187,\n",
      "          -0.0181, -0.0621, -0.0724, -0.0609, -0.2118, -0.0607,  0.0000,\n",
      "          -0.0133,  0.0000, -0.0116, -0.0492, -0.0041, -0.0585, -0.0156,\n",
      "          -0.0836, -0.0108, -0.0047, -0.0094, -0.0353,  0.0000,  0.0000,\n",
      "          -0.1974, -0.0588, -0.0718, -0.0133, -0.0551,  0.0000, -0.1018,\n",
      "          -0.0500,  0.0000, -0.0354, -0.0636, -0.0502, -0.0683, -0.1169,\n",
      "          -0.0649, -0.0585, -0.0211, -0.0508, -0.1909,  0.0000,  0.0000,\n",
      "          -0.0183,  0.0000,  0.0000, -0.0090, -0.0016, -0.0135,  0.0000,\n",
      "          -0.0018, -0.0206, -0.0013, -0.0138, -0.0001, -0.0056, -0.0036,\n",
      "          -0.0041,  0.0000,  0.0000, -0.0004, -0.0011, -0.0080, -0.0066,\n",
      "          -0.0152,  0.0000, -0.0102, -0.0011, -0.0024, -0.0012, -0.0096,\n",
      "           0.0000, -0.0003, -0.0085, -0.0028,  0.0000, -0.0014, -0.0018,\n",
      "           0.0000, -0.0009, -0.0035,  0.0000,  0.0000, -0.0001, -0.0006,\n",
      "          -0.0002,  0.0000, -0.0453, -0.0089, -0.0037, -0.0072,  0.0000,\n",
      "          -0.0582,  0.0000, -0.0121, -0.0091, -0.0051,  0.0000, -0.0181,\n",
      "          -0.0035, -0.0043, -0.0033, -0.0000, -0.0023, -0.0004, -0.0056,\n",
      "          -0.0023, -0.0072, -0.0052,  0.0000, -0.0124,  0.0000, -0.0048,\n",
      "          -0.0006, -0.0002, -0.0077, -0.0087, -0.0181,  0.0000, -0.0088,\n",
      "           0.0000, -0.0377, -0.0001,  0.0000, -0.0063,  0.0000, -0.0293,\n",
      "          -0.0088, -0.0049, -0.0140, -0.0074, -0.0575, -0.0090, -0.0099,\n",
      "           0.0000, -0.0158, -0.0021, -0.0099, -0.0059, -0.0038, -0.0032,\n",
      "          -0.0004, -0.0040,  0.0000, -0.0019, -0.0081, -0.0067, -0.0148,\n",
      "          -0.0406, -0.0026, -0.0040, -0.0179, -0.0056, -0.0180, -0.0090,\n",
      "          -0.0078,  0.0000, -0.0120, -0.0089,  0.0000,  0.0000, -0.0331,\n",
      "          -0.0037,  0.0000, -0.0234,  0.0000, -0.0253, -0.0001, -0.0055,\n",
      "          -0.0220, -0.0029, -0.0000, -0.0040,  0.0000,  0.0000, -0.0289,\n",
      "          -0.0077,  0.0000, -0.0091, -0.0041, -0.0105, -0.0020,  0.0000,\n",
      "          -0.0178, -0.0029,  0.0000, -0.0292, -0.0119, -0.0111, -0.0357,\n",
      "           0.0000, -0.0329, -0.0006, -0.0087, -0.0011, -0.0162, -0.0190,\n",
      "           0.0000, -0.0186,  0.0000, -0.0056, -0.0046, -0.0038, -0.0120,\n",
      "          -0.0206, -0.0027, -0.1294, -0.0033, -0.0032, -0.0107, -0.0048,\n",
      "          -0.0019, -0.0218, -0.0024, -0.0292, -0.0006, -0.0120, -0.0144,\n",
      "           0.0000,  0.0000, -0.0071, -0.0107, -0.0081, -0.0135,  0.0000,\n",
      "          -0.0037, -0.0084, -0.0091, -0.0040, -0.0022,  0.0000, -0.0076,\n",
      "          -0.0042, -0.0163, -0.0008,  0.0000, -0.0152,  0.0000, -0.0027,\n",
      "           0.0000, -0.0026, -0.0358, -0.0191,  0.0000, -0.0160, -0.0059,\n",
      "          -0.0160, -0.0363, -0.0003,  0.0000, -0.0127, -0.0050,  0.0000,\n",
      "          -0.0452, -0.0021, -0.0228, -0.0113,  0.0000, -0.0076, -0.0392,\n",
      "          -0.0001, -0.0214,  0.0000, -0.0054, -0.0086,  0.0000, -0.0192,\n",
      "          -0.0044, -0.0004, -0.0002, -0.0038, -0.0036, -0.0061, -0.0114,\n",
      "          -0.0017, -0.0178, -0.0047, -0.0038, -0.0000,  0.0000, -0.0223,\n",
      "          -0.0131, -0.0161, -0.0045, -0.0070, -0.0077,  0.0000, -0.0052,\n",
      "           0.0000, -0.0192, -0.0004, -0.0197, -0.0020,  0.0000, -0.0150,\n",
      "          -0.0029, -0.0001,  0.0000, -0.0004, -0.0040, -0.0087, -0.0025,\n",
      "          -0.0000, -0.0028, -0.0114, -0.0020, -0.0177, -0.0186, -0.0120,\n",
      "          -0.0164, -0.0196,  0.0000,  0.0000,  0.0000, -0.0257, -0.0122,\n",
      "           0.0000, -0.0037, -0.0250, -0.0005,  0.0000, -0.0017, -0.0000,\n",
      "          -0.0029, -0.0017, -0.0349, -0.0023, -0.0069, -0.0412,  0.0000,\n",
      "           0.0000, -0.0093, -0.0109, -0.0135, -0.0074, -0.0004, -0.0037,\n",
      "          -0.0091, -0.0018, -0.0043, -0.0007, -0.0036, -0.0052, -0.0030,\n",
      "          -0.0029, -0.0128, -0.0014, -0.0079, -0.0176, -0.0093, -0.0237,\n",
      "          -0.0268,  0.0000,  0.0000, -0.0169, -0.0033, -0.0036, -0.0002,\n",
      "          -0.0004, -0.0034, -0.0304, -0.0079, -0.0033, -0.0020,  0.0000,\n",
      "          -0.0030, -0.0538, -0.0006, -0.0170, -0.0186, -0.0019, -0.0093,\n",
      "          -0.0003, -0.0017,  0.0000, -0.0146, -0.0030, -0.0201, -0.0036,\n",
      "           0.0000, -0.0423, -0.0051, -0.0207, -0.0202, -0.0036, -0.0045,\n",
      "          -0.0053, -0.0027,  0.0000, -0.0095,  0.0000, -0.0010, -0.0231,\n",
      "           0.0000, -0.0010, -0.0142, -0.0002,  0.0000,  0.0000, -0.0037,\n",
      "          -0.0288, -0.0000, -0.0285, -0.0114,  0.0000, -0.1030,  0.0000,\n",
      "          -0.0189, -0.0012,  0.0000,  0.0000, -0.0072,  0.0000, -0.0220,\n",
      "          -0.0050, -0.0015,  0.0000,  0.0000,  0.0000, -0.0008, -0.0125,\n",
      "          -0.0087, -0.0028, -0.0013,  0.0000,  0.0000, -0.0219, -0.0177,\n",
      "          -0.0063, -0.0035,  0.0000, -0.0055, -0.0121,  0.0000, -0.0274,\n",
      "           0.0000,  0.0000,  0.0000, -0.0000, -0.0036, -0.0140, -0.0232,\n",
      "          -0.0059, -0.0140,  0.0000, -0.0230, -0.0007, -0.0274, -0.0015,\n",
      "          -0.0015,  0.0000, -0.0069,  0.0000, -0.0104, -0.0076, -0.0140,\n",
      "          -0.0000, -0.0088,  0.0000,  0.0000,  0.0000, -0.0217, -0.0011,\n",
      "          -0.0149, -0.0115, -0.0367, -0.0017,  0.0000,  0.0000, -0.0127,\n",
      "          -0.0055, -0.0041,  0.0000, -0.0270, -0.0001, -0.0025, -0.0019,\n",
      "          -0.0220, -0.0039, -0.0196, -0.0075,  0.0000, -0.0363, -0.0030,\n",
      "          -0.0208, -0.0002, -0.0011, -0.0146, -0.0070, -0.0471, -0.0145,\n",
      "           0.0000]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-02 *\n",
      "       [[-2.2109,  2.5224, -2.1350,  9.9453, -3.0743, -1.2323,  2.0631,\n",
      "         -2.3698,  5.2773]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 448, 512])\n",
      "tensor([[ 1.4927e-03, -5.0566e-03, -3.2910e-03,  ...,  1.2184e-03,\n",
      "         -4.4352e-03, -2.8716e-04],\n",
      "        [ 5.6337e-04, -2.9258e-04,  4.9355e-03,  ...,  1.0268e-03,\n",
      "          8.8470e-04, -2.4463e-03],\n",
      "        [ 1.2706e-03,  8.5958e-04,  5.3679e-03,  ...,  3.4800e-03,\n",
      "          1.8753e-03,  4.7968e-04],\n",
      "        ...,\n",
      "        [ 8.3634e-04, -2.8376e-04, -1.6318e-03,  ...,  1.5227e-03,\n",
      "         -6.3785e-04, -3.9603e-04],\n",
      "        [-5.5679e-04, -2.1375e-03, -4.6717e-03,  ...,  1.5922e-03,\n",
      "          1.5163e-03, -2.2918e-03],\n",
      "        [-3.4869e-03, -3.6529e-03, -4.0580e-03,  ..., -3.1138e-03,\n",
      "         -2.7280e-03, -1.8556e-03]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 448, 512])\n",
      "tensor([[ 1.4927e-04, -5.0565e-04, -3.2910e-04,  ...,  1.2184e-04,\n",
      "         -4.4352e-04, -2.8716e-05],\n",
      "        [ 5.6337e-05, -2.9258e-05,  4.9355e-04,  ...,  1.0268e-04,\n",
      "          8.8470e-05, -2.4463e-04],\n",
      "        [ 1.2706e-04,  8.5958e-05,  5.3679e-04,  ...,  3.4800e-04,\n",
      "          1.8753e-04,  4.7968e-05],\n",
      "        ...,\n",
      "        [-1.8034e-04, -3.2977e-04,  3.0418e-04,  ..., -2.6781e-04,\n",
      "         -3.4260e-04, -4.5330e-04],\n",
      "        [-1.7754e-04, -9.2671e-05,  1.0705e-04,  ..., -4.8442e-05,\n",
      "          1.6195e-04, -4.6104e-05],\n",
      "        [-3.7877e-04,  1.9521e-04,  5.8186e-05,  ..., -2.9765e-04,\n",
      "         -8.9574e-05,  1.8593e-04]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 1.9603, Accuracy: 2529/5000 (50.00%)\n",
      "\n",
      "the time of this epoch:[38.9338538646698 s]\n",
      "Train Epoch: 36 [0/50000 (0%)]\tLoss: 0.291750, Accuracy: 90.62\n",
      "Train Epoch: 36 [2560/50000 (6%)]\tLoss: 0.274418, Accuracy: 91.80\n",
      "Train Epoch: 36 [5120/50000 (11%)]\tLoss: 0.261432, Accuracy: 91.02\n",
      "Train Epoch: 36 [7680/50000 (17%)]\tLoss: 0.250964, Accuracy: 91.41\n",
      "Train Epoch: 36 [10240/50000 (23%)]\tLoss: 0.360120, Accuracy: 89.45\n",
      "Train Epoch: 36 [12800/50000 (28%)]\tLoss: 0.248869, Accuracy: 90.82\n",
      "Train Epoch: 36 [15360/50000 (34%)]\tLoss: 0.321396, Accuracy: 87.89\n",
      "Train Epoch: 36 [17920/50000 (40%)]\tLoss: 0.331538, Accuracy: 89.45\n",
      "Train Epoch: 36 [20480/50000 (45%)]\tLoss: 0.386341, Accuracy: 87.50\n",
      "Train Epoch: 36 [23040/50000 (51%)]\tLoss: 0.308836, Accuracy: 90.04\n",
      "Train Epoch: 36 [25600/50000 (57%)]\tLoss: 0.246571, Accuracy: 90.62\n",
      "Train Epoch: 36 [28160/50000 (62%)]\tLoss: 0.349726, Accuracy: 89.26\n",
      "Train Epoch: 36 [30720/50000 (68%)]\tLoss: 0.284181, Accuracy: 90.43\n",
      "Train Epoch: 36 [33280/50000 (74%)]\tLoss: 0.340816, Accuracy: 85.74\n",
      "Train Epoch: 36 [35840/50000 (80%)]\tLoss: 0.346261, Accuracy: 87.30\n",
      "Train Epoch: 36 [38400/50000 (85%)]\tLoss: 0.296663, Accuracy: 90.23\n",
      "Train Epoch: 36 [40960/50000 (91%)]\tLoss: 0.302762, Accuracy: 89.45\n",
      "Train Epoch: 36 [43520/50000 (97%)]\tLoss: 0.312246, Accuracy: 88.28\n",
      "\n",
      "Validation set: Average loss: 1.3371, Accuracy: 3441/5000 (68.00%)\n",
      "\n",
      "the time of this epoch:[35.61565804481506 s]\n",
      "\n",
      "Test set: Average loss: 1.3666, Accuracy: 6857/10000 (68.57%)\n",
      "\n",
      "Train Epoch: 37 [0/50000 (0%)]\tLoss: 0.255569, Accuracy: 91.41\n",
      "Train Epoch: 37 [2560/50000 (6%)]\tLoss: 0.286866, Accuracy: 89.84\n",
      "Train Epoch: 37 [5120/50000 (11%)]\tLoss: 0.285711, Accuracy: 91.02\n",
      "Train Epoch: 37 [7680/50000 (17%)]\tLoss: 0.269541, Accuracy: 90.23\n",
      "Train Epoch: 37 [10240/50000 (23%)]\tLoss: 0.274706, Accuracy: 89.84\n",
      "Train Epoch: 37 [12800/50000 (28%)]\tLoss: 0.331143, Accuracy: 89.45\n",
      "Train Epoch: 37 [15360/50000 (34%)]\tLoss: 0.392840, Accuracy: 86.72\n",
      "Train Epoch: 37 [17920/50000 (40%)]\tLoss: 0.336074, Accuracy: 87.30\n",
      "Train Epoch: 37 [20480/50000 (45%)]\tLoss: 0.292273, Accuracy: 88.67\n",
      "Train Epoch: 37 [23040/50000 (51%)]\tLoss: 0.314499, Accuracy: 89.65\n",
      "Train Epoch: 37 [25600/50000 (57%)]\tLoss: 0.302858, Accuracy: 90.43\n",
      "Train Epoch: 37 [28160/50000 (62%)]\tLoss: 0.282802, Accuracy: 91.41\n",
      "Train Epoch: 37 [30720/50000 (68%)]\tLoss: 0.368419, Accuracy: 86.91\n",
      "Train Epoch: 37 [33280/50000 (74%)]\tLoss: 0.277009, Accuracy: 90.43\n",
      "Train Epoch: 37 [35840/50000 (80%)]\tLoss: 0.295650, Accuracy: 88.48\n",
      "Train Epoch: 37 [38400/50000 (85%)]\tLoss: 0.335249, Accuracy: 89.06\n",
      "Train Epoch: 37 [40960/50000 (91%)]\tLoss: 0.329789, Accuracy: 89.26\n",
      "Train Epoch: 37 [43520/50000 (97%)]\tLoss: 0.347145, Accuracy: 89.06\n",
      "\n",
      "Validation set: Average loss: 1.4823, Accuracy: 3072/5000 (61.00%)\n",
      "\n",
      "the time of this epoch:[39.10303544998169 s]\n",
      "Train Epoch: 38 [0/50000 (0%)]\tLoss: 0.281458, Accuracy: 90.62\n",
      "Train Epoch: 38 [2560/50000 (6%)]\tLoss: 0.246078, Accuracy: 91.41\n",
      "Train Epoch: 38 [5120/50000 (11%)]\tLoss: 0.242618, Accuracy: 92.58\n",
      "Train Epoch: 38 [7680/50000 (17%)]\tLoss: 0.286083, Accuracy: 90.04\n",
      "Train Epoch: 38 [10240/50000 (23%)]\tLoss: 0.327356, Accuracy: 90.62\n",
      "Train Epoch: 38 [12800/50000 (28%)]\tLoss: 0.260084, Accuracy: 90.43\n",
      "Train Epoch: 38 [15360/50000 (34%)]\tLoss: 0.319749, Accuracy: 88.87\n",
      "Train Epoch: 38 [17920/50000 (40%)]\tLoss: 0.260453, Accuracy: 92.19\n",
      "Train Epoch: 38 [20480/50000 (45%)]\tLoss: 0.228468, Accuracy: 92.97\n",
      "Train Epoch: 38 [23040/50000 (51%)]\tLoss: 0.311622, Accuracy: 89.26\n",
      "Train Epoch: 38 [25600/50000 (57%)]\tLoss: 0.289818, Accuracy: 90.62\n",
      "Train Epoch: 38 [28160/50000 (62%)]\tLoss: 0.271652, Accuracy: 91.02\n",
      "Train Epoch: 38 [30720/50000 (68%)]\tLoss: 0.327619, Accuracy: 88.28\n",
      "Train Epoch: 38 [33280/50000 (74%)]\tLoss: 0.278481, Accuracy: 90.04\n",
      "Train Epoch: 38 [35840/50000 (80%)]\tLoss: 0.290524, Accuracy: 88.87\n",
      "Train Epoch: 38 [38400/50000 (85%)]\tLoss: 0.269571, Accuracy: 92.19\n",
      "Train Epoch: 38 [40960/50000 (91%)]\tLoss: 0.298534, Accuracy: 90.04\n",
      "Train Epoch: 38 [43520/50000 (97%)]\tLoss: 0.285904, Accuracy: 89.06\n",
      "\n",
      "Validation set: Average loss: 1.4293, Accuracy: 3243/5000 (64.00%)\n",
      "\n",
      "the time of this epoch:[35.97376537322998 s]\n",
      "\n",
      "Test set: Average loss: 1.5051, Accuracy: 6396/10000 (63.96%)\n",
      "\n",
      "Train Epoch: 39 [0/50000 (0%)]\tLoss: 0.277841, Accuracy: 90.43\n",
      "Train Epoch: 39 [2560/50000 (6%)]\tLoss: 0.238799, Accuracy: 91.41\n",
      "Train Epoch: 39 [5120/50000 (11%)]\tLoss: 0.280150, Accuracy: 89.84\n",
      "Train Epoch: 39 [7680/50000 (17%)]\tLoss: 0.235870, Accuracy: 91.99\n",
      "Train Epoch: 39 [10240/50000 (23%)]\tLoss: 0.403181, Accuracy: 86.13\n",
      "Train Epoch: 39 [12800/50000 (28%)]\tLoss: 0.319670, Accuracy: 87.30\n",
      "Train Epoch: 39 [15360/50000 (34%)]\tLoss: 0.324067, Accuracy: 89.26\n",
      "Train Epoch: 39 [17920/50000 (40%)]\tLoss: 0.311117, Accuracy: 90.62\n",
      "Train Epoch: 39 [20480/50000 (45%)]\tLoss: 0.244304, Accuracy: 90.62\n",
      "Train Epoch: 39 [23040/50000 (51%)]\tLoss: 0.298919, Accuracy: 90.04\n",
      "Train Epoch: 39 [25600/50000 (57%)]\tLoss: 0.244679, Accuracy: 92.77\n",
      "Train Epoch: 39 [28160/50000 (62%)]\tLoss: 0.296471, Accuracy: 90.43\n",
      "Train Epoch: 39 [30720/50000 (68%)]\tLoss: 0.297519, Accuracy: 90.23\n",
      "Train Epoch: 39 [33280/50000 (74%)]\tLoss: 0.250168, Accuracy: 92.58\n",
      "Train Epoch: 39 [35840/50000 (80%)]\tLoss: 0.313510, Accuracy: 90.04\n",
      "Train Epoch: 39 [38400/50000 (85%)]\tLoss: 0.250408, Accuracy: 91.60\n",
      "Train Epoch: 39 [40960/50000 (91%)]\tLoss: 0.290305, Accuracy: 89.65\n",
      "Train Epoch: 39 [43520/50000 (97%)]\tLoss: 0.285808, Accuracy: 91.21\n",
      "\n",
      "Validation set: Average loss: 3.2857, Accuracy: 2220/5000 (44.00%)\n",
      "\n",
      "the time of this epoch:[39.571829319000244 s]\n",
      "Train Epoch: 40 [0/50000 (0%)]\tLoss: 0.258575, Accuracy: 91.60\n",
      "Train Epoch: 40 [2560/50000 (6%)]\tLoss: 0.260870, Accuracy: 91.80\n",
      "Train Epoch: 40 [5120/50000 (11%)]\tLoss: 0.232119, Accuracy: 91.02\n",
      "Train Epoch: 40 [7680/50000 (17%)]\tLoss: 0.236000, Accuracy: 93.36\n",
      "Train Epoch: 40 [10240/50000 (23%)]\tLoss: 0.238134, Accuracy: 91.21\n",
      "Train Epoch: 40 [12800/50000 (28%)]\tLoss: 0.242851, Accuracy: 90.82\n",
      "Train Epoch: 40 [15360/50000 (34%)]\tLoss: 0.265591, Accuracy: 90.62\n",
      "Train Epoch: 40 [17920/50000 (40%)]\tLoss: 0.319426, Accuracy: 89.06\n",
      "Train Epoch: 40 [20480/50000 (45%)]\tLoss: 0.277990, Accuracy: 89.26\n",
      "Train Epoch: 40 [23040/50000 (51%)]\tLoss: 0.310057, Accuracy: 89.26\n",
      "Train Epoch: 40 [25600/50000 (57%)]\tLoss: 0.334819, Accuracy: 87.70\n",
      "Train Epoch: 40 [28160/50000 (62%)]\tLoss: 0.273351, Accuracy: 89.84\n",
      "Train Epoch: 40 [30720/50000 (68%)]\tLoss: 0.282969, Accuracy: 90.43\n",
      "Train Epoch: 40 [33280/50000 (74%)]\tLoss: 0.281753, Accuracy: 90.23\n",
      "Train Epoch: 40 [35840/50000 (80%)]\tLoss: 0.325551, Accuracy: 88.28\n",
      "Train Epoch: 40 [38400/50000 (85%)]\tLoss: 0.257171, Accuracy: 91.02\n",
      "Train Epoch: 40 [40960/50000 (91%)]\tLoss: 0.333544, Accuracy: 89.84\n",
      "Train Epoch: 40 [43520/50000 (97%)]\tLoss: 0.244558, Accuracy: 91.60\n",
      "\n",
      "Validation set: Average loss: 1.5865, Accuracy: 2902/5000 (58.00%)\n",
      "\n",
      "the time of this epoch:[36.226436614990234 s]\n",
      "\n",
      "Test set: Average loss: 1.6613, Accuracy: 5838/10000 (58.38%)\n",
      "\n",
      "Train Epoch: 41 [0/50000 (0%)]\tLoss: 0.215352, Accuracy: 91.60\n",
      "Train Epoch: 41 [2560/50000 (6%)]\tLoss: 0.281283, Accuracy: 89.84\n",
      "Train Epoch: 41 [5120/50000 (11%)]\tLoss: 0.295055, Accuracy: 90.43\n",
      "Train Epoch: 41 [7680/50000 (17%)]\tLoss: 0.277333, Accuracy: 91.02\n",
      "Train Epoch: 41 [10240/50000 (23%)]\tLoss: 0.205601, Accuracy: 93.75\n",
      "Train Epoch: 41 [12800/50000 (28%)]\tLoss: 0.248196, Accuracy: 90.82\n",
      "Train Epoch: 41 [15360/50000 (34%)]\tLoss: 0.299683, Accuracy: 89.65\n",
      "Train Epoch: 41 [17920/50000 (40%)]\tLoss: 0.252857, Accuracy: 91.99\n",
      "Train Epoch: 41 [20480/50000 (45%)]\tLoss: 0.299438, Accuracy: 90.62\n",
      "Train Epoch: 41 [23040/50000 (51%)]\tLoss: 0.390208, Accuracy: 87.30\n",
      "Train Epoch: 41 [25600/50000 (57%)]\tLoss: 0.291955, Accuracy: 90.23\n",
      "Train Epoch: 41 [28160/50000 (62%)]\tLoss: 0.268433, Accuracy: 90.23\n",
      "Train Epoch: 41 [30720/50000 (68%)]\tLoss: 0.257107, Accuracy: 91.80\n",
      "Train Epoch: 41 [33280/50000 (74%)]\tLoss: 0.257031, Accuracy: 92.19\n",
      "Train Epoch: 41 [35840/50000 (80%)]\tLoss: 0.264407, Accuracy: 91.21\n",
      "Train Epoch: 41 [38400/50000 (85%)]\tLoss: 0.288666, Accuracy: 90.82\n",
      "Train Epoch: 41 [40960/50000 (91%)]\tLoss: 0.297358, Accuracy: 89.45\n",
      "Train Epoch: 41 [43520/50000 (97%)]\tLoss: 0.282203, Accuracy: 91.21\n",
      "\n",
      "Validation set: Average loss: 0.9577, Accuracy: 3731/5000 (74.00%)\n",
      "\n",
      "the time of this epoch:[39.36857080459595 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 42 [0/50000 (0%)]\tLoss: 0.250382, Accuracy: 91.41\n",
      "Train Epoch: 42 [2560/50000 (6%)]\tLoss: 0.267630, Accuracy: 91.80\n",
      "Train Epoch: 42 [5120/50000 (11%)]\tLoss: 0.355480, Accuracy: 87.70\n",
      "Train Epoch: 42 [7680/50000 (17%)]\tLoss: 0.230709, Accuracy: 91.99\n",
      "Train Epoch: 42 [10240/50000 (23%)]\tLoss: 0.263617, Accuracy: 92.77\n",
      "Train Epoch: 42 [12800/50000 (28%)]\tLoss: 0.245998, Accuracy: 91.80\n",
      "Train Epoch: 42 [15360/50000 (34%)]\tLoss: 0.247542, Accuracy: 91.21\n",
      "Train Epoch: 42 [17920/50000 (40%)]\tLoss: 0.258517, Accuracy: 90.62\n",
      "Train Epoch: 42 [20480/50000 (45%)]\tLoss: 0.247924, Accuracy: 92.38\n",
      "Train Epoch: 42 [23040/50000 (51%)]\tLoss: 0.278645, Accuracy: 89.26\n",
      "Train Epoch: 42 [25600/50000 (57%)]\tLoss: 0.261265, Accuracy: 92.19\n",
      "Train Epoch: 42 [28160/50000 (62%)]\tLoss: 0.284159, Accuracy: 91.41\n",
      "Train Epoch: 42 [30720/50000 (68%)]\tLoss: 0.257122, Accuracy: 91.80\n",
      "Train Epoch: 42 [33280/50000 (74%)]\tLoss: 0.306357, Accuracy: 90.23\n",
      "Train Epoch: 42 [35840/50000 (80%)]\tLoss: 0.260161, Accuracy: 91.41\n",
      "Train Epoch: 42 [38400/50000 (85%)]\tLoss: 0.291530, Accuracy: 90.82\n",
      "Train Epoch: 42 [40960/50000 (91%)]\tLoss: 0.286254, Accuracy: 91.21\n",
      "Train Epoch: 42 [43520/50000 (97%)]\tLoss: 0.318470, Accuracy: 89.65\n",
      "\n",
      "Validation set: Average loss: 1.1968, Accuracy: 3360/5000 (67.00%)\n",
      "\n",
      "the time of this epoch:[36.39030861854553 s]\n",
      "\n",
      "Test set: Average loss: 1.1355, Accuracy: 6921/10000 (69.21%)\n",
      "\n",
      "Train Epoch: 43 [0/50000 (0%)]\tLoss: 0.241943, Accuracy: 91.21\n",
      "Train Epoch: 43 [2560/50000 (6%)]\tLoss: 0.240243, Accuracy: 91.02\n",
      "Train Epoch: 43 [5120/50000 (11%)]\tLoss: 0.238524, Accuracy: 90.82\n",
      "Train Epoch: 43 [7680/50000 (17%)]\tLoss: 0.243373, Accuracy: 91.41\n",
      "Train Epoch: 43 [10240/50000 (23%)]\tLoss: 0.219840, Accuracy: 93.16\n",
      "Train Epoch: 43 [12800/50000 (28%)]\tLoss: 0.338743, Accuracy: 88.09\n",
      "Train Epoch: 43 [15360/50000 (34%)]\tLoss: 0.256642, Accuracy: 91.60\n",
      "Train Epoch: 43 [17920/50000 (40%)]\tLoss: 0.338058, Accuracy: 88.87\n",
      "Train Epoch: 43 [20480/50000 (45%)]\tLoss: 0.237844, Accuracy: 91.41\n",
      "Train Epoch: 43 [23040/50000 (51%)]\tLoss: 0.233252, Accuracy: 91.80\n",
      "Train Epoch: 43 [25600/50000 (57%)]\tLoss: 0.280106, Accuracy: 90.04\n",
      "Train Epoch: 43 [28160/50000 (62%)]\tLoss: 0.305566, Accuracy: 90.43\n",
      "Train Epoch: 43 [30720/50000 (68%)]\tLoss: 0.293184, Accuracy: 90.43\n",
      "Train Epoch: 43 [33280/50000 (74%)]\tLoss: 0.307402, Accuracy: 90.62\n",
      "Train Epoch: 43 [35840/50000 (80%)]\tLoss: 0.233102, Accuracy: 92.38\n",
      "Train Epoch: 43 [38400/50000 (85%)]\tLoss: 0.227675, Accuracy: 92.58\n",
      "Train Epoch: 43 [40960/50000 (91%)]\tLoss: 0.257308, Accuracy: 89.65\n",
      "Train Epoch: 43 [43520/50000 (97%)]\tLoss: 0.297406, Accuracy: 90.23\n",
      "\n",
      "Validation set: Average loss: 6.3169, Accuracy: 868/5000 (17.00%)\n",
      "\n",
      "the time of this epoch:[40.874844789505005 s]\n",
      "Train Epoch: 44 [0/50000 (0%)]\tLoss: 0.260744, Accuracy: 91.41\n",
      "Train Epoch: 44 [2560/50000 (6%)]\tLoss: 0.209364, Accuracy: 92.58\n",
      "Train Epoch: 44 [5120/50000 (11%)]\tLoss: 0.242605, Accuracy: 91.80\n",
      "Train Epoch: 44 [7680/50000 (17%)]\tLoss: 0.254008, Accuracy: 91.21\n",
      "Train Epoch: 44 [10240/50000 (23%)]\tLoss: 0.272012, Accuracy: 89.65\n",
      "Train Epoch: 44 [12800/50000 (28%)]\tLoss: 0.239835, Accuracy: 91.80\n",
      "Train Epoch: 44 [15360/50000 (34%)]\tLoss: 0.307290, Accuracy: 88.48\n",
      "Train Epoch: 44 [17920/50000 (40%)]\tLoss: 0.250881, Accuracy: 90.82\n",
      "Train Epoch: 44 [20480/50000 (45%)]\tLoss: 0.306921, Accuracy: 89.84\n",
      "Train Epoch: 44 [23040/50000 (51%)]\tLoss: 0.327677, Accuracy: 88.48\n",
      "Train Epoch: 44 [25600/50000 (57%)]\tLoss: 0.299721, Accuracy: 91.80\n",
      "Train Epoch: 44 [28160/50000 (62%)]\tLoss: 0.253340, Accuracy: 92.97\n",
      "Train Epoch: 44 [30720/50000 (68%)]\tLoss: 0.279806, Accuracy: 89.45\n",
      "Train Epoch: 44 [33280/50000 (74%)]\tLoss: 0.298867, Accuracy: 90.23\n",
      "Train Epoch: 44 [35840/50000 (80%)]\tLoss: 0.331153, Accuracy: 89.26\n",
      "Train Epoch: 44 [38400/50000 (85%)]\tLoss: 0.314804, Accuracy: 89.65\n",
      "Train Epoch: 44 [40960/50000 (91%)]\tLoss: 0.291376, Accuracy: 90.43\n",
      "Train Epoch: 44 [43520/50000 (97%)]\tLoss: 0.395367, Accuracy: 87.89\n",
      "\n",
      "Validation set: Average loss: 1.3110, Accuracy: 2953/5000 (59.00%)\n",
      "\n",
      "the time of this epoch:[37.21977686882019 s]\n",
      "\n",
      "Test set: Average loss: 1.3150, Accuracy: 5876/10000 (58.76%)\n",
      "\n",
      "Train Epoch: 45 [0/50000 (0%)]\tLoss: 0.290888, Accuracy: 91.21\n",
      "Train Epoch: 45 [2560/50000 (6%)]\tLoss: 0.315330, Accuracy: 88.48\n",
      "Train Epoch: 45 [5120/50000 (11%)]\tLoss: 0.293392, Accuracy: 89.45\n",
      "Train Epoch: 45 [7680/50000 (17%)]\tLoss: 0.324347, Accuracy: 88.28\n",
      "Train Epoch: 45 [10240/50000 (23%)]\tLoss: 0.281935, Accuracy: 89.65\n",
      "Train Epoch: 45 [12800/50000 (28%)]\tLoss: 0.290548, Accuracy: 89.84\n",
      "Train Epoch: 45 [15360/50000 (34%)]\tLoss: 0.267612, Accuracy: 90.62\n",
      "Train Epoch: 45 [17920/50000 (40%)]\tLoss: 0.255300, Accuracy: 92.19\n",
      "Train Epoch: 45 [20480/50000 (45%)]\tLoss: 0.266006, Accuracy: 90.62\n",
      "Train Epoch: 45 [23040/50000 (51%)]\tLoss: 0.247518, Accuracy: 91.80\n",
      "Train Epoch: 45 [25600/50000 (57%)]\tLoss: 0.313940, Accuracy: 90.82\n",
      "Train Epoch: 45 [28160/50000 (62%)]\tLoss: 0.270863, Accuracy: 91.02\n",
      "Train Epoch: 45 [30720/50000 (68%)]\tLoss: 0.317730, Accuracy: 89.45\n",
      "Train Epoch: 45 [33280/50000 (74%)]\tLoss: 0.253674, Accuracy: 91.60\n",
      "Train Epoch: 45 [35840/50000 (80%)]\tLoss: 0.275830, Accuracy: 91.21\n",
      "Train Epoch: 45 [38400/50000 (85%)]\tLoss: 0.307910, Accuracy: 90.23\n",
      "Train Epoch: 45 [40960/50000 (91%)]\tLoss: 0.237784, Accuracy: 91.80\n",
      "Train Epoch: 45 [43520/50000 (97%)]\tLoss: 0.226858, Accuracy: 92.58\n",
      "\n",
      "Validation set: Average loss: 1.0361, Accuracy: 3395/5000 (67.00%)\n",
      "\n",
      "the time of this epoch:[40.69509768486023 s]\n",
      "Train Epoch: 46 [0/50000 (0%)]\tLoss: 0.220132, Accuracy: 93.16\n",
      "Train Epoch: 46 [2560/50000 (6%)]\tLoss: 0.268890, Accuracy: 92.58\n",
      "Train Epoch: 46 [5120/50000 (11%)]\tLoss: 0.240874, Accuracy: 92.19\n",
      "Train Epoch: 46 [7680/50000 (17%)]\tLoss: 0.265642, Accuracy: 91.02\n",
      "Train Epoch: 46 [10240/50000 (23%)]\tLoss: 0.232151, Accuracy: 92.58\n",
      "Train Epoch: 46 [12800/50000 (28%)]\tLoss: 0.313987, Accuracy: 90.04\n",
      "Train Epoch: 46 [15360/50000 (34%)]\tLoss: 0.239523, Accuracy: 91.02\n",
      "Train Epoch: 46 [17920/50000 (40%)]\tLoss: 0.281905, Accuracy: 89.84\n",
      "Train Epoch: 46 [20480/50000 (45%)]\tLoss: 0.266597, Accuracy: 90.82\n",
      "Train Epoch: 46 [23040/50000 (51%)]\tLoss: 0.210082, Accuracy: 93.55\n",
      "Train Epoch: 46 [25600/50000 (57%)]\tLoss: 0.255953, Accuracy: 91.41\n",
      "Train Epoch: 46 [28160/50000 (62%)]\tLoss: 0.183084, Accuracy: 93.95\n",
      "Train Epoch: 46 [30720/50000 (68%)]\tLoss: 0.269392, Accuracy: 91.21\n",
      "Train Epoch: 46 [33280/50000 (74%)]\tLoss: 0.223469, Accuracy: 91.99\n",
      "Train Epoch: 46 [35840/50000 (80%)]\tLoss: 0.314790, Accuracy: 89.65\n",
      "Train Epoch: 46 [38400/50000 (85%)]\tLoss: 0.196836, Accuracy: 92.97\n",
      "Train Epoch: 46 [40960/50000 (91%)]\tLoss: 0.287738, Accuracy: 90.23\n",
      "Train Epoch: 46 [43520/50000 (97%)]\tLoss: 0.259869, Accuracy: 89.84\n",
      "\n",
      "Validation set: Average loss: 1.3824, Accuracy: 3457/5000 (69.00%)\n",
      "\n",
      "the time of this epoch:[36.415464878082275 s]\n",
      "\n",
      "Test set: Average loss: 1.4653, Accuracy: 6678/10000 (66.78%)\n",
      "\n",
      "Train Epoch: 47 [0/50000 (0%)]\tLoss: 0.232295, Accuracy: 91.80\n",
      "Train Epoch: 47 [2560/50000 (6%)]\tLoss: 0.198124, Accuracy: 94.14\n",
      "Train Epoch: 47 [5120/50000 (11%)]\tLoss: 0.261169, Accuracy: 90.04\n",
      "Train Epoch: 47 [7680/50000 (17%)]\tLoss: 0.264786, Accuracy: 91.41\n",
      "Train Epoch: 47 [10240/50000 (23%)]\tLoss: 0.198185, Accuracy: 92.77\n",
      "Train Epoch: 47 [12800/50000 (28%)]\tLoss: 0.207673, Accuracy: 92.19\n",
      "Train Epoch: 47 [15360/50000 (34%)]\tLoss: 0.246687, Accuracy: 89.65\n",
      "Train Epoch: 47 [17920/50000 (40%)]\tLoss: 0.288701, Accuracy: 89.45\n",
      "Train Epoch: 47 [20480/50000 (45%)]\tLoss: 0.312527, Accuracy: 90.62\n",
      "Train Epoch: 47 [23040/50000 (51%)]\tLoss: 0.216515, Accuracy: 93.36\n",
      "Train Epoch: 47 [25600/50000 (57%)]\tLoss: 0.309845, Accuracy: 90.23\n",
      "Train Epoch: 47 [28160/50000 (62%)]\tLoss: 0.301112, Accuracy: 90.04\n",
      "Train Epoch: 47 [30720/50000 (68%)]\tLoss: 0.265206, Accuracy: 90.82\n",
      "Train Epoch: 47 [33280/50000 (74%)]\tLoss: 0.258781, Accuracy: 91.02\n",
      "Train Epoch: 47 [35840/50000 (80%)]\tLoss: 0.316224, Accuracy: 89.84\n",
      "Train Epoch: 47 [38400/50000 (85%)]\tLoss: 0.311656, Accuracy: 87.70\n",
      "Train Epoch: 47 [40960/50000 (91%)]\tLoss: 0.281080, Accuracy: 90.43\n",
      "Train Epoch: 47 [43520/50000 (97%)]\tLoss: 0.249803, Accuracy: 91.80\n",
      "\n",
      "Validation set: Average loss: 8.3077, Accuracy: 485/5000 (9.00%)\n",
      "\n",
      "the time of this epoch:[39.42196035385132 s]\n",
      "Train Epoch: 48 [0/50000 (0%)]\tLoss: 0.228816, Accuracy: 92.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 48 [2560/50000 (6%)]\tLoss: 0.241858, Accuracy: 91.99\n",
      "Train Epoch: 48 [5120/50000 (11%)]\tLoss: 0.239063, Accuracy: 92.38\n",
      "Train Epoch: 48 [7680/50000 (17%)]\tLoss: 0.264350, Accuracy: 91.02\n",
      "Train Epoch: 48 [10240/50000 (23%)]\tLoss: 0.289782, Accuracy: 89.84\n",
      "Train Epoch: 48 [12800/50000 (28%)]\tLoss: 0.292412, Accuracy: 89.65\n",
      "Train Epoch: 48 [15360/50000 (34%)]\tLoss: 0.209965, Accuracy: 93.36\n",
      "Train Epoch: 48 [17920/50000 (40%)]\tLoss: 0.236119, Accuracy: 90.82\n",
      "Train Epoch: 48 [20480/50000 (45%)]\tLoss: 0.254522, Accuracy: 91.41\n",
      "Train Epoch: 48 [23040/50000 (51%)]\tLoss: 0.234620, Accuracy: 91.80\n",
      "Train Epoch: 48 [25600/50000 (57%)]\tLoss: 0.236416, Accuracy: 91.41\n",
      "Train Epoch: 48 [28160/50000 (62%)]\tLoss: 0.255361, Accuracy: 90.82\n",
      "Train Epoch: 48 [30720/50000 (68%)]\tLoss: 0.246539, Accuracy: 91.21\n",
      "Train Epoch: 48 [33280/50000 (74%)]\tLoss: 0.294043, Accuracy: 89.65\n",
      "Train Epoch: 48 [35840/50000 (80%)]\tLoss: 0.258401, Accuracy: 91.21\n",
      "Train Epoch: 48 [38400/50000 (85%)]\tLoss: 0.264855, Accuracy: 92.19\n",
      "Train Epoch: 48 [40960/50000 (91%)]\tLoss: 0.249778, Accuracy: 91.60\n",
      "Train Epoch: 48 [43520/50000 (97%)]\tLoss: 0.311967, Accuracy: 88.67\n",
      "\n",
      "Validation set: Average loss: 1.6271, Accuracy: 3222/5000 (64.00%)\n",
      "\n",
      "the time of this epoch:[36.046326637268066 s]\n",
      "\n",
      "Test set: Average loss: 1.4268, Accuracy: 6723/10000 (67.23%)\n",
      "\n",
      "Train Epoch: 49 [0/50000 (0%)]\tLoss: 0.306010, Accuracy: 88.67\n",
      "Train Epoch: 49 [2560/50000 (6%)]\tLoss: 0.250766, Accuracy: 91.80\n",
      "Train Epoch: 49 [5120/50000 (11%)]\tLoss: 0.254563, Accuracy: 91.21\n",
      "Train Epoch: 49 [7680/50000 (17%)]\tLoss: 0.288901, Accuracy: 90.62\n",
      "Train Epoch: 49 [10240/50000 (23%)]\tLoss: 0.214399, Accuracy: 92.97\n",
      "Train Epoch: 49 [12800/50000 (28%)]\tLoss: 0.262901, Accuracy: 92.19\n",
      "Train Epoch: 49 [15360/50000 (34%)]\tLoss: 0.318473, Accuracy: 89.45\n",
      "Train Epoch: 49 [17920/50000 (40%)]\tLoss: 0.241906, Accuracy: 91.99\n",
      "Train Epoch: 49 [20480/50000 (45%)]\tLoss: 0.214780, Accuracy: 92.38\n",
      "Train Epoch: 49 [23040/50000 (51%)]\tLoss: 0.279179, Accuracy: 90.23\n",
      "Train Epoch: 49 [25600/50000 (57%)]\tLoss: 0.281690, Accuracy: 91.02\n",
      "Train Epoch: 49 [28160/50000 (62%)]\tLoss: 0.256604, Accuracy: 91.21\n",
      "Train Epoch: 49 [30720/50000 (68%)]\tLoss: 0.317542, Accuracy: 89.45\n",
      "Train Epoch: 49 [33280/50000 (74%)]\tLoss: 0.314296, Accuracy: 90.04\n",
      "Train Epoch: 49 [35840/50000 (80%)]\tLoss: 0.210097, Accuracy: 92.58\n",
      "Train Epoch: 49 [38400/50000 (85%)]\tLoss: 0.258657, Accuracy: 90.43\n",
      "Train Epoch: 49 [40960/50000 (91%)]\tLoss: 0.294439, Accuracy: 90.43\n",
      "Train Epoch: 49 [43520/50000 (97%)]\tLoss: 0.281374, Accuracy: 89.65\n",
      "\n",
      "Validation set: Average loss: 1.1384, Accuracy: 3394/5000 (67.00%)\n",
      "\n",
      "the time of this epoch:[39.30608773231506 s]\n",
      "Train Epoch: 50 [0/50000 (0%)]\tLoss: 0.210849, Accuracy: 94.14\n",
      "Train Epoch: 50 [2560/50000 (6%)]\tLoss: 0.302730, Accuracy: 90.43\n",
      "Train Epoch: 50 [5120/50000 (11%)]\tLoss: 0.193844, Accuracy: 93.95\n",
      "Train Epoch: 50 [7680/50000 (17%)]\tLoss: 0.195218, Accuracy: 94.14\n",
      "Train Epoch: 50 [10240/50000 (23%)]\tLoss: 0.239161, Accuracy: 90.82\n",
      "Train Epoch: 50 [12800/50000 (28%)]\tLoss: 0.213710, Accuracy: 91.60\n",
      "Train Epoch: 50 [15360/50000 (34%)]\tLoss: 0.246406, Accuracy: 91.02\n",
      "Train Epoch: 50 [17920/50000 (40%)]\tLoss: 0.320758, Accuracy: 88.28\n",
      "Train Epoch: 50 [20480/50000 (45%)]\tLoss: 0.304975, Accuracy: 89.65\n",
      "Train Epoch: 50 [23040/50000 (51%)]\tLoss: 0.257122, Accuracy: 91.02\n",
      "Train Epoch: 50 [25600/50000 (57%)]\tLoss: 0.247840, Accuracy: 91.21\n",
      "Train Epoch: 50 [28160/50000 (62%)]\tLoss: 0.277562, Accuracy: 89.84\n",
      "Train Epoch: 50 [30720/50000 (68%)]\tLoss: 0.263723, Accuracy: 91.21\n",
      "Train Epoch: 50 [33280/50000 (74%)]\tLoss: 0.320686, Accuracy: 89.65\n",
      "Train Epoch: 50 [35840/50000 (80%)]\tLoss: 0.234973, Accuracy: 91.21\n",
      "Train Epoch: 50 [38400/50000 (85%)]\tLoss: 0.285747, Accuracy: 90.82\n",
      "Train Epoch: 50 [40960/50000 (91%)]\tLoss: 0.307440, Accuracy: 88.48\n",
      "Train Epoch: 50 [43520/50000 (97%)]\tLoss: 0.271175, Accuracy: 90.23\n",
      "\n",
      "Validation set: Average loss: 1.1582, Accuracy: 3515/5000 (70.00%)\n",
      "\n",
      "the time of this epoch:[37.13801646232605 s]\n",
      "\n",
      "Test set: Average loss: 1.1351, Accuracy: 7092/10000 (70.92%)\n",
      "\n",
      "Train Epoch: 51 [0/50000 (0%)]\tLoss: 0.257353, Accuracy: 90.62\n",
      "Train Epoch: 51 [2560/50000 (6%)]\tLoss: 0.215365, Accuracy: 91.41\n",
      "Train Epoch: 51 [5120/50000 (11%)]\tLoss: 0.293922, Accuracy: 89.84\n",
      "Train Epoch: 51 [7680/50000 (17%)]\tLoss: 0.267545, Accuracy: 91.21\n",
      "Train Epoch: 51 [10240/50000 (23%)]\tLoss: 0.237651, Accuracy: 91.60\n",
      "Train Epoch: 51 [12800/50000 (28%)]\tLoss: 0.218974, Accuracy: 91.80\n",
      "Train Epoch: 51 [15360/50000 (34%)]\tLoss: 0.259040, Accuracy: 90.82\n",
      "Train Epoch: 51 [17920/50000 (40%)]\tLoss: 0.339497, Accuracy: 89.26\n",
      "Train Epoch: 51 [20480/50000 (45%)]\tLoss: 0.262128, Accuracy: 91.02\n",
      "Train Epoch: 51 [23040/50000 (51%)]\tLoss: 0.257714, Accuracy: 91.41\n",
      "Train Epoch: 51 [25600/50000 (57%)]\tLoss: 0.263019, Accuracy: 90.43\n",
      "Train Epoch: 51 [28160/50000 (62%)]\tLoss: 0.226780, Accuracy: 92.19\n",
      "Train Epoch: 51 [30720/50000 (68%)]\tLoss: 0.247462, Accuracy: 91.21\n",
      "Train Epoch: 51 [33280/50000 (74%)]\tLoss: 0.302375, Accuracy: 90.82\n",
      "Train Epoch: 51 [35840/50000 (80%)]\tLoss: 0.289533, Accuracy: 91.02\n",
      "Train Epoch: 51 [38400/50000 (85%)]\tLoss: 0.307965, Accuracy: 88.67\n",
      "Train Epoch: 51 [40960/50000 (91%)]\tLoss: 0.300578, Accuracy: 88.67\n",
      "Train Epoch: 51 [43520/50000 (97%)]\tLoss: 0.234603, Accuracy: 91.02\n",
      "\n",
      "Validation set: Average loss: 1.4661, Accuracy: 3411/5000 (68.00%)\n",
      "\n",
      "the time of this epoch:[40.5214409828186 s]\n",
      "Train Epoch: 52 [0/50000 (0%)]\tLoss: 0.266198, Accuracy: 91.41\n",
      "Train Epoch: 52 [2560/50000 (6%)]\tLoss: 0.275033, Accuracy: 90.62\n",
      "Train Epoch: 52 [5120/50000 (11%)]\tLoss: 0.256117, Accuracy: 90.62\n",
      "Train Epoch: 52 [7680/50000 (17%)]\tLoss: 0.248798, Accuracy: 91.02\n",
      "Train Epoch: 52 [10240/50000 (23%)]\tLoss: 0.253949, Accuracy: 92.19\n",
      "Train Epoch: 52 [12800/50000 (28%)]\tLoss: 0.205508, Accuracy: 92.97\n",
      "Train Epoch: 52 [15360/50000 (34%)]\tLoss: 0.272255, Accuracy: 91.21\n",
      "Train Epoch: 52 [17920/50000 (40%)]\tLoss: 0.238789, Accuracy: 90.43\n",
      "Train Epoch: 52 [20480/50000 (45%)]\tLoss: 0.367809, Accuracy: 87.70\n",
      "Train Epoch: 52 [23040/50000 (51%)]\tLoss: 0.304413, Accuracy: 88.87\n",
      "Train Epoch: 52 [25600/50000 (57%)]\tLoss: 0.266070, Accuracy: 91.80\n",
      "Train Epoch: 52 [28160/50000 (62%)]\tLoss: 0.251548, Accuracy: 91.02\n",
      "Train Epoch: 52 [30720/50000 (68%)]\tLoss: 0.219488, Accuracy: 92.19\n",
      "Train Epoch: 52 [33280/50000 (74%)]\tLoss: 0.269157, Accuracy: 91.60\n",
      "Train Epoch: 52 [35840/50000 (80%)]\tLoss: 0.320148, Accuracy: 88.48\n",
      "Train Epoch: 52 [38400/50000 (85%)]\tLoss: 0.324967, Accuracy: 89.45\n",
      "Train Epoch: 52 [40960/50000 (91%)]\tLoss: 0.295749, Accuracy: 89.06\n",
      "Train Epoch: 52 [43520/50000 (97%)]\tLoss: 0.309818, Accuracy: 89.06\n",
      "\n",
      "Validation set: Average loss: 1.0324, Accuracy: 3408/5000 (68.00%)\n",
      "\n",
      "the time of this epoch:[35.85874581336975 s]\n",
      "\n",
      "Test set: Average loss: 1.1087, Accuracy: 6613/10000 (66.13%)\n",
      "\n",
      "Train Epoch: 53 [0/50000 (0%)]\tLoss: 0.217802, Accuracy: 92.77\n",
      "Train Epoch: 53 [2560/50000 (6%)]\tLoss: 0.264025, Accuracy: 90.82\n",
      "Train Epoch: 53 [5120/50000 (11%)]\tLoss: 0.218272, Accuracy: 93.16\n",
      "Train Epoch: 53 [7680/50000 (17%)]\tLoss: 0.257741, Accuracy: 91.02\n",
      "Train Epoch: 53 [10240/50000 (23%)]\tLoss: 0.214113, Accuracy: 91.60\n",
      "Train Epoch: 53 [12800/50000 (28%)]\tLoss: 0.240454, Accuracy: 91.80\n",
      "Train Epoch: 53 [15360/50000 (34%)]\tLoss: 0.208790, Accuracy: 92.58\n",
      "Train Epoch: 53 [17920/50000 (40%)]\tLoss: 0.229439, Accuracy: 92.97\n",
      "Train Epoch: 53 [20480/50000 (45%)]\tLoss: 0.226171, Accuracy: 92.19\n",
      "Train Epoch: 53 [23040/50000 (51%)]\tLoss: 0.196372, Accuracy: 92.97\n",
      "Train Epoch: 53 [25600/50000 (57%)]\tLoss: 0.222895, Accuracy: 91.99\n",
      "Train Epoch: 53 [28160/50000 (62%)]\tLoss: 0.312675, Accuracy: 89.84\n",
      "Train Epoch: 53 [30720/50000 (68%)]\tLoss: 0.305940, Accuracy: 89.45\n",
      "Train Epoch: 53 [33280/50000 (74%)]\tLoss: 0.231861, Accuracy: 91.41\n",
      "Train Epoch: 53 [35840/50000 (80%)]\tLoss: 0.219945, Accuracy: 91.99\n",
      "Train Epoch: 53 [38400/50000 (85%)]\tLoss: 0.319931, Accuracy: 89.45\n",
      "Train Epoch: 53 [40960/50000 (91%)]\tLoss: 0.335647, Accuracy: 88.87\n",
      "Train Epoch: 53 [43520/50000 (97%)]\tLoss: 0.354244, Accuracy: 88.87\n",
      "------------------------------\n",
      "before autoscale: torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.2377]],\n",
      "\n",
      "        [[ 4.1978]],\n",
      "\n",
      "        [[ 0.0050]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0074]],\n",
      "\n",
      "        [[ 0.2846]],\n",
      "\n",
      "        [[ 0.0140]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0424]],\n",
      "\n",
      "        [[ 1.3408]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[ 2.7465]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 512])\n",
      "tensor([[[  0.6528,  11.5294,   0.0137,   0.0000,   0.0204,   0.7816,\n",
      "            0.0384,   0.0000,   0.1166,   3.6826,   0.2532,   0.1374,\n",
      "            0.0000,   0.1088,   0.1365,   0.2219,   0.4999,   0.1090,\n",
      "            0.0997,   0.6722,   0.0082,   0.2905,   0.1753,   0.0100,\n",
      "            0.3922,   5.0984,   0.5089,   0.1981,   9.3035,   0.1626,\n",
      "            1.6405,   0.3964,   0.0487,   0.5346,   0.4569,   0.2448,\n",
      "           10.0786,   1.0108,   2.1077,   0.0000,   0.0000,   0.0000,\n",
      "            3.6216,   0.0502,   0.0416,   0.4832,   0.0502,   0.3263,\n",
      "            0.3131,  11.7680,   0.0711,   0.1806,   0.0617,   1.6178,\n",
      "            0.4999,   0.2568,   0.4277,   0.0124,   0.2813,   0.1615,\n",
      "            0.4434,   0.6079,   4.2681,   0.2734,   0.1020,   0.0000,\n",
      "           11.9877,   0.0719,   0.0009,   0.0000,   0.4680,   0.0000,\n",
      "            0.0362,   1.2731,   0.0000,   0.0371,   0.0005,   0.0009,\n",
      "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "            0.0000,   1.2525,   0.0057,   0.0000,   0.0000,   5.7881,\n",
      "            0.5289,   0.0246,   0.0067,   0.0000,   0.0000,   1.6590,\n",
      "            0.0005,   0.0000,   0.0087,   0.0433,   0.0000,   0.0971,\n",
      "            0.0000,   0.1063,   0.1757,   0.0406,   0.0000,   0.0902,\n",
      "            0.0000,   0.0000,   0.1652,   0.6165,   0.0000,   1.9557,\n",
      "            0.0000,   0.0000,   0.0000,   1.6236,   0.0000,   0.0000,\n",
      "            0.0000,   0.0001,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "            0.0000,   0.0000,   0.0067,   1.0295,   0.0000,   0.0043,\n",
      "            0.0066,   0.0025,   0.0026,   0.0026,   0.0000,   0.0000,\n",
      "            0.0000,   1.4897,   0.0000,   4.6380,   0.0000,   0.8089,\n",
      "            0.0000,   0.3990,   0.0000,   0.0005,   0.0001,   0.0406,\n",
      "            0.0119,   0.8920,   0.0000,   0.0000,   0.0001,   0.0000,\n",
      "            0.0000,   0.0061,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "            0.0145,   0.0009,   0.1033,   0.2724,   0.0061,   0.0230,\n",
      "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "            0.0107,   0.2101,   0.0000,   0.0000,  10.2235,   0.2734,\n",
      "            0.0000,   0.1946,   0.0000,   0.2215,   0.0000,   0.0000,\n",
      "            0.0021,   0.0002,   0.0000,   0.2233,   4.4390,   0.3241,\n",
      "            0.0000,   0.0076,   0.0000,   0.0000,   0.0000,   0.1135,\n",
      "           11.5409,   0.0000,   0.0000,   0.0000,   0.0230,   0.0126,\n",
      "            0.0000,   0.0000,   0.0000,   3.7645,   0.0000,   0.1452,\n",
      "            1.4561,   0.0000,   1.2406,   0.0020,   0.0067,   0.0000,\n",
      "            0.0000,   0.0000,   0.0215,   0.0000,   0.0297,   0.0000,\n",
      "            0.0000,   0.0000,   0.6167,   0.0000,   0.1263,   0.0000,\n",
      "            0.0204,   0.0010,   0.0003,   0.0647,   1.0185,   0.0000,\n",
      "            0.0590,   0.0000,   0.0000,   0.0681,   0.0000,   0.0000,\n",
      "            0.0150,   0.0000,   0.0000,  11.8356,   0.0000,   0.1446,\n",
      "            0.0000,   0.0167,   0.0065,   0.0201,   0.0000,   0.0000,\n",
      "            0.0140,   0.0000,   0.0027,   0.1529,   1.2614,   7.8474,\n",
      "            0.0010,   0.5028,   0.0000,   0.3358,   0.0000,   0.0778,\n",
      "            0.0000,   0.0005,   0.0803,   0.1352,   0.0972,   0.0356,\n",
      "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0680,\n",
      "            0.0752,   0.0000,   0.0000,   0.0000,   0.0008,   0.0325,\n",
      "            0.0000,   0.0000,   0.0000,  10.7328,   1.5131,   0.0641,\n",
      "            0.1269,   0.0000,   0.0000,   0.0000,   0.0896,   0.0323,\n",
      "            0.0312,   0.0468,   0.0009,   0.0000,   0.0000,   1.3951,\n",
      "            0.0047,   0.0000,   0.0000,   3.1428,   0.0000,   0.0000,\n",
      "            0.2419,   0.0002,   0.0007,   0.0000,   0.1427,   0.0009,\n",
      "            0.0000,   0.0000,   0.0000,   0.5255,   0.0000,   0.0000,\n",
      "            0.0000,   0.0454,   0.0019,   0.0000,   0.0000,   0.0000,\n",
      "            0.0013,   0.0000,   0.0000,   0.0000,   0.1328,   0.8936,\n",
      "           10.4779,   0.1739,   0.0021,   0.9062,   0.0000,   0.0001,\n",
      "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   1.6915,\n",
      "            0.0000,   0.2599,   0.0000,   0.2274,   0.0145,   2.3336,\n",
      "            0.0000,   0.0040,   0.0000,   0.0000,   0.0000,   1.0280,\n",
      "            0.0000,   0.0001,   0.4552,   0.0000,   0.1528,   0.0023,\n",
      "            0.3812,   0.0000,   0.0000,   0.0524,   0.1934,   0.1043,\n",
      "            0.0000,   0.0000,   0.0003,   0.0214,   0.0038,   0.0239,\n",
      "            0.0000,   0.3822,   0.1157,   0.0000,   0.0009,   0.0815,\n",
      "            0.0000,   0.0137,   0.0000,   0.0189,   0.0000,   0.0317,\n",
      "            0.4125,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "            0.0000,   0.0000,   0.1262,   0.0000,   0.0000,   0.0000,\n",
      "            0.1017,   0.0000,   0.0002,   0.9884,   0.0014,   0.0000,\n",
      "            0.0000,   0.0000,   0.0000,   0.4933,   0.0000,   0.0124,\n",
      "            1.0330,   0.0695,   0.0000,   2.8045,   0.0011,   1.2021,\n",
      "            0.0000,   0.0002,   1.2145,   0.0000,   0.0000,   0.0000,\n",
      "            0.0208,   0.0000,   0.0000,   0.2265,   0.0000,   0.0340,\n",
      "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,  11.0223,\n",
      "            0.0000,   0.3268,   0.0000,   0.0000,   0.0000,   0.0028,\n",
      "            0.0042,   0.0000,   0.0273,   0.0005,   0.3135,   0.0109,\n",
      "            0.1915,   0.0000,   0.0692,   0.0000,   0.0000,   0.0000,\n",
      "            0.0000,   1.9963,   0.0050,   0.0289,   0.0533,   0.3044,\n",
      "            0.0000,   0.0000,   0.0000,   0.0000,   3.1070,   0.0009,\n",
      "            0.0000,   0.0213,   0.0282,   0.0000,   0.0000,   0.0000,\n",
      "            0.0000,  11.3316,   0.3435,   0.0000,   0.0000,   0.2396,\n",
      "            0.0013,   0.0507,   0.0000,   0.0000,   0.0265,   0.2328,\n",
      "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0049,\n",
      "            0.0000,   0.2376,   0.0648,   0.0674,   0.0000,   0.0000,\n",
      "            0.0000,   0.0000,   0.0000,   0.0000,   0.0106,   0.0038,\n",
      "            0.3198,   0.0000,   0.0002,   0.0242,   0.0002,   0.1851,\n",
      "            0.5654,   0.0000,   0.0000,   0.0000,   0.0640,   0.0735,\n",
      "            0.0000,   0.0343]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-02 *\n",
      "       [[-0.9415, -1.6485, -2.3489,  0.6979,  2.9390,  0.9281,  2.5414,\n",
      "          3.0964, -0.8076]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 896, 512])\n",
      "tensor([[ 1.2637e-01,  3.3786e-01,  8.9943e-02,  ...,  3.4783e-03,\n",
      "         -6.7274e-04, -1.7739e-03],\n",
      "        [ 2.2344e-02,  1.1707e-01,  2.8955e-01,  ...,  1.9457e-03,\n",
      "          1.0037e-03, -2.0267e-03],\n",
      "        [-8.6460e-02, -2.7837e-01,  2.9715e-01,  ..., -1.1293e-03,\n",
      "          2.6933e-03,  1.2881e-03],\n",
      "        ...,\n",
      "        [ 2.3144e-01,  3.1048e-01,  1.6553e-01,  ...,  3.5500e-03,\n",
      "          3.3457e-03,  3.9911e-03],\n",
      "        [-1.0920e-01, -2.5615e-01,  2.7986e-01,  ..., -4.4717e-04,\n",
      "          1.0991e-03, -2.9931e-03],\n",
      "        [ 2.9993e-01, -2.0264e-01,  1.2894e-01,  ..., -2.5754e-03,\n",
      "          3.7868e-03,  6.7542e-04]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 896, 512])\n",
      "tensor([[ 1.2570e-02,  3.2556e-02,  8.9701e-03,  ...,  3.4782e-04,\n",
      "         -6.7274e-05, -1.7739e-04],\n",
      "        [ 2.2340e-03,  1.1653e-02,  2.8172e-02,  ...,  1.9457e-04,\n",
      "          1.0037e-04, -2.0267e-04],\n",
      "        [-8.6245e-03, -2.7140e-02,  2.8870e-02,  ..., -1.1293e-04,\n",
      "          2.6933e-04,  1.2881e-04],\n",
      "        ...,\n",
      "        [-3.3089e-02,  1.2462e-02,  8.4374e-03,  ...,  1.2909e-04,\n",
      "         -1.5304e-04, -9.8211e-06],\n",
      "        [-3.1685e-02, -2.2768e-02,  3.4302e-02,  ..., -4.4027e-05,\n",
      "          2.7314e-04, -5.4772e-05],\n",
      "        [ 3.0166e-02, -2.0700e-02, -2.7630e-02,  ..., -2.7113e-04,\n",
      "         -9.7985e-05, -1.6292e-04]], device='cuda:0')\n",
      "\n",
      "Validation set: Average loss: 1.2915, Accuracy: 3449/5000 (68.00%)\n",
      "\n",
      "the time of this epoch:[39.55405831336975 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 54 [0/50000 (0%)]\tLoss: 0.274261, Accuracy: 91.21\n",
      "Train Epoch: 54 [2560/50000 (6%)]\tLoss: 0.184618, Accuracy: 93.36\n",
      "Train Epoch: 54 [5120/50000 (11%)]\tLoss: 0.267924, Accuracy: 91.21\n",
      "Train Epoch: 54 [7680/50000 (17%)]\tLoss: 0.283890, Accuracy: 91.41\n",
      "Train Epoch: 54 [10240/50000 (23%)]\tLoss: 0.239126, Accuracy: 91.21\n",
      "Train Epoch: 54 [12800/50000 (28%)]\tLoss: 0.212529, Accuracy: 93.95\n",
      "Train Epoch: 54 [15360/50000 (34%)]\tLoss: 0.269323, Accuracy: 91.80\n",
      "Train Epoch: 54 [17920/50000 (40%)]\tLoss: 0.301041, Accuracy: 91.41\n",
      "Train Epoch: 54 [20480/50000 (45%)]\tLoss: 0.255673, Accuracy: 90.43\n",
      "Train Epoch: 54 [23040/50000 (51%)]\tLoss: 0.283988, Accuracy: 90.62\n",
      "Train Epoch: 54 [25600/50000 (57%)]\tLoss: 0.270693, Accuracy: 91.21\n",
      "Train Epoch: 54 [28160/50000 (62%)]\tLoss: 0.288442, Accuracy: 89.26\n",
      "Train Epoch: 54 [30720/50000 (68%)]\tLoss: 0.268029, Accuracy: 91.21\n",
      "Train Epoch: 54 [33280/50000 (74%)]\tLoss: 0.302758, Accuracy: 89.45\n",
      "Train Epoch: 54 [35840/50000 (80%)]\tLoss: 0.240904, Accuracy: 92.19\n",
      "Train Epoch: 54 [38400/50000 (85%)]\tLoss: 0.269101, Accuracy: 91.99\n",
      "Train Epoch: 54 [40960/50000 (91%)]\tLoss: 0.310347, Accuracy: 88.48\n",
      "Train Epoch: 54 [43520/50000 (97%)]\tLoss: 0.245537, Accuracy: 91.99\n",
      "\n",
      "Validation set: Average loss: 3.8631, Accuracy: 668/5000 (13.00%)\n",
      "\n",
      "the time of this epoch:[36.11216497421265 s]\n",
      "------------------------------\n",
      "before autoscale: torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.0669]],\n",
      "\n",
      "        [[ 5.3724]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0038]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0109]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0033]],\n",
      "\n",
      "        [[ 0.0068]],\n",
      "\n",
      "        [[ 1.6857]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[ 2.6290]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 512])\n",
      "tensor([[[  0.1758,  14.1239,   0.0000,   0.0099,   0.0000,   0.0286,\n",
      "            0.0000,   0.0086,   0.0179,   4.4316,   0.0048,   0.0004,\n",
      "            0.0541,   0.0000,   0.1186,   0.2069,   0.3758,   0.3894,\n",
      "            1.9339,   0.5923,   0.6413,   0.1714,   0.0000,   0.0000,\n",
      "            0.0119,   4.4611,   0.1066,   0.0263,  13.4897,   0.0000,\n",
      "            0.0585,   0.3428,   0.0000,   0.2372,   0.4529,   0.4544,\n",
      "           13.1861,   1.0421,   3.5540,   0.0000,   0.0000,   0.0000,\n",
      "            5.2838,   0.0000,   0.4484,   0.5898,   0.0000,   0.3416,\n",
      "            0.0885,  15.0276,   0.0000,   0.0006,   0.0000,   0.0010,\n",
      "            0.4932,   0.3767,   0.4296,   0.0000,   0.4045,   0.0000,\n",
      "            0.0262,   0.0518,   7.2999,   0.0019,   0.0757,   0.0000,\n",
      "           15.5302,   0.1623,   0.0057,   0.0000,   1.4472,   0.0000,\n",
      "            0.1199,   2.0053,   0.0000,   0.0348,   0.0000,   0.0000,\n",
      "            0.0000,   0.1052,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "            0.0000,   0.1539,   0.0000,   0.0000,   3.5460,  13.5175,\n",
      "            0.5403,   0.0000,   0.0000,   0.0000,   0.0000,   6.8070,\n",
      "            0.0000,   0.0000,   0.0086,   0.0488,   0.0000,   0.1063,\n",
      "            0.0000,   0.1014,   3.1312,   0.0000,   0.0000,   0.1211,\n",
      "            0.0000,   0.0000,   0.0140,   2.1217,   0.0000,   1.9717,\n",
      "            0.0000,   0.0000,   0.0000,   7.5587,   0.0000,   0.0000,\n",
      "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "            0.0000,   0.0000,   0.0117,   3.5606,   0.0000,   0.0000,\n",
      "            0.0086,   0.0000,   0.0054,   0.0000,   0.0000,   0.0000,\n",
      "            0.0000,  12.0383,   2.6898,  13.0761,   0.0000,   4.2525,\n",
      "            0.0000,   1.7037,   0.0000,   0.0015,   0.0000,   0.0076,\n",
      "            0.0114,   2.6232,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "            0.0000,   0.0069,   0.0000,   0.0000,   0.0000,   0.0001,\n",
      "            0.1183,   0.0000,   0.0876,   0.6294,   0.0000,   0.0096,\n",
      "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "            0.0000,   0.2114,   0.0000,   0.0000,  13.3931,   0.0161,\n",
      "            0.0000,   0.3955,   0.0000,   0.2145,   0.0000,   0.0000,\n",
      "            0.0000,   0.0000,   6.4787,   0.1914,  11.6763,   0.7957,\n",
      "            0.0000,   0.0415,   0.0000,   0.0000,   0.0217,   0.0012,\n",
      "           15.2551,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "            0.0000,   0.1118,   0.0000,   9.9121,   0.0000,   0.0780,\n",
      "            4.0804,   0.0000,   5.2293,   0.0000,   0.0000,   0.0000,\n",
      "            0.0000,   0.0000,   0.0118,   0.0000,   0.0171,   0.0000,\n",
      "            0.0000,   0.0000,   2.4822,   0.0000,   0.1670,   0.1789,\n",
      "            0.0010,   0.0000,   0.0812,   0.0702,   4.6939,   0.0000,\n",
      "            0.0139,   0.0000,   0.0000,   0.0786,   0.0000,   0.0000,\n",
      "            0.0000,   0.0000,   0.0000,  15.2416,   0.0000,   0.0106,\n",
      "            0.0000,   0.0000,   0.0000,   0.0042,   0.0000,   0.0000,\n",
      "            0.0048,   0.0000,   0.0000,   0.5224,   2.5024,  13.2914,\n",
      "            0.0080,   0.1025,   0.0000,   0.4375,   0.0000,   0.0000,\n",
      "            0.1107,   0.0000,   0.0792,   0.1232,   0.0973,   0.0000,\n",
      "            0.2282,   0.0000,   0.0000,   0.0000,   0.0000,   0.0751,\n",
      "            0.0103,   0.0000,   0.0000,   0.0000,   0.0038,   0.0513,\n",
      "            0.0000,   0.0000,   0.0000,  14.7582,   3.4537,   0.0941,\n",
      "            0.0000,   0.0000,   0.0000,   0.0003,   0.2328,   0.0332,\n",
      "            0.0373,   0.0000,   0.0000,   0.0000,   0.0000,   1.8804,\n",
      "            0.0000,   0.0000,   0.0000,  10.4635,   0.0000,   0.0000,\n",
      "            0.0179,   0.0045,   0.0015,   0.0000,   0.0401,   0.0000,\n",
      "            0.0000,   0.0000,   0.0206,   0.2147,   0.0000,   0.0000,\n",
      "            0.0000,   0.0000,   0.0040,   0.0000,   0.0000,   0.0000,\n",
      "            0.0000,   0.0000,   0.0000,   0.0000,   0.1483,   2.6120,\n",
      "           14.5709,   0.3045,   0.0059,   0.9872,   0.0000,   0.0008,\n",
      "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   4.1562,\n",
      "            0.0000,   0.3181,   0.0000,   1.6198,   0.0000,   8.6869,\n",
      "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   3.1249,\n",
      "            0.0000,   0.0000,   1.6780,   0.0000,   0.1553,   0.0003,\n",
      "            0.3543,   0.0000,   0.0000,   0.0678,   0.0976,   0.0000,\n",
      "            0.0000,   0.0000,   0.0824,   0.0000,   0.0000,   0.0158,\n",
      "            0.0000,   0.3202,   0.1413,   0.0000,   0.0000,   0.0439,\n",
      "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0304,\n",
      "            7.1704,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "            0.0000,   0.0000,   0.1818,   0.0000,   0.0000,   0.0000,\n",
      "            0.0954,   0.0000,   0.0000,   3.3786,   0.0000,   0.0000,\n",
      "            0.0000,   0.0000,   0.0000,   1.5011,   0.0000,   0.0000,\n",
      "            0.7193,   0.0655,   0.0000,   3.4430,   0.0000,   5.9221,\n",
      "            0.0000,   0.0000,   7.1309,   0.0000,   0.0000,   0.0000,\n",
      "            0.0028,   0.0000,   0.0000,   0.8324,   0.0000,   0.0362,\n",
      "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,  14.7375,\n",
      "            0.0000,   1.2597,   0.0000,   0.0007,   0.0000,   0.0000,\n",
      "            0.0026,   0.0000,   0.0314,   0.0000,   0.5359,   0.0033,\n",
      "            0.3789,   0.0000,   0.0650,   0.0000,   0.0000,   2.6149,\n",
      "            0.0000,   2.2370,   0.0000,   0.0228,   0.0526,   0.9432,\n",
      "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "            0.0000,   0.0000,   0.5916,   0.0000,   0.0000,   0.0000,\n",
      "            0.0000,  15.3611,   0.0000,   0.0000,   0.0000,   0.2323,\n",
      "            0.0005,   0.0053,   0.0000,   0.0000,   0.0210,   0.5535,\n",
      "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "            0.0000,   0.0013,   0.0571,   0.0139,   0.0000,   0.0000,\n",
      "            0.0000,   0.0000,   0.0000,   0.0000,   0.0110,   0.0000,\n",
      "            0.6719,   0.0000,   0.0000,   0.0295,   0.0000,   0.1668,\n",
      "            4.1300,   0.0000,   0.0000,   0.0000,   0.2667,   0.0070,\n",
      "            0.0000,   0.0340]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-02 *\n",
      "       [[-0.9007, -1.5772, -2.2473,  0.6677,  2.8119,  0.8880,  2.4315,\n",
      "          2.9625, -0.7727]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 896, 512])\n",
      "tensor([[ 0.1307,  0.3983,  0.0913,  ...,  0.0028, -0.0056, -0.0034],\n",
      "        [ 0.0279,  0.1113,  0.3175,  ...,  0.0059, -0.0035, -0.0050],\n",
      "        [-0.0871, -0.3476,  0.3302,  ...,  0.0053,  0.0045,  0.0028],\n",
      "        ...,\n",
      "        [ 0.2554,  0.3544,  0.1741,  ...,  0.0042,  0.0078,  0.0052],\n",
      "        [-0.1137, -0.3040,  0.3330,  ...,  0.0058, -0.0020, -0.0075],\n",
      "        [ 0.3934, -0.2560,  0.0066,  ..., -0.0014,  0.0122, -0.0073]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 896, 512])\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 1.2991,  3.7854,  0.9104,  ...,  0.0280, -0.0564, -0.0341],\n",
      "        [ 0.2785,  1.1085,  3.0721,  ...,  0.0588, -0.0352, -0.0501],\n",
      "        [-0.8686, -3.3429,  3.1866,  ...,  0.0527,  0.0446,  0.0280],\n",
      "        ...,\n",
      "        [-3.8789,  1.2896,  1.2046,  ...,  0.0244, -0.0555,  0.0385],\n",
      "        [-3.5489, -2.8023,  3.8366,  ...,  0.0672,  0.0531, -0.0658],\n",
      "        [ 3.5821, -2.2573, -3.1494,  ..., -0.0621,  0.0008, -0.0401]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.8159, Accuracy: 1331/10000 (13.31%)\n",
      "\n",
      "Train Epoch: 55 [0/50000 (0%)]\tLoss: 0.282766, Accuracy: 91.02\n",
      "Train Epoch: 55 [2560/50000 (6%)]\tLoss: 0.194701, Accuracy: 94.34\n",
      "Train Epoch: 55 [5120/50000 (11%)]\tLoss: 0.221152, Accuracy: 92.77\n",
      "Train Epoch: 55 [7680/50000 (17%)]\tLoss: 0.200402, Accuracy: 93.75\n",
      "Train Epoch: 55 [10240/50000 (23%)]\tLoss: 0.235327, Accuracy: 93.16\n",
      "Train Epoch: 55 [12800/50000 (28%)]\tLoss: 0.225638, Accuracy: 90.43\n",
      "Train Epoch: 55 [15360/50000 (34%)]\tLoss: 0.224108, Accuracy: 92.77\n",
      "Train Epoch: 55 [17920/50000 (40%)]\tLoss: 0.205645, Accuracy: 93.55\n",
      "Train Epoch: 55 [20480/50000 (45%)]\tLoss: 0.246684, Accuracy: 91.41\n",
      "Train Epoch: 55 [23040/50000 (51%)]\tLoss: 0.302204, Accuracy: 88.67\n",
      "Train Epoch: 55 [25600/50000 (57%)]\tLoss: 0.266676, Accuracy: 91.21\n",
      "Train Epoch: 55 [28160/50000 (62%)]\tLoss: 0.227943, Accuracy: 92.38\n",
      "Train Epoch: 55 [30720/50000 (68%)]\tLoss: 0.307903, Accuracy: 89.45\n",
      "Train Epoch: 55 [33280/50000 (74%)]\tLoss: 0.269146, Accuracy: 90.62\n",
      "Train Epoch: 55 [35840/50000 (80%)]\tLoss: 0.232467, Accuracy: 92.97\n",
      "Train Epoch: 55 [38400/50000 (85%)]\tLoss: 0.274264, Accuracy: 91.80\n",
      "Train Epoch: 55 [40960/50000 (91%)]\tLoss: 0.241047, Accuracy: 91.21\n",
      "Train Epoch: 55 [43520/50000 (97%)]\tLoss: 0.228497, Accuracy: 91.60\n",
      "\n",
      "Validation set: Average loss: 1.2164, Accuracy: 3179/5000 (63.00%)\n",
      "\n",
      "the time of this epoch:[40.2304208278656 s]\n",
      "Train Epoch: 56 [0/50000 (0%)]\tLoss: 0.230690, Accuracy: 93.36\n",
      "Train Epoch: 56 [2560/50000 (6%)]\tLoss: 0.208486, Accuracy: 93.95\n",
      "Train Epoch: 56 [5120/50000 (11%)]\tLoss: 0.231955, Accuracy: 92.58\n",
      "Train Epoch: 56 [7680/50000 (17%)]\tLoss: 0.189585, Accuracy: 93.16\n",
      "Train Epoch: 56 [10240/50000 (23%)]\tLoss: 0.287926, Accuracy: 89.45\n",
      "Train Epoch: 56 [12800/50000 (28%)]\tLoss: 0.226491, Accuracy: 92.58\n",
      "Train Epoch: 56 [15360/50000 (34%)]\tLoss: 0.243696, Accuracy: 91.80\n",
      "Train Epoch: 56 [17920/50000 (40%)]\tLoss: 0.252844, Accuracy: 92.38\n",
      "Train Epoch: 56 [20480/50000 (45%)]\tLoss: 0.206198, Accuracy: 92.38\n",
      "Train Epoch: 56 [23040/50000 (51%)]\tLoss: 0.293065, Accuracy: 91.21\n",
      "Train Epoch: 56 [25600/50000 (57%)]\tLoss: 0.307725, Accuracy: 89.45\n",
      "Train Epoch: 56 [28160/50000 (62%)]\tLoss: 0.346143, Accuracy: 88.09\n",
      "Train Epoch: 56 [30720/50000 (68%)]\tLoss: 0.270124, Accuracy: 89.84\n",
      "Train Epoch: 56 [33280/50000 (74%)]\tLoss: 0.343588, Accuracy: 87.30\n",
      "Train Epoch: 56 [35840/50000 (80%)]\tLoss: 0.286071, Accuracy: 91.21\n",
      "Train Epoch: 56 [38400/50000 (85%)]\tLoss: 0.284634, Accuracy: 88.87\n",
      "Train Epoch: 56 [40960/50000 (91%)]\tLoss: 0.252564, Accuracy: 92.38\n",
      "Train Epoch: 56 [43520/50000 (97%)]\tLoss: 0.268322, Accuracy: 91.60\n",
      "\n",
      "Validation set: Average loss: 0.9634, Accuracy: 3699/5000 (73.00%)\n",
      "\n",
      "the time of this epoch:[36.9931206703186 s]\n",
      "\n",
      "Test set: Average loss: 0.9475, Accuracy: 7344/10000 (73.44%)\n",
      "\n",
      "Train Epoch: 57 [0/50000 (0%)]\tLoss: 0.247670, Accuracy: 90.04\n",
      "Train Epoch: 57 [2560/50000 (6%)]\tLoss: 0.257179, Accuracy: 91.99\n",
      "Train Epoch: 57 [5120/50000 (11%)]\tLoss: 0.227055, Accuracy: 92.19\n",
      "Train Epoch: 57 [7680/50000 (17%)]\tLoss: 0.241195, Accuracy: 89.84\n",
      "Train Epoch: 57 [10240/50000 (23%)]\tLoss: 0.175913, Accuracy: 94.14\n",
      "Train Epoch: 57 [12800/50000 (28%)]\tLoss: 0.206195, Accuracy: 93.16\n",
      "Train Epoch: 57 [15360/50000 (34%)]\tLoss: 0.180840, Accuracy: 93.55\n",
      "Train Epoch: 57 [17920/50000 (40%)]\tLoss: 0.281780, Accuracy: 91.80\n",
      "Train Epoch: 57 [20480/50000 (45%)]\tLoss: 0.275615, Accuracy: 89.84\n",
      "Train Epoch: 57 [23040/50000 (51%)]\tLoss: 0.254585, Accuracy: 90.23\n",
      "Train Epoch: 57 [25600/50000 (57%)]\tLoss: 0.208256, Accuracy: 92.38\n",
      "Train Epoch: 57 [28160/50000 (62%)]\tLoss: 0.263221, Accuracy: 90.04\n",
      "Train Epoch: 57 [30720/50000 (68%)]\tLoss: 0.248379, Accuracy: 92.38\n",
      "Train Epoch: 57 [33280/50000 (74%)]\tLoss: 0.264357, Accuracy: 90.23\n",
      "Train Epoch: 57 [35840/50000 (80%)]\tLoss: 0.304841, Accuracy: 90.82\n",
      "Train Epoch: 57 [38400/50000 (85%)]\tLoss: 0.302475, Accuracy: 90.04\n",
      "Train Epoch: 57 [40960/50000 (91%)]\tLoss: 0.213138, Accuracy: 91.99\n",
      "Train Epoch: 57 [43520/50000 (97%)]\tLoss: 0.273258, Accuracy: 90.82\n",
      "\n",
      "Validation set: Average loss: 1.0350, Accuracy: 3694/5000 (73.00%)\n",
      "\n",
      "the time of this epoch:[39.369757890701294 s]\n",
      "Train Epoch: 58 [0/50000 (0%)]\tLoss: 0.185685, Accuracy: 94.34\n",
      "Train Epoch: 58 [2560/50000 (6%)]\tLoss: 0.231637, Accuracy: 91.41\n",
      "Train Epoch: 58 [5120/50000 (11%)]\tLoss: 0.208515, Accuracy: 91.80\n",
      "Train Epoch: 58 [7680/50000 (17%)]\tLoss: 0.192254, Accuracy: 93.55\n",
      "Train Epoch: 58 [10240/50000 (23%)]\tLoss: 0.272815, Accuracy: 91.41\n",
      "Train Epoch: 58 [12800/50000 (28%)]\tLoss: 0.241248, Accuracy: 90.82\n",
      "Train Epoch: 58 [15360/50000 (34%)]\tLoss: 0.229872, Accuracy: 92.19\n",
      "Train Epoch: 58 [17920/50000 (40%)]\tLoss: 0.246519, Accuracy: 91.02\n",
      "Train Epoch: 58 [20480/50000 (45%)]\tLoss: 0.281521, Accuracy: 90.04\n",
      "Train Epoch: 58 [23040/50000 (51%)]\tLoss: 0.297214, Accuracy: 91.21\n",
      "Train Epoch: 58 [25600/50000 (57%)]\tLoss: 0.278118, Accuracy: 89.65\n",
      "Train Epoch: 58 [28160/50000 (62%)]\tLoss: 0.307686, Accuracy: 89.26\n",
      "Train Epoch: 58 [30720/50000 (68%)]\tLoss: 0.233009, Accuracy: 91.80\n",
      "Train Epoch: 58 [33280/50000 (74%)]\tLoss: 0.232132, Accuracy: 92.58\n",
      "Train Epoch: 58 [35840/50000 (80%)]\tLoss: 0.249454, Accuracy: 92.19\n",
      "Train Epoch: 58 [38400/50000 (85%)]\tLoss: 0.268918, Accuracy: 90.62\n",
      "Train Epoch: 58 [40960/50000 (91%)]\tLoss: 0.216911, Accuracy: 92.97\n",
      "Train Epoch: 58 [43520/50000 (97%)]\tLoss: 0.252974, Accuracy: 90.23\n",
      "\n",
      "Validation set: Average loss: 1.0824, Accuracy: 3456/5000 (69.00%)\n",
      "\n",
      "the time of this epoch:[35.80547738075256 s]\n",
      "\n",
      "Test set: Average loss: 0.9305, Accuracy: 7355/10000 (73.55%)\n",
      "\n",
      "Train Epoch: 59 [0/50000 (0%)]\tLoss: 0.232769, Accuracy: 92.97\n",
      "Train Epoch: 59 [2560/50000 (6%)]\tLoss: 0.214503, Accuracy: 92.77\n",
      "Train Epoch: 59 [5120/50000 (11%)]\tLoss: 0.183727, Accuracy: 93.55\n",
      "Train Epoch: 59 [7680/50000 (17%)]\tLoss: 0.225692, Accuracy: 90.82\n",
      "Train Epoch: 59 [10240/50000 (23%)]\tLoss: 0.209230, Accuracy: 93.36\n",
      "Train Epoch: 59 [12800/50000 (28%)]\tLoss: 0.279120, Accuracy: 90.43\n",
      "Train Epoch: 59 [15360/50000 (34%)]\tLoss: 0.221204, Accuracy: 92.19\n",
      "Train Epoch: 59 [17920/50000 (40%)]\tLoss: 0.256695, Accuracy: 91.21\n",
      "Train Epoch: 59 [20480/50000 (45%)]\tLoss: 0.203764, Accuracy: 92.77\n",
      "Train Epoch: 59 [23040/50000 (51%)]\tLoss: 0.258195, Accuracy: 90.82\n",
      "Train Epoch: 59 [25600/50000 (57%)]\tLoss: 0.230355, Accuracy: 92.97\n",
      "Train Epoch: 59 [28160/50000 (62%)]\tLoss: 0.269317, Accuracy: 90.43\n",
      "Train Epoch: 59 [30720/50000 (68%)]\tLoss: 0.308803, Accuracy: 90.23\n",
      "Train Epoch: 59 [33280/50000 (74%)]\tLoss: 0.221222, Accuracy: 92.77\n",
      "Train Epoch: 59 [35840/50000 (80%)]\tLoss: 0.297434, Accuracy: 90.04\n",
      "Train Epoch: 59 [38400/50000 (85%)]\tLoss: 0.267913, Accuracy: 90.62\n",
      "Train Epoch: 59 [40960/50000 (91%)]\tLoss: 0.304054, Accuracy: 90.82\n",
      "Train Epoch: 59 [43520/50000 (97%)]\tLoss: 0.246946, Accuracy: 89.84\n",
      "\n",
      "Validation set: Average loss: 0.8463, Accuracy: 3818/5000 (76.00%)\n",
      "\n",
      "the time of this epoch:[39.30113863945007 s]\n",
      "Train Epoch: 60 [0/50000 (0%)]\tLoss: 0.245657, Accuracy: 91.80\n",
      "Train Epoch: 60 [2560/50000 (6%)]\tLoss: 0.215440, Accuracy: 92.77\n",
      "Train Epoch: 60 [5120/50000 (11%)]\tLoss: 0.184721, Accuracy: 94.14\n",
      "Train Epoch: 60 [7680/50000 (17%)]\tLoss: 0.346255, Accuracy: 88.48\n",
      "Train Epoch: 60 [10240/50000 (23%)]\tLoss: 0.216260, Accuracy: 92.58\n",
      "Train Epoch: 60 [12800/50000 (28%)]\tLoss: 0.207737, Accuracy: 92.77\n",
      "Train Epoch: 60 [15360/50000 (34%)]\tLoss: 0.272005, Accuracy: 90.82\n",
      "Train Epoch: 60 [17920/50000 (40%)]\tLoss: 0.203308, Accuracy: 93.95\n",
      "Train Epoch: 60 [20480/50000 (45%)]\tLoss: 0.257516, Accuracy: 91.21\n",
      "Train Epoch: 60 [23040/50000 (51%)]\tLoss: 0.310646, Accuracy: 89.06\n",
      "Train Epoch: 60 [25600/50000 (57%)]\tLoss: 0.236010, Accuracy: 91.80\n",
      "Train Epoch: 60 [28160/50000 (62%)]\tLoss: 0.227408, Accuracy: 91.99\n",
      "Train Epoch: 60 [30720/50000 (68%)]\tLoss: 0.277050, Accuracy: 90.43\n",
      "Train Epoch: 60 [33280/50000 (74%)]\tLoss: 0.205411, Accuracy: 92.58\n",
      "Train Epoch: 60 [35840/50000 (80%)]\tLoss: 0.251297, Accuracy: 91.02\n",
      "Train Epoch: 60 [38400/50000 (85%)]\tLoss: 0.222627, Accuracy: 91.60\n",
      "Train Epoch: 60 [40960/50000 (91%)]\tLoss: 0.202354, Accuracy: 93.36\n",
      "Train Epoch: 60 [43520/50000 (97%)]\tLoss: 0.268840, Accuracy: 90.82\n",
      "\n",
      "Validation set: Average loss: 3.1035, Accuracy: 1880/5000 (37.00%)\n",
      "\n",
      "the time of this epoch:[35.9210901260376 s]\n",
      "\n",
      "Test set: Average loss: 3.0379, Accuracy: 3723/10000 (37.23%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 61 [0/50000 (0%)]\tLoss: 0.240184, Accuracy: 92.38\n",
      "Train Epoch: 61 [2560/50000 (6%)]\tLoss: 0.268245, Accuracy: 90.23\n",
      "Train Epoch: 61 [5120/50000 (11%)]\tLoss: 0.259832, Accuracy: 90.62\n",
      "Train Epoch: 61 [7680/50000 (17%)]\tLoss: 0.187397, Accuracy: 93.16\n",
      "Train Epoch: 61 [10240/50000 (23%)]\tLoss: 0.247539, Accuracy: 90.43\n",
      "Train Epoch: 61 [12800/50000 (28%)]\tLoss: 0.232223, Accuracy: 92.97\n",
      "Train Epoch: 61 [15360/50000 (34%)]\tLoss: 0.250509, Accuracy: 91.60\n",
      "Train Epoch: 61 [17920/50000 (40%)]\tLoss: 0.184537, Accuracy: 93.95\n",
      "Train Epoch: 61 [20480/50000 (45%)]\tLoss: 0.200582, Accuracy: 94.34\n",
      "Train Epoch: 61 [23040/50000 (51%)]\tLoss: 0.232862, Accuracy: 91.80\n",
      "Train Epoch: 61 [25600/50000 (57%)]\tLoss: 0.297687, Accuracy: 89.65\n",
      "Train Epoch: 61 [28160/50000 (62%)]\tLoss: 0.227604, Accuracy: 92.97\n",
      "Train Epoch: 61 [30720/50000 (68%)]\tLoss: 0.269419, Accuracy: 90.04\n",
      "Train Epoch: 61 [33280/50000 (74%)]\tLoss: 0.216872, Accuracy: 91.60\n",
      "Train Epoch: 61 [35840/50000 (80%)]\tLoss: 0.215558, Accuracy: 92.97\n",
      "Train Epoch: 61 [38400/50000 (85%)]\tLoss: 0.246988, Accuracy: 90.82\n",
      "Train Epoch: 61 [40960/50000 (91%)]\tLoss: 0.298273, Accuracy: 90.43\n",
      "Train Epoch: 61 [43520/50000 (97%)]\tLoss: 0.346320, Accuracy: 87.11\n",
      "\n",
      "Validation set: Average loss: 3.6335, Accuracy: 1962/5000 (39.00%)\n",
      "\n",
      "the time of this epoch:[39.31458520889282 s]\n",
      "Train Epoch: 62 [0/50000 (0%)]\tLoss: 0.244186, Accuracy: 91.02\n",
      "Train Epoch: 62 [2560/50000 (6%)]\tLoss: 0.205400, Accuracy: 92.58\n",
      "Train Epoch: 62 [5120/50000 (11%)]\tLoss: 0.231470, Accuracy: 94.14\n",
      "Train Epoch: 62 [7680/50000 (17%)]\tLoss: 0.164689, Accuracy: 94.34\n",
      "Train Epoch: 62 [10240/50000 (23%)]\tLoss: 0.237526, Accuracy: 91.21\n",
      "Train Epoch: 62 [12800/50000 (28%)]\tLoss: 0.264751, Accuracy: 91.02\n",
      "Train Epoch: 62 [15360/50000 (34%)]\tLoss: 0.237390, Accuracy: 92.38\n",
      "Train Epoch: 62 [17920/50000 (40%)]\tLoss: 0.228586, Accuracy: 93.55\n",
      "Train Epoch: 62 [20480/50000 (45%)]\tLoss: 0.255283, Accuracy: 92.77\n",
      "Train Epoch: 62 [23040/50000 (51%)]\tLoss: 0.210309, Accuracy: 93.55\n",
      "Train Epoch: 62 [25600/50000 (57%)]\tLoss: 0.210658, Accuracy: 93.16\n",
      "Train Epoch: 62 [28160/50000 (62%)]\tLoss: 0.327519, Accuracy: 88.87\n",
      "Train Epoch: 62 [30720/50000 (68%)]\tLoss: 0.244710, Accuracy: 91.02\n",
      "Train Epoch: 62 [33280/50000 (74%)]\tLoss: 0.243833, Accuracy: 91.21\n",
      "Train Epoch: 62 [35840/50000 (80%)]\tLoss: 0.290502, Accuracy: 89.65\n",
      "Train Epoch: 62 [38400/50000 (85%)]\tLoss: 0.278894, Accuracy: 89.84\n",
      "Train Epoch: 62 [40960/50000 (91%)]\tLoss: 0.279308, Accuracy: 90.43\n",
      "Train Epoch: 62 [43520/50000 (97%)]\tLoss: 0.261089, Accuracy: 91.41\n",
      "\n",
      "Validation set: Average loss: 0.9910, Accuracy: 3787/5000 (75.00%)\n",
      "\n",
      "the time of this epoch:[36.19808030128479 s]\n",
      "\n",
      "Test set: Average loss: 0.9635, Accuracy: 7581/10000 (75.81%)\n",
      "\n",
      "Train Epoch: 63 [0/50000 (0%)]\tLoss: 0.158273, Accuracy: 94.53\n",
      "Train Epoch: 63 [2560/50000 (6%)]\tLoss: 0.187510, Accuracy: 93.75\n",
      "Train Epoch: 63 [5120/50000 (11%)]\tLoss: 0.212437, Accuracy: 92.58\n",
      "Train Epoch: 63 [7680/50000 (17%)]\tLoss: 0.232734, Accuracy: 92.19\n",
      "Train Epoch: 63 [10240/50000 (23%)]\tLoss: 0.170268, Accuracy: 93.95\n",
      "Train Epoch: 63 [12800/50000 (28%)]\tLoss: 0.249832, Accuracy: 92.58\n",
      "Train Epoch: 63 [15360/50000 (34%)]\tLoss: 0.249254, Accuracy: 92.58\n",
      "Train Epoch: 63 [17920/50000 (40%)]\tLoss: 0.263855, Accuracy: 91.21\n",
      "Train Epoch: 63 [20480/50000 (45%)]\tLoss: 0.223990, Accuracy: 91.99\n",
      "Train Epoch: 63 [23040/50000 (51%)]\tLoss: 0.247394, Accuracy: 91.41\n",
      "Train Epoch: 63 [25600/50000 (57%)]\tLoss: 0.257097, Accuracy: 91.02\n",
      "Train Epoch: 63 [28160/50000 (62%)]\tLoss: 0.279865, Accuracy: 90.62\n",
      "Train Epoch: 63 [30720/50000 (68%)]\tLoss: 0.291093, Accuracy: 90.04\n",
      "Train Epoch: 63 [33280/50000 (74%)]\tLoss: 0.241942, Accuracy: 92.38\n",
      "Train Epoch: 63 [35840/50000 (80%)]\tLoss: 0.289776, Accuracy: 90.43\n",
      "Train Epoch: 63 [38400/50000 (85%)]\tLoss: 0.214362, Accuracy: 92.58\n",
      "Train Epoch: 63 [40960/50000 (91%)]\tLoss: 0.231360, Accuracy: 91.99\n",
      "Train Epoch: 63 [43520/50000 (97%)]\tLoss: 0.285353, Accuracy: 89.65\n",
      "\n",
      "Validation set: Average loss: 1.3142, Accuracy: 3461/5000 (69.00%)\n",
      "\n",
      "the time of this epoch:[39.55297565460205 s]\n",
      "Train Epoch: 64 [0/50000 (0%)]\tLoss: 0.294933, Accuracy: 89.65\n",
      "Train Epoch: 64 [2560/50000 (6%)]\tLoss: 0.228128, Accuracy: 91.60\n",
      "Train Epoch: 64 [5120/50000 (11%)]\tLoss: 0.197361, Accuracy: 93.36\n",
      "Train Epoch: 64 [7680/50000 (17%)]\tLoss: 0.225523, Accuracy: 92.38\n",
      "Train Epoch: 64 [10240/50000 (23%)]\tLoss: 0.239042, Accuracy: 92.97\n",
      "Train Epoch: 64 [12800/50000 (28%)]\tLoss: 0.206484, Accuracy: 93.36\n",
      "Train Epoch: 64 [15360/50000 (34%)]\tLoss: 0.222835, Accuracy: 92.77\n",
      "Train Epoch: 64 [17920/50000 (40%)]\tLoss: 0.278365, Accuracy: 90.23\n",
      "Train Epoch: 64 [20480/50000 (45%)]\tLoss: 0.263550, Accuracy: 91.02\n",
      "Train Epoch: 64 [23040/50000 (51%)]\tLoss: 0.222513, Accuracy: 92.58\n",
      "Train Epoch: 64 [25600/50000 (57%)]\tLoss: 0.275860, Accuracy: 89.45\n",
      "Train Epoch: 64 [28160/50000 (62%)]\tLoss: 0.228820, Accuracy: 92.38\n",
      "Train Epoch: 64 [30720/50000 (68%)]\tLoss: 0.237971, Accuracy: 91.60\n",
      "Train Epoch: 64 [33280/50000 (74%)]\tLoss: 0.251269, Accuracy: 91.60\n",
      "Train Epoch: 64 [35840/50000 (80%)]\tLoss: 0.213302, Accuracy: 91.99\n",
      "Train Epoch: 64 [38400/50000 (85%)]\tLoss: 0.214717, Accuracy: 92.38\n",
      "Train Epoch: 64 [40960/50000 (91%)]\tLoss: 0.199525, Accuracy: 92.97\n",
      "Train Epoch: 64 [43520/50000 (97%)]\tLoss: 0.271145, Accuracy: 90.04\n",
      "\n",
      "Validation set: Average loss: 7.6010, Accuracy: 1094/5000 (21.00%)\n",
      "\n",
      "the time of this epoch:[36.06239414215088 s]\n",
      "\n",
      "Test set: Average loss: 7.7335, Accuracy: 2149/10000 (21.49%)\n",
      "\n",
      "Train Epoch: 65 [0/50000 (0%)]\tLoss: 0.213239, Accuracy: 91.99\n",
      "Train Epoch: 65 [2560/50000 (6%)]\tLoss: 0.182802, Accuracy: 93.95\n",
      "Train Epoch: 65 [5120/50000 (11%)]\tLoss: 0.204557, Accuracy: 93.16\n",
      "Train Epoch: 65 [7680/50000 (17%)]\tLoss: 0.275431, Accuracy: 90.23\n",
      "Train Epoch: 65 [10240/50000 (23%)]\tLoss: 0.280451, Accuracy: 90.43\n",
      "Train Epoch: 65 [12800/50000 (28%)]\tLoss: 0.257329, Accuracy: 91.60\n",
      "Train Epoch: 65 [15360/50000 (34%)]\tLoss: 0.232579, Accuracy: 91.99\n",
      "Train Epoch: 65 [17920/50000 (40%)]\tLoss: 0.157632, Accuracy: 93.55\n",
      "Train Epoch: 65 [20480/50000 (45%)]\tLoss: 0.233836, Accuracy: 91.41\n",
      "Train Epoch: 65 [23040/50000 (51%)]\tLoss: 0.229055, Accuracy: 91.80\n",
      "Train Epoch: 65 [25600/50000 (57%)]\tLoss: 0.254521, Accuracy: 91.99\n",
      "Train Epoch: 65 [28160/50000 (62%)]\tLoss: 0.196504, Accuracy: 91.80\n",
      "Train Epoch: 65 [30720/50000 (68%)]\tLoss: 0.270930, Accuracy: 90.43\n",
      "Train Epoch: 65 [33280/50000 (74%)]\tLoss: 0.278566, Accuracy: 89.06\n",
      "Train Epoch: 65 [35840/50000 (80%)]\tLoss: 0.253854, Accuracy: 91.41\n",
      "Train Epoch: 65 [38400/50000 (85%)]\tLoss: 0.222560, Accuracy: 91.99\n",
      "Train Epoch: 65 [40960/50000 (91%)]\tLoss: 0.217126, Accuracy: 93.36\n",
      "Train Epoch: 65 [43520/50000 (97%)]\tLoss: 0.257799, Accuracy: 91.02\n",
      "\n",
      "Validation set: Average loss: 1.5127, Accuracy: 2971/5000 (59.00%)\n",
      "\n",
      "the time of this epoch:[39.62857365608215 s]\n",
      "Train Epoch: 66 [0/50000 (0%)]\tLoss: 0.252842, Accuracy: 91.21\n",
      "Train Epoch: 66 [2560/50000 (6%)]\tLoss: 0.211956, Accuracy: 93.75\n",
      "Train Epoch: 66 [5120/50000 (11%)]\tLoss: 0.248985, Accuracy: 90.82\n",
      "Train Epoch: 66 [7680/50000 (17%)]\tLoss: 0.220272, Accuracy: 91.80\n",
      "Train Epoch: 66 [10240/50000 (23%)]\tLoss: 0.232096, Accuracy: 91.80\n",
      "Train Epoch: 66 [12800/50000 (28%)]\tLoss: 0.211158, Accuracy: 92.38\n",
      "Train Epoch: 66 [15360/50000 (34%)]\tLoss: 0.287301, Accuracy: 90.82\n",
      "Train Epoch: 66 [17920/50000 (40%)]\tLoss: 0.250915, Accuracy: 91.80\n",
      "Train Epoch: 66 [20480/50000 (45%)]\tLoss: 0.216156, Accuracy: 92.38\n",
      "Train Epoch: 66 [23040/50000 (51%)]\tLoss: 0.300679, Accuracy: 89.26\n",
      "Train Epoch: 66 [25600/50000 (57%)]\tLoss: 0.256455, Accuracy: 90.62\n",
      "Train Epoch: 66 [28160/50000 (62%)]\tLoss: 0.245882, Accuracy: 91.02\n",
      "Train Epoch: 66 [30720/50000 (68%)]\tLoss: 0.238485, Accuracy: 91.80\n",
      "Train Epoch: 66 [33280/50000 (74%)]\tLoss: 0.203248, Accuracy: 92.97\n",
      "Train Epoch: 66 [35840/50000 (80%)]\tLoss: 0.269787, Accuracy: 91.60\n",
      "Train Epoch: 66 [38400/50000 (85%)]\tLoss: 0.193266, Accuracy: 93.16\n",
      "Train Epoch: 66 [40960/50000 (91%)]\tLoss: 0.272581, Accuracy: 90.04\n",
      "Train Epoch: 66 [43520/50000 (97%)]\tLoss: 0.288933, Accuracy: 90.82\n",
      "\n",
      "Validation set: Average loss: 2.0176, Accuracy: 2497/5000 (49.00%)\n",
      "\n",
      "the time of this epoch:[35.90278244018555 s]\n",
      "\n",
      "Test set: Average loss: 2.0697, Accuracy: 4832/10000 (48.32%)\n",
      "\n",
      "Train Epoch: 67 [0/50000 (0%)]\tLoss: 0.250943, Accuracy: 91.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 67 [2560/50000 (6%)]\tLoss: 0.266276, Accuracy: 90.04\n",
      "Train Epoch: 67 [5120/50000 (11%)]\tLoss: 0.250190, Accuracy: 90.23\n",
      "Train Epoch: 67 [7680/50000 (17%)]\tLoss: 0.195729, Accuracy: 93.55\n",
      "Train Epoch: 67 [10240/50000 (23%)]\tLoss: 0.206032, Accuracy: 92.97\n",
      "Train Epoch: 67 [12800/50000 (28%)]\tLoss: 0.211601, Accuracy: 93.16\n",
      "Train Epoch: 67 [15360/50000 (34%)]\tLoss: 0.285170, Accuracy: 90.82\n",
      "Train Epoch: 67 [17920/50000 (40%)]\tLoss: 0.300833, Accuracy: 90.23\n",
      "Train Epoch: 67 [20480/50000 (45%)]\tLoss: 0.235029, Accuracy: 90.23\n",
      "Train Epoch: 67 [23040/50000 (51%)]\tLoss: 0.253074, Accuracy: 91.41\n",
      "Train Epoch: 67 [25600/50000 (57%)]\tLoss: 0.175729, Accuracy: 92.97\n",
      "Train Epoch: 67 [28160/50000 (62%)]\tLoss: 0.284138, Accuracy: 90.82\n",
      "Train Epoch: 67 [30720/50000 (68%)]\tLoss: 0.200132, Accuracy: 92.77\n",
      "Train Epoch: 67 [33280/50000 (74%)]\tLoss: 0.234356, Accuracy: 93.16\n",
      "Train Epoch: 67 [35840/50000 (80%)]\tLoss: 0.321839, Accuracy: 89.26\n",
      "Train Epoch: 67 [38400/50000 (85%)]\tLoss: 0.269009, Accuracy: 90.43\n",
      "Train Epoch: 67 [40960/50000 (91%)]\tLoss: 0.214264, Accuracy: 91.99\n",
      "Train Epoch: 67 [43520/50000 (97%)]\tLoss: 0.232298, Accuracy: 91.21\n",
      "\n",
      "Validation set: Average loss: 1.1616, Accuracy: 3624/5000 (72.00%)\n",
      "\n",
      "the time of this epoch:[39.49512600898743 s]\n",
      "Train Epoch: 68 [0/50000 (0%)]\tLoss: 0.249584, Accuracy: 91.41\n",
      "Train Epoch: 68 [2560/50000 (6%)]\tLoss: 0.282367, Accuracy: 90.04\n",
      "Train Epoch: 68 [5120/50000 (11%)]\tLoss: 0.218352, Accuracy: 92.97\n",
      "Train Epoch: 68 [7680/50000 (17%)]\tLoss: 0.264984, Accuracy: 89.65\n",
      "Train Epoch: 68 [10240/50000 (23%)]\tLoss: 0.294428, Accuracy: 89.65\n",
      "Train Epoch: 68 [12800/50000 (28%)]\tLoss: 0.187762, Accuracy: 92.77\n",
      "Train Epoch: 68 [15360/50000 (34%)]\tLoss: 0.258087, Accuracy: 90.23\n",
      "Train Epoch: 68 [17920/50000 (40%)]\tLoss: 0.220212, Accuracy: 92.58\n",
      "Train Epoch: 68 [20480/50000 (45%)]\tLoss: 0.241937, Accuracy: 91.80\n",
      "Train Epoch: 68 [23040/50000 (51%)]\tLoss: 0.230600, Accuracy: 92.19\n",
      "Train Epoch: 68 [25600/50000 (57%)]\tLoss: 0.200620, Accuracy: 92.58\n",
      "Train Epoch: 68 [28160/50000 (62%)]\tLoss: 0.220519, Accuracy: 92.97\n",
      "Train Epoch: 68 [30720/50000 (68%)]\tLoss: 0.242497, Accuracy: 90.62\n",
      "Train Epoch: 68 [33280/50000 (74%)]\tLoss: 0.202741, Accuracy: 93.36\n",
      "Train Epoch: 68 [35840/50000 (80%)]\tLoss: 0.256530, Accuracy: 90.43\n",
      "Train Epoch: 68 [38400/50000 (85%)]\tLoss: 0.210928, Accuracy: 91.99\n",
      "Train Epoch: 68 [40960/50000 (91%)]\tLoss: 0.229080, Accuracy: 92.38\n",
      "Train Epoch: 68 [43520/50000 (97%)]\tLoss: 0.336956, Accuracy: 88.48\n",
      "\n",
      "Validation set: Average loss: 0.8834, Accuracy: 3900/5000 (78.00%)\n",
      "\n",
      "the time of this epoch:[35.94909715652466 s]\n",
      "\n",
      "Test set: Average loss: 0.8791, Accuracy: 7729/10000 (77.29%)\n",
      "\n",
      "Train Epoch: 69 [0/50000 (0%)]\tLoss: 0.222285, Accuracy: 92.58\n",
      "Train Epoch: 69 [2560/50000 (6%)]\tLoss: 0.174083, Accuracy: 93.55\n",
      "Train Epoch: 69 [5120/50000 (11%)]\tLoss: 0.206947, Accuracy: 93.36\n",
      "Train Epoch: 69 [7680/50000 (17%)]\tLoss: 0.215597, Accuracy: 91.99\n",
      "Train Epoch: 69 [10240/50000 (23%)]\tLoss: 0.226592, Accuracy: 91.41\n",
      "Train Epoch: 69 [12800/50000 (28%)]\tLoss: 0.235152, Accuracy: 92.19\n",
      "Train Epoch: 69 [15360/50000 (34%)]\tLoss: 0.195514, Accuracy: 93.36\n",
      "Train Epoch: 69 [17920/50000 (40%)]\tLoss: 0.267383, Accuracy: 90.04\n",
      "Train Epoch: 69 [20480/50000 (45%)]\tLoss: 0.252664, Accuracy: 91.80\n",
      "Train Epoch: 69 [23040/50000 (51%)]\tLoss: 0.251515, Accuracy: 92.19\n",
      "Train Epoch: 69 [25600/50000 (57%)]\tLoss: 0.277832, Accuracy: 90.23\n",
      "Train Epoch: 69 [28160/50000 (62%)]\tLoss: 0.226912, Accuracy: 92.38\n",
      "Train Epoch: 69 [30720/50000 (68%)]\tLoss: 0.243205, Accuracy: 92.97\n",
      "Train Epoch: 69 [33280/50000 (74%)]\tLoss: 0.230121, Accuracy: 92.97\n",
      "Train Epoch: 69 [35840/50000 (80%)]\tLoss: 0.172657, Accuracy: 95.31\n",
      "Train Epoch: 69 [38400/50000 (85%)]\tLoss: 0.247677, Accuracy: 89.65\n",
      "Train Epoch: 69 [40960/50000 (91%)]\tLoss: 0.213831, Accuracy: 92.19\n",
      "Train Epoch: 69 [43520/50000 (97%)]\tLoss: 0.237219, Accuracy: 91.99\n",
      "\n",
      "Validation set: Average loss: 1.1179, Accuracy: 3298/5000 (65.00%)\n",
      "\n",
      "the time of this epoch:[39.32446646690369 s]\n",
      "Train Epoch: 70 [0/50000 (0%)]\tLoss: 0.160342, Accuracy: 94.14\n",
      "Train Epoch: 70 [2560/50000 (6%)]\tLoss: 0.197092, Accuracy: 92.58\n",
      "Train Epoch: 70 [5120/50000 (11%)]\tLoss: 0.229958, Accuracy: 91.60\n",
      "Train Epoch: 70 [7680/50000 (17%)]\tLoss: 0.280196, Accuracy: 91.99\n",
      "Train Epoch: 70 [10240/50000 (23%)]\tLoss: 0.215083, Accuracy: 92.97\n",
      "Train Epoch: 70 [12800/50000 (28%)]\tLoss: 0.225210, Accuracy: 92.19\n",
      "Train Epoch: 70 [15360/50000 (34%)]\tLoss: 0.267672, Accuracy: 91.41\n",
      "Train Epoch: 70 [17920/50000 (40%)]\tLoss: 0.234423, Accuracy: 91.80\n",
      "Train Epoch: 70 [20480/50000 (45%)]\tLoss: 0.271052, Accuracy: 90.04\n",
      "Train Epoch: 70 [23040/50000 (51%)]\tLoss: 0.235349, Accuracy: 91.60\n",
      "Train Epoch: 70 [25600/50000 (57%)]\tLoss: 0.253141, Accuracy: 91.21\n",
      "Train Epoch: 70 [28160/50000 (62%)]\tLoss: 0.260032, Accuracy: 91.60\n",
      "Train Epoch: 70 [30720/50000 (68%)]\tLoss: 0.218352, Accuracy: 92.38\n",
      "Train Epoch: 70 [33280/50000 (74%)]\tLoss: 0.249066, Accuracy: 90.82\n",
      "Train Epoch: 70 [35840/50000 (80%)]\tLoss: 0.237626, Accuracy: 91.80\n",
      "Train Epoch: 70 [38400/50000 (85%)]\tLoss: 0.273509, Accuracy: 90.82\n",
      "Train Epoch: 70 [40960/50000 (91%)]\tLoss: 0.248333, Accuracy: 91.41\n",
      "Train Epoch: 70 [43520/50000 (97%)]\tLoss: 0.273178, Accuracy: 90.82\n",
      "\n",
      "Validation set: Average loss: 1.0600, Accuracy: 3375/5000 (67.00%)\n",
      "\n",
      "the time of this epoch:[37.41307806968689 s]\n",
      "\n",
      "Test set: Average loss: 1.0983, Accuracy: 6716/10000 (67.16%)\n",
      "\n",
      "Train Epoch: 71 [0/50000 (0%)]\tLoss: 0.190524, Accuracy: 93.36\n",
      "Train Epoch: 71 [2560/50000 (6%)]\tLoss: 0.192630, Accuracy: 92.77\n",
      "Train Epoch: 71 [5120/50000 (11%)]\tLoss: 0.239238, Accuracy: 91.21\n",
      "Train Epoch: 71 [7680/50000 (17%)]\tLoss: 0.208369, Accuracy: 93.36\n",
      "Train Epoch: 71 [10240/50000 (23%)]\tLoss: 0.245871, Accuracy: 90.82\n",
      "Train Epoch: 71 [12800/50000 (28%)]\tLoss: 0.133962, Accuracy: 95.70\n",
      "Train Epoch: 71 [15360/50000 (34%)]\tLoss: 0.183852, Accuracy: 93.95\n",
      "Train Epoch: 71 [17920/50000 (40%)]\tLoss: 0.221136, Accuracy: 92.77\n",
      "Train Epoch: 71 [20480/50000 (45%)]\tLoss: 0.223135, Accuracy: 93.75\n",
      "Train Epoch: 71 [23040/50000 (51%)]\tLoss: 0.191364, Accuracy: 93.36\n",
      "Train Epoch: 71 [25600/50000 (57%)]\tLoss: 0.263794, Accuracy: 90.43\n",
      "Train Epoch: 71 [28160/50000 (62%)]\tLoss: 0.262544, Accuracy: 90.04\n",
      "Train Epoch: 71 [30720/50000 (68%)]\tLoss: 0.226048, Accuracy: 91.80\n",
      "Train Epoch: 71 [33280/50000 (74%)]\tLoss: 0.250931, Accuracy: 91.99\n",
      "Train Epoch: 71 [35840/50000 (80%)]\tLoss: 0.282890, Accuracy: 89.84\n",
      "Train Epoch: 71 [38400/50000 (85%)]\tLoss: 0.281481, Accuracy: 89.65\n",
      "Train Epoch: 71 [40960/50000 (91%)]\tLoss: 0.237901, Accuracy: 91.60\n",
      "Train Epoch: 71 [43520/50000 (97%)]\tLoss: 0.228315, Accuracy: 91.41\n",
      "\n",
      "Validation set: Average loss: 1.1332, Accuracy: 3592/5000 (71.00%)\n",
      "\n",
      "the time of this epoch:[39.93297600746155 s]\n",
      "Train Epoch: 72 [0/50000 (0%)]\tLoss: 0.232700, Accuracy: 93.36\n",
      "Train Epoch: 72 [2560/50000 (6%)]\tLoss: 0.187967, Accuracy: 94.53\n",
      "Train Epoch: 72 [5120/50000 (11%)]\tLoss: 0.193005, Accuracy: 93.16\n",
      "Train Epoch: 72 [7680/50000 (17%)]\tLoss: 0.200437, Accuracy: 92.97\n",
      "Train Epoch: 72 [10240/50000 (23%)]\tLoss: 0.236978, Accuracy: 91.60\n",
      "Train Epoch: 72 [12800/50000 (28%)]\tLoss: 0.207222, Accuracy: 91.60\n",
      "Train Epoch: 72 [15360/50000 (34%)]\tLoss: 0.174409, Accuracy: 94.53\n",
      "Train Epoch: 72 [17920/50000 (40%)]\tLoss: 0.183495, Accuracy: 93.55\n",
      "Train Epoch: 72 [20480/50000 (45%)]\tLoss: 0.247935, Accuracy: 90.43\n",
      "Train Epoch: 72 [23040/50000 (51%)]\tLoss: 0.226735, Accuracy: 93.16\n",
      "Train Epoch: 72 [25600/50000 (57%)]\tLoss: 0.262902, Accuracy: 91.21\n",
      "Train Epoch: 72 [28160/50000 (62%)]\tLoss: 0.238051, Accuracy: 91.21\n",
      "Train Epoch: 72 [30720/50000 (68%)]\tLoss: 0.220581, Accuracy: 91.60\n",
      "Train Epoch: 72 [33280/50000 (74%)]\tLoss: 0.194108, Accuracy: 92.97\n",
      "Train Epoch: 72 [35840/50000 (80%)]\tLoss: 0.221469, Accuracy: 92.77\n",
      "Train Epoch: 72 [38400/50000 (85%)]\tLoss: 0.224064, Accuracy: 91.80\n",
      "Train Epoch: 72 [40960/50000 (91%)]\tLoss: 0.287602, Accuracy: 90.04\n",
      "Train Epoch: 72 [43520/50000 (97%)]\tLoss: 0.243682, Accuracy: 92.77\n",
      "\n",
      "Validation set: Average loss: 0.6753, Accuracy: 4040/5000 (80.00%)\n",
      "\n",
      "the time of this epoch:[36.33636116981506 s]\n",
      "\n",
      "Test set: Average loss: 0.6756, Accuracy: 8022/10000 (80.22%)\n",
      "\n",
      "Train Epoch: 73 [0/50000 (0%)]\tLoss: 0.207966, Accuracy: 93.36\n",
      "Train Epoch: 73 [2560/50000 (6%)]\tLoss: 0.224478, Accuracy: 92.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 73 [5120/50000 (11%)]\tLoss: 0.225899, Accuracy: 93.75\n",
      "Train Epoch: 73 [7680/50000 (17%)]\tLoss: 0.215888, Accuracy: 91.80\n",
      "Train Epoch: 73 [10240/50000 (23%)]\tLoss: 0.255954, Accuracy: 92.58\n",
      "Train Epoch: 73 [12800/50000 (28%)]\tLoss: 0.235664, Accuracy: 91.99\n",
      "Train Epoch: 73 [15360/50000 (34%)]\tLoss: 0.249495, Accuracy: 91.02\n",
      "Train Epoch: 73 [17920/50000 (40%)]\tLoss: 0.231072, Accuracy: 91.99\n",
      "Train Epoch: 73 [20480/50000 (45%)]\tLoss: 0.155238, Accuracy: 95.31\n",
      "Train Epoch: 73 [23040/50000 (51%)]\tLoss: 0.214593, Accuracy: 92.77\n",
      "Train Epoch: 73 [25600/50000 (57%)]\tLoss: 0.204324, Accuracy: 92.38\n",
      "Train Epoch: 73 [28160/50000 (62%)]\tLoss: 0.232731, Accuracy: 92.19\n",
      "Train Epoch: 73 [30720/50000 (68%)]\tLoss: 0.201539, Accuracy: 92.97\n",
      "Train Epoch: 73 [33280/50000 (74%)]\tLoss: 0.249573, Accuracy: 91.80\n",
      "Train Epoch: 73 [35840/50000 (80%)]\tLoss: 0.232559, Accuracy: 91.41\n",
      "Train Epoch: 73 [38400/50000 (85%)]\tLoss: 0.267714, Accuracy: 91.60\n",
      "Train Epoch: 73 [40960/50000 (91%)]\tLoss: 0.217030, Accuracy: 91.99\n",
      "Train Epoch: 73 [43520/50000 (97%)]\tLoss: 0.281454, Accuracy: 89.84\n",
      "\n",
      "Validation set: Average loss: 0.9088, Accuracy: 3637/5000 (72.00%)\n",
      "\n",
      "the time of this epoch:[38.997727155685425 s]\n",
      "Train Epoch: 74 [0/50000 (0%)]\tLoss: 0.158624, Accuracy: 94.73\n",
      "Train Epoch: 74 [2560/50000 (6%)]\tLoss: 0.226688, Accuracy: 91.41\n",
      "Train Epoch: 74 [5120/50000 (11%)]\tLoss: 0.202214, Accuracy: 92.58\n",
      "Train Epoch: 74 [7680/50000 (17%)]\tLoss: 0.224256, Accuracy: 92.58\n",
      "Train Epoch: 74 [10240/50000 (23%)]\tLoss: 0.200805, Accuracy: 93.55\n",
      "Train Epoch: 74 [12800/50000 (28%)]\tLoss: 0.238972, Accuracy: 91.02\n",
      "Train Epoch: 74 [15360/50000 (34%)]\tLoss: 0.204719, Accuracy: 92.58\n",
      "Train Epoch: 74 [17920/50000 (40%)]\tLoss: 0.222274, Accuracy: 92.58\n",
      "Train Epoch: 74 [20480/50000 (45%)]\tLoss: 0.206771, Accuracy: 92.97\n",
      "Train Epoch: 74 [23040/50000 (51%)]\tLoss: 0.220809, Accuracy: 93.55\n",
      "Train Epoch: 74 [25600/50000 (57%)]\tLoss: 0.236421, Accuracy: 92.38\n",
      "Train Epoch: 74 [28160/50000 (62%)]\tLoss: 0.295934, Accuracy: 90.23\n",
      "Train Epoch: 74 [30720/50000 (68%)]\tLoss: 0.269512, Accuracy: 91.99\n",
      "Train Epoch: 74 [33280/50000 (74%)]\tLoss: 0.244135, Accuracy: 91.99\n",
      "Train Epoch: 74 [35840/50000 (80%)]\tLoss: 0.226182, Accuracy: 92.19\n",
      "Train Epoch: 74 [38400/50000 (85%)]\tLoss: 0.272749, Accuracy: 90.82\n",
      "Train Epoch: 74 [40960/50000 (91%)]\tLoss: 0.210841, Accuracy: 93.36\n",
      "Train Epoch: 74 [43520/50000 (97%)]\tLoss: 0.262718, Accuracy: 91.80\n",
      "\n",
      "Validation set: Average loss: 1.4983, Accuracy: 2935/5000 (58.00%)\n",
      "\n",
      "the time of this epoch:[35.592833042144775 s]\n",
      "------------------------------\n",
      "before autoscale: torch.Size([1024, 1, 1])\n",
      "tensor([[[ 0.0015]],\n",
      "\n",
      "        [[ 0.0951]],\n",
      "\n",
      "        [[ 0.1045]],\n",
      "\n",
      "        [[ 0.0178]],\n",
      "\n",
      "        [[ 0.4218]],\n",
      "\n",
      "        [[ 0.0558]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0560]],\n",
      "\n",
      "        [[ 0.0089]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[ 1.0033]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 1024])\n",
      "tensor([[[ 0.0015,  0.0955,  0.1048,  ...,  0.0437,  0.0037,  0.0031]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-02 *\n",
      "       [[ 1.2865,  0.0692,  1.9237, -0.4831, -0.5040, -1.0450, -0.3890,\n",
      "          1.4063,  1.9766]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 896, 1024])\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.7205,  0.5406, -0.2007,  ..., -0.0125, -0.0242,  0.0884],\n",
      "        [-0.3402, -0.5514, -1.0977,  ..., -0.0284, -0.0464, -0.1391],\n",
      "        [-0.6154, -0.4570, -0.1262,  ..., -0.0117,  0.1263, -0.0579],\n",
      "        ...,\n",
      "        [ 0.4276, -0.1305, -0.2418,  ...,  0.0008, -0.0183, -0.0000],\n",
      "        [ 0.7428,  0.3818, -0.0551,  ..., -0.0024,  0.0087,  0.0417],\n",
      "        [-0.3980, -0.3381, -0.1270,  ..., -0.0403,  0.0524,  0.0084]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 896, 1024])\n",
      "tensor(1.00000e-03 *\n",
      "       [[ 0.7204,  0.5406, -0.2007,  ..., -0.0125, -0.0242,  0.0884],\n",
      "        [-0.3402, -0.5513, -1.0977,  ..., -0.0284, -0.0464, -0.1391],\n",
      "        [-0.6154, -0.4570, -0.1262,  ..., -0.0117,  0.1263, -0.0579],\n",
      "        ...,\n",
      "        [-0.7883, -0.1446,  0.3593,  ...,  0.0045, -0.0854, -0.0357],\n",
      "        [-0.3118, -0.2842, -0.3932,  ..., -0.0010, -0.0227, -0.0158],\n",
      "        [ 0.1934,  1.0457, -0.0061,  ..., -0.0012,  0.1036,  0.0028]], device='cuda:0')\n",
      "\n",
      "Test set: Average loss: 1.5178, Accuracy: 5713/10000 (57.13%)\n",
      "\n",
      "Train Epoch: 75 [0/50000 (0%)]\tLoss: 0.144692, Accuracy: 95.12\n",
      "Train Epoch: 75 [2560/50000 (6%)]\tLoss: 0.196856, Accuracy: 93.95\n",
      "Train Epoch: 75 [5120/50000 (11%)]\tLoss: 0.149810, Accuracy: 94.53\n",
      "Train Epoch: 75 [7680/50000 (17%)]\tLoss: 0.255797, Accuracy: 90.82\n",
      "Train Epoch: 75 [10240/50000 (23%)]\tLoss: 0.213183, Accuracy: 92.58\n",
      "Train Epoch: 75 [12800/50000 (28%)]\tLoss: 0.240045, Accuracy: 90.82\n",
      "Train Epoch: 75 [15360/50000 (34%)]\tLoss: 0.286929, Accuracy: 89.84\n",
      "Train Epoch: 75 [17920/50000 (40%)]\tLoss: 0.166813, Accuracy: 94.53\n",
      "Train Epoch: 75 [20480/50000 (45%)]\tLoss: 0.236175, Accuracy: 92.38\n",
      "Train Epoch: 75 [23040/50000 (51%)]\tLoss: 0.225957, Accuracy: 92.19\n",
      "Train Epoch: 75 [25600/50000 (57%)]\tLoss: 0.221577, Accuracy: 92.77\n",
      "Train Epoch: 75 [28160/50000 (62%)]\tLoss: 0.247922, Accuracy: 90.82\n",
      "Train Epoch: 75 [30720/50000 (68%)]\tLoss: 0.231394, Accuracy: 91.80\n",
      "Train Epoch: 75 [33280/50000 (74%)]\tLoss: 0.224806, Accuracy: 91.80\n",
      "Train Epoch: 75 [35840/50000 (80%)]\tLoss: 0.291006, Accuracy: 90.62\n",
      "Train Epoch: 75 [38400/50000 (85%)]\tLoss: 0.251798, Accuracy: 91.02\n",
      "Train Epoch: 75 [40960/50000 (91%)]\tLoss: 0.233521, Accuracy: 91.80\n",
      "Train Epoch: 75 [43520/50000 (97%)]\tLoss: 0.267228, Accuracy: 90.04\n",
      "\n",
      "Validation set: Average loss: 1.5484, Accuracy: 2786/5000 (55.00%)\n",
      "\n",
      "the time of this epoch:[39.24698281288147 s]\n",
      "Train Epoch: 76 [0/50000 (0%)]\tLoss: 0.184789, Accuracy: 94.73\n",
      "Train Epoch: 76 [2560/50000 (6%)]\tLoss: 0.199037, Accuracy: 92.38\n",
      "Train Epoch: 76 [5120/50000 (11%)]\tLoss: 0.208214, Accuracy: 92.97\n",
      "Train Epoch: 76 [7680/50000 (17%)]\tLoss: 0.242408, Accuracy: 90.62\n",
      "Train Epoch: 76 [10240/50000 (23%)]\tLoss: 0.182253, Accuracy: 94.14\n",
      "Train Epoch: 76 [12800/50000 (28%)]\tLoss: 0.212536, Accuracy: 91.99\n",
      "Train Epoch: 76 [15360/50000 (34%)]\tLoss: 0.234253, Accuracy: 92.19\n",
      "Train Epoch: 76 [17920/50000 (40%)]\tLoss: 0.215728, Accuracy: 92.19\n",
      "Train Epoch: 76 [20480/50000 (45%)]\tLoss: 0.307853, Accuracy: 89.45\n",
      "Train Epoch: 76 [23040/50000 (51%)]\tLoss: 0.216257, Accuracy: 93.75\n",
      "Train Epoch: 76 [25600/50000 (57%)]\tLoss: 0.224793, Accuracy: 91.02\n",
      "Train Epoch: 76 [28160/50000 (62%)]\tLoss: 0.252048, Accuracy: 93.36\n",
      "Train Epoch: 76 [30720/50000 (68%)]\tLoss: 0.228594, Accuracy: 92.38\n",
      "Train Epoch: 76 [33280/50000 (74%)]\tLoss: 0.229958, Accuracy: 92.77\n",
      "Train Epoch: 76 [35840/50000 (80%)]\tLoss: 0.281630, Accuracy: 90.04\n",
      "Train Epoch: 76 [38400/50000 (85%)]\tLoss: 0.229493, Accuracy: 92.97\n",
      "Train Epoch: 76 [40960/50000 (91%)]\tLoss: 0.262331, Accuracy: 91.41\n",
      "Train Epoch: 76 [43520/50000 (97%)]\tLoss: 0.236206, Accuracy: 91.60\n",
      "\n",
      "Validation set: Average loss: 0.8156, Accuracy: 3838/5000 (76.00%)\n",
      "\n",
      "the time of this epoch:[35.82891607284546 s]\n",
      "\n",
      "Test set: Average loss: 0.8425, Accuracy: 7627/10000 (76.27%)\n",
      "\n",
      "Train Epoch: 77 [0/50000 (0%)]\tLoss: 0.185687, Accuracy: 93.95\n",
      "Train Epoch: 77 [2560/50000 (6%)]\tLoss: 0.224028, Accuracy: 91.80\n",
      "Train Epoch: 77 [5120/50000 (11%)]\tLoss: 0.181489, Accuracy: 93.95\n",
      "Train Epoch: 77 [7680/50000 (17%)]\tLoss: 0.232877, Accuracy: 92.38\n",
      "Train Epoch: 77 [10240/50000 (23%)]\tLoss: 0.209235, Accuracy: 92.38\n",
      "Train Epoch: 77 [12800/50000 (28%)]\tLoss: 0.177867, Accuracy: 93.75\n",
      "Train Epoch: 77 [15360/50000 (34%)]\tLoss: 0.205195, Accuracy: 94.14\n",
      "Train Epoch: 77 [17920/50000 (40%)]\tLoss: 0.220884, Accuracy: 92.97\n",
      "Train Epoch: 77 [20480/50000 (45%)]\tLoss: 0.277335, Accuracy: 90.82\n",
      "Train Epoch: 77 [23040/50000 (51%)]\tLoss: 0.273687, Accuracy: 91.21\n",
      "Train Epoch: 77 [25600/50000 (57%)]\tLoss: 0.288852, Accuracy: 90.43\n",
      "Train Epoch: 77 [28160/50000 (62%)]\tLoss: 0.231100, Accuracy: 91.99\n",
      "Train Epoch: 77 [30720/50000 (68%)]\tLoss: 0.269900, Accuracy: 89.84\n",
      "Train Epoch: 77 [33280/50000 (74%)]\tLoss: 0.242190, Accuracy: 92.38\n",
      "Train Epoch: 77 [35840/50000 (80%)]\tLoss: 0.221722, Accuracy: 91.60\n",
      "Train Epoch: 77 [38400/50000 (85%)]\tLoss: 0.252640, Accuracy: 91.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 77 [40960/50000 (91%)]\tLoss: 0.209316, Accuracy: 92.77\n",
      "Train Epoch: 77 [43520/50000 (97%)]\tLoss: 0.227918, Accuracy: 90.82\n",
      "\n",
      "Validation set: Average loss: 0.8732, Accuracy: 3671/5000 (73.00%)\n",
      "\n",
      "the time of this epoch:[39.083820819854736 s]\n",
      "Train Epoch: 78 [0/50000 (0%)]\tLoss: 0.219089, Accuracy: 93.16\n",
      "Train Epoch: 78 [2560/50000 (6%)]\tLoss: 0.153100, Accuracy: 95.12\n",
      "Train Epoch: 78 [5120/50000 (11%)]\tLoss: 0.260058, Accuracy: 92.38\n",
      "Train Epoch: 78 [7680/50000 (17%)]\tLoss: 0.259870, Accuracy: 92.19\n",
      "Train Epoch: 78 [10240/50000 (23%)]\tLoss: 0.221652, Accuracy: 92.38\n",
      "Train Epoch: 78 [12800/50000 (28%)]\tLoss: 0.244000, Accuracy: 92.38\n",
      "Train Epoch: 78 [15360/50000 (34%)]\tLoss: 0.250930, Accuracy: 91.02\n",
      "Train Epoch: 78 [17920/50000 (40%)]\tLoss: 0.206689, Accuracy: 92.97\n",
      "Train Epoch: 78 [20480/50000 (45%)]\tLoss: 0.255020, Accuracy: 89.45\n",
      "Train Epoch: 78 [23040/50000 (51%)]\tLoss: 0.186677, Accuracy: 93.36\n",
      "Train Epoch: 78 [25600/50000 (57%)]\tLoss: 0.247514, Accuracy: 91.21\n",
      "Train Epoch: 78 [28160/50000 (62%)]\tLoss: 0.183676, Accuracy: 94.34\n",
      "Train Epoch: 78 [30720/50000 (68%)]\tLoss: 0.231184, Accuracy: 92.58\n",
      "Train Epoch: 78 [33280/50000 (74%)]\tLoss: 0.200919, Accuracy: 91.41\n",
      "Train Epoch: 78 [35840/50000 (80%)]\tLoss: 0.215994, Accuracy: 93.95\n",
      "Train Epoch: 78 [38400/50000 (85%)]\tLoss: 0.240960, Accuracy: 91.99\n",
      "Train Epoch: 78 [40960/50000 (91%)]\tLoss: 0.265390, Accuracy: 91.80\n",
      "Train Epoch: 78 [43520/50000 (97%)]\tLoss: 0.203796, Accuracy: 92.77\n",
      "\n",
      "Validation set: Average loss: 0.7789, Accuracy: 3940/5000 (78.00%)\n",
      "\n",
      "the time of this epoch:[36.18082571029663 s]\n",
      "\n",
      "Test set: Average loss: 0.8338, Accuracy: 7821/10000 (78.21%)\n",
      "\n",
      "Train Epoch: 79 [0/50000 (0%)]\tLoss: 0.202146, Accuracy: 93.75\n",
      "Train Epoch: 79 [2560/50000 (6%)]\tLoss: 0.191434, Accuracy: 91.80\n",
      "Train Epoch: 79 [5120/50000 (11%)]\tLoss: 0.205151, Accuracy: 92.77\n",
      "Train Epoch: 79 [7680/50000 (17%)]\tLoss: 0.250934, Accuracy: 92.19\n",
      "Train Epoch: 79 [10240/50000 (23%)]\tLoss: 0.202050, Accuracy: 92.97\n",
      "Train Epoch: 79 [12800/50000 (28%)]\tLoss: 0.267522, Accuracy: 91.21\n",
      "Train Epoch: 79 [15360/50000 (34%)]\tLoss: 0.288322, Accuracy: 90.23\n",
      "Train Epoch: 79 [17920/50000 (40%)]\tLoss: 0.177616, Accuracy: 94.34\n",
      "Train Epoch: 79 [20480/50000 (45%)]\tLoss: 0.265919, Accuracy: 90.62\n",
      "Train Epoch: 79 [23040/50000 (51%)]\tLoss: 0.238208, Accuracy: 91.21\n",
      "Train Epoch: 79 [25600/50000 (57%)]\tLoss: 0.209825, Accuracy: 93.16\n",
      "Train Epoch: 79 [28160/50000 (62%)]\tLoss: 0.210599, Accuracy: 92.58\n",
      "Train Epoch: 79 [30720/50000 (68%)]\tLoss: 0.262407, Accuracy: 91.02\n",
      "Train Epoch: 79 [33280/50000 (74%)]\tLoss: 0.238849, Accuracy: 91.41\n",
      "Train Epoch: 79 [35840/50000 (80%)]\tLoss: 0.177874, Accuracy: 94.53\n",
      "Train Epoch: 79 [38400/50000 (85%)]\tLoss: 0.222623, Accuracy: 91.60\n",
      "Train Epoch: 79 [40960/50000 (91%)]\tLoss: 0.247458, Accuracy: 91.41\n",
      "Train Epoch: 79 [43520/50000 (97%)]\tLoss: 0.270808, Accuracy: 89.26\n",
      "\n",
      "Validation set: Average loss: 0.7286, Accuracy: 3932/5000 (78.00%)\n",
      "\n",
      "the time of this epoch:[38.71650695800781 s]\n",
      "Train Epoch: 80 [0/50000 (0%)]\tLoss: 0.196976, Accuracy: 93.36\n",
      "Train Epoch: 80 [2560/50000 (6%)]\tLoss: 0.193055, Accuracy: 91.99\n",
      "Train Epoch: 80 [5120/50000 (11%)]\tLoss: 0.238067, Accuracy: 91.60\n",
      "Train Epoch: 80 [7680/50000 (17%)]\tLoss: 0.227698, Accuracy: 92.38\n",
      "Train Epoch: 80 [10240/50000 (23%)]\tLoss: 0.251455, Accuracy: 92.38\n",
      "Train Epoch: 80 [12800/50000 (28%)]\tLoss: 0.192815, Accuracy: 92.77\n",
      "Train Epoch: 80 [15360/50000 (34%)]\tLoss: 0.280742, Accuracy: 90.62\n",
      "Train Epoch: 80 [17920/50000 (40%)]\tLoss: 0.269754, Accuracy: 90.04\n",
      "Train Epoch: 80 [20480/50000 (45%)]\tLoss: 0.220045, Accuracy: 92.58\n",
      "Train Epoch: 80 [23040/50000 (51%)]\tLoss: 0.227260, Accuracy: 91.60\n",
      "Train Epoch: 80 [25600/50000 (57%)]\tLoss: 0.257749, Accuracy: 91.21\n",
      "Train Epoch: 80 [28160/50000 (62%)]\tLoss: 0.234339, Accuracy: 92.58\n",
      "Train Epoch: 80 [30720/50000 (68%)]\tLoss: 0.231646, Accuracy: 92.19\n",
      "Train Epoch: 80 [33280/50000 (74%)]\tLoss: 0.267558, Accuracy: 90.82\n",
      "Train Epoch: 80 [35840/50000 (80%)]\tLoss: 0.256002, Accuracy: 90.82\n",
      "Train Epoch: 80 [38400/50000 (85%)]\tLoss: 0.216552, Accuracy: 93.16\n",
      "Train Epoch: 80 [40960/50000 (91%)]\tLoss: 0.257090, Accuracy: 92.38\n",
      "Train Epoch: 80 [43520/50000 (97%)]\tLoss: 0.281094, Accuracy: 92.38\n",
      "\n",
      "Validation set: Average loss: 0.8507, Accuracy: 3829/5000 (76.00%)\n",
      "\n",
      "the time of this epoch:[35.61485934257507 s]\n",
      "\n",
      "Test set: Average loss: 0.7527, Accuracy: 7887/10000 (78.87%)\n",
      "\n",
      "Train Epoch: 81 [0/50000 (0%)]\tLoss: 0.257312, Accuracy: 90.62\n",
      "Train Epoch: 81 [2560/50000 (6%)]\tLoss: 0.279115, Accuracy: 90.23\n",
      "Train Epoch: 81 [5120/50000 (11%)]\tLoss: 0.204847, Accuracy: 92.97\n",
      "Train Epoch: 81 [7680/50000 (17%)]\tLoss: 0.187910, Accuracy: 92.77\n",
      "Train Epoch: 81 [10240/50000 (23%)]\tLoss: 0.170289, Accuracy: 94.53\n",
      "Train Epoch: 81 [12800/50000 (28%)]\tLoss: 0.174963, Accuracy: 94.53\n",
      "Train Epoch: 81 [15360/50000 (34%)]\tLoss: 0.219152, Accuracy: 92.58\n",
      "Train Epoch: 81 [17920/50000 (40%)]\tLoss: 0.164960, Accuracy: 94.92\n",
      "Train Epoch: 81 [20480/50000 (45%)]\tLoss: 0.178262, Accuracy: 92.97\n",
      "Train Epoch: 81 [23040/50000 (51%)]\tLoss: 0.280075, Accuracy: 90.04\n",
      "Train Epoch: 81 [25600/50000 (57%)]\tLoss: 0.247166, Accuracy: 92.19\n",
      "Train Epoch: 81 [28160/50000 (62%)]\tLoss: 0.263457, Accuracy: 92.58\n",
      "Train Epoch: 81 [30720/50000 (68%)]\tLoss: 0.248494, Accuracy: 91.60\n",
      "Train Epoch: 81 [33280/50000 (74%)]\tLoss: 0.200925, Accuracy: 93.75\n",
      "Train Epoch: 81 [35840/50000 (80%)]\tLoss: 0.171487, Accuracy: 93.95\n",
      "Train Epoch: 81 [38400/50000 (85%)]\tLoss: 0.295164, Accuracy: 90.62\n",
      "Train Epoch: 81 [40960/50000 (91%)]\tLoss: 0.246073, Accuracy: 90.82\n",
      "Train Epoch: 81 [43520/50000 (97%)]\tLoss: 0.205309, Accuracy: 93.16\n",
      "\n",
      "Validation set: Average loss: 0.9706, Accuracy: 3798/5000 (75.00%)\n",
      "\n",
      "the time of this epoch:[38.82812738418579 s]\n",
      "Train Epoch: 82 [0/50000 (0%)]\tLoss: 0.219875, Accuracy: 93.55\n",
      "Train Epoch: 82 [2560/50000 (6%)]\tLoss: 0.168543, Accuracy: 94.53\n",
      "Train Epoch: 82 [5120/50000 (11%)]\tLoss: 0.217157, Accuracy: 92.77\n",
      "Train Epoch: 82 [7680/50000 (17%)]\tLoss: 0.230644, Accuracy: 92.97\n",
      "Train Epoch: 82 [10240/50000 (23%)]\tLoss: 0.190267, Accuracy: 92.97\n",
      "Train Epoch: 82 [12800/50000 (28%)]\tLoss: 0.228544, Accuracy: 92.58\n",
      "Train Epoch: 82 [15360/50000 (34%)]\tLoss: 0.187996, Accuracy: 93.16\n",
      "Train Epoch: 82 [17920/50000 (40%)]\tLoss: 0.231758, Accuracy: 91.60\n",
      "Train Epoch: 82 [20480/50000 (45%)]\tLoss: 0.229243, Accuracy: 92.38\n",
      "Train Epoch: 82 [23040/50000 (51%)]\tLoss: 0.244394, Accuracy: 90.23\n",
      "Train Epoch: 82 [25600/50000 (57%)]\tLoss: 0.182391, Accuracy: 93.75\n",
      "Train Epoch: 82 [28160/50000 (62%)]\tLoss: 0.263827, Accuracy: 91.60\n",
      "Train Epoch: 82 [30720/50000 (68%)]\tLoss: 0.220920, Accuracy: 91.99\n",
      "Train Epoch: 82 [33280/50000 (74%)]\tLoss: 0.209122, Accuracy: 92.58\n",
      "Train Epoch: 82 [35840/50000 (80%)]\tLoss: 0.234110, Accuracy: 92.38\n",
      "Train Epoch: 82 [38400/50000 (85%)]\tLoss: 0.219596, Accuracy: 93.55\n",
      "Train Epoch: 82 [40960/50000 (91%)]\tLoss: 0.229025, Accuracy: 92.38\n",
      "Train Epoch: 82 [43520/50000 (97%)]\tLoss: 0.246647, Accuracy: 91.60\n",
      "\n",
      "Validation set: Average loss: 0.7579, Accuracy: 3850/5000 (77.00%)\n",
      "\n",
      "the time of this epoch:[35.52848982810974 s]\n",
      "\n",
      "Test set: Average loss: 0.7971, Accuracy: 7580/10000 (75.80%)\n",
      "\n",
      "Train Epoch: 83 [0/50000 (0%)]\tLoss: 0.251461, Accuracy: 91.60\n",
      "Train Epoch: 83 [2560/50000 (6%)]\tLoss: 0.183308, Accuracy: 93.16\n",
      "Train Epoch: 83 [5120/50000 (11%)]\tLoss: 0.183297, Accuracy: 94.34\n",
      "Train Epoch: 83 [7680/50000 (17%)]\tLoss: 0.316316, Accuracy: 90.82\n",
      "Train Epoch: 83 [10240/50000 (23%)]\tLoss: 0.251883, Accuracy: 91.99\n",
      "Train Epoch: 83 [12800/50000 (28%)]\tLoss: 0.251304, Accuracy: 91.99\n",
      "Train Epoch: 83 [15360/50000 (34%)]\tLoss: 0.259695, Accuracy: 91.60\n",
      "------------------------------\n",
      "before autoscale: torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.1174]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0006]],\n",
      "\n",
      "        [[ 0.0176]],\n",
      "\n",
      "        [[ 0.0048]],\n",
      "\n",
      "        [[ 0.0708]],\n",
      "\n",
      "        [[ 0.0491]],\n",
      "\n",
      "        [[ 0.0507]],\n",
      "\n",
      "        [[ 0.1417]],\n",
      "\n",
      "        [[ 0.2073]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[-0.4841]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 512])\n",
      "tensor([[[-0.0568,  0.0000, -0.0003, -0.0085, -0.0023, -0.0343, -0.0238,\n",
      "          -0.0246, -0.0686, -0.1003, -0.0031, -0.1360, -0.2584, -0.0775,\n",
      "           0.0000, -0.0066, -0.0065, -0.0268, -0.0416, -0.0384, -0.0837,\n",
      "          -0.0430, -0.0127, -0.0766, -0.0594, -0.1224, -0.0474,  0.0000,\n",
      "          -0.0245,  0.0000, -0.1175, -0.0868, -0.0226, -0.0211, -0.0412,\n",
      "          -0.1036, -0.0105, -0.0134, -0.0419, -0.0618,  0.0000,  0.0000,\n",
      "          -0.1275, -0.0477, -0.0222, -0.0820,  0.0000,  0.0000, -0.0941,\n",
      "          -0.0815,  0.0000, -0.0867, -0.0707, -0.0902, -0.1500, -0.1500,\n",
      "          -0.0225, -0.0834, -0.1185, -0.1590, -0.0503,  0.0000,  0.0000,\n",
      "          -0.0027,  0.0000,  0.0000, -0.0091, -0.0029, -0.0013,  0.0000,\n",
      "          -0.0011, -0.0118, -0.0023, -0.0059,  0.0000, -0.0001, -0.0011,\n",
      "          -0.0008,  0.0000,  0.0000,  0.0000, -0.0017, -0.0002, -0.0025,\n",
      "          -0.0343, -0.0002, -0.0013, -0.0002, -0.0016,  0.0000, -0.0034,\n",
      "           0.0000, -0.0100, -0.0021,  0.0000,  0.0000, -0.0010, -0.0037,\n",
      "           0.0000, -0.0002, -0.0035,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0034, -0.0014, -0.0121, -0.0092, -0.0129, -0.0086,  0.0000,\n",
      "          -0.0257, -0.0009, -0.0020, -0.0162, -0.0103,  0.0000, -0.0050,\n",
      "          -0.0012, -0.0090, -0.0002,  0.0000, -0.0015, -0.0030, -0.0060,\n",
      "          -0.0022, -0.0015, -0.0000,  0.0000, -0.0061,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000, -0.0049, -0.0053,  0.0000,  0.0000, -0.0018,\n",
      "          -0.0015, -0.0078,  0.0000,  0.0000, -0.0024,  0.0000, -0.0068,\n",
      "          -0.0071, -0.0001, -0.0286, -0.0038, -0.0047, -0.0005, -0.0056,\n",
      "           0.0000,  0.0000,  0.0000, -0.0029, -0.0035, -0.0017, -0.0045,\n",
      "          -0.0059, -0.0012,  0.0000,  0.0000, -0.0034, -0.0085, -0.0037,\n",
      "          -0.0212, -0.0010, -0.0047, -0.0132, -0.0110, -0.0129, -0.0026,\n",
      "          -0.0017,  0.0000, -0.0025, -0.0038,  0.0000,  0.0000, -0.0067,\n",
      "          -0.0038, -0.0001,  0.0000,  0.0000,  0.0000,  0.0000, -0.0022,\n",
      "          -0.0322, -0.0012,  0.0000,  0.0000,  0.0000,  0.0000, -0.0162,\n",
      "          -0.0044,  0.0000, -0.0019, -0.0023, -0.0018, -0.0007,  0.0000,\n",
      "          -0.0031, -0.0049,  0.0000, -0.0032, -0.0068,  0.0000, -0.0149,\n",
      "           0.0000, -0.0189, -0.0011, -0.0072, -0.0038, -0.0112, -0.0012,\n",
      "           0.0000, -0.0039,  0.0000, -0.0076,  0.0000, -0.0027, -0.0001,\n",
      "          -0.0064, -0.0196, -0.5695, -0.0123, -0.0044,  0.0000, -0.0004,\n",
      "          -0.0043, -0.0136, -0.0011, -0.0172, -0.0007, -0.0039, -0.0263,\n",
      "           0.0000,  0.0000, -0.0001, -0.0131, -0.0129, -0.0038,  0.0000,\n",
      "          -0.0009, -0.0056, -0.0041, -0.0039, -0.0058,  0.0000, -0.0074,\n",
      "          -0.0068, -0.0002, -0.0001,  0.0000, -0.0040,  0.0000, -0.0009,\n",
      "           0.0000, -0.0134, -0.0278, -0.0025,  0.0000,  0.0000, -0.0000,\n",
      "          -0.0081, -0.0055,  0.0000,  0.0000, -0.0015, -0.0049,  0.0000,\n",
      "          -0.0142, -0.0016, -0.0165, -0.0050,  0.0000, -0.0054, -0.0087,\n",
      "          -0.0006, -0.0001,  0.0000, -0.0006, -0.0052,  0.0000, -0.0074,\n",
      "          -0.0039, -0.0056,  0.0000, -0.0021, -0.0043, -0.0031, -0.0050,\n",
      "           0.0000, -0.0108, -0.0012,  0.0000,  0.0000,  0.0000, -0.0056,\n",
      "          -0.0134, -0.0068, -0.0019, -0.0008, -0.0021,  0.0000, -0.0012,\n",
      "          -0.0005, -0.0116, -0.0005, -0.0029,  0.0000,  0.0000, -0.0132,\n",
      "          -0.0025, -0.0007,  0.0000, -0.0032, -0.0015, -0.0057, -0.0013,\n",
      "          -0.0037, -0.0038, -0.0044, -0.0074, -0.0290, -0.0061, -0.0023,\n",
      "          -0.0038, -0.0017,  0.0000,  0.0000,  0.0000, -0.0133, -0.0141,\n",
      "           0.0000, -0.0027, -0.0010,  0.0000,  0.0000, -0.0067,  0.0000,\n",
      "          -0.0040, -0.0013, -0.0041, -0.0152, -0.0010, -0.0082,  0.0000,\n",
      "           0.0000, -0.0004, -0.0014, -0.0074, -0.0048, -0.0022, -0.0010,\n",
      "          -0.0010, -0.0027, -0.0060, -0.0011, -0.0027, -0.0038, -0.0013,\n",
      "          -0.0022, -0.0252, -0.0063, -0.0002,  0.0000, -0.0215, -0.0094,\n",
      "          -0.0075,  0.0000,  0.0000, -0.0068, -0.0036, -0.0012,  0.0000,\n",
      "           0.0000, -0.0019, -0.0108, -0.0026, -0.0034, -0.0048,  0.0000,\n",
      "          -0.0068, -0.0113, -0.0004, -0.0053, -0.0119, -0.0003, -0.0003,\n",
      "          -0.0000, -0.0056,  0.0000, -0.0215, -0.0000, -0.0128, -0.0029,\n",
      "           0.0000, -0.0041, -0.0040, -0.0034, -0.0039, -0.0039, -0.0021,\n",
      "           0.0000, -0.0030,  0.0000, -0.0054,  0.0000, -0.0104,  0.0000,\n",
      "           0.0000, -0.0067, -0.0155,  0.0000,  0.0000,  0.0000, -0.0028,\n",
      "          -0.0300,  0.0000, -0.0030, -0.0019,  0.0000, -0.0404,  0.0000,\n",
      "          -0.0210,  0.0000,  0.0000,  0.0000, -0.0009,  0.0000,  0.0000,\n",
      "          -0.0023,  0.0000,  0.0000,  0.0000,  0.0000, -0.0019, -0.0010,\n",
      "          -0.0325, -0.0050, -0.0016,  0.0000,  0.0000, -0.0094, -0.0065,\n",
      "          -0.0079, -0.0000,  0.0000, -0.0177, -0.0034,  0.0000, -0.0054,\n",
      "           0.0000, -0.0021,  0.0000, -0.0008, -0.0034, -0.0040, -0.0086,\n",
      "          -0.0000, -0.0035,  0.0000, -0.0085, -0.0002, -0.0149, -0.0025,\n",
      "          -0.0028,  0.0000, -0.0003,  0.0000, -0.0034, -0.0049, -0.0025,\n",
      "          -0.0010, -0.0021,  0.0000,  0.0000,  0.0000, -0.0177, -0.0033,\n",
      "          -0.0048, -0.0072, -0.0005,  0.0000,  0.0000,  0.0000, -0.0085,\n",
      "          -0.0064, -0.0014,  0.0000, -0.0209, -0.0019, -0.0039, -0.0050,\n",
      "          -0.0326, -0.0122, -0.0172, -0.0001,  0.0000, -0.0127, -0.0088,\n",
      "          -0.0112, -0.0039,  0.0000, -0.0198, -0.0059, -0.0321, -0.0059,\n",
      "          -0.0034]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-02 *\n",
      "       [[-0.5444,  0.0381, -0.4068,  1.2340, -0.7933, -0.1160,  1.0252,\n",
      "         -0.7683,  0.3418]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 448, 512])\n",
      "tensor([[ 5.0550e-04, -8.8762e-04,  4.0167e-04,  ...,  2.5462e-04,\n",
      "         -3.2823e-04,  1.9025e-04],\n",
      "        [ 8.4681e-05,  2.8330e-04, -1.6750e-04,  ..., -4.2294e-05,\n",
      "          1.1716e-04, -2.5188e-04],\n",
      "        [ 3.0612e-03,  9.3996e-04,  4.4130e-04,  ...,  2.1084e-03,\n",
      "          1.0903e-03,  5.6280e-04],\n",
      "        ...,\n",
      "        [-6.9925e-05, -8.2928e-04, -2.6852e-04,  ..., -4.5608e-05,\n",
      "         -1.0635e-04, -9.7114e-05],\n",
      "        [ 2.8992e-04,  1.2542e-04, -6.6977e-04,  ...,  6.6853e-05,\n",
      "          9.6512e-05, -1.8008e-04],\n",
      "        [-3.2613e-04, -3.9940e-04, -5.4555e-04,  ..., -3.0413e-04,\n",
      "         -2.0932e-04, -1.0758e-04]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 448, 512])\n",
      "tensor([[ 5.0550e-05, -8.8762e-05,  4.0167e-05,  ...,  2.5462e-05,\n",
      "         -3.2823e-05,  1.9025e-05],\n",
      "        [ 8.4681e-06,  2.8330e-05, -1.6750e-05,  ..., -4.2294e-06,\n",
      "          1.1716e-05, -2.5188e-05],\n",
      "        [ 3.0612e-04,  9.3996e-05,  4.4130e-05,  ...,  2.1084e-04,\n",
      "          1.0903e-04,  5.6280e-05],\n",
      "        ...,\n",
      "        [-5.4342e-05, -4.3853e-06, -1.1054e-04,  ..., -7.2766e-05,\n",
      "         -7.3703e-05, -9.4437e-05],\n",
      "        [-4.5795e-06,  1.2394e-04, -1.4284e-05,  ..., -1.4751e-05,\n",
      "          2.0310e-05, -5.9601e-06],\n",
      "        [-4.8009e-05, -1.4471e-05, -5.3448e-06,  ..., -1.8108e-05,\n",
      "         -1.1901e-06,  1.2184e-05]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 83 [17920/50000 (40%)]\tLoss: 0.237835, Accuracy: 91.99\n",
      "Train Epoch: 83 [20480/50000 (45%)]\tLoss: 0.202850, Accuracy: 92.19\n",
      "Train Epoch: 83 [23040/50000 (51%)]\tLoss: 0.200230, Accuracy: 94.53\n",
      "Train Epoch: 83 [25600/50000 (57%)]\tLoss: 0.266039, Accuracy: 89.84\n",
      "Train Epoch: 83 [28160/50000 (62%)]\tLoss: 0.240357, Accuracy: 92.97\n",
      "Train Epoch: 83 [30720/50000 (68%)]\tLoss: 0.227390, Accuracy: 92.97\n",
      "Train Epoch: 83 [33280/50000 (74%)]\tLoss: 0.202135, Accuracy: 92.19\n",
      "Train Epoch: 83 [35840/50000 (80%)]\tLoss: 0.289136, Accuracy: 90.04\n",
      "Train Epoch: 83 [38400/50000 (85%)]\tLoss: 0.194868, Accuracy: 92.58\n",
      "Train Epoch: 83 [40960/50000 (91%)]\tLoss: 0.199867, Accuracy: 92.97\n",
      "Train Epoch: 83 [43520/50000 (97%)]\tLoss: 0.234771, Accuracy: 90.62\n",
      "\n",
      "Validation set: Average loss: 0.5740, Accuracy: 4169/5000 (83.00%)\n",
      "\n",
      "the time of this epoch:[38.969828605651855 s]\n",
      "Train Epoch: 84 [0/50000 (0%)]\tLoss: 0.211602, Accuracy: 93.16\n",
      "Train Epoch: 84 [2560/50000 (6%)]\tLoss: 0.213811, Accuracy: 93.36\n",
      "Train Epoch: 84 [5120/50000 (11%)]\tLoss: 0.263566, Accuracy: 90.82\n",
      "Train Epoch: 84 [7680/50000 (17%)]\tLoss: 0.179357, Accuracy: 92.97\n",
      "Train Epoch: 84 [10240/50000 (23%)]\tLoss: 0.200154, Accuracy: 93.16\n",
      "Train Epoch: 84 [12800/50000 (28%)]\tLoss: 0.227875, Accuracy: 91.80\n",
      "Train Epoch: 84 [15360/50000 (34%)]\tLoss: 0.243212, Accuracy: 92.58\n",
      "Train Epoch: 84 [17920/50000 (40%)]\tLoss: 0.203065, Accuracy: 92.77\n",
      "Train Epoch: 84 [20480/50000 (45%)]\tLoss: 0.177492, Accuracy: 93.55\n",
      "Train Epoch: 84 [23040/50000 (51%)]\tLoss: 0.234141, Accuracy: 91.02\n",
      "Train Epoch: 84 [25600/50000 (57%)]\tLoss: 0.233466, Accuracy: 93.16\n",
      "Train Epoch: 84 [28160/50000 (62%)]\tLoss: 0.238607, Accuracy: 91.41\n",
      "Train Epoch: 84 [30720/50000 (68%)]\tLoss: 0.267209, Accuracy: 91.60\n",
      "Train Epoch: 84 [33280/50000 (74%)]\tLoss: 0.178421, Accuracy: 94.53\n",
      "Train Epoch: 84 [35840/50000 (80%)]\tLoss: 0.278207, Accuracy: 90.04\n",
      "Train Epoch: 84 [38400/50000 (85%)]\tLoss: 0.271065, Accuracy: 90.23\n",
      "Train Epoch: 84 [40960/50000 (91%)]\tLoss: 0.276748, Accuracy: 91.41\n",
      "Train Epoch: 84 [43520/50000 (97%)]\tLoss: 0.251024, Accuracy: 91.41\n",
      "\n",
      "Validation set: Average loss: 0.9459, Accuracy: 3736/5000 (74.00%)\n",
      "\n",
      "the time of this epoch:[35.363664865493774 s]\n",
      "\n",
      "Test set: Average loss: 0.9427, Accuracy: 7447/10000 (74.47%)\n",
      "\n",
      "Train Epoch: 85 [0/50000 (0%)]\tLoss: 0.250330, Accuracy: 91.41\n",
      "Train Epoch: 85 [2560/50000 (6%)]\tLoss: 0.221151, Accuracy: 93.55\n",
      "Train Epoch: 85 [5120/50000 (11%)]\tLoss: 0.223646, Accuracy: 93.75\n",
      "Train Epoch: 85 [7680/50000 (17%)]\tLoss: 0.227088, Accuracy: 91.21\n",
      "Train Epoch: 85 [10240/50000 (23%)]\tLoss: 0.153064, Accuracy: 94.73\n",
      "Train Epoch: 85 [12800/50000 (28%)]\tLoss: 0.197372, Accuracy: 92.58\n",
      "Train Epoch: 85 [15360/50000 (34%)]\tLoss: 0.276796, Accuracy: 91.21\n",
      "Train Epoch: 85 [17920/50000 (40%)]\tLoss: 0.294257, Accuracy: 89.26\n",
      "Train Epoch: 85 [20480/50000 (45%)]\tLoss: 0.296650, Accuracy: 89.65\n",
      "Train Epoch: 85 [23040/50000 (51%)]\tLoss: 0.210914, Accuracy: 93.95\n",
      "Train Epoch: 85 [25600/50000 (57%)]\tLoss: 0.244295, Accuracy: 90.82\n",
      "Train Epoch: 85 [28160/50000 (62%)]\tLoss: 0.243843, Accuracy: 91.02\n",
      "Train Epoch: 85 [30720/50000 (68%)]\tLoss: 0.255679, Accuracy: 91.60\n",
      "Train Epoch: 85 [33280/50000 (74%)]\tLoss: 0.236311, Accuracy: 91.80\n",
      "Train Epoch: 85 [35840/50000 (80%)]\tLoss: 0.248915, Accuracy: 91.60\n",
      "Train Epoch: 85 [38400/50000 (85%)]\tLoss: 0.214726, Accuracy: 92.97\n",
      "Train Epoch: 85 [40960/50000 (91%)]\tLoss: 0.230443, Accuracy: 92.97\n",
      "Train Epoch: 85 [43520/50000 (97%)]\tLoss: 0.229578, Accuracy: 92.19\n",
      "\n",
      "Validation set: Average loss: 0.7097, Accuracy: 3964/5000 (79.00%)\n",
      "\n",
      "the time of this epoch:[38.835078954696655 s]\n",
      "Train Epoch: 86 [0/50000 (0%)]\tLoss: 0.216819, Accuracy: 92.77\n",
      "Train Epoch: 86 [2560/50000 (6%)]\tLoss: 0.203610, Accuracy: 93.75\n",
      "Train Epoch: 86 [5120/50000 (11%)]\tLoss: 0.145268, Accuracy: 95.12\n",
      "Train Epoch: 86 [7680/50000 (17%)]\tLoss: 0.235052, Accuracy: 91.02\n",
      "Train Epoch: 86 [10240/50000 (23%)]\tLoss: 0.287620, Accuracy: 90.82\n",
      "Train Epoch: 86 [12800/50000 (28%)]\tLoss: 0.190840, Accuracy: 93.16\n",
      "Train Epoch: 86 [15360/50000 (34%)]\tLoss: 0.202167, Accuracy: 93.16\n",
      "Train Epoch: 86 [17920/50000 (40%)]\tLoss: 0.216844, Accuracy: 93.95\n",
      "Train Epoch: 86 [20480/50000 (45%)]\tLoss: 0.210208, Accuracy: 93.55\n",
      "Train Epoch: 86 [23040/50000 (51%)]\tLoss: 0.300835, Accuracy: 90.62\n",
      "Train Epoch: 86 [25600/50000 (57%)]\tLoss: 0.268897, Accuracy: 91.60\n",
      "Train Epoch: 86 [28160/50000 (62%)]\tLoss: 0.233630, Accuracy: 91.80\n",
      "Train Epoch: 86 [30720/50000 (68%)]\tLoss: 0.220753, Accuracy: 92.58\n",
      "Train Epoch: 86 [33280/50000 (74%)]\tLoss: 0.214439, Accuracy: 92.58\n",
      "Train Epoch: 86 [35840/50000 (80%)]\tLoss: 0.214394, Accuracy: 93.16\n",
      "Train Epoch: 86 [38400/50000 (85%)]\tLoss: 0.254174, Accuracy: 91.60\n",
      "Train Epoch: 86 [40960/50000 (91%)]\tLoss: 0.237671, Accuracy: 90.82\n",
      "Train Epoch: 86 [43520/50000 (97%)]\tLoss: 0.253006, Accuracy: 91.99\n",
      "\n",
      "Validation set: Average loss: 0.7353, Accuracy: 3959/5000 (79.00%)\n",
      "\n",
      "the time of this epoch:[35.194709062576294 s]\n",
      "\n",
      "Test set: Average loss: 0.8050, Accuracy: 7734/10000 (77.34%)\n",
      "\n",
      "Train Epoch: 87 [0/50000 (0%)]\tLoss: 0.193443, Accuracy: 93.16\n",
      "Train Epoch: 87 [2560/50000 (6%)]\tLoss: 0.182664, Accuracy: 93.16\n",
      "Train Epoch: 87 [5120/50000 (11%)]\tLoss: 0.239450, Accuracy: 92.77\n",
      "Train Epoch: 87 [7680/50000 (17%)]\tLoss: 0.198968, Accuracy: 92.58\n",
      "Train Epoch: 87 [10240/50000 (23%)]\tLoss: 0.171448, Accuracy: 94.53\n",
      "Train Epoch: 87 [12800/50000 (28%)]\tLoss: 0.204489, Accuracy: 93.16\n",
      "Train Epoch: 87 [15360/50000 (34%)]\tLoss: 0.181763, Accuracy: 93.55\n",
      "Train Epoch: 87 [17920/50000 (40%)]\tLoss: 0.190089, Accuracy: 93.36\n",
      "Train Epoch: 87 [20480/50000 (45%)]\tLoss: 0.205376, Accuracy: 91.60\n",
      "Train Epoch: 87 [23040/50000 (51%)]\tLoss: 0.248517, Accuracy: 92.19\n",
      "Train Epoch: 87 [25600/50000 (57%)]\tLoss: 0.222160, Accuracy: 92.38\n",
      "Train Epoch: 87 [28160/50000 (62%)]\tLoss: 0.293296, Accuracy: 90.23\n",
      "Train Epoch: 87 [30720/50000 (68%)]\tLoss: 0.231684, Accuracy: 91.80\n",
      "Train Epoch: 87 [33280/50000 (74%)]\tLoss: 0.199106, Accuracy: 93.16\n",
      "Train Epoch: 87 [35840/50000 (80%)]\tLoss: 0.238717, Accuracy: 92.38\n",
      "Train Epoch: 87 [38400/50000 (85%)]\tLoss: 0.235549, Accuracy: 92.97\n",
      "Train Epoch: 87 [40960/50000 (91%)]\tLoss: 0.286265, Accuracy: 89.65\n",
      "Train Epoch: 87 [43520/50000 (97%)]\tLoss: 0.241518, Accuracy: 91.80\n",
      "\n",
      "Validation set: Average loss: 0.9242, Accuracy: 3828/5000 (76.00%)\n",
      "\n",
      "the time of this epoch:[38.4852569103241 s]\n",
      "Train Epoch: 88 [0/50000 (0%)]\tLoss: 0.207926, Accuracy: 93.95\n",
      "Train Epoch: 88 [2560/50000 (6%)]\tLoss: 0.196335, Accuracy: 92.38\n",
      "Train Epoch: 88 [5120/50000 (11%)]\tLoss: 0.220008, Accuracy: 91.99\n",
      "Train Epoch: 88 [7680/50000 (17%)]\tLoss: 0.247043, Accuracy: 90.62\n",
      "Train Epoch: 88 [10240/50000 (23%)]\tLoss: 0.223653, Accuracy: 93.75\n",
      "Train Epoch: 88 [12800/50000 (28%)]\tLoss: 0.227600, Accuracy: 91.41\n",
      "Train Epoch: 88 [15360/50000 (34%)]\tLoss: 0.169917, Accuracy: 94.34\n",
      "Train Epoch: 88 [17920/50000 (40%)]\tLoss: 0.188284, Accuracy: 92.58\n",
      "Train Epoch: 88 [20480/50000 (45%)]\tLoss: 0.247905, Accuracy: 91.41\n",
      "Train Epoch: 88 [23040/50000 (51%)]\tLoss: 0.214207, Accuracy: 92.38\n",
      "Train Epoch: 88 [25600/50000 (57%)]\tLoss: 0.248435, Accuracy: 91.99\n",
      "Train Epoch: 88 [28160/50000 (62%)]\tLoss: 0.154249, Accuracy: 94.73\n",
      "Train Epoch: 88 [30720/50000 (68%)]\tLoss: 0.247997, Accuracy: 91.80\n",
      "Train Epoch: 88 [33280/50000 (74%)]\tLoss: 0.228811, Accuracy: 92.19\n",
      "Train Epoch: 88 [35840/50000 (80%)]\tLoss: 0.245259, Accuracy: 91.41\n",
      "Train Epoch: 88 [38400/50000 (85%)]\tLoss: 0.247703, Accuracy: 91.21\n",
      "Train Epoch: 88 [40960/50000 (91%)]\tLoss: 0.195665, Accuracy: 94.53\n",
      "Train Epoch: 88 [43520/50000 (97%)]\tLoss: 0.243406, Accuracy: 92.77\n",
      "\n",
      "Validation set: Average loss: 1.0943, Accuracy: 3370/5000 (67.00%)\n",
      "\n",
      "the time of this epoch:[35.182878494262695 s]\n",
      "\n",
      "Test set: Average loss: 1.0805, Accuracy: 6741/10000 (67.41%)\n",
      "\n",
      "Train Epoch: 89 [0/50000 (0%)]\tLoss: 0.188777, Accuracy: 93.95\n",
      "Train Epoch: 89 [2560/50000 (6%)]\tLoss: 0.235077, Accuracy: 91.21\n",
      "Train Epoch: 89 [5120/50000 (11%)]\tLoss: 0.262112, Accuracy: 91.41\n",
      "Train Epoch: 89 [7680/50000 (17%)]\tLoss: 0.242521, Accuracy: 91.60\n",
      "Train Epoch: 89 [10240/50000 (23%)]\tLoss: 0.199014, Accuracy: 92.58\n",
      "Train Epoch: 89 [12800/50000 (28%)]\tLoss: 0.273648, Accuracy: 91.02\n",
      "Train Epoch: 89 [15360/50000 (34%)]\tLoss: 0.222015, Accuracy: 92.19\n",
      "Train Epoch: 89 [17920/50000 (40%)]\tLoss: 0.216933, Accuracy: 92.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 89 [20480/50000 (45%)]\tLoss: 0.250230, Accuracy: 92.19\n",
      "Train Epoch: 89 [23040/50000 (51%)]\tLoss: 0.201088, Accuracy: 92.58\n",
      "Train Epoch: 89 [25600/50000 (57%)]\tLoss: 0.186781, Accuracy: 92.19\n",
      "Train Epoch: 89 [28160/50000 (62%)]\tLoss: 0.232962, Accuracy: 91.80\n",
      "Train Epoch: 89 [30720/50000 (68%)]\tLoss: 0.254465, Accuracy: 90.04\n",
      "Train Epoch: 89 [33280/50000 (74%)]\tLoss: 0.253647, Accuracy: 92.58\n",
      "Train Epoch: 89 [35840/50000 (80%)]\tLoss: 0.214275, Accuracy: 91.99\n",
      "Train Epoch: 89 [38400/50000 (85%)]\tLoss: 0.220727, Accuracy: 91.80\n",
      "Train Epoch: 89 [40960/50000 (91%)]\tLoss: 0.183983, Accuracy: 93.95\n",
      "Train Epoch: 89 [43520/50000 (97%)]\tLoss: 0.208915, Accuracy: 92.38\n",
      "\n",
      "Validation set: Average loss: 0.9159, Accuracy: 3883/5000 (77.00%)\n",
      "\n",
      "the time of this epoch:[38.59506678581238 s]\n",
      "Train Epoch: 90 [0/50000 (0%)]\tLoss: 0.195593, Accuracy: 92.77\n",
      "Train Epoch: 90 [2560/50000 (6%)]\tLoss: 0.146074, Accuracy: 95.12\n",
      "Train Epoch: 90 [5120/50000 (11%)]\tLoss: 0.228895, Accuracy: 91.21\n",
      "Train Epoch: 90 [7680/50000 (17%)]\tLoss: 0.154549, Accuracy: 95.31\n",
      "Train Epoch: 90 [10240/50000 (23%)]\tLoss: 0.176000, Accuracy: 94.53\n",
      "Train Epoch: 90 [12800/50000 (28%)]\tLoss: 0.293067, Accuracy: 89.26\n",
      "Train Epoch: 90 [15360/50000 (34%)]\tLoss: 0.229230, Accuracy: 93.16\n",
      "Train Epoch: 90 [17920/50000 (40%)]\tLoss: 0.202269, Accuracy: 92.97\n",
      "Train Epoch: 90 [20480/50000 (45%)]\tLoss: 0.186970, Accuracy: 93.36\n",
      "Train Epoch: 90 [23040/50000 (51%)]\tLoss: 0.238527, Accuracy: 92.97\n",
      "Train Epoch: 90 [25600/50000 (57%)]\tLoss: 0.201937, Accuracy: 91.99\n",
      "Train Epoch: 90 [28160/50000 (62%)]\tLoss: 0.242844, Accuracy: 91.60\n",
      "Train Epoch: 90 [30720/50000 (68%)]\tLoss: 0.163446, Accuracy: 93.36\n",
      "Train Epoch: 90 [33280/50000 (74%)]\tLoss: 0.261400, Accuracy: 91.60\n",
      "Train Epoch: 90 [35840/50000 (80%)]\tLoss: 0.198850, Accuracy: 93.55\n",
      "Train Epoch: 90 [38400/50000 (85%)]\tLoss: 0.253301, Accuracy: 92.58\n",
      "Train Epoch: 90 [40960/50000 (91%)]\tLoss: 0.220398, Accuracy: 93.16\n",
      "Train Epoch: 90 [43520/50000 (97%)]\tLoss: 0.266181, Accuracy: 91.21\n",
      "\n",
      "Validation set: Average loss: 6.7628, Accuracy: 773/5000 (15.00%)\n",
      "\n",
      "the time of this epoch:[35.53512930870056 s]\n",
      "------------------------------\n",
      "before autoscale: torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.3570]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0113]],\n",
      "\n",
      "        [[ 0.0026]],\n",
      "\n",
      "        [[ 0.0080]],\n",
      "\n",
      "        [[ 0.0607]],\n",
      "\n",
      "        [[ 0.0264]],\n",
      "\n",
      "        [[ 0.0443]],\n",
      "\n",
      "        [[ 0.0940]],\n",
      "\n",
      "        [[ 0.1973]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[-0.4504]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 512])\n",
      "tensor([[[-0.1608,  0.0000, -0.0051, -0.0012, -0.0036, -0.0273, -0.0119,\n",
      "          -0.0200, -0.0423, -0.0889, -0.0015, -0.1094, -0.4200, -0.0807,\n",
      "           0.0000,  0.0000, -0.0064, -0.0329, -0.0019, -0.0396, -0.0668,\n",
      "          -0.0568, -0.0070, -0.0436, -0.0020, -0.1840, -0.0594,  0.0000,\n",
      "          -0.0028, -0.0032, -0.0465, -0.1203, -0.0208, -0.0023, -0.0238,\n",
      "          -0.1079, -0.0008, -0.0330, -0.0431, -0.0394,  0.0000,  0.0000,\n",
      "          -0.0728, -0.0002, -0.0259, -0.0853,  0.0000,  0.0000, -0.0001,\n",
      "          -0.0625,  0.0000, -0.0808, -0.0635, -0.0814, -0.1446, -0.1206,\n",
      "          -0.0545, -0.0967, -0.1081, -0.1295, -0.0192,  0.0000,  0.0000,\n",
      "          -0.0414,  0.0000,  0.0000, -0.0483, -0.0083, -0.0006,  0.0000,\n",
      "          -0.0007, -0.0182, -0.0007, -0.0038,  0.0000, -0.0003, -0.0007,\n",
      "          -0.0004,  0.0000,  0.0000,  0.0000, -0.0000, -0.0001,  0.0000,\n",
      "          -0.0273,  0.0000, -0.0010,  0.0000, -0.0002,  0.0000, -0.0027,\n",
      "           0.0000, -0.0003, -0.0000, -0.0126,  0.0000, -0.0004, -0.0032,\n",
      "           0.0000, -0.0003, -0.0001,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0001, -0.0021, -0.0119, -0.0006, -0.0176, -0.0076,  0.0000,\n",
      "          -0.0259, -0.0085,  0.0000, -0.3521, -0.0117,  0.0000, -0.0001,\n",
      "          -0.0000, -0.0152,  0.0000,  0.0000, -0.0000, -0.0023,  0.0000,\n",
      "          -0.0014, -0.0010, -0.0001,  0.0000, -0.0048,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000, -0.0049, -0.0001,  0.0000,  0.0000, -0.0020,\n",
      "           0.0000, -0.0063,  0.0000,  0.0000, -0.0002,  0.0000, -0.0073,\n",
      "          -0.0069, -0.0011, -0.1666,  0.0000, -0.0077, -0.0394, -0.0049,\n",
      "           0.0000,  0.0000,  0.0000, -0.0019, -0.0023, -0.0011, -0.0030,\n",
      "          -0.0099, -0.0009,  0.0000,  0.0000, -0.0028, -0.0174, -0.0029,\n",
      "          -0.1040,  0.0000, -0.0044, -0.0388,  0.0000, -0.1264,  0.0000,\n",
      "          -0.0014,  0.0000, -0.0017, -0.0028,  0.0000,  0.0000, -0.0059,\n",
      "          -0.0004, -0.0009, -0.0035,  0.0000,  0.0000,  0.0000, -0.0000,\n",
      "          -0.0033,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0127,\n",
      "          -0.0000,  0.0000, -0.0021, -0.0000, -0.0013, -0.0003,  0.0000,\n",
      "          -0.0033, -0.0044,  0.0000, -0.0091,  0.0000, -0.0000, -0.0154,\n",
      "           0.0000,  0.0000, -0.0016, -0.0081,  0.0000, -0.0083, -0.0030,\n",
      "           0.0000, -0.0082,  0.0000, -0.0151,  0.0000, -0.0002,  0.0000,\n",
      "          -0.0100, -0.0000, -2.1119,  0.0000, -0.0008,  0.0000,  0.0000,\n",
      "          -0.0023, -0.0007, -0.0001, -0.0000, -0.0006, -0.0007, -0.0210,\n",
      "           0.0000,  0.0000,  0.0000, -0.0048, -0.0123, -0.0052,  0.0000,\n",
      "          -0.0008, -0.0001, -0.0000, -0.0034,  0.0000,  0.0000, -0.0055,\n",
      "          -0.0070,  0.0000, -0.0000,  0.0000, -0.0020,  0.0000, -0.0004,\n",
      "           0.0000, -0.0123, -0.1237,  0.0000,  0.0000,  0.0000, -0.0002,\n",
      "          -0.0030, -0.0663,  0.0000,  0.0000, -0.0017, -0.0041,  0.0000,\n",
      "          -0.0002, -0.0162, -0.0082, -0.0054,  0.0000, -0.0041, -0.0326,\n",
      "           0.0000, -0.0012,  0.0000,  0.0000, -0.0039,  0.0000, -0.0063,\n",
      "           0.0000, -0.0015,  0.0000, -0.0030, -0.0053, -0.0029, -0.0040,\n",
      "           0.0000, -0.0130, -0.0020,  0.0000,  0.0000,  0.0000, -0.0077,\n",
      "          -0.0101, -0.0067, -0.0488, -0.0090, -0.0050,  0.0000, -0.0037,\n",
      "          -0.0002, -0.0170,  0.0000,  0.0000,  0.0000,  0.0000, -0.0061,\n",
      "          -0.0022,  0.0000,  0.0000, -0.0024, -0.0014, -0.0044,  0.0000,\n",
      "          -0.0031,  0.0000, -0.0059, -0.0071, -0.0490, -0.0145, -0.0033,\n",
      "          -0.0139, -0.0021,  0.0000,  0.0000,  0.0000, -0.0202,  0.0000,\n",
      "           0.0000, -0.0000, -0.0094,  0.0000,  0.0000, -0.0057,  0.0000,\n",
      "          -0.0036, -0.0015, -0.0000,  0.0000, -0.0010, -0.0250,  0.0000,\n",
      "           0.0000, -0.0009, -0.0001, -0.0042, -0.0010, -0.0016,  0.0000,\n",
      "          -0.0005, -0.0028, -0.0057, -0.0018, -0.0001, -0.1286, -0.0001,\n",
      "          -0.0022, -0.0250, -0.0048, -0.0000,  0.0000, -0.0020, -0.0073,\n",
      "          -0.0164,  0.0000,  0.0000, -0.0008, -0.0049,  0.0000,  0.0000,\n",
      "           0.0000, -0.0046, -0.0015, -0.0000, -0.0046, -0.0061,  0.0000,\n",
      "          -0.0018, -0.0691,  0.0000, -0.0034, -0.0279,  0.0000,  0.0000,\n",
      "           0.0000, -0.0040,  0.0000, -0.0053,  0.0000, -0.0009, -0.0000,\n",
      "           0.0000, -0.0000, -0.0002, -0.0021, -0.0061,  0.0000,  0.0000,\n",
      "           0.0000, -0.0024,  0.0000, -0.0094,  0.0000, -0.0102, -0.0611,\n",
      "           0.0000, -0.0075, -0.0199,  0.0000,  0.0000,  0.0000, -0.0002,\n",
      "           0.0000,  0.0000, -0.0227, -0.0225,  0.0000, -0.0584,  0.0000,\n",
      "          -0.0216, -0.0015,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0021,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0423, -0.0034, -0.0001,  0.0000,  0.0000, -0.0015, -0.0075,\n",
      "           0.0000,  0.0000,  0.0000, -0.0146, -0.0021,  0.0000, -0.0050,\n",
      "           0.0000, -0.0012,  0.0000, -0.0004, -0.0030, -0.0032, -0.0065,\n",
      "           0.0000, -0.0189,  0.0000,  0.0000,  0.0000, -0.0103, -0.0039,\n",
      "          -0.0037,  0.0000, -0.0139,  0.0000,  0.0000, -0.0066, -0.0017,\n",
      "          -0.0126, -0.0016,  0.0000,  0.0000,  0.0000, -0.0159, -0.0035,\n",
      "          -0.0036,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0004,\n",
      "          -0.0061,  0.0000,  0.0000,  0.0000, -0.0097, -0.0036, -0.0054,\n",
      "          -0.0161, -0.0092, -0.0012,  0.0000,  0.0000, -0.0106, -0.0076,\n",
      "          -0.0419,  0.0000,  0.0000, -0.1861,  0.0000, -0.0326, -0.0068,\n",
      "          -0.0026]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-03 *\n",
      "       [[-3.8896,  0.2720, -2.9071,  8.8174, -5.6683, -0.8291,  7.3257,\n",
      "         -5.4900,  2.4420]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 448, 512])\n",
      "tensor([[ 8.7173e-04, -1.4690e-03,  5.9179e-04,  ...,  7.1271e-04,\n",
      "         -2.9799e-04,  7.7357e-04],\n",
      "        [ 1.5956e-04,  3.9304e-04, -6.5228e-04,  ..., -7.2202e-04,\n",
      "          3.6194e-04, -7.4600e-04],\n",
      "        [ 6.5735e-03,  1.9042e-03,  1.0183e-03,  ...,  2.4667e-03,\n",
      "          2.7436e-03,  2.8909e-04],\n",
      "        ...,\n",
      "        [-8.1533e-05, -1.2287e-03, -1.6851e-04,  ..., -7.1372e-05,\n",
      "          9.4252e-04, -5.3612e-04],\n",
      "        [ 6.8146e-04,  4.6741e-04, -9.0392e-04,  ..., -7.4378e-04,\n",
      "         -1.7249e-04, -1.4825e-04],\n",
      "        [-5.6351e-04, -7.3145e-04, -7.0537e-04,  ..., -7.6695e-04,\n",
      "          1.9379e-04,  3.8819e-04]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 448, 512])\n",
      "tensor([[ 8.7173e-05, -1.4690e-04,  5.9179e-05,  ...,  7.1271e-05,\n",
      "         -2.9799e-05,  7.7357e-05],\n",
      "        [ 1.5956e-05,  3.9304e-05, -6.5228e-05,  ..., -7.2202e-05,\n",
      "          3.6194e-05, -7.4600e-05],\n",
      "        [ 6.5734e-04,  1.9042e-04,  1.0183e-04,  ...,  2.4667e-04,\n",
      "          2.7436e-04,  2.8909e-05],\n",
      "        ...,\n",
      "        [-1.0436e-04, -6.9924e-05, -2.5969e-04,  ..., -3.0078e-04,\n",
      "         -2.7804e-04, -1.4901e-04],\n",
      "        [-1.4777e-05,  1.5604e-04, -4.4237e-05,  ..., -5.8748e-05,\n",
      "         -6.7419e-06,  1.9362e-08],\n",
      "        [-8.2268e-05, -4.7596e-05,  2.8714e-05,  ...,  3.1202e-05,\n",
      "          8.9316e-05,  9.1037e-06]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 6.7952, Accuracy: 1606/10000 (16.06%)\n",
      "\n",
      "Train Epoch: 91 [0/50000 (0%)]\tLoss: 0.198038, Accuracy: 93.36\n",
      "Train Epoch: 91 [2560/50000 (6%)]\tLoss: 0.230065, Accuracy: 91.99\n",
      "Train Epoch: 91 [5120/50000 (11%)]\tLoss: 0.179815, Accuracy: 92.97\n",
      "Train Epoch: 91 [7680/50000 (17%)]\tLoss: 0.244953, Accuracy: 90.82\n",
      "Train Epoch: 91 [10240/50000 (23%)]\tLoss: 0.246563, Accuracy: 91.80\n",
      "Train Epoch: 91 [12800/50000 (28%)]\tLoss: 0.252733, Accuracy: 91.21\n",
      "Train Epoch: 91 [15360/50000 (34%)]\tLoss: 0.201588, Accuracy: 94.14\n",
      "Train Epoch: 91 [17920/50000 (40%)]\tLoss: 0.191381, Accuracy: 93.16\n",
      "Train Epoch: 91 [20480/50000 (45%)]\tLoss: 0.254804, Accuracy: 90.62\n",
      "Train Epoch: 91 [23040/50000 (51%)]\tLoss: 0.212273, Accuracy: 92.19\n",
      "Train Epoch: 91 [25600/50000 (57%)]\tLoss: 0.276620, Accuracy: 89.84\n",
      "Train Epoch: 91 [28160/50000 (62%)]\tLoss: 0.272824, Accuracy: 90.82\n",
      "Train Epoch: 91 [30720/50000 (68%)]\tLoss: 0.218700, Accuracy: 92.97\n",
      "Train Epoch: 91 [33280/50000 (74%)]\tLoss: 0.214700, Accuracy: 93.36\n",
      "Train Epoch: 91 [35840/50000 (80%)]\tLoss: 0.227708, Accuracy: 92.77\n",
      "Train Epoch: 91 [38400/50000 (85%)]\tLoss: 0.239125, Accuracy: 90.43\n",
      "Train Epoch: 91 [40960/50000 (91%)]\tLoss: 0.264504, Accuracy: 90.23\n",
      "Train Epoch: 91 [43520/50000 (97%)]\tLoss: 0.244343, Accuracy: 91.21\n",
      "\n",
      "Validation set: Average loss: 23.6516, Accuracy: 492/5000 (9.00%)\n",
      "\n",
      "the time of this epoch:[38.85773992538452 s]\n",
      "Train Epoch: 92 [0/50000 (0%)]\tLoss: 0.224277, Accuracy: 91.60\n",
      "Train Epoch: 92 [2560/50000 (6%)]\tLoss: 0.177827, Accuracy: 94.34\n",
      "Train Epoch: 92 [5120/50000 (11%)]\tLoss: 0.249883, Accuracy: 91.99\n",
      "Train Epoch: 92 [7680/50000 (17%)]\tLoss: 0.182529, Accuracy: 93.75\n",
      "Train Epoch: 92 [10240/50000 (23%)]\tLoss: 0.217216, Accuracy: 91.99\n",
      "Train Epoch: 92 [12800/50000 (28%)]\tLoss: 0.178574, Accuracy: 92.77\n",
      "Train Epoch: 92 [15360/50000 (34%)]\tLoss: 0.253501, Accuracy: 90.62\n",
      "Train Epoch: 92 [17920/50000 (40%)]\tLoss: 0.255507, Accuracy: 90.82\n",
      "Train Epoch: 92 [20480/50000 (45%)]\tLoss: 0.257718, Accuracy: 91.60\n",
      "Train Epoch: 92 [23040/50000 (51%)]\tLoss: 0.215890, Accuracy: 91.99\n",
      "Train Epoch: 92 [25600/50000 (57%)]\tLoss: 0.290775, Accuracy: 90.43\n",
      "Train Epoch: 92 [28160/50000 (62%)]\tLoss: 0.245055, Accuracy: 91.21\n",
      "Train Epoch: 92 [30720/50000 (68%)]\tLoss: 0.238278, Accuracy: 92.38\n",
      "Train Epoch: 92 [33280/50000 (74%)]\tLoss: 0.227022, Accuracy: 91.99\n",
      "Train Epoch: 92 [35840/50000 (80%)]\tLoss: 0.232773, Accuracy: 91.41\n",
      "Train Epoch: 92 [38400/50000 (85%)]\tLoss: 0.255791, Accuracy: 90.43\n",
      "Train Epoch: 92 [40960/50000 (91%)]\tLoss: 0.272524, Accuracy: 90.23\n",
      "Train Epoch: 92 [43520/50000 (97%)]\tLoss: 0.272954, Accuracy: 89.45\n",
      "\n",
      "Validation set: Average loss: 0.7656, Accuracy: 3873/5000 (77.00%)\n",
      "\n",
      "the time of this epoch:[35.48418641090393 s]\n",
      "\n",
      "Test set: Average loss: 0.8126, Accuracy: 7710/10000 (77.10%)\n",
      "\n",
      "Train Epoch: 93 [0/50000 (0%)]\tLoss: 0.187984, Accuracy: 93.55\n",
      "Train Epoch: 93 [2560/50000 (6%)]\tLoss: 0.192232, Accuracy: 93.75\n",
      "Train Epoch: 93 [5120/50000 (11%)]\tLoss: 0.187072, Accuracy: 94.14\n",
      "Train Epoch: 93 [7680/50000 (17%)]\tLoss: 0.173659, Accuracy: 93.95\n",
      "Train Epoch: 93 [10240/50000 (23%)]\tLoss: 0.208918, Accuracy: 93.16\n",
      "Train Epoch: 93 [12800/50000 (28%)]\tLoss: 0.155337, Accuracy: 95.70\n",
      "Train Epoch: 93 [15360/50000 (34%)]\tLoss: 0.269177, Accuracy: 91.21\n",
      "Train Epoch: 93 [17920/50000 (40%)]\tLoss: 0.262437, Accuracy: 91.60\n",
      "Train Epoch: 93 [20480/50000 (45%)]\tLoss: 0.223781, Accuracy: 90.82\n",
      "Train Epoch: 93 [23040/50000 (51%)]\tLoss: 0.183932, Accuracy: 93.16\n",
      "Train Epoch: 93 [25600/50000 (57%)]\tLoss: 0.267758, Accuracy: 90.62\n",
      "Train Epoch: 93 [28160/50000 (62%)]\tLoss: 0.197415, Accuracy: 92.38\n",
      "Train Epoch: 93 [30720/50000 (68%)]\tLoss: 0.217473, Accuracy: 92.77\n",
      "Train Epoch: 93 [33280/50000 (74%)]\tLoss: 0.204747, Accuracy: 92.58\n",
      "Train Epoch: 93 [35840/50000 (80%)]\tLoss: 0.164220, Accuracy: 93.95\n",
      "Train Epoch: 93 [38400/50000 (85%)]\tLoss: 0.223734, Accuracy: 91.60\n",
      "Train Epoch: 93 [40960/50000 (91%)]\tLoss: 0.289488, Accuracy: 90.23\n",
      "Train Epoch: 93 [43520/50000 (97%)]\tLoss: 0.297801, Accuracy: 90.04\n",
      "\n",
      "Validation set: Average loss: 1.2225, Accuracy: 3272/5000 (65.00%)\n",
      "\n",
      "the time of this epoch:[38.8508882522583 s]\n",
      "Train Epoch: 94 [0/50000 (0%)]\tLoss: 0.224512, Accuracy: 92.97\n",
      "Train Epoch: 94 [2560/50000 (6%)]\tLoss: 0.248365, Accuracy: 91.02\n",
      "Train Epoch: 94 [5120/50000 (11%)]\tLoss: 0.200655, Accuracy: 92.19\n",
      "Train Epoch: 94 [7680/50000 (17%)]\tLoss: 0.244232, Accuracy: 91.80\n",
      "Train Epoch: 94 [10240/50000 (23%)]\tLoss: 0.199790, Accuracy: 93.95\n",
      "Train Epoch: 94 [12800/50000 (28%)]\tLoss: 0.173841, Accuracy: 94.14\n",
      "Train Epoch: 94 [15360/50000 (34%)]\tLoss: 0.235460, Accuracy: 91.80\n",
      "Train Epoch: 94 [17920/50000 (40%)]\tLoss: 0.222303, Accuracy: 91.60\n",
      "Train Epoch: 94 [20480/50000 (45%)]\tLoss: 0.190685, Accuracy: 93.16\n",
      "Train Epoch: 94 [23040/50000 (51%)]\tLoss: 0.258697, Accuracy: 91.02\n",
      "Train Epoch: 94 [25600/50000 (57%)]\tLoss: 0.250597, Accuracy: 91.02\n",
      "Train Epoch: 94 [28160/50000 (62%)]\tLoss: 0.173993, Accuracy: 94.53\n",
      "Train Epoch: 94 [30720/50000 (68%)]\tLoss: 0.261128, Accuracy: 91.02\n",
      "Train Epoch: 94 [33280/50000 (74%)]\tLoss: 0.191165, Accuracy: 95.12\n",
      "Train Epoch: 94 [35840/50000 (80%)]\tLoss: 0.171857, Accuracy: 93.16\n",
      "Train Epoch: 94 [38400/50000 (85%)]\tLoss: 0.209554, Accuracy: 91.99\n",
      "Train Epoch: 94 [40960/50000 (91%)]\tLoss: 0.262346, Accuracy: 89.26\n",
      "Train Epoch: 94 [43520/50000 (97%)]\tLoss: 0.250979, Accuracy: 89.84\n",
      "\n",
      "Validation set: Average loss: 0.6928, Accuracy: 4034/5000 (80.00%)\n",
      "\n",
      "the time of this epoch:[35.47258996963501 s]\n",
      "\n",
      "Test set: Average loss: 0.7272, Accuracy: 7933/10000 (79.33%)\n",
      "\n",
      "Train Epoch: 95 [0/50000 (0%)]\tLoss: 0.148782, Accuracy: 94.92\n",
      "Train Epoch: 95 [2560/50000 (6%)]\tLoss: 0.199397, Accuracy: 92.77\n",
      "Train Epoch: 95 [5120/50000 (11%)]\tLoss: 0.213188, Accuracy: 93.16\n",
      "Train Epoch: 95 [7680/50000 (17%)]\tLoss: 0.190990, Accuracy: 94.14\n",
      "Train Epoch: 95 [10240/50000 (23%)]\tLoss: 0.214150, Accuracy: 92.97\n",
      "Train Epoch: 95 [12800/50000 (28%)]\tLoss: 0.225195, Accuracy: 92.77\n",
      "Train Epoch: 95 [15360/50000 (34%)]\tLoss: 0.233924, Accuracy: 91.60\n",
      "Train Epoch: 95 [17920/50000 (40%)]\tLoss: 0.262756, Accuracy: 91.21\n",
      "Train Epoch: 95 [20480/50000 (45%)]\tLoss: 0.250428, Accuracy: 90.62\n",
      "Train Epoch: 95 [23040/50000 (51%)]\tLoss: 0.220776, Accuracy: 91.21\n",
      "Train Epoch: 95 [25600/50000 (57%)]\tLoss: 0.218669, Accuracy: 92.77\n",
      "Train Epoch: 95 [28160/50000 (62%)]\tLoss: 0.275672, Accuracy: 90.62\n",
      "Train Epoch: 95 [30720/50000 (68%)]\tLoss: 0.192746, Accuracy: 93.16\n",
      "Train Epoch: 95 [33280/50000 (74%)]\tLoss: 0.234692, Accuracy: 91.80\n",
      "Train Epoch: 95 [35840/50000 (80%)]\tLoss: 0.260164, Accuracy: 91.60\n",
      "Train Epoch: 95 [38400/50000 (85%)]\tLoss: 0.234849, Accuracy: 92.38\n",
      "Train Epoch: 95 [40960/50000 (91%)]\tLoss: 0.176137, Accuracy: 93.36\n",
      "Train Epoch: 95 [43520/50000 (97%)]\tLoss: 0.208781, Accuracy: 91.80\n",
      "\n",
      "Validation set: Average loss: 0.9054, Accuracy: 3626/5000 (72.00%)\n",
      "\n",
      "the time of this epoch:[38.83235764503479 s]\n",
      "Train Epoch: 96 [0/50000 (0%)]\tLoss: 0.188445, Accuracy: 93.36\n",
      "Train Epoch: 96 [2560/50000 (6%)]\tLoss: 0.197582, Accuracy: 93.16\n",
      "Train Epoch: 96 [5120/50000 (11%)]\tLoss: 0.290020, Accuracy: 90.04\n",
      "Train Epoch: 96 [7680/50000 (17%)]\tLoss: 0.218663, Accuracy: 93.55\n",
      "Train Epoch: 96 [10240/50000 (23%)]\tLoss: 0.171031, Accuracy: 94.34\n",
      "Train Epoch: 96 [12800/50000 (28%)]\tLoss: 0.252142, Accuracy: 91.02\n",
      "Train Epoch: 96 [15360/50000 (34%)]\tLoss: 0.193870, Accuracy: 92.77\n",
      "Train Epoch: 96 [17920/50000 (40%)]\tLoss: 0.239946, Accuracy: 91.60\n",
      "Train Epoch: 96 [20480/50000 (45%)]\tLoss: 0.235479, Accuracy: 91.99\n",
      "Train Epoch: 96 [23040/50000 (51%)]\tLoss: 0.228633, Accuracy: 91.02\n",
      "Train Epoch: 96 [25600/50000 (57%)]\tLoss: 0.186088, Accuracy: 93.36\n",
      "Train Epoch: 96 [28160/50000 (62%)]\tLoss: 0.185229, Accuracy: 93.16\n",
      "Train Epoch: 96 [30720/50000 (68%)]\tLoss: 0.204584, Accuracy: 92.19\n",
      "Train Epoch: 96 [33280/50000 (74%)]\tLoss: 0.267811, Accuracy: 90.43\n",
      "Train Epoch: 96 [35840/50000 (80%)]\tLoss: 0.193290, Accuracy: 93.55\n",
      "Train Epoch: 96 [38400/50000 (85%)]\tLoss: 0.307073, Accuracy: 88.87\n",
      "Train Epoch: 96 [40960/50000 (91%)]\tLoss: 0.279064, Accuracy: 90.82\n",
      "Train Epoch: 96 [43520/50000 (97%)]\tLoss: 0.209098, Accuracy: 93.16\n",
      "\n",
      "Validation set: Average loss: 0.7891, Accuracy: 3853/5000 (77.00%)\n",
      "\n",
      "the time of this epoch:[35.46112394332886 s]\n",
      "\n",
      "Test set: Average loss: 0.8553, Accuracy: 7626/10000 (76.26%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 97 [0/50000 (0%)]\tLoss: 0.188772, Accuracy: 94.14\n",
      "Train Epoch: 97 [2560/50000 (6%)]\tLoss: 0.185630, Accuracy: 94.14\n",
      "Train Epoch: 97 [5120/50000 (11%)]\tLoss: 0.203214, Accuracy: 92.58\n",
      "Train Epoch: 97 [7680/50000 (17%)]\tLoss: 0.170407, Accuracy: 94.73\n",
      "Train Epoch: 97 [10240/50000 (23%)]\tLoss: 0.239248, Accuracy: 91.21\n",
      "Train Epoch: 97 [12800/50000 (28%)]\tLoss: 0.175136, Accuracy: 94.34\n",
      "Train Epoch: 97 [15360/50000 (34%)]\tLoss: 0.194957, Accuracy: 93.95\n",
      "Train Epoch: 97 [17920/50000 (40%)]\tLoss: 0.249070, Accuracy: 91.41\n",
      "Train Epoch: 97 [20480/50000 (45%)]\tLoss: 0.240677, Accuracy: 92.19\n",
      "Train Epoch: 97 [23040/50000 (51%)]\tLoss: 0.263612, Accuracy: 90.23\n",
      "Train Epoch: 97 [25600/50000 (57%)]\tLoss: 0.210782, Accuracy: 92.19\n",
      "Train Epoch: 97 [28160/50000 (62%)]\tLoss: 0.238404, Accuracy: 92.19\n",
      "Train Epoch: 97 [30720/50000 (68%)]\tLoss: 0.192967, Accuracy: 93.95\n",
      "Train Epoch: 97 [33280/50000 (74%)]\tLoss: 0.286507, Accuracy: 90.82\n",
      "Train Epoch: 97 [35840/50000 (80%)]\tLoss: 0.210676, Accuracy: 92.97\n",
      "Train Epoch: 97 [38400/50000 (85%)]\tLoss: 0.229944, Accuracy: 92.38\n",
      "Train Epoch: 97 [40960/50000 (91%)]\tLoss: 0.244328, Accuracy: 92.97\n",
      "Train Epoch: 97 [43520/50000 (97%)]\tLoss: 0.257786, Accuracy: 90.82\n",
      "\n",
      "Validation set: Average loss: 0.7482, Accuracy: 3977/5000 (79.00%)\n",
      "\n",
      "the time of this epoch:[38.83648943901062 s]\n",
      "Train Epoch: 98 [0/50000 (0%)]\tLoss: 0.203883, Accuracy: 92.38\n",
      "Train Epoch: 98 [2560/50000 (6%)]\tLoss: 0.239359, Accuracy: 92.97\n",
      "Train Epoch: 98 [5120/50000 (11%)]\tLoss: 0.222575, Accuracy: 92.38\n",
      "Train Epoch: 98 [7680/50000 (17%)]\tLoss: 0.193718, Accuracy: 92.97\n",
      "Train Epoch: 98 [10240/50000 (23%)]\tLoss: 0.161873, Accuracy: 94.73\n",
      "Train Epoch: 98 [12800/50000 (28%)]\tLoss: 0.164423, Accuracy: 95.31\n",
      "Train Epoch: 98 [15360/50000 (34%)]\tLoss: 0.242085, Accuracy: 90.62\n",
      "Train Epoch: 98 [17920/50000 (40%)]\tLoss: 0.185884, Accuracy: 93.75\n",
      "Train Epoch: 98 [20480/50000 (45%)]\tLoss: 0.233040, Accuracy: 92.38\n",
      "Train Epoch: 98 [23040/50000 (51%)]\tLoss: 0.198684, Accuracy: 92.97\n",
      "Train Epoch: 98 [25600/50000 (57%)]\tLoss: 0.187314, Accuracy: 94.14\n",
      "Train Epoch: 98 [28160/50000 (62%)]\tLoss: 0.296643, Accuracy: 89.45\n",
      "Train Epoch: 98 [30720/50000 (68%)]\tLoss: 0.217946, Accuracy: 90.82\n",
      "Train Epoch: 98 [33280/50000 (74%)]\tLoss: 0.185929, Accuracy: 93.16\n",
      "Train Epoch: 98 [35840/50000 (80%)]\tLoss: 0.193371, Accuracy: 92.97\n",
      "Train Epoch: 98 [38400/50000 (85%)]\tLoss: 0.244029, Accuracy: 91.41\n",
      "Train Epoch: 98 [40960/50000 (91%)]\tLoss: 0.262219, Accuracy: 91.21\n",
      "Train Epoch: 98 [43520/50000 (97%)]\tLoss: 0.236811, Accuracy: 91.99\n",
      "\n",
      "Validation set: Average loss: 1.0230, Accuracy: 3559/5000 (71.00%)\n",
      "\n",
      "the time of this epoch:[36.15691041946411 s]\n",
      "\n",
      "Test set: Average loss: 1.0081, Accuracy: 7122/10000 (71.22%)\n",
      "\n",
      "Train Epoch: 99 [0/50000 (0%)]\tLoss: 0.181497, Accuracy: 93.75\n",
      "Train Epoch: 99 [2560/50000 (6%)]\tLoss: 0.180524, Accuracy: 93.75\n",
      "Train Epoch: 99 [5120/50000 (11%)]\tLoss: 0.188741, Accuracy: 93.16\n",
      "Train Epoch: 99 [7680/50000 (17%)]\tLoss: 0.244079, Accuracy: 93.36\n",
      "Train Epoch: 99 [10240/50000 (23%)]\tLoss: 0.185080, Accuracy: 94.34\n",
      "Train Epoch: 99 [12800/50000 (28%)]\tLoss: 0.265175, Accuracy: 91.60\n",
      "Train Epoch: 99 [15360/50000 (34%)]\tLoss: 0.256315, Accuracy: 92.19\n",
      "Train Epoch: 99 [17920/50000 (40%)]\tLoss: 0.253328, Accuracy: 91.41\n",
      "Train Epoch: 99 [20480/50000 (45%)]\tLoss: 0.247337, Accuracy: 91.80\n",
      "Train Epoch: 99 [23040/50000 (51%)]\tLoss: 0.200154, Accuracy: 92.58\n",
      "Train Epoch: 99 [25600/50000 (57%)]\tLoss: 0.263878, Accuracy: 91.02\n",
      "Train Epoch: 99 [28160/50000 (62%)]\tLoss: 0.255961, Accuracy: 91.60\n",
      "Train Epoch: 99 [30720/50000 (68%)]\tLoss: 0.198335, Accuracy: 93.36\n",
      "Train Epoch: 99 [33280/50000 (74%)]\tLoss: 0.189016, Accuracy: 93.55\n",
      "Train Epoch: 99 [35840/50000 (80%)]\tLoss: 0.157750, Accuracy: 94.73\n",
      "Train Epoch: 99 [38400/50000 (85%)]\tLoss: 0.245108, Accuracy: 90.82\n",
      "Train Epoch: 99 [40960/50000 (91%)]\tLoss: 0.238816, Accuracy: 91.41\n",
      "Train Epoch: 99 [43520/50000 (97%)]\tLoss: 0.195127, Accuracy: 93.75\n",
      "------------------------------\n",
      "before autoscale: torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.1376]],\n",
      "\n",
      "        [[ 0.0607]],\n",
      "\n",
      "        [[ 0.0929]],\n",
      "\n",
      "        [[ 0.0883]],\n",
      "\n",
      "        [[ 0.1067]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.1190]],\n",
      "\n",
      "        [[ 0.1645]],\n",
      "\n",
      "        [[ 0.0397]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[-0.5196]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 512])\n",
      "tensor([[[-0.0715, -0.0315, -0.0483, -0.0459, -0.0554,  0.0000,  0.0000,\n",
      "          -0.0618, -0.0855, -0.0206, -0.0162, -0.0413, -0.0007, -0.0299,\n",
      "          -0.0516, -0.0115,  0.0000, -0.0164, -0.0578, -0.0165, -0.0966,\n",
      "          -0.0675, -0.4859, -0.0539, -0.0474, -0.0464, -0.1038,  0.0000,\n",
      "          -0.0970, -0.0819, -0.0769, -0.0503, -0.1620, -0.0575, -0.0029,\n",
      "          -0.0987,  0.0000, -0.1041, -0.1156,  0.0000, -0.0458, -0.0085,\n",
      "          -0.0717, -0.0469, -0.0406, -0.0843, -0.0244, -0.8708, -0.0477,\n",
      "          -0.0101, -0.0724, -0.0854, -0.0129, -0.0551, -0.1166, -0.0169,\n",
      "          -0.0120, -0.0024, -0.0308, -0.0388, -0.0093, -0.0886, -0.0000,\n",
      "          -0.0274,  0.0000,  0.0000, -0.0134, -0.0086,  0.0000,  0.0000,\n",
      "           0.0000, -0.0165,  0.0000, -0.0033, -0.0028, -0.0004, -0.0003,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0050, -0.0174, -0.0020,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0005, -0.0012,\n",
      "          -0.0003, -0.0009, -0.0007,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000, -0.0040, -0.0025,  0.0000, -0.0086,  0.0000,\n",
      "          -0.0010,  0.0000,  0.0000, -0.0015,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0011,  0.0000, -0.0057, -0.0001,\n",
      "          -0.0014, -0.0025,  0.0000, -0.0012, -0.0014, -0.0012, -0.0000,\n",
      "          -0.0020, -0.0009,  0.0000,  0.0000,  0.0000, -0.0018,  0.0000,\n",
      "          -0.0176,  0.0000, -0.0018, -0.0100, -0.0288,  0.0000,  0.0000,\n",
      "          -0.0092,  0.0000, -0.0017,  0.0000, -0.0008, -0.0004, -0.0023,\n",
      "          -0.0051,  0.0000,  0.0000, -0.0015,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0005, -0.0017,  0.0000,  0.0000, -0.0012,  0.0000,\n",
      "           0.0000,  0.0000, -0.0006,  0.0000,  0.0000,  0.0000, -0.0002,\n",
      "          -0.0001,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0045,\n",
      "          -0.0009,  0.0000, -0.0010, -0.0012, -0.0015, -0.0021, -0.0009,\n",
      "           0.0000, -0.0007, -0.0009, -0.0010, -0.0014,  0.0000, -0.0012,\n",
      "          -0.0024, -0.0011,  0.0000,  0.0000, -0.0020, -0.0002,  0.0000,\n",
      "           0.0000, -0.0088, -0.0007,  0.0000,  0.0000, -0.0010,  0.0000,\n",
      "           0.0000, -0.0016, -0.0002,  0.0000,  0.0000, -0.0018,  0.0000,\n",
      "           0.0000,  0.0000, -0.0001,  0.0000,  0.0000, -0.0026,  0.0000,\n",
      "           0.0000, -0.0010,  0.0000, -0.0028,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0000,  0.0000, -0.0001,  0.0000, -0.0007,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0032,\n",
      "          -0.0108,  0.0000,  0.0000, -0.0129, -0.0189,  0.0000,  0.0000,\n",
      "          -0.0054,  0.0000, -0.0025,  0.0000,  0.0000, -0.0151, -0.0673,\n",
      "           0.0000,  0.0000, -0.0091,  0.0000, -0.0012, -0.0102,  0.0000,\n",
      "          -0.0008, -0.0026, -0.0046,  0.0000, -0.0016, -0.0447, -0.0031,\n",
      "           0.0000, -0.0056,  0.0000, -0.0020,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0005,  0.0000,  0.0000, -0.0002,  0.0000,  0.0000, -0.0002,\n",
      "          -0.0016,  0.0000, -0.0029,  0.0000, -0.0011,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0009, -0.0002, -0.0009, -0.0020,\n",
      "           0.0000, -0.0010,  0.0000, -0.0008,  0.0000,  0.0000, -0.0005,\n",
      "           0.0000,  0.0000, -0.0001,  0.0000,  0.0000, -0.0005,  0.0000,\n",
      "           0.0000, -0.0017, -0.0016, -0.0011, -0.0013,  0.0000, -0.0031,\n",
      "           0.0000,  0.0000,  0.0000, -0.0013,  0.0000, -0.0025,  0.0000,\n",
      "          -0.0051,  0.0000,  0.0000, -0.0030,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0071, -0.0020,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0002,  0.0000,  0.0000, -0.0047, -0.0076, -0.0189, -0.0011,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0017, -0.0003, -0.0010,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0293,  0.0000,\n",
      "           0.0000, -0.0508,  0.0000,  0.0000, -0.0057,  0.0000, -0.0006,\n",
      "          -0.0013,  0.0000, -0.0012,  0.0000,  0.0000,  0.0000, -0.0013,\n",
      "           0.0000, -0.0004, -0.0009, -0.0019,  0.0000,  0.0000, -0.0049,\n",
      "          -0.0426,  0.0000,  0.0000,  0.0000, -0.0059, -0.0538,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0014,  0.0000, -0.0053,  0.0000,\n",
      "          -0.0301, -0.0088,  0.0000, -0.0031,  0.0000,  0.0000, -0.0039,\n",
      "          -0.0441,  0.0000,  0.0000, -0.0033, -0.0040,  0.0000,  0.0000,\n",
      "          -0.0030, -0.0058,  0.0000,  0.0000,  0.0000,  0.0000, -0.0073,\n",
      "          -0.0181,  0.0000,  0.0000, -0.0115, -0.0013,  0.0000,  0.0000,\n",
      "           0.0000, -0.0064, -0.0164, -0.0019,  0.0000, -0.0109, -0.0019,\n",
      "           0.0000,  0.0000,  0.0000, -0.0092,  0.0000,  0.0000, -0.0037,\n",
      "           0.0000,  0.0000, -0.0013,  0.0000, -0.0003,  0.0000, -0.0039,\n",
      "          -0.0010,  0.0000, -0.0027, -0.0010, -0.0009,  0.0000, -0.0023,\n",
      "          -0.0024,  0.0000, -0.0012, -0.0001, -0.0049,  0.0000, -0.0011,\n",
      "           0.0000, -0.0004,  0.0000,  0.0000,  0.0000, -0.0018,  0.0000,\n",
      "           0.0000, -0.0062, -0.0345,  0.0000,  0.0000, -0.0235,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0318, -0.0029,  0.0000,  0.0000,\n",
      "           0.0000, -0.0007, -0.0010,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0279, -0.0748,  0.0000,  0.0000,  0.0000,  0.0000, -0.0009,\n",
      "          -0.0015,  0.0000, -0.0005, -0.0004, -0.0005,  0.0000, -0.0000,\n",
      "           0.0000, -0.0012,  0.0000,  0.0000,  0.0000,  0.0000, -0.0001,\n",
      "          -0.0004,  0.0000,  0.0000, -0.0006, -0.0003, -0.0004,  0.0000,\n",
      "           0.0000]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-03 *\n",
      "       [[-3.1239,  1.3428,  3.7780, -0.6337,  1.2404, -2.4908, -2.1200,\n",
      "         -2.6709, -0.1587]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 448, 512])\n",
      "tensor([[ 2.2345e-04,  3.7173e-04, -7.8257e-05,  ..., -2.4151e-06,\n",
      "         -1.4973e-06,  8.4754e-08],\n",
      "        [ 1.2905e-04, -7.9110e-05,  1.3844e-04,  ...,  7.4975e-07,\n",
      "         -5.3777e-07, -1.8501e-06],\n",
      "        [ 3.4295e-03,  2.9840e-03, -1.0464e-03,  ..., -1.2779e-05,\n",
      "          1.8890e-05,  1.8527e-05],\n",
      "        ...,\n",
      "        [ 2.1342e-04,  1.5903e-04,  1.1279e-04,  ...,  5.4245e-07,\n",
      "          2.1234e-06, -1.5122e-06],\n",
      "        [ 2.5021e-05,  2.0393e-04,  2.2927e-04,  ...,  2.2788e-07,\n",
      "          1.2170e-06,  2.1760e-06],\n",
      "        [-9.6603e-05,  4.8600e-05,  1.8234e-04,  ...,  7.7728e-07,\n",
      "          1.3756e-06,  1.1225e-06]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 448, 512])\n",
      "tensor([[ 2.2345e-05,  3.7173e-05, -7.8257e-06,  ..., -2.4151e-07,\n",
      "         -1.4973e-07,  8.4754e-09],\n",
      "        [ 1.2905e-05, -7.9110e-06,  1.3844e-05,  ...,  7.4975e-08,\n",
      "         -5.3777e-08, -1.8501e-07],\n",
      "        [ 3.4295e-04,  2.9840e-04, -1.0464e-04,  ..., -1.2779e-06,\n",
      "          1.8890e-06,  1.8527e-06],\n",
      "        ...,\n",
      "        [ 2.7484e-05, -7.9305e-05, -4.5537e-05,  ..., -5.2371e-07,\n",
      "         -1.6573e-07,  1.8069e-07],\n",
      "        [-4.6367e-05, -6.1109e-05, -6.2971e-05,  ..., -1.4228e-07,\n",
      "         -3.9426e-07, -5.6158e-07],\n",
      "        [-9.7945e-05, -4.0417e-06,  2.5044e-05,  ...,  1.1089e-06,\n",
      "          1.5788e-06,  1.8768e-06]], device='cuda:0')\n",
      "\n",
      "Validation set: Average loss: 0.9180, Accuracy: 3889/5000 (77.00%)\n",
      "\n",
      "the time of this epoch:[38.45183253288269 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 0.182681, Accuracy: 93.75\n",
      "Train Epoch: 100 [2560/50000 (6%)]\tLoss: 0.207700, Accuracy: 92.77\n",
      "Train Epoch: 100 [5120/50000 (11%)]\tLoss: 0.214505, Accuracy: 92.19\n",
      "Train Epoch: 100 [7680/50000 (17%)]\tLoss: 0.215277, Accuracy: 91.41\n",
      "Train Epoch: 100 [10240/50000 (23%)]\tLoss: 0.250784, Accuracy: 91.99\n",
      "Train Epoch: 100 [12800/50000 (28%)]\tLoss: 0.222409, Accuracy: 93.16\n",
      "Train Epoch: 100 [15360/50000 (34%)]\tLoss: 0.236921, Accuracy: 92.38\n",
      "Train Epoch: 100 [17920/50000 (40%)]\tLoss: 0.219570, Accuracy: 92.58\n",
      "Train Epoch: 100 [20480/50000 (45%)]\tLoss: 0.262855, Accuracy: 89.84\n",
      "Train Epoch: 100 [23040/50000 (51%)]\tLoss: 0.215849, Accuracy: 91.99\n",
      "Train Epoch: 100 [25600/50000 (57%)]\tLoss: 0.225976, Accuracy: 91.60\n",
      "Train Epoch: 100 [28160/50000 (62%)]\tLoss: 0.270879, Accuracy: 90.23\n",
      "Train Epoch: 100 [30720/50000 (68%)]\tLoss: 0.187498, Accuracy: 92.77\n",
      "Train Epoch: 100 [33280/50000 (74%)]\tLoss: 0.234768, Accuracy: 92.38\n",
      "Train Epoch: 100 [35840/50000 (80%)]\tLoss: 0.220979, Accuracy: 92.19\n",
      "Train Epoch: 100 [38400/50000 (85%)]\tLoss: 0.268357, Accuracy: 90.82\n",
      "Train Epoch: 100 [40960/50000 (91%)]\tLoss: 0.314521, Accuracy: 89.06\n",
      "Train Epoch: 100 [43520/50000 (97%)]\tLoss: 0.210776, Accuracy: 93.55\n",
      "\n",
      "Validation set: Average loss: 1.0723, Accuracy: 3721/5000 (74.00%)\n",
      "\n",
      "the time of this epoch:[35.23040771484375 s]\n",
      "\n",
      "Test set: Average loss: 1.0501, Accuracy: 7525/10000 (75.25%)\n",
      "\n",
      "Train Epoch: 101 [0/50000 (0%)]\tLoss: 0.188922, Accuracy: 94.14\n",
      "Train Epoch: 101 [2560/50000 (6%)]\tLoss: 0.176004, Accuracy: 93.95\n",
      "Train Epoch: 101 [5120/50000 (11%)]\tLoss: 0.184172, Accuracy: 91.99\n",
      "Train Epoch: 101 [7680/50000 (17%)]\tLoss: 0.229047, Accuracy: 92.19\n",
      "Train Epoch: 101 [10240/50000 (23%)]\tLoss: 0.217654, Accuracy: 92.38\n",
      "Train Epoch: 101 [12800/50000 (28%)]\tLoss: 0.181523, Accuracy: 93.16\n",
      "Train Epoch: 101 [15360/50000 (34%)]\tLoss: 0.219923, Accuracy: 93.16\n",
      "Train Epoch: 101 [17920/50000 (40%)]\tLoss: 0.275718, Accuracy: 92.38\n",
      "Train Epoch: 101 [20480/50000 (45%)]\tLoss: 0.225670, Accuracy: 91.02\n",
      "Train Epoch: 101 [23040/50000 (51%)]\tLoss: 0.251313, Accuracy: 91.80\n",
      "Train Epoch: 101 [25600/50000 (57%)]\tLoss: 0.251736, Accuracy: 92.58\n",
      "Train Epoch: 101 [28160/50000 (62%)]\tLoss: 0.219184, Accuracy: 92.38\n",
      "Train Epoch: 101 [30720/50000 (68%)]\tLoss: 0.272258, Accuracy: 90.43\n",
      "Train Epoch: 101 [33280/50000 (74%)]\tLoss: 0.271113, Accuracy: 91.80\n",
      "Train Epoch: 101 [35840/50000 (80%)]\tLoss: 0.214532, Accuracy: 92.97\n",
      "Train Epoch: 101 [38400/50000 (85%)]\tLoss: 0.241128, Accuracy: 91.02\n",
      "Train Epoch: 101 [40960/50000 (91%)]\tLoss: 0.198692, Accuracy: 93.36\n",
      "Train Epoch: 101 [43520/50000 (97%)]\tLoss: 0.207496, Accuracy: 93.55\n",
      "\n",
      "Validation set: Average loss: 0.8424, Accuracy: 3748/5000 (74.00%)\n",
      "\n",
      "the time of this epoch:[38.454023361206055 s]\n",
      "Train Epoch: 102 [0/50000 (0%)]\tLoss: 0.213516, Accuracy: 94.14\n",
      "Train Epoch: 102 [2560/50000 (6%)]\tLoss: 0.213508, Accuracy: 92.58\n",
      "Train Epoch: 102 [5120/50000 (11%)]\tLoss: 0.199082, Accuracy: 92.77\n",
      "Train Epoch: 102 [7680/50000 (17%)]\tLoss: 0.178538, Accuracy: 93.75\n",
      "Train Epoch: 102 [10240/50000 (23%)]\tLoss: 0.207598, Accuracy: 92.19\n",
      "Train Epoch: 102 [12800/50000 (28%)]\tLoss: 0.149626, Accuracy: 94.73\n",
      "Train Epoch: 102 [15360/50000 (34%)]\tLoss: 0.182882, Accuracy: 93.75\n",
      "Train Epoch: 102 [17920/50000 (40%)]\tLoss: 0.231010, Accuracy: 91.21\n",
      "Train Epoch: 102 [20480/50000 (45%)]\tLoss: 0.212390, Accuracy: 92.58\n",
      "Train Epoch: 102 [23040/50000 (51%)]\tLoss: 0.250621, Accuracy: 91.60\n",
      "Train Epoch: 102 [25600/50000 (57%)]\tLoss: 0.227452, Accuracy: 91.99\n",
      "Train Epoch: 102 [28160/50000 (62%)]\tLoss: 0.218059, Accuracy: 93.36\n",
      "Train Epoch: 102 [30720/50000 (68%)]\tLoss: 0.216876, Accuracy: 92.58\n",
      "Train Epoch: 102 [33280/50000 (74%)]\tLoss: 0.239846, Accuracy: 91.80\n",
      "Train Epoch: 102 [35840/50000 (80%)]\tLoss: 0.219641, Accuracy: 91.80\n",
      "Train Epoch: 102 [38400/50000 (85%)]\tLoss: 0.303844, Accuracy: 89.65\n",
      "Train Epoch: 102 [40960/50000 (91%)]\tLoss: 0.225263, Accuracy: 92.19\n",
      "Train Epoch: 102 [43520/50000 (97%)]\tLoss: 0.261440, Accuracy: 91.60\n",
      "\n",
      "Validation set: Average loss: 2.6975, Accuracy: 1811/5000 (36.00%)\n",
      "\n",
      "the time of this epoch:[35.133466482162476 s]\n",
      "\n",
      "Test set: Average loss: 2.6345, Accuracy: 3777/10000 (37.77%)\n",
      "\n",
      "Train Epoch: 103 [0/50000 (0%)]\tLoss: 0.235384, Accuracy: 92.97\n",
      "Train Epoch: 103 [2560/50000 (6%)]\tLoss: 0.195377, Accuracy: 93.75\n",
      "Train Epoch: 103 [5120/50000 (11%)]\tLoss: 0.175972, Accuracy: 93.75\n",
      "Train Epoch: 103 [7680/50000 (17%)]\tLoss: 0.224870, Accuracy: 93.16\n",
      "Train Epoch: 103 [10240/50000 (23%)]\tLoss: 0.185666, Accuracy: 92.77\n",
      "Train Epoch: 103 [12800/50000 (28%)]\tLoss: 0.180338, Accuracy: 93.55\n",
      "Train Epoch: 103 [15360/50000 (34%)]\tLoss: 0.217876, Accuracy: 93.16\n",
      "Train Epoch: 103 [17920/50000 (40%)]\tLoss: 0.236002, Accuracy: 91.99\n",
      "Train Epoch: 103 [20480/50000 (45%)]\tLoss: 0.237703, Accuracy: 91.80\n",
      "Train Epoch: 103 [23040/50000 (51%)]\tLoss: 0.231943, Accuracy: 91.80\n",
      "Train Epoch: 103 [25600/50000 (57%)]\tLoss: 0.289704, Accuracy: 89.06\n",
      "Train Epoch: 103 [28160/50000 (62%)]\tLoss: 0.202958, Accuracy: 93.95\n",
      "Train Epoch: 103 [30720/50000 (68%)]\tLoss: 0.226709, Accuracy: 91.21\n",
      "Train Epoch: 103 [33280/50000 (74%)]\tLoss: 0.228088, Accuracy: 91.60\n",
      "Train Epoch: 103 [35840/50000 (80%)]\tLoss: 0.243681, Accuracy: 91.21\n",
      "Train Epoch: 103 [38400/50000 (85%)]\tLoss: 0.186087, Accuracy: 94.14\n",
      "Train Epoch: 103 [40960/50000 (91%)]\tLoss: 0.192943, Accuracy: 93.75\n",
      "Train Epoch: 103 [43520/50000 (97%)]\tLoss: 0.226158, Accuracy: 92.19\n",
      "\n",
      "Validation set: Average loss: 1.0107, Accuracy: 3480/5000 (69.00%)\n",
      "\n",
      "the time of this epoch:[39.73292922973633 s]\n",
      "Train Epoch: 104 [0/50000 (0%)]\tLoss: 0.243878, Accuracy: 90.62\n",
      "Train Epoch: 104 [2560/50000 (6%)]\tLoss: 0.176016, Accuracy: 93.36\n",
      "Train Epoch: 104 [5120/50000 (11%)]\tLoss: 0.228878, Accuracy: 92.97\n",
      "Train Epoch: 104 [7680/50000 (17%)]\tLoss: 0.214850, Accuracy: 92.77\n",
      "Train Epoch: 104 [10240/50000 (23%)]\tLoss: 0.209592, Accuracy: 91.60\n",
      "Train Epoch: 104 [12800/50000 (28%)]\tLoss: 0.214272, Accuracy: 92.77\n",
      "Train Epoch: 104 [15360/50000 (34%)]\tLoss: 0.244140, Accuracy: 91.60\n",
      "Train Epoch: 104 [17920/50000 (40%)]\tLoss: 0.255328, Accuracy: 90.43\n",
      "Train Epoch: 104 [20480/50000 (45%)]\tLoss: 0.195036, Accuracy: 92.58\n",
      "Train Epoch: 104 [23040/50000 (51%)]\tLoss: 0.252956, Accuracy: 91.60\n",
      "Train Epoch: 104 [25600/50000 (57%)]\tLoss: 0.233762, Accuracy: 91.60\n",
      "Train Epoch: 104 [28160/50000 (62%)]\tLoss: 0.223003, Accuracy: 92.19\n",
      "Train Epoch: 104 [30720/50000 (68%)]\tLoss: 0.211131, Accuracy: 93.36\n",
      "Train Epoch: 104 [33280/50000 (74%)]\tLoss: 0.245824, Accuracy: 92.19\n",
      "Train Epoch: 104 [35840/50000 (80%)]\tLoss: 0.231352, Accuracy: 91.99\n",
      "Train Epoch: 104 [38400/50000 (85%)]\tLoss: 0.168130, Accuracy: 94.92\n",
      "Train Epoch: 104 [40960/50000 (91%)]\tLoss: 0.240450, Accuracy: 91.02\n",
      "Train Epoch: 104 [43520/50000 (97%)]\tLoss: 0.223495, Accuracy: 92.58\n",
      "\n",
      "Validation set: Average loss: 1.0788, Accuracy: 3658/5000 (73.00%)\n",
      "\n",
      "the time of this epoch:[35.30217933654785 s]\n",
      "\n",
      "Test set: Average loss: 1.0896, Accuracy: 7211/10000 (72.11%)\n",
      "\n",
      "Train Epoch: 105 [0/50000 (0%)]\tLoss: 0.192180, Accuracy: 93.36\n",
      "Train Epoch: 105 [2560/50000 (6%)]\tLoss: 0.193493, Accuracy: 93.75\n",
      "Train Epoch: 105 [5120/50000 (11%)]\tLoss: 0.185518, Accuracy: 93.36\n",
      "Train Epoch: 105 [7680/50000 (17%)]\tLoss: 0.176707, Accuracy: 93.75\n",
      "Train Epoch: 105 [10240/50000 (23%)]\tLoss: 0.167105, Accuracy: 94.14\n",
      "Train Epoch: 105 [12800/50000 (28%)]\tLoss: 0.167125, Accuracy: 94.53\n",
      "Train Epoch: 105 [15360/50000 (34%)]\tLoss: 0.170760, Accuracy: 93.75\n",
      "Train Epoch: 105 [17920/50000 (40%)]\tLoss: 0.169954, Accuracy: 93.55\n",
      "Train Epoch: 105 [20480/50000 (45%)]\tLoss: 0.236179, Accuracy: 92.38\n",
      "Train Epoch: 105 [23040/50000 (51%)]\tLoss: 0.236713, Accuracy: 91.80\n",
      "Train Epoch: 105 [25600/50000 (57%)]\tLoss: 0.188271, Accuracy: 92.19\n",
      "Train Epoch: 105 [28160/50000 (62%)]\tLoss: 0.183737, Accuracy: 93.75\n",
      "Train Epoch: 105 [30720/50000 (68%)]\tLoss: 0.208827, Accuracy: 92.77\n",
      "Train Epoch: 105 [33280/50000 (74%)]\tLoss: 0.195846, Accuracy: 95.12\n",
      "Train Epoch: 105 [35840/50000 (80%)]\tLoss: 0.192974, Accuracy: 93.55\n",
      "Train Epoch: 105 [38400/50000 (85%)]\tLoss: 0.237296, Accuracy: 91.60\n",
      "Train Epoch: 105 [40960/50000 (91%)]\tLoss: 0.271842, Accuracy: 90.82\n",
      "Train Epoch: 105 [43520/50000 (97%)]\tLoss: 0.242729, Accuracy: 92.38\n",
      "\n",
      "Validation set: Average loss: 1.1464, Accuracy: 3660/5000 (73.00%)\n",
      "\n",
      "the time of this epoch:[38.73188900947571 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 106 [0/50000 (0%)]\tLoss: 0.193521, Accuracy: 93.75\n",
      "Train Epoch: 106 [2560/50000 (6%)]\tLoss: 0.218159, Accuracy: 91.41\n",
      "Train Epoch: 106 [5120/50000 (11%)]\tLoss: 0.203970, Accuracy: 92.77\n",
      "Train Epoch: 106 [7680/50000 (17%)]\tLoss: 0.181449, Accuracy: 93.36\n",
      "Train Epoch: 106 [10240/50000 (23%)]\tLoss: 0.205267, Accuracy: 93.16\n",
      "Train Epoch: 106 [12800/50000 (28%)]\tLoss: 0.183396, Accuracy: 94.14\n",
      "Train Epoch: 106 [15360/50000 (34%)]\tLoss: 0.190752, Accuracy: 93.95\n",
      "Train Epoch: 106 [17920/50000 (40%)]\tLoss: 0.235897, Accuracy: 91.99\n",
      "Train Epoch: 106 [20480/50000 (45%)]\tLoss: 0.229540, Accuracy: 91.99\n",
      "Train Epoch: 106 [23040/50000 (51%)]\tLoss: 0.189548, Accuracy: 91.99\n",
      "Train Epoch: 106 [25600/50000 (57%)]\tLoss: 0.220247, Accuracy: 93.16\n",
      "Train Epoch: 106 [28160/50000 (62%)]\tLoss: 0.263440, Accuracy: 90.43\n",
      "Train Epoch: 106 [30720/50000 (68%)]\tLoss: 0.219523, Accuracy: 92.97\n",
      "Train Epoch: 106 [33280/50000 (74%)]\tLoss: 0.253258, Accuracy: 91.41\n",
      "Train Epoch: 106 [35840/50000 (80%)]\tLoss: 0.195137, Accuracy: 93.36\n",
      "Train Epoch: 106 [38400/50000 (85%)]\tLoss: 0.250191, Accuracy: 91.02\n",
      "Train Epoch: 106 [40960/50000 (91%)]\tLoss: 0.230771, Accuracy: 91.99\n",
      "Train Epoch: 106 [43520/50000 (97%)]\tLoss: 0.228240, Accuracy: 91.80\n",
      "\n",
      "Validation set: Average loss: 13.2399, Accuracy: 1058/5000 (21.00%)\n",
      "\n",
      "the time of this epoch:[36.36867070198059 s]\n",
      "\n",
      "Test set: Average loss: 12.7127, Accuracy: 2212/10000 (22.12%)\n",
      "\n",
      "Train Epoch: 107 [0/50000 (0%)]\tLoss: 0.203957, Accuracy: 92.77\n",
      "Train Epoch: 107 [2560/50000 (6%)]\tLoss: 0.198927, Accuracy: 93.16\n",
      "Train Epoch: 107 [5120/50000 (11%)]\tLoss: 0.218813, Accuracy: 92.19\n",
      "Train Epoch: 107 [7680/50000 (17%)]\tLoss: 0.177673, Accuracy: 92.97\n",
      "Train Epoch: 107 [10240/50000 (23%)]\tLoss: 0.203196, Accuracy: 93.36\n",
      "Train Epoch: 107 [12800/50000 (28%)]\tLoss: 0.233053, Accuracy: 91.21\n",
      "Train Epoch: 107 [15360/50000 (34%)]\tLoss: 0.189157, Accuracy: 93.55\n",
      "Train Epoch: 107 [17920/50000 (40%)]\tLoss: 0.193297, Accuracy: 93.75\n",
      "Train Epoch: 107 [20480/50000 (45%)]\tLoss: 0.224764, Accuracy: 91.21\n",
      "Train Epoch: 107 [23040/50000 (51%)]\tLoss: 0.287377, Accuracy: 90.04\n",
      "Train Epoch: 107 [25600/50000 (57%)]\tLoss: 0.199059, Accuracy: 93.16\n",
      "Train Epoch: 107 [28160/50000 (62%)]\tLoss: 0.227018, Accuracy: 91.80\n",
      "Train Epoch: 107 [30720/50000 (68%)]\tLoss: 0.225683, Accuracy: 91.60\n",
      "Train Epoch: 107 [33280/50000 (74%)]\tLoss: 0.265334, Accuracy: 92.38\n",
      "Train Epoch: 107 [35840/50000 (80%)]\tLoss: 0.239959, Accuracy: 91.80\n",
      "Train Epoch: 107 [38400/50000 (85%)]\tLoss: 0.288883, Accuracy: 90.23\n",
      "Train Epoch: 107 [40960/50000 (91%)]\tLoss: 0.274843, Accuracy: 90.23\n",
      "Train Epoch: 107 [43520/50000 (97%)]\tLoss: 0.256841, Accuracy: 91.02\n",
      "\n",
      "Validation set: Average loss: 0.7935, Accuracy: 3890/5000 (77.00%)\n",
      "\n",
      "the time of this epoch:[39.45512795448303 s]\n",
      "Train Epoch: 108 [0/50000 (0%)]\tLoss: 0.178359, Accuracy: 94.14\n",
      "Train Epoch: 108 [2560/50000 (6%)]\tLoss: 0.175734, Accuracy: 93.95\n",
      "Train Epoch: 108 [5120/50000 (11%)]\tLoss: 0.216221, Accuracy: 93.55\n",
      "Train Epoch: 108 [7680/50000 (17%)]\tLoss: 0.188652, Accuracy: 93.16\n",
      "Train Epoch: 108 [10240/50000 (23%)]\tLoss: 0.231692, Accuracy: 91.99\n",
      "Train Epoch: 108 [12800/50000 (28%)]\tLoss: 0.144433, Accuracy: 94.34\n",
      "Train Epoch: 108 [15360/50000 (34%)]\tLoss: 0.186667, Accuracy: 93.36\n",
      "Train Epoch: 108 [17920/50000 (40%)]\tLoss: 0.173046, Accuracy: 93.75\n",
      "Train Epoch: 108 [20480/50000 (45%)]\tLoss: 0.184690, Accuracy: 93.55\n",
      "Train Epoch: 108 [23040/50000 (51%)]\tLoss: 0.223572, Accuracy: 92.77\n",
      "Train Epoch: 108 [25600/50000 (57%)]\tLoss: 0.262790, Accuracy: 91.80\n",
      "Train Epoch: 108 [28160/50000 (62%)]\tLoss: 0.234276, Accuracy: 91.21\n",
      "Train Epoch: 108 [30720/50000 (68%)]\tLoss: 0.192129, Accuracy: 93.95\n",
      "Train Epoch: 108 [33280/50000 (74%)]\tLoss: 0.167325, Accuracy: 93.95\n",
      "Train Epoch: 108 [35840/50000 (80%)]\tLoss: 0.238172, Accuracy: 92.19\n",
      "Train Epoch: 108 [38400/50000 (85%)]\tLoss: 0.235296, Accuracy: 91.60\n",
      "Train Epoch: 108 [40960/50000 (91%)]\tLoss: 0.283077, Accuracy: 89.84\n",
      "Train Epoch: 108 [43520/50000 (97%)]\tLoss: 0.247680, Accuracy: 91.02\n",
      "\n",
      "Validation set: Average loss: 1.1813, Accuracy: 3609/5000 (72.00%)\n",
      "\n",
      "the time of this epoch:[35.16980791091919 s]\n",
      "\n",
      "Test set: Average loss: 1.1673, Accuracy: 7283/10000 (72.83%)\n",
      "\n",
      "Train Epoch: 109 [0/50000 (0%)]\tLoss: 0.179294, Accuracy: 94.34\n",
      "Train Epoch: 109 [2560/50000 (6%)]\tLoss: 0.194874, Accuracy: 94.53\n",
      "Train Epoch: 109 [5120/50000 (11%)]\tLoss: 0.160632, Accuracy: 94.73\n",
      "Train Epoch: 109 [7680/50000 (17%)]\tLoss: 0.187858, Accuracy: 93.16\n",
      "Train Epoch: 109 [10240/50000 (23%)]\tLoss: 0.292101, Accuracy: 90.82\n",
      "Train Epoch: 109 [12800/50000 (28%)]\tLoss: 0.202949, Accuracy: 93.55\n",
      "Train Epoch: 109 [15360/50000 (34%)]\tLoss: 0.248596, Accuracy: 91.41\n",
      "Train Epoch: 109 [17920/50000 (40%)]\tLoss: 0.279494, Accuracy: 92.58\n",
      "Train Epoch: 109 [20480/50000 (45%)]\tLoss: 0.233157, Accuracy: 92.38\n",
      "Train Epoch: 109 [23040/50000 (51%)]\tLoss: 0.267822, Accuracy: 91.21\n",
      "Train Epoch: 109 [25600/50000 (57%)]\tLoss: 0.214293, Accuracy: 92.19\n",
      "Train Epoch: 109 [28160/50000 (62%)]\tLoss: 0.223949, Accuracy: 93.36\n",
      "Train Epoch: 109 [30720/50000 (68%)]\tLoss: 0.273482, Accuracy: 90.04\n",
      "Train Epoch: 109 [33280/50000 (74%)]\tLoss: 0.227548, Accuracy: 92.77\n",
      "Train Epoch: 109 [35840/50000 (80%)]\tLoss: 0.300112, Accuracy: 90.62\n",
      "Train Epoch: 109 [38400/50000 (85%)]\tLoss: 0.212435, Accuracy: 92.38\n",
      "Train Epoch: 109 [40960/50000 (91%)]\tLoss: 0.201563, Accuracy: 92.77\n",
      "Train Epoch: 109 [43520/50000 (97%)]\tLoss: 0.229907, Accuracy: 91.60\n",
      "\n",
      "Validation set: Average loss: 0.7447, Accuracy: 3876/5000 (77.00%)\n",
      "\n",
      "the time of this epoch:[38.43189835548401 s]\n",
      "Train Epoch: 110 [0/50000 (0%)]\tLoss: 0.197357, Accuracy: 94.34\n",
      "Train Epoch: 110 [2560/50000 (6%)]\tLoss: 0.184086, Accuracy: 93.36\n",
      "Train Epoch: 110 [5120/50000 (11%)]\tLoss: 0.197208, Accuracy: 93.16\n",
      "Train Epoch: 110 [7680/50000 (17%)]\tLoss: 0.189593, Accuracy: 93.16\n",
      "Train Epoch: 110 [10240/50000 (23%)]\tLoss: 0.259538, Accuracy: 90.62\n",
      "Train Epoch: 110 [12800/50000 (28%)]\tLoss: 0.207009, Accuracy: 93.36\n",
      "Train Epoch: 110 [15360/50000 (34%)]\tLoss: 0.250162, Accuracy: 91.60\n",
      "Train Epoch: 110 [17920/50000 (40%)]\tLoss: 0.203825, Accuracy: 92.77\n",
      "Train Epoch: 110 [20480/50000 (45%)]\tLoss: 0.189964, Accuracy: 93.95\n",
      "Train Epoch: 110 [23040/50000 (51%)]\tLoss: 0.207847, Accuracy: 91.99\n",
      "Train Epoch: 110 [25600/50000 (57%)]\tLoss: 0.186518, Accuracy: 92.97\n",
      "Train Epoch: 110 [28160/50000 (62%)]\tLoss: 0.249635, Accuracy: 91.80\n",
      "Train Epoch: 110 [30720/50000 (68%)]\tLoss: 0.290045, Accuracy: 90.43\n",
      "Train Epoch: 110 [33280/50000 (74%)]\tLoss: 0.198888, Accuracy: 93.95\n",
      "Train Epoch: 110 [35840/50000 (80%)]\tLoss: 0.273907, Accuracy: 90.82\n",
      "Train Epoch: 110 [38400/50000 (85%)]\tLoss: 0.205221, Accuracy: 92.97\n",
      "Train Epoch: 110 [40960/50000 (91%)]\tLoss: 0.249922, Accuracy: 91.02\n",
      "Train Epoch: 110 [43520/50000 (97%)]\tLoss: 0.234537, Accuracy: 91.99\n",
      "\n",
      "Validation set: Average loss: 0.7642, Accuracy: 3858/5000 (77.00%)\n",
      "\n",
      "the time of this epoch:[35.126150131225586 s]\n",
      "------------------------------\n",
      "before autoscale: torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.0000]],\n",
      "\n",
      "        [[ 0.0824]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0520]],\n",
      "\n",
      "        [[ 0.0134]],\n",
      "\n",
      "        [[ 0.2758]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.1140]],\n",
      "\n",
      "        [[ 0.0083]],\n",
      "\n",
      "        [[ 0.2056]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[-0.3258]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 512])\n",
      "tensor([[[ 0.0000, -0.0269,  0.0000, -0.0169, -0.0044, -0.0899,  0.0000,\n",
      "          -0.0371, -0.0027, -0.0670, -0.0637, -0.1191, -0.0798, -0.0690,\n",
      "           0.0000, -0.0066, -0.0286,  0.0000, -0.0025, -0.0785, -0.0560,\n",
      "          -0.0458, -0.0719, -0.1136, -0.0665, -0.0802, -0.0007, -0.0236,\n",
      "           0.0000, -0.0849, -0.0683, -0.0100, -0.0069, -0.0214, -0.0592,\n",
      "          -0.0651, -0.0410,  0.0000, -0.0012,  0.0000, -0.0397, -0.0124,\n",
      "          -0.0706, -0.0592, -0.0281, -0.0234, -0.0014, -0.0057, -0.0329,\n",
      "          -0.0884, -0.0278, -0.0617, -0.0339, -0.1393, -0.0330, -0.0286,\n",
      "           0.0000,  0.0000, -0.0067, -0.0014, -0.0408, -0.1003, -0.1045,\n",
      "           0.0000, -0.0211, -0.0170, -0.0078, -0.0002, -0.0017, -0.0051,\n",
      "          -0.0007,  0.0000,  0.0000,  0.0000, -0.0129, -0.0003, -0.0006,\n",
      "          -0.0017, -0.0016, -0.0018, -0.0026, -0.0000, -0.0016,  0.0000,\n",
      "          -0.0029, -0.0025, -0.0005,  0.0000, -0.0005,  0.0000,  0.0000,\n",
      "          -0.0004,  0.0000, -0.0004,  0.0000,  0.0000, -0.0095,  0.0000,\n",
      "          -0.0023, -0.0003, -0.0017, -0.0012, -0.0009,  0.0000, -0.0005,\n",
      "          -0.0004, -0.0140,  0.0000,  0.0000,  0.0000,  0.0000, -0.0012,\n",
      "          -0.0059,  0.0000, -0.0048,  0.0000, -0.0517,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0002,  0.0000,  0.0000,\n",
      "          -0.0009, -0.0003, -0.0000,  0.0000, -0.0001, -0.0004,  0.0000,\n",
      "           0.0000,  0.0000, -0.0001, -0.0001,  0.0000, -0.0002, -0.0004,\n",
      "           0.0000, -0.0012,  0.0000,  0.0000, -0.0012, -0.0002,  0.0000,\n",
      "          -0.0418,  0.0000,  0.0000, -0.0081, -0.0009, -0.0128, -0.0004,\n",
      "          -0.0012, -0.0017,  0.0000,  0.0000, -0.0002,  0.0000,  0.0000,\n",
      "           0.0000, -0.0004, -0.0016,  0.0000,  0.0000, -0.0133, -0.0001,\n",
      "          -0.0009, -0.0013, -0.0014,  0.0000, -0.0013, -0.0016, -0.0013,\n",
      "          -0.0023, -0.0019, -0.0009,  0.0000, -0.0005, -0.0104, -0.0029,\n",
      "           0.0000, -0.0028,  0.0000,  0.0000, -0.0035, -0.0035, -0.0010,\n",
      "          -0.0004, -0.0003, -0.0002, -0.0002, -0.0002, -0.0004, -0.0004,\n",
      "           0.0000,  0.0000,  0.0000, -0.0037, -0.0422,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000, -0.0020, -0.0002, -0.0013,  0.0000, -0.0016,\n",
      "           0.0000,  0.0000, -0.0000, -0.0007,  0.0000, -0.0000,  0.0000,\n",
      "          -0.0001, -0.0007, -0.0006, -0.0004, -0.0003,  0.0000, -0.0000,\n",
      "          -0.0002,  0.0000, -0.0003, -0.0002,  0.0000, -0.0002, -0.0001,\n",
      "          -0.0001,  0.0000,  0.0000, -0.0016, -0.0063, -0.0000,  0.0000,\n",
      "           0.0000,  0.0000, -0.0030, -0.0002,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0001, -0.0001, -0.0005, -0.0004,  0.0000,  0.0000, -0.0000,\n",
      "          -0.0001, -0.0023,  0.0000, -0.0017, -0.0009, -0.0007,  0.0000,\n",
      "          -0.0015, -0.0015, -0.0026, -0.0006,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0015, -0.0002, -0.0002, -0.0002, -0.0002, -0.0007,  0.0000,\n",
      "          -0.0034, -0.0102, -0.0048, -0.0000, -0.0028, -0.0041, -0.0052,\n",
      "          -0.0040, -0.0011, -0.0011,  0.0000, -0.0021, -0.0016, -0.0028,\n",
      "          -0.0008, -0.0026, -0.0026,  0.0000, -0.0028, -0.0011, -0.0014,\n",
      "           0.0000, -0.0000, -0.0011, -0.0017, -0.0028,  0.0000, -0.0006,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0010, -0.0001,  0.0000,  0.0000, -0.0048, -0.0013,  0.0000,\n",
      "          -0.0002, -0.0038,  0.0000, -0.0047,  0.0000, -0.0003, -0.0024,\n",
      "           0.0000,  0.0000,  0.0000, -0.0003, -0.0001, -0.0000, -0.0004,\n",
      "           0.0000, -0.0015, -0.0021, -0.0018, -0.0009, -0.0016, -0.0004,\n",
      "           0.0000, -0.0040, -0.0027, -0.0012,  0.0000,  0.0000, -0.0021,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0005,  0.0000,  0.0000,\n",
      "          -0.0023, -0.0021,  0.0000, -0.0045,  0.0000, -0.0020, -0.0025,\n",
      "          -0.0024,  0.0000, -0.0005, -0.0006, -0.0010, -0.0014, -0.0003,\n",
      "           0.0000, -0.0009, -0.0009, -0.0010, -0.0003, -0.0003, -0.0004,\n",
      "           0.0000, -0.0004,  0.0000, -0.0004, -0.0106, -0.0001,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0008, -0.0001,  0.0000,\n",
      "          -0.0001, -0.0009, -0.0003, -0.0003, -0.0035, -0.0033, -0.0032,\n",
      "          -0.0043, -0.0036, -0.0019,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0317,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0192,\n",
      "          -0.0001,  0.0000, -0.0018,  0.0000, -0.0026, -0.0001, -0.0001,\n",
      "           0.0000, -0.0002,  0.0000,  0.0000, -0.0017,  0.0000, -0.4945,\n",
      "          -0.0002, -0.0001,  0.0000,  0.0000, -0.0031,  0.0000, -0.0025,\n",
      "          -0.0019,  0.0000,  0.0000, -0.0001,  0.0000,  0.0000, -0.0002,\n",
      "           0.0000,  0.0000, -0.0012, -0.0004,  0.0000, -0.0002, -0.0003,\n",
      "          -0.0003, -0.0004,  0.0000,  0.0000,  0.0000, -0.0007, -0.0024,\n",
      "           0.0000, -0.0022, -0.0012, -0.0025, -0.0001,  0.0000,  0.0000,\n",
      "           0.0000, -0.0014,  0.0000, -0.0002, -0.0008,  0.0000, -0.0007,\n",
      "          -0.0005,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,\n",
      "           0.0000, -0.0028, -0.0039,  0.0000, -0.0018,  0.0000, -0.0014,\n",
      "          -0.0014, -0.0011,  0.0000, -0.0078, -0.0003,  0.0000,  0.0000,\n",
      "           0.0000, -0.0589, -0.0084,  0.0000,  0.0000,  0.0000, -0.0011,\n",
      "          -0.0007, -0.0023,  0.0000, -0.0008,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0001, -0.0017, -0.0001,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0375, -0.0005, -0.0011,  0.0000, -0.0001,  0.0000,\n",
      "           0.0000]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-03 *\n",
      "       [[ 0.7619,  1.3118,  0.3393,  0.8002,  1.6440, -0.7996,  2.6170,\n",
      "          2.2504, -0.7091]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 448, 512])\n",
      "tensor([[-1.3554e-05, -3.4574e-05, -2.2159e-04,  ..., -2.9743e-05,\n",
      "         -1.8384e-06, -8.3233e-07],\n",
      "        [-5.0426e-05,  1.4379e-04, -1.1253e-04,  ...,  9.4191e-05,\n",
      "          3.7721e-06,  2.6763e-06],\n",
      "        [ 8.1434e-05,  6.3882e-05,  9.3912e-05,  ...,  8.6597e-06,\n",
      "          1.9582e-06,  2.7793e-07],\n",
      "        ...,\n",
      "        [-1.5757e-05,  1.1080e-04, -7.4084e-05,  ...,  1.0287e-04,\n",
      "          2.0807e-06,  2.9399e-06],\n",
      "        [ 8.1303e-05, -4.6994e-05,  1.3918e-04,  ..., -8.6094e-05,\n",
      "         -9.4305e-07, -2.4814e-06],\n",
      "        [-6.3716e-05, -1.7413e-04,  1.5210e-05,  ..., -6.8938e-05,\n",
      "         -2.6058e-06, -1.9399e-06]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 448, 512])\n",
      "tensor([[-1.3554e-06, -3.4574e-06, -2.2159e-05,  ..., -2.9743e-06,\n",
      "         -1.8384e-07, -8.3233e-08],\n",
      "        [-5.0426e-06,  1.4379e-05, -1.1253e-05,  ...,  9.4191e-06,\n",
      "          3.7721e-07,  2.6763e-07],\n",
      "        [ 8.1434e-06,  6.3882e-06,  9.3912e-06,  ...,  8.6597e-07,\n",
      "          1.9582e-07,  2.7793e-08],\n",
      "        ...,\n",
      "        [-1.7542e-05, -7.2729e-05, -4.6687e-05,  ..., -4.8904e-06,\n",
      "         -2.0317e-07, -1.3760e-07],\n",
      "        [-7.8250e-05, -2.7712e-04, -2.6905e-04,  ..., -5.8779e-05,\n",
      "         -2.7832e-06, -1.6942e-06],\n",
      "        [-1.0012e-05, -3.7035e-05, -3.6311e-05,  ..., -5.0933e-06,\n",
      "         -2.8472e-07, -1.4940e-07]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7981, Accuracy: 7719/10000 (77.19%)\n",
      "\n",
      "Train Epoch: 111 [0/50000 (0%)]\tLoss: 0.201481, Accuracy: 93.16\n",
      "Train Epoch: 111 [2560/50000 (6%)]\tLoss: 0.192773, Accuracy: 92.97\n",
      "Train Epoch: 111 [5120/50000 (11%)]\tLoss: 0.165734, Accuracy: 94.53\n",
      "Train Epoch: 111 [7680/50000 (17%)]\tLoss: 0.231122, Accuracy: 91.41\n",
      "Train Epoch: 111 [10240/50000 (23%)]\tLoss: 0.193555, Accuracy: 92.77\n",
      "Train Epoch: 111 [12800/50000 (28%)]\tLoss: 0.260915, Accuracy: 90.04\n",
      "Train Epoch: 111 [15360/50000 (34%)]\tLoss: 0.217302, Accuracy: 93.55\n",
      "Train Epoch: 111 [17920/50000 (40%)]\tLoss: 0.186585, Accuracy: 94.34\n",
      "Train Epoch: 111 [20480/50000 (45%)]\tLoss: 0.180593, Accuracy: 93.75\n",
      "Train Epoch: 111 [23040/50000 (51%)]\tLoss: 0.284832, Accuracy: 88.87\n",
      "Train Epoch: 111 [25600/50000 (57%)]\tLoss: 0.208710, Accuracy: 93.16\n",
      "Train Epoch: 111 [28160/50000 (62%)]\tLoss: 0.205015, Accuracy: 93.55\n",
      "Train Epoch: 111 [30720/50000 (68%)]\tLoss: 0.190390, Accuracy: 93.55\n",
      "Train Epoch: 111 [33280/50000 (74%)]\tLoss: 0.228408, Accuracy: 92.38\n",
      "Train Epoch: 111 [35840/50000 (80%)]\tLoss: 0.202640, Accuracy: 93.95\n",
      "Train Epoch: 111 [38400/50000 (85%)]\tLoss: 0.257585, Accuracy: 91.02\n",
      "Train Epoch: 111 [40960/50000 (91%)]\tLoss: 0.236844, Accuracy: 92.38\n",
      "Train Epoch: 111 [43520/50000 (97%)]\tLoss: 0.177634, Accuracy: 93.95\n",
      "\n",
      "Validation set: Average loss: 0.7282, Accuracy: 3970/5000 (79.00%)\n",
      "\n",
      "the time of this epoch:[38.49509596824646 s]\n",
      "Train Epoch: 112 [0/50000 (0%)]\tLoss: 0.223809, Accuracy: 93.36\n",
      "Train Epoch: 112 [2560/50000 (6%)]\tLoss: 0.201909, Accuracy: 92.97\n",
      "Train Epoch: 112 [5120/50000 (11%)]\tLoss: 0.175360, Accuracy: 94.73\n",
      "Train Epoch: 112 [7680/50000 (17%)]\tLoss: 0.231063, Accuracy: 93.75\n",
      "Train Epoch: 112 [10240/50000 (23%)]\tLoss: 0.183943, Accuracy: 93.75\n",
      "Train Epoch: 112 [12800/50000 (28%)]\tLoss: 0.191813, Accuracy: 93.36\n",
      "Train Epoch: 112 [15360/50000 (34%)]\tLoss: 0.170968, Accuracy: 93.95\n",
      "Train Epoch: 112 [17920/50000 (40%)]\tLoss: 0.153389, Accuracy: 93.55\n",
      "Train Epoch: 112 [20480/50000 (45%)]\tLoss: 0.185484, Accuracy: 93.75\n",
      "Train Epoch: 112 [23040/50000 (51%)]\tLoss: 0.222654, Accuracy: 91.02\n",
      "Train Epoch: 112 [25600/50000 (57%)]\tLoss: 0.269777, Accuracy: 89.84\n",
      "Train Epoch: 112 [28160/50000 (62%)]\tLoss: 0.170489, Accuracy: 93.36\n",
      "Train Epoch: 112 [30720/50000 (68%)]\tLoss: 0.168920, Accuracy: 95.12\n",
      "Train Epoch: 112 [33280/50000 (74%)]\tLoss: 0.204767, Accuracy: 93.36\n",
      "Train Epoch: 112 [35840/50000 (80%)]\tLoss: 0.188960, Accuracy: 93.75\n",
      "Train Epoch: 112 [38400/50000 (85%)]\tLoss: 0.207170, Accuracy: 92.19\n",
      "Train Epoch: 112 [40960/50000 (91%)]\tLoss: 0.227940, Accuracy: 91.80\n",
      "Train Epoch: 112 [43520/50000 (97%)]\tLoss: 0.216908, Accuracy: 92.77\n",
      "\n",
      "Validation set: Average loss: 0.8293, Accuracy: 3793/5000 (75.00%)\n",
      "\n",
      "the time of this epoch:[35.163185358047485 s]\n",
      "\n",
      "Test set: Average loss: 0.8175, Accuracy: 7645/10000 (76.45%)\n",
      "\n",
      "Train Epoch: 113 [0/50000 (0%)]\tLoss: 0.152803, Accuracy: 95.31\n",
      "Train Epoch: 113 [2560/50000 (6%)]\tLoss: 0.178693, Accuracy: 93.75\n",
      "Train Epoch: 113 [5120/50000 (11%)]\tLoss: 0.226037, Accuracy: 92.19\n",
      "Train Epoch: 113 [7680/50000 (17%)]\tLoss: 0.246420, Accuracy: 91.80\n",
      "Train Epoch: 113 [10240/50000 (23%)]\tLoss: 0.209144, Accuracy: 93.16\n",
      "Train Epoch: 113 [12800/50000 (28%)]\tLoss: 0.206715, Accuracy: 92.97\n",
      "Train Epoch: 113 [15360/50000 (34%)]\tLoss: 0.197344, Accuracy: 92.97\n",
      "Train Epoch: 113 [17920/50000 (40%)]\tLoss: 0.222469, Accuracy: 93.55\n",
      "Train Epoch: 113 [20480/50000 (45%)]\tLoss: 0.250154, Accuracy: 91.21\n",
      "Train Epoch: 113 [23040/50000 (51%)]\tLoss: 0.191287, Accuracy: 92.58\n",
      "Train Epoch: 113 [25600/50000 (57%)]\tLoss: 0.197909, Accuracy: 95.12\n",
      "Train Epoch: 113 [28160/50000 (62%)]\tLoss: 0.196428, Accuracy: 93.75\n",
      "Train Epoch: 113 [30720/50000 (68%)]\tLoss: 0.178803, Accuracy: 92.97\n",
      "Train Epoch: 113 [33280/50000 (74%)]\tLoss: 0.219738, Accuracy: 91.60\n",
      "Train Epoch: 113 [35840/50000 (80%)]\tLoss: 0.190184, Accuracy: 93.16\n",
      "Train Epoch: 113 [38400/50000 (85%)]\tLoss: 0.242438, Accuracy: 91.41\n",
      "Train Epoch: 113 [40960/50000 (91%)]\tLoss: 0.211359, Accuracy: 91.99\n",
      "Train Epoch: 113 [43520/50000 (97%)]\tLoss: 0.267747, Accuracy: 92.19\n",
      "\n",
      "Validation set: Average loss: 0.9333, Accuracy: 3730/5000 (74.00%)\n",
      "\n",
      "the time of this epoch:[38.811816930770874 s]\n",
      "Train Epoch: 114 [0/50000 (0%)]\tLoss: 0.174265, Accuracy: 93.75\n",
      "Train Epoch: 114 [2560/50000 (6%)]\tLoss: 0.201843, Accuracy: 92.77\n",
      "Train Epoch: 114 [5120/50000 (11%)]\tLoss: 0.203025, Accuracy: 93.36\n",
      "Train Epoch: 114 [7680/50000 (17%)]\tLoss: 0.289097, Accuracy: 89.84\n",
      "Train Epoch: 114 [10240/50000 (23%)]\tLoss: 0.176244, Accuracy: 94.92\n",
      "Train Epoch: 114 [12800/50000 (28%)]\tLoss: 0.193631, Accuracy: 94.73\n",
      "Train Epoch: 114 [15360/50000 (34%)]\tLoss: 0.169989, Accuracy: 94.34\n",
      "Train Epoch: 114 [17920/50000 (40%)]\tLoss: 0.214097, Accuracy: 93.16\n",
      "Train Epoch: 114 [20480/50000 (45%)]\tLoss: 0.169232, Accuracy: 92.97\n",
      "Train Epoch: 114 [23040/50000 (51%)]\tLoss: 0.274872, Accuracy: 89.06\n",
      "Train Epoch: 114 [25600/50000 (57%)]\tLoss: 0.190714, Accuracy: 92.97\n",
      "Train Epoch: 114 [28160/50000 (62%)]\tLoss: 0.195088, Accuracy: 93.75\n",
      "Train Epoch: 114 [30720/50000 (68%)]\tLoss: 0.225825, Accuracy: 93.36\n",
      "Train Epoch: 114 [33280/50000 (74%)]\tLoss: 0.240957, Accuracy: 91.99\n",
      "Train Epoch: 114 [35840/50000 (80%)]\tLoss: 0.206686, Accuracy: 92.97\n",
      "Train Epoch: 114 [38400/50000 (85%)]\tLoss: 0.211474, Accuracy: 92.97\n",
      "Train Epoch: 114 [40960/50000 (91%)]\tLoss: 0.185904, Accuracy: 92.58\n",
      "Train Epoch: 114 [43520/50000 (97%)]\tLoss: 0.252993, Accuracy: 91.21\n",
      "\n",
      "Validation set: Average loss: 0.7261, Accuracy: 3917/5000 (78.00%)\n",
      "\n",
      "the time of this epoch:[35.63958239555359 s]\n",
      "\n",
      "Test set: Average loss: 0.7548, Accuracy: 7745/10000 (77.45%)\n",
      "\n",
      "Train Epoch: 115 [0/50000 (0%)]\tLoss: 0.197312, Accuracy: 92.38\n",
      "Train Epoch: 115 [2560/50000 (6%)]\tLoss: 0.208790, Accuracy: 92.38\n",
      "Train Epoch: 115 [5120/50000 (11%)]\tLoss: 0.204917, Accuracy: 92.97\n",
      "Train Epoch: 115 [7680/50000 (17%)]\tLoss: 0.244703, Accuracy: 91.99\n",
      "Train Epoch: 115 [10240/50000 (23%)]\tLoss: 0.260803, Accuracy: 92.19\n",
      "Train Epoch: 115 [12800/50000 (28%)]\tLoss: 0.178285, Accuracy: 94.53\n",
      "Train Epoch: 115 [15360/50000 (34%)]\tLoss: 0.248766, Accuracy: 92.19\n",
      "Train Epoch: 115 [17920/50000 (40%)]\tLoss: 0.224623, Accuracy: 92.58\n",
      "Train Epoch: 115 [20480/50000 (45%)]\tLoss: 0.210395, Accuracy: 91.21\n",
      "Train Epoch: 115 [23040/50000 (51%)]\tLoss: 0.247899, Accuracy: 90.82\n",
      "Train Epoch: 115 [25600/50000 (57%)]\tLoss: 0.231013, Accuracy: 92.38\n",
      "Train Epoch: 115 [28160/50000 (62%)]\tLoss: 0.218733, Accuracy: 91.80\n",
      "Train Epoch: 115 [30720/50000 (68%)]\tLoss: 0.233406, Accuracy: 91.60\n",
      "Train Epoch: 115 [33280/50000 (74%)]\tLoss: 0.214899, Accuracy: 92.38\n",
      "Train Epoch: 115 [35840/50000 (80%)]\tLoss: 0.186589, Accuracy: 93.55\n",
      "Train Epoch: 115 [38400/50000 (85%)]\tLoss: 0.255880, Accuracy: 91.60\n",
      "Train Epoch: 115 [40960/50000 (91%)]\tLoss: 0.240016, Accuracy: 92.19\n",
      "Train Epoch: 115 [43520/50000 (97%)]\tLoss: 0.226345, Accuracy: 93.55\n",
      "\n",
      "Validation set: Average loss: 0.6854, Accuracy: 3981/5000 (79.00%)\n",
      "\n",
      "the time of this epoch:[38.73871922492981 s]\n",
      "Train Epoch: 116 [0/50000 (0%)]\tLoss: 0.178077, Accuracy: 93.55\n",
      "Train Epoch: 116 [2560/50000 (6%)]\tLoss: 0.211201, Accuracy: 92.38\n",
      "Train Epoch: 116 [5120/50000 (11%)]\tLoss: 0.179458, Accuracy: 94.34\n",
      "Train Epoch: 116 [7680/50000 (17%)]\tLoss: 0.167527, Accuracy: 94.34\n",
      "Train Epoch: 116 [10240/50000 (23%)]\tLoss: 0.239844, Accuracy: 91.21\n",
      "Train Epoch: 116 [12800/50000 (28%)]\tLoss: 0.183934, Accuracy: 93.95\n",
      "Train Epoch: 116 [15360/50000 (34%)]\tLoss: 0.221369, Accuracy: 91.80\n",
      "Train Epoch: 116 [17920/50000 (40%)]\tLoss: 0.222876, Accuracy: 91.60\n",
      "Train Epoch: 116 [20480/50000 (45%)]\tLoss: 0.210541, Accuracy: 93.75\n",
      "Train Epoch: 116 [23040/50000 (51%)]\tLoss: 0.177796, Accuracy: 94.34\n",
      "Train Epoch: 116 [25600/50000 (57%)]\tLoss: 0.177999, Accuracy: 94.92\n",
      "Train Epoch: 116 [28160/50000 (62%)]\tLoss: 0.168474, Accuracy: 93.75\n",
      "Train Epoch: 116 [30720/50000 (68%)]\tLoss: 0.269924, Accuracy: 90.43\n",
      "Train Epoch: 116 [33280/50000 (74%)]\tLoss: 0.206380, Accuracy: 92.97\n",
      "Train Epoch: 116 [35840/50000 (80%)]\tLoss: 0.226458, Accuracy: 92.38\n",
      "Train Epoch: 116 [38400/50000 (85%)]\tLoss: 0.229286, Accuracy: 90.82\n",
      "Train Epoch: 116 [40960/50000 (91%)]\tLoss: 0.311188, Accuracy: 90.82\n",
      "Train Epoch: 116 [43520/50000 (97%)]\tLoss: 0.307920, Accuracy: 89.65\n",
      "\n",
      "Validation set: Average loss: 0.7510, Accuracy: 4015/5000 (80.00%)\n",
      "\n",
      "the time of this epoch:[35.1362681388855 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8117, Accuracy: 7907/10000 (79.07%)\n",
      "\n",
      "Train Epoch: 117 [0/50000 (0%)]\tLoss: 0.228499, Accuracy: 92.38\n",
      "Train Epoch: 117 [2560/50000 (6%)]\tLoss: 0.199648, Accuracy: 93.55\n",
      "Train Epoch: 117 [5120/50000 (11%)]\tLoss: 0.272612, Accuracy: 90.23\n",
      "Train Epoch: 117 [7680/50000 (17%)]\tLoss: 0.209632, Accuracy: 93.75\n",
      "Train Epoch: 117 [10240/50000 (23%)]\tLoss: 0.236274, Accuracy: 92.19\n",
      "Train Epoch: 117 [12800/50000 (28%)]\tLoss: 0.191671, Accuracy: 92.97\n",
      "Train Epoch: 117 [15360/50000 (34%)]\tLoss: 0.206545, Accuracy: 92.58\n",
      "Train Epoch: 117 [17920/50000 (40%)]\tLoss: 0.186985, Accuracy: 93.55\n",
      "Train Epoch: 117 [20480/50000 (45%)]\tLoss: 0.208854, Accuracy: 92.97\n",
      "Train Epoch: 117 [23040/50000 (51%)]\tLoss: 0.202225, Accuracy: 93.75\n",
      "Train Epoch: 117 [25600/50000 (57%)]\tLoss: 0.180187, Accuracy: 94.14\n",
      "Train Epoch: 117 [28160/50000 (62%)]\tLoss: 0.246569, Accuracy: 90.23\n",
      "Train Epoch: 117 [30720/50000 (68%)]\tLoss: 0.238879, Accuracy: 91.80\n",
      "Train Epoch: 117 [33280/50000 (74%)]\tLoss: 0.233430, Accuracy: 92.97\n",
      "Train Epoch: 117 [35840/50000 (80%)]\tLoss: 0.177457, Accuracy: 93.95\n",
      "Train Epoch: 117 [38400/50000 (85%)]\tLoss: 0.259545, Accuracy: 90.82\n",
      "Train Epoch: 117 [40960/50000 (91%)]\tLoss: 0.195819, Accuracy: 92.77\n",
      "Train Epoch: 117 [43520/50000 (97%)]\tLoss: 0.212960, Accuracy: 93.16\n",
      "\n",
      "Validation set: Average loss: 0.7864, Accuracy: 3847/5000 (76.00%)\n",
      "\n",
      "the time of this epoch:[38.419100761413574 s]\n",
      "Train Epoch: 118 [0/50000 (0%)]\tLoss: 0.182235, Accuracy: 93.95\n",
      "Train Epoch: 118 [2560/50000 (6%)]\tLoss: 0.172543, Accuracy: 94.14\n",
      "Train Epoch: 118 [5120/50000 (11%)]\tLoss: 0.217417, Accuracy: 93.36\n",
      "Train Epoch: 118 [7680/50000 (17%)]\tLoss: 0.191997, Accuracy: 92.38\n",
      "Train Epoch: 118 [10240/50000 (23%)]\tLoss: 0.232939, Accuracy: 91.99\n",
      "Train Epoch: 118 [12800/50000 (28%)]\tLoss: 0.166747, Accuracy: 93.36\n",
      "Train Epoch: 118 [15360/50000 (34%)]\tLoss: 0.259850, Accuracy: 91.41\n",
      "Train Epoch: 118 [17920/50000 (40%)]\tLoss: 0.216316, Accuracy: 93.16\n",
      "Train Epoch: 118 [20480/50000 (45%)]\tLoss: 0.300674, Accuracy: 89.84\n",
      "Train Epoch: 118 [23040/50000 (51%)]\tLoss: 0.224619, Accuracy: 93.36\n",
      "Train Epoch: 118 [25600/50000 (57%)]\tLoss: 0.239793, Accuracy: 90.82\n",
      "Train Epoch: 118 [28160/50000 (62%)]\tLoss: 0.205123, Accuracy: 92.77\n",
      "Train Epoch: 118 [30720/50000 (68%)]\tLoss: 0.203386, Accuracy: 92.38\n",
      "Train Epoch: 118 [33280/50000 (74%)]\tLoss: 0.235274, Accuracy: 91.80\n",
      "Train Epoch: 118 [35840/50000 (80%)]\tLoss: 0.226847, Accuracy: 91.21\n",
      "Train Epoch: 118 [38400/50000 (85%)]\tLoss: 0.207590, Accuracy: 93.36\n",
      "Train Epoch: 118 [40960/50000 (91%)]\tLoss: 0.240454, Accuracy: 91.02\n",
      "Train Epoch: 118 [43520/50000 (97%)]\tLoss: 0.200213, Accuracy: 93.55\n",
      "\n",
      "Validation set: Average loss: 0.6312, Accuracy: 3962/5000 (79.00%)\n",
      "\n",
      "the time of this epoch:[35.17354774475098 s]\n",
      "\n",
      "Test set: Average loss: 0.6234, Accuracy: 8027/10000 (80.27%)\n",
      "\n",
      "Train Epoch: 119 [0/50000 (0%)]\tLoss: 0.228741, Accuracy: 92.58\n",
      "Train Epoch: 119 [2560/50000 (6%)]\tLoss: 0.205479, Accuracy: 93.55\n",
      "Train Epoch: 119 [5120/50000 (11%)]\tLoss: 0.241996, Accuracy: 92.19\n",
      "Train Epoch: 119 [7680/50000 (17%)]\tLoss: 0.186377, Accuracy: 94.14\n",
      "Train Epoch: 119 [10240/50000 (23%)]\tLoss: 0.160418, Accuracy: 93.75\n",
      "Train Epoch: 119 [12800/50000 (28%)]\tLoss: 0.196788, Accuracy: 92.97\n",
      "Train Epoch: 119 [15360/50000 (34%)]\tLoss: 0.181311, Accuracy: 93.75\n",
      "Train Epoch: 119 [17920/50000 (40%)]\tLoss: 0.272075, Accuracy: 91.41\n",
      "Train Epoch: 119 [20480/50000 (45%)]\tLoss: 0.194987, Accuracy: 93.36\n",
      "Train Epoch: 119 [23040/50000 (51%)]\tLoss: 0.209616, Accuracy: 91.99\n",
      "Train Epoch: 119 [25600/50000 (57%)]\tLoss: 0.219837, Accuracy: 92.38\n",
      "Train Epoch: 119 [28160/50000 (62%)]\tLoss: 0.229517, Accuracy: 92.19\n",
      "Train Epoch: 119 [30720/50000 (68%)]\tLoss: 0.303163, Accuracy: 91.02\n",
      "Train Epoch: 119 [33280/50000 (74%)]\tLoss: 0.272502, Accuracy: 91.99\n",
      "Train Epoch: 119 [35840/50000 (80%)]\tLoss: 0.249919, Accuracy: 90.62\n",
      "Train Epoch: 119 [38400/50000 (85%)]\tLoss: 0.194813, Accuracy: 92.58\n",
      "Train Epoch: 119 [40960/50000 (91%)]\tLoss: 0.236701, Accuracy: 92.19\n",
      "Train Epoch: 119 [43520/50000 (97%)]\tLoss: 0.207197, Accuracy: 92.77\n",
      "\n",
      "Validation set: Average loss: 0.9681, Accuracy: 3624/5000 (72.00%)\n",
      "\n",
      "the time of this epoch:[38.4256706237793 s]\n",
      "Train Epoch: 120 [0/50000 (0%)]\tLoss: 0.188584, Accuracy: 93.36\n",
      "Train Epoch: 120 [2560/50000 (6%)]\tLoss: 0.201029, Accuracy: 92.97\n",
      "Train Epoch: 120 [5120/50000 (11%)]\tLoss: 0.205733, Accuracy: 92.77\n",
      "Train Epoch: 120 [7680/50000 (17%)]\tLoss: 0.171225, Accuracy: 93.55\n",
      "Train Epoch: 120 [10240/50000 (23%)]\tLoss: 0.247325, Accuracy: 92.38\n",
      "Train Epoch: 120 [12800/50000 (28%)]\tLoss: 0.264110, Accuracy: 90.82\n",
      "Train Epoch: 120 [15360/50000 (34%)]\tLoss: 0.285643, Accuracy: 90.82\n",
      "Train Epoch: 120 [17920/50000 (40%)]\tLoss: 0.222338, Accuracy: 91.21\n",
      "Train Epoch: 120 [20480/50000 (45%)]\tLoss: 0.229823, Accuracy: 91.41\n",
      "Train Epoch: 120 [23040/50000 (51%)]\tLoss: 0.189250, Accuracy: 91.99\n",
      "Train Epoch: 120 [25600/50000 (57%)]\tLoss: 0.222379, Accuracy: 93.55\n",
      "Train Epoch: 120 [28160/50000 (62%)]\tLoss: 0.192746, Accuracy: 92.97\n",
      "Train Epoch: 120 [30720/50000 (68%)]\tLoss: 0.238366, Accuracy: 92.77\n",
      "Train Epoch: 120 [33280/50000 (74%)]\tLoss: 0.221871, Accuracy: 92.58\n",
      "Train Epoch: 120 [35840/50000 (80%)]\tLoss: 0.219144, Accuracy: 91.80\n",
      "Train Epoch: 120 [38400/50000 (85%)]\tLoss: 0.195927, Accuracy: 93.36\n",
      "Train Epoch: 120 [40960/50000 (91%)]\tLoss: 0.237182, Accuracy: 92.97\n",
      "Train Epoch: 120 [43520/50000 (97%)]\tLoss: 0.200160, Accuracy: 94.34\n",
      "\n",
      "Validation set: Average loss: 1.5728, Accuracy: 3414/5000 (68.00%)\n",
      "\n",
      "the time of this epoch:[35.14995861053467 s]\n",
      "\n",
      "Test set: Average loss: 1.8547, Accuracy: 6510/10000 (65.10%)\n",
      "\n",
      "Train Epoch: 121 [0/50000 (0%)]\tLoss: 0.221775, Accuracy: 92.77\n",
      "Train Epoch: 121 [2560/50000 (6%)]\tLoss: 0.174600, Accuracy: 94.14\n",
      "Train Epoch: 121 [5120/50000 (11%)]\tLoss: 0.188257, Accuracy: 94.14\n",
      "Train Epoch: 121 [7680/50000 (17%)]\tLoss: 0.190939, Accuracy: 93.36\n",
      "Train Epoch: 121 [10240/50000 (23%)]\tLoss: 0.170264, Accuracy: 94.73\n",
      "Train Epoch: 121 [12800/50000 (28%)]\tLoss: 0.233602, Accuracy: 92.77\n",
      "Train Epoch: 121 [15360/50000 (34%)]\tLoss: 0.239337, Accuracy: 91.80\n",
      "Train Epoch: 121 [17920/50000 (40%)]\tLoss: 0.224063, Accuracy: 91.21\n",
      "Train Epoch: 121 [20480/50000 (45%)]\tLoss: 0.227683, Accuracy: 91.41\n",
      "Train Epoch: 121 [23040/50000 (51%)]\tLoss: 0.221396, Accuracy: 91.60\n",
      "Train Epoch: 121 [25600/50000 (57%)]\tLoss: 0.209469, Accuracy: 92.77\n",
      "Train Epoch: 121 [28160/50000 (62%)]\tLoss: 0.203708, Accuracy: 93.55\n",
      "Train Epoch: 121 [30720/50000 (68%)]\tLoss: 0.233960, Accuracy: 91.80\n",
      "Train Epoch: 121 [33280/50000 (74%)]\tLoss: 0.235867, Accuracy: 91.60\n",
      "Train Epoch: 121 [35840/50000 (80%)]\tLoss: 0.235660, Accuracy: 91.80\n",
      "Train Epoch: 121 [38400/50000 (85%)]\tLoss: 0.249189, Accuracy: 92.97\n",
      "Train Epoch: 121 [40960/50000 (91%)]\tLoss: 0.214330, Accuracy: 92.77\n",
      "Train Epoch: 121 [43520/50000 (97%)]\tLoss: 0.223224, Accuracy: 91.41\n",
      "\n",
      "Validation set: Average loss: 1.0630, Accuracy: 3630/5000 (72.00%)\n",
      "\n",
      "the time of this epoch:[38.42217254638672 s]\n",
      "Train Epoch: 122 [0/50000 (0%)]\tLoss: 0.211212, Accuracy: 92.97\n",
      "Train Epoch: 122 [2560/50000 (6%)]\tLoss: 0.238738, Accuracy: 91.80\n",
      "Train Epoch: 122 [5120/50000 (11%)]\tLoss: 0.200489, Accuracy: 93.55\n",
      "Train Epoch: 122 [7680/50000 (17%)]\tLoss: 0.183253, Accuracy: 94.53\n",
      "Train Epoch: 122 [10240/50000 (23%)]\tLoss: 0.182196, Accuracy: 93.55\n",
      "Train Epoch: 122 [12800/50000 (28%)]\tLoss: 0.166954, Accuracy: 94.73\n",
      "Train Epoch: 122 [15360/50000 (34%)]\tLoss: 0.179459, Accuracy: 93.55\n",
      "Train Epoch: 122 [17920/50000 (40%)]\tLoss: 0.227016, Accuracy: 93.75\n",
      "Train Epoch: 122 [20480/50000 (45%)]\tLoss: 0.154205, Accuracy: 95.31\n",
      "Train Epoch: 122 [23040/50000 (51%)]\tLoss: 0.160596, Accuracy: 94.73\n",
      "Train Epoch: 122 [25600/50000 (57%)]\tLoss: 0.271472, Accuracy: 90.23\n",
      "Train Epoch: 122 [28160/50000 (62%)]\tLoss: 0.187745, Accuracy: 93.55\n",
      "Train Epoch: 122 [30720/50000 (68%)]\tLoss: 0.182474, Accuracy: 93.55\n",
      "Train Epoch: 122 [33280/50000 (74%)]\tLoss: 0.247464, Accuracy: 92.58\n",
      "Train Epoch: 122 [35840/50000 (80%)]\tLoss: 0.210140, Accuracy: 93.55\n",
      "Train Epoch: 122 [38400/50000 (85%)]\tLoss: 0.242777, Accuracy: 91.80\n",
      "Train Epoch: 122 [40960/50000 (91%)]\tLoss: 0.212245, Accuracy: 93.16\n",
      "Train Epoch: 122 [43520/50000 (97%)]\tLoss: 0.212328, Accuracy: 91.99\n",
      "\n",
      "Validation set: Average loss: 0.9356, Accuracy: 3823/5000 (76.00%)\n",
      "\n",
      "the time of this epoch:[35.16101956367493 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7835, Accuracy: 7847/10000 (78.47%)\n",
      "\n",
      "Train Epoch: 123 [0/50000 (0%)]\tLoss: 0.177405, Accuracy: 93.75\n",
      "Train Epoch: 123 [2560/50000 (6%)]\tLoss: 0.187218, Accuracy: 91.99\n",
      "Train Epoch: 123 [5120/50000 (11%)]\tLoss: 0.183287, Accuracy: 93.36\n",
      "Train Epoch: 123 [7680/50000 (17%)]\tLoss: 0.156021, Accuracy: 94.14\n",
      "Train Epoch: 123 [10240/50000 (23%)]\tLoss: 0.250369, Accuracy: 91.80\n",
      "Train Epoch: 123 [12800/50000 (28%)]\tLoss: 0.215745, Accuracy: 92.77\n",
      "Train Epoch: 123 [15360/50000 (34%)]\tLoss: 0.201819, Accuracy: 92.77\n",
      "Train Epoch: 123 [17920/50000 (40%)]\tLoss: 0.225762, Accuracy: 91.99\n",
      "Train Epoch: 123 [20480/50000 (45%)]\tLoss: 0.208800, Accuracy: 93.36\n",
      "Train Epoch: 123 [23040/50000 (51%)]\tLoss: 0.211349, Accuracy: 92.97\n",
      "Train Epoch: 123 [25600/50000 (57%)]\tLoss: 0.253688, Accuracy: 90.43\n",
      "Train Epoch: 123 [28160/50000 (62%)]\tLoss: 0.200882, Accuracy: 93.95\n",
      "Train Epoch: 123 [30720/50000 (68%)]\tLoss: 0.214907, Accuracy: 93.36\n",
      "Train Epoch: 123 [33280/50000 (74%)]\tLoss: 0.216324, Accuracy: 92.97\n",
      "Train Epoch: 123 [35840/50000 (80%)]\tLoss: 0.156843, Accuracy: 94.73\n",
      "Train Epoch: 123 [38400/50000 (85%)]\tLoss: 0.197637, Accuracy: 93.75\n",
      "Train Epoch: 123 [40960/50000 (91%)]\tLoss: 0.214007, Accuracy: 92.19\n",
      "Train Epoch: 123 [43520/50000 (97%)]\tLoss: 0.287735, Accuracy: 90.04\n",
      "\n",
      "Validation set: Average loss: 0.6564, Accuracy: 3982/5000 (79.00%)\n",
      "\n",
      "the time of this epoch:[38.419310092926025 s]\n",
      "Train Epoch: 124 [0/50000 (0%)]\tLoss: 0.169460, Accuracy: 94.34\n",
      "Train Epoch: 124 [2560/50000 (6%)]\tLoss: 0.247318, Accuracy: 90.62\n",
      "Train Epoch: 124 [5120/50000 (11%)]\tLoss: 0.173276, Accuracy: 94.34\n",
      "Train Epoch: 124 [7680/50000 (17%)]\tLoss: 0.186808, Accuracy: 94.34\n",
      "Train Epoch: 124 [10240/50000 (23%)]\tLoss: 0.179647, Accuracy: 93.95\n",
      "Train Epoch: 124 [12800/50000 (28%)]\tLoss: 0.215285, Accuracy: 92.97\n",
      "Train Epoch: 124 [15360/50000 (34%)]\tLoss: 0.163377, Accuracy: 94.73\n",
      "Train Epoch: 124 [17920/50000 (40%)]\tLoss: 0.209891, Accuracy: 93.16\n",
      "Train Epoch: 124 [20480/50000 (45%)]\tLoss: 0.220370, Accuracy: 92.58\n",
      "Train Epoch: 124 [23040/50000 (51%)]\tLoss: 0.238935, Accuracy: 91.21\n",
      "Train Epoch: 124 [25600/50000 (57%)]\tLoss: 0.200137, Accuracy: 92.97\n",
      "Train Epoch: 124 [28160/50000 (62%)]\tLoss: 0.219241, Accuracy: 92.19\n",
      "Train Epoch: 124 [30720/50000 (68%)]\tLoss: 0.232160, Accuracy: 92.19\n",
      "Train Epoch: 124 [33280/50000 (74%)]\tLoss: 0.170548, Accuracy: 93.36\n",
      "Train Epoch: 124 [35840/50000 (80%)]\tLoss: 0.214973, Accuracy: 93.95\n",
      "Train Epoch: 124 [38400/50000 (85%)]\tLoss: 0.265022, Accuracy: 90.04\n",
      "Train Epoch: 124 [40960/50000 (91%)]\tLoss: 0.241378, Accuracy: 92.38\n",
      "Train Epoch: 124 [43520/50000 (97%)]\tLoss: 0.180290, Accuracy: 93.36\n",
      "\n",
      "Validation set: Average loss: 0.6440, Accuracy: 4044/5000 (80.00%)\n",
      "\n",
      "the time of this epoch:[35.131349086761475 s]\n",
      "\n",
      "Test set: Average loss: 0.6706, Accuracy: 8062/10000 (80.62%)\n",
      "\n",
      "Train Epoch: 125 [0/50000 (0%)]\tLoss: 0.185936, Accuracy: 93.75\n",
      "Train Epoch: 125 [2560/50000 (6%)]\tLoss: 0.216852, Accuracy: 91.41\n",
      "Train Epoch: 125 [5120/50000 (11%)]\tLoss: 0.197675, Accuracy: 92.77\n",
      "Train Epoch: 125 [7680/50000 (17%)]\tLoss: 0.211562, Accuracy: 92.97\n",
      "Train Epoch: 125 [10240/50000 (23%)]\tLoss: 0.220782, Accuracy: 91.80\n",
      "Train Epoch: 125 [12800/50000 (28%)]\tLoss: 0.204554, Accuracy: 93.55\n",
      "Train Epoch: 125 [15360/50000 (34%)]\tLoss: 0.223217, Accuracy: 93.16\n",
      "Train Epoch: 125 [17920/50000 (40%)]\tLoss: 0.211440, Accuracy: 93.75\n",
      "Train Epoch: 125 [20480/50000 (45%)]\tLoss: 0.265039, Accuracy: 91.02\n",
      "Train Epoch: 125 [23040/50000 (51%)]\tLoss: 0.217847, Accuracy: 91.99\n",
      "Train Epoch: 125 [25600/50000 (57%)]\tLoss: 0.232621, Accuracy: 92.97\n",
      "Train Epoch: 125 [28160/50000 (62%)]\tLoss: 0.261668, Accuracy: 90.43\n",
      "Train Epoch: 125 [30720/50000 (68%)]\tLoss: 0.262235, Accuracy: 91.60\n",
      "Train Epoch: 125 [33280/50000 (74%)]\tLoss: 0.216637, Accuracy: 91.80\n",
      "Train Epoch: 125 [35840/50000 (80%)]\tLoss: 0.194555, Accuracy: 94.14\n",
      "Train Epoch: 125 [38400/50000 (85%)]\tLoss: 0.185944, Accuracy: 93.55\n",
      "Train Epoch: 125 [40960/50000 (91%)]\tLoss: 0.225584, Accuracy: 93.16\n",
      "Train Epoch: 125 [43520/50000 (97%)]\tLoss: 0.242569, Accuracy: 91.99\n",
      "\n",
      "Validation set: Average loss: 0.9062, Accuracy: 3727/5000 (74.00%)\n",
      "\n",
      "the time of this epoch:[38.480236768722534 s]\n",
      "Train Epoch: 126 [0/50000 (0%)]\tLoss: 0.203945, Accuracy: 92.97\n",
      "Train Epoch: 126 [2560/50000 (6%)]\tLoss: 0.228399, Accuracy: 93.75\n",
      "Train Epoch: 126 [5120/50000 (11%)]\tLoss: 0.185954, Accuracy: 94.92\n",
      "Train Epoch: 126 [7680/50000 (17%)]\tLoss: 0.241106, Accuracy: 91.02\n",
      "Train Epoch: 126 [10240/50000 (23%)]\tLoss: 0.163455, Accuracy: 94.73\n",
      "Train Epoch: 126 [12800/50000 (28%)]\tLoss: 0.163268, Accuracy: 93.75\n",
      "Train Epoch: 126 [15360/50000 (34%)]\tLoss: 0.235723, Accuracy: 92.77\n",
      "Train Epoch: 126 [17920/50000 (40%)]\tLoss: 0.197694, Accuracy: 92.77\n",
      "Train Epoch: 126 [20480/50000 (45%)]\tLoss: 0.203393, Accuracy: 93.75\n",
      "Train Epoch: 126 [23040/50000 (51%)]\tLoss: 0.208863, Accuracy: 93.55\n",
      "Train Epoch: 126 [25600/50000 (57%)]\tLoss: 0.189545, Accuracy: 93.95\n",
      "Train Epoch: 126 [28160/50000 (62%)]\tLoss: 0.188774, Accuracy: 91.99\n",
      "Train Epoch: 126 [30720/50000 (68%)]\tLoss: 0.211533, Accuracy: 92.19\n",
      "Train Epoch: 126 [33280/50000 (74%)]\tLoss: 0.179969, Accuracy: 93.36\n",
      "Train Epoch: 126 [35840/50000 (80%)]\tLoss: 0.192071, Accuracy: 92.38\n",
      "Train Epoch: 126 [38400/50000 (85%)]\tLoss: 0.184952, Accuracy: 93.55\n",
      "Train Epoch: 126 [40960/50000 (91%)]\tLoss: 0.268123, Accuracy: 91.02\n",
      "Train Epoch: 126 [43520/50000 (97%)]\tLoss: 0.193910, Accuracy: 93.16\n",
      "\n",
      "Validation set: Average loss: 0.6543, Accuracy: 4064/5000 (81.00%)\n",
      "\n",
      "the time of this epoch:[35.51392364501953 s]\n",
      "\n",
      "Test set: Average loss: 0.6773, Accuracy: 8030/10000 (80.30%)\n",
      "\n",
      "Train Epoch: 127 [0/50000 (0%)]\tLoss: 0.262446, Accuracy: 91.21\n",
      "Train Epoch: 127 [2560/50000 (6%)]\tLoss: 0.202946, Accuracy: 92.38\n",
      "Train Epoch: 127 [5120/50000 (11%)]\tLoss: 0.174780, Accuracy: 94.14\n",
      "Train Epoch: 127 [7680/50000 (17%)]\tLoss: 0.191221, Accuracy: 92.38\n",
      "Train Epoch: 127 [10240/50000 (23%)]\tLoss: 0.205814, Accuracy: 93.16\n",
      "Train Epoch: 127 [12800/50000 (28%)]\tLoss: 0.169434, Accuracy: 94.73\n",
      "Train Epoch: 127 [15360/50000 (34%)]\tLoss: 0.226743, Accuracy: 92.19\n",
      "Train Epoch: 127 [17920/50000 (40%)]\tLoss: 0.200761, Accuracy: 93.16\n",
      "Train Epoch: 127 [20480/50000 (45%)]\tLoss: 0.260423, Accuracy: 91.02\n",
      "Train Epoch: 127 [23040/50000 (51%)]\tLoss: 0.241323, Accuracy: 91.60\n",
      "Train Epoch: 127 [25600/50000 (57%)]\tLoss: 0.150211, Accuracy: 95.31\n",
      "Train Epoch: 127 [28160/50000 (62%)]\tLoss: 0.215948, Accuracy: 91.80\n",
      "Train Epoch: 127 [30720/50000 (68%)]\tLoss: 0.211624, Accuracy: 93.55\n",
      "Train Epoch: 127 [33280/50000 (74%)]\tLoss: 0.256366, Accuracy: 91.02\n",
      "Train Epoch: 127 [35840/50000 (80%)]\tLoss: 0.188859, Accuracy: 92.38\n",
      "Train Epoch: 127 [38400/50000 (85%)]\tLoss: 0.170208, Accuracy: 93.75\n",
      "Train Epoch: 127 [40960/50000 (91%)]\tLoss: 0.274911, Accuracy: 91.02\n",
      "Train Epoch: 127 [43520/50000 (97%)]\tLoss: 0.207713, Accuracy: 92.77\n",
      "\n",
      "Validation set: Average loss: 0.6383, Accuracy: 4075/5000 (81.00%)\n",
      "\n",
      "the time of this epoch:[39.307318687438965 s]\n",
      "Train Epoch: 128 [0/50000 (0%)]\tLoss: 0.250689, Accuracy: 91.60\n",
      "Train Epoch: 128 [2560/50000 (6%)]\tLoss: 0.231441, Accuracy: 91.80\n",
      "Train Epoch: 128 [5120/50000 (11%)]\tLoss: 0.161072, Accuracy: 94.73\n",
      "Train Epoch: 128 [7680/50000 (17%)]\tLoss: 0.204199, Accuracy: 92.58\n",
      "Train Epoch: 128 [10240/50000 (23%)]\tLoss: 0.240381, Accuracy: 91.02\n",
      "Train Epoch: 128 [12800/50000 (28%)]\tLoss: 0.214693, Accuracy: 93.16\n",
      "Train Epoch: 128 [15360/50000 (34%)]\tLoss: 0.249592, Accuracy: 91.60\n",
      "Train Epoch: 128 [17920/50000 (40%)]\tLoss: 0.217589, Accuracy: 92.19\n",
      "Train Epoch: 128 [20480/50000 (45%)]\tLoss: 0.266019, Accuracy: 89.65\n",
      "Train Epoch: 128 [23040/50000 (51%)]\tLoss: 0.190520, Accuracy: 94.14\n",
      "Train Epoch: 128 [25600/50000 (57%)]\tLoss: 0.212971, Accuracy: 93.16\n",
      "Train Epoch: 128 [28160/50000 (62%)]\tLoss: 0.278066, Accuracy: 90.04\n",
      "Train Epoch: 128 [30720/50000 (68%)]\tLoss: 0.176948, Accuracy: 93.75\n",
      "Train Epoch: 128 [33280/50000 (74%)]\tLoss: 0.200491, Accuracy: 93.36\n",
      "Train Epoch: 128 [35840/50000 (80%)]\tLoss: 0.260302, Accuracy: 91.60\n",
      "Train Epoch: 128 [38400/50000 (85%)]\tLoss: 0.253166, Accuracy: 90.04\n",
      "Train Epoch: 128 [40960/50000 (91%)]\tLoss: 0.247257, Accuracy: 91.80\n",
      "Train Epoch: 128 [43520/50000 (97%)]\tLoss: 0.266080, Accuracy: 90.62\n",
      "\n",
      "Validation set: Average loss: 0.8287, Accuracy: 3867/5000 (77.00%)\n",
      "\n",
      "the time of this epoch:[35.50004243850708 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8799, Accuracy: 7628/10000 (76.28%)\n",
      "\n",
      "Train Epoch: 129 [0/50000 (0%)]\tLoss: 0.210928, Accuracy: 91.99\n",
      "Train Epoch: 129 [2560/50000 (6%)]\tLoss: 0.144291, Accuracy: 95.12\n",
      "Train Epoch: 129 [5120/50000 (11%)]\tLoss: 0.150268, Accuracy: 93.36\n",
      "Train Epoch: 129 [7680/50000 (17%)]\tLoss: 0.197600, Accuracy: 93.36\n",
      "Train Epoch: 129 [10240/50000 (23%)]\tLoss: 0.207226, Accuracy: 93.16\n",
      "Train Epoch: 129 [12800/50000 (28%)]\tLoss: 0.152083, Accuracy: 94.73\n",
      "Train Epoch: 129 [15360/50000 (34%)]\tLoss: 0.230889, Accuracy: 92.19\n",
      "Train Epoch: 129 [17920/50000 (40%)]\tLoss: 0.243558, Accuracy: 92.19\n",
      "Train Epoch: 129 [20480/50000 (45%)]\tLoss: 0.250377, Accuracy: 91.80\n",
      "Train Epoch: 129 [23040/50000 (51%)]\tLoss: 0.226221, Accuracy: 92.19\n",
      "Train Epoch: 129 [25600/50000 (57%)]\tLoss: 0.207151, Accuracy: 93.55\n",
      "Train Epoch: 129 [28160/50000 (62%)]\tLoss: 0.265645, Accuracy: 91.21\n",
      "Train Epoch: 129 [30720/50000 (68%)]\tLoss: 0.178020, Accuracy: 93.95\n",
      "Train Epoch: 129 [33280/50000 (74%)]\tLoss: 0.203381, Accuracy: 92.97\n",
      "Train Epoch: 129 [35840/50000 (80%)]\tLoss: 0.213100, Accuracy: 92.38\n",
      "Train Epoch: 129 [38400/50000 (85%)]\tLoss: 0.274642, Accuracy: 90.43\n",
      "Train Epoch: 129 [40960/50000 (91%)]\tLoss: 0.257062, Accuracy: 91.41\n",
      "Train Epoch: 129 [43520/50000 (97%)]\tLoss: 0.305072, Accuracy: 90.23\n",
      "\n",
      "Validation set: Average loss: 0.7948, Accuracy: 3835/5000 (76.00%)\n",
      "\n",
      "the time of this epoch:[38.472190380096436 s]\n",
      "Train Epoch: 130 [0/50000 (0%)]\tLoss: 0.162388, Accuracy: 93.95\n",
      "Train Epoch: 130 [2560/50000 (6%)]\tLoss: 0.190429, Accuracy: 93.75\n",
      "Train Epoch: 130 [5120/50000 (11%)]\tLoss: 0.181338, Accuracy: 92.97\n",
      "Train Epoch: 130 [7680/50000 (17%)]\tLoss: 0.247298, Accuracy: 92.97\n",
      "Train Epoch: 130 [10240/50000 (23%)]\tLoss: 0.237649, Accuracy: 92.38\n",
      "Train Epoch: 130 [12800/50000 (28%)]\tLoss: 0.230180, Accuracy: 92.58\n",
      "Train Epoch: 130 [15360/50000 (34%)]\tLoss: 0.183259, Accuracy: 93.75\n",
      "Train Epoch: 130 [17920/50000 (40%)]\tLoss: 0.212072, Accuracy: 92.58\n",
      "Train Epoch: 130 [20480/50000 (45%)]\tLoss: 0.204522, Accuracy: 93.36\n",
      "Train Epoch: 130 [23040/50000 (51%)]\tLoss: 0.179012, Accuracy: 94.92\n",
      "Train Epoch: 130 [25600/50000 (57%)]\tLoss: 0.164049, Accuracy: 94.34\n",
      "Train Epoch: 130 [28160/50000 (62%)]\tLoss: 0.173884, Accuracy: 94.34\n",
      "Train Epoch: 130 [30720/50000 (68%)]\tLoss: 0.195888, Accuracy: 93.55\n",
      "Train Epoch: 130 [33280/50000 (74%)]\tLoss: 0.203204, Accuracy: 92.19\n",
      "Train Epoch: 130 [35840/50000 (80%)]\tLoss: 0.244084, Accuracy: 91.41\n",
      "Train Epoch: 130 [38400/50000 (85%)]\tLoss: 0.222532, Accuracy: 91.99\n",
      "Train Epoch: 130 [40960/50000 (91%)]\tLoss: 0.294969, Accuracy: 88.87\n",
      "Train Epoch: 130 [43520/50000 (97%)]\tLoss: 0.237199, Accuracy: 91.80\n",
      "\n",
      "Validation set: Average loss: 0.7336, Accuracy: 3961/5000 (79.00%)\n",
      "\n",
      "the time of this epoch:[35.15269207954407 s]\n",
      "\n",
      "Test set: Average loss: 0.7390, Accuracy: 7887/10000 (78.87%)\n",
      "\n",
      "Train Epoch: 131 [0/50000 (0%)]\tLoss: 0.204159, Accuracy: 92.97\n",
      "Train Epoch: 131 [2560/50000 (6%)]\tLoss: 0.154897, Accuracy: 96.09\n",
      "Train Epoch: 131 [5120/50000 (11%)]\tLoss: 0.189022, Accuracy: 93.36\n",
      "Train Epoch: 131 [7680/50000 (17%)]\tLoss: 0.228028, Accuracy: 91.99\n",
      "Train Epoch: 131 [10240/50000 (23%)]\tLoss: 0.201556, Accuracy: 93.16\n",
      "Train Epoch: 131 [12800/50000 (28%)]\tLoss: 0.243945, Accuracy: 92.38\n",
      "Train Epoch: 131 [15360/50000 (34%)]\tLoss: 0.180017, Accuracy: 93.75\n",
      "Train Epoch: 131 [17920/50000 (40%)]\tLoss: 0.191653, Accuracy: 92.38\n",
      "Train Epoch: 131 [20480/50000 (45%)]\tLoss: 0.253074, Accuracy: 91.21\n",
      "Train Epoch: 131 [23040/50000 (51%)]\tLoss: 0.224165, Accuracy: 92.19\n",
      "Train Epoch: 131 [25600/50000 (57%)]\tLoss: 0.191496, Accuracy: 93.75\n",
      "Train Epoch: 131 [28160/50000 (62%)]\tLoss: 0.234361, Accuracy: 92.77\n",
      "Train Epoch: 131 [30720/50000 (68%)]\tLoss: 0.189269, Accuracy: 93.75\n",
      "Train Epoch: 131 [33280/50000 (74%)]\tLoss: 0.248503, Accuracy: 92.77\n",
      "Train Epoch: 131 [35840/50000 (80%)]\tLoss: 0.249142, Accuracy: 92.58\n",
      "Train Epoch: 131 [38400/50000 (85%)]\tLoss: 0.229994, Accuracy: 91.99\n",
      "Train Epoch: 131 [40960/50000 (91%)]\tLoss: 0.252032, Accuracy: 91.80\n",
      "Train Epoch: 131 [43520/50000 (97%)]\tLoss: 0.247578, Accuracy: 91.41\n",
      "\n",
      "Validation set: Average loss: 0.5705, Accuracy: 4124/5000 (82.00%)\n",
      "\n",
      "the time of this epoch:[38.40990948677063 s]\n",
      "Train Epoch: 132 [0/50000 (0%)]\tLoss: 0.199191, Accuracy: 93.55\n",
      "Train Epoch: 132 [2560/50000 (6%)]\tLoss: 0.200379, Accuracy: 93.55\n",
      "Train Epoch: 132 [5120/50000 (11%)]\tLoss: 0.168987, Accuracy: 93.36\n",
      "Train Epoch: 132 [7680/50000 (17%)]\tLoss: 0.139459, Accuracy: 95.31\n",
      "Train Epoch: 132 [10240/50000 (23%)]\tLoss: 0.217223, Accuracy: 93.16\n",
      "Train Epoch: 132 [12800/50000 (28%)]\tLoss: 0.225728, Accuracy: 92.19\n",
      "Train Epoch: 132 [15360/50000 (34%)]\tLoss: 0.248712, Accuracy: 91.02\n",
      "Train Epoch: 132 [17920/50000 (40%)]\tLoss: 0.225012, Accuracy: 92.77\n",
      "Train Epoch: 132 [20480/50000 (45%)]\tLoss: 0.202634, Accuracy: 92.77\n",
      "Train Epoch: 132 [23040/50000 (51%)]\tLoss: 0.194689, Accuracy: 93.95\n",
      "Train Epoch: 132 [25600/50000 (57%)]\tLoss: 0.168322, Accuracy: 94.14\n",
      "Train Epoch: 132 [28160/50000 (62%)]\tLoss: 0.213099, Accuracy: 92.58\n",
      "Train Epoch: 132 [30720/50000 (68%)]\tLoss: 0.210089, Accuracy: 92.77\n",
      "Train Epoch: 132 [33280/50000 (74%)]\tLoss: 0.255514, Accuracy: 92.77\n",
      "Train Epoch: 132 [35840/50000 (80%)]\tLoss: 0.209116, Accuracy: 92.58\n",
      "Train Epoch: 132 [38400/50000 (85%)]\tLoss: 0.243169, Accuracy: 92.58\n",
      "Train Epoch: 132 [40960/50000 (91%)]\tLoss: 0.185373, Accuracy: 92.77\n",
      "Train Epoch: 132 [43520/50000 (97%)]\tLoss: 0.232585, Accuracy: 91.21\n",
      "\n",
      "Validation set: Average loss: 0.6839, Accuracy: 3978/5000 (79.00%)\n",
      "\n",
      "the time of this epoch:[35.12521052360535 s]\n",
      "\n",
      "Test set: Average loss: 0.7165, Accuracy: 7913/10000 (79.13%)\n",
      "\n",
      "Train Epoch: 133 [0/50000 (0%)]\tLoss: 0.172645, Accuracy: 94.34\n",
      "Train Epoch: 133 [2560/50000 (6%)]\tLoss: 0.158918, Accuracy: 94.53\n",
      "Train Epoch: 133 [5120/50000 (11%)]\tLoss: 0.225418, Accuracy: 93.16\n",
      "Train Epoch: 133 [7680/50000 (17%)]\tLoss: 0.189108, Accuracy: 94.34\n",
      "Train Epoch: 133 [10240/50000 (23%)]\tLoss: 0.215068, Accuracy: 93.36\n",
      "Train Epoch: 133 [12800/50000 (28%)]\tLoss: 0.158450, Accuracy: 95.12\n",
      "Train Epoch: 133 [15360/50000 (34%)]\tLoss: 0.183306, Accuracy: 92.58\n",
      "------------------------------\n",
      "before autoscale: torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.0092]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0360]],\n",
      "\n",
      "        [[ 0.0544]],\n",
      "\n",
      "        [[ 0.2971]],\n",
      "\n",
      "        [[ 0.0894]],\n",
      "\n",
      "        [[ 0.0438]],\n",
      "\n",
      "        [[ 0.2112]],\n",
      "\n",
      "        [[ 0.1129]],\n",
      "\n",
      "        [[ 0.1614]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[-0.2976]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 512])\n",
      "tensor(1.00000e-02 *\n",
      "       [[[-0.2738,  0.0000, -1.0717, -1.6202, -8.8393, -2.6612, -1.3024,\n",
      "          -6.2849, -3.3585, -4.8037, -0.9532, -6.7795, -0.8483, -1.3235,\n",
      "           0.0000, -1.5786, -1.9434, -3.3907, -6.2070, -3.0024, -5.7444,\n",
      "          -2.0534, -3.5520, -3.1196, -2.6939,  0.0000, -3.2544,  0.0000,\n",
      "          -0.1557, -2.9672, -3.6625, -3.2361, -1.2011, -1.4546, -2.1489,\n",
      "          -4.2978, -2.8555, -0.0266, -6.5308, -3.1013,  0.0000,  0.0000,\n",
      "          -0.0109, -1.1150, -2.3151, -3.7772,  0.0000,  0.0000, -2.9260,\n",
      "          -6.6467,  0.0000, -5.1067, -6.0248, -3.1793, -5.1283, -3.6238,\n",
      "           0.0000, -5.0065, -2.7618, -5.8684, -2.1415,  0.0000,  0.0000,\n",
      "          -1.7181,  0.0000,  0.0000, -1.9020, -1.3133,  0.0000,  0.0000,\n",
      "           0.0000, -0.0290, -0.0194, -0.0335,  0.0000,  0.0000, -0.0072,\n",
      "          -0.0056,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0206,\n",
      "          -0.7152, -0.4444,  0.0000, -0.0442,  0.0000,  0.0000, -0.1088,\n",
      "           0.0000, -0.2020, -0.1149, -0.0682,  0.0000, -0.1393, -0.1707,\n",
      "           0.0000, -0.0398, -0.0509,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.3488, -0.3428, -0.2822, -0.4828, -1.6943, -0.5927,  0.0000,\n",
      "          -1.2313, -3.5049,  0.0000, -0.8007, -0.7836,  0.0000, -0.3850,\n",
      "           0.0000, -0.0249, -0.0134,  0.0000, -0.0424, -0.0336, -0.6183,\n",
      "          -0.0314, -0.0216,  0.0000,  0.0000, -0.1337,  0.0000,  0.0000,\n",
      "          -0.1314,  0.0000, -0.3173, -0.4451, -0.1243,  0.0000, -0.3871,\n",
      "          -1.0944, -0.3331,  0.0000,  0.0000, -0.0900,  0.0000, -0.1815,\n",
      "          -0.2346, -0.2446, -0.4511, -0.2494, -0.3369, -0.0719, -0.3163,\n",
      "           0.0000,  0.0000,  0.0000, -0.0202, -0.0257, -0.0128, -0.0376,\n",
      "          -0.0229, -0.0153,  0.0000,  0.0000, -0.1470, -0.1022, -0.1752,\n",
      "          -0.4006, -0.1543, -0.2243, -0.2270, -0.7585,  0.0000, -0.2826,\n",
      "          -0.0373,  0.0000, -0.0373, -0.0484,  0.0000,  0.0000, -0.0328,\n",
      "          -0.0368, -0.0244,  0.0000,  0.0000,  0.0000,  0.0000, -0.1438,\n",
      "          -0.7883,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0907,\n",
      "          -0.1316,  0.0000, -0.0539, -0.1036, -0.1514, -0.0489,  0.0000,\n",
      "          -0.1751, -0.1523,  0.0000, -0.1792, -0.3435,  0.0000, -0.4231,\n",
      "           0.0000, -0.0347, -0.1996, -0.3804, -0.3368, -0.0406, -0.0358,\n",
      "           0.0000, -0.0617,  0.0000, -0.0805,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.2249,  0.0000, -1.2612,  0.0000,  0.0000, -0.1402,\n",
      "          -0.4885, -0.5830, -0.5440, -0.0046,  0.0000, -0.3147, -0.4364,\n",
      "           0.0000,  0.0000,  0.0000, -0.0932, -0.1218,  0.0000,  0.0000,\n",
      "          -0.0733, -0.1341, -0.1152, -0.1014, -0.6150,  0.0000, -0.7039,\n",
      "          -0.1520, -0.0421,  0.0000,  0.0000, -0.0276,  0.0000, -0.0315,\n",
      "           0.0000, -0.1666, -0.1733, -0.8454,  0.0000,  0.0000, -0.0504,\n",
      "          -0.1540,  0.0000,  0.0000,  0.0000, -0.1027, -0.1331,  0.0000,\n",
      "          -0.3320, -0.3223, -0.2155, -0.2023,  0.0000, -0.1543, -0.0465,\n",
      "          -0.8740, -0.0262,  0.0000, -0.0680, -0.1554,  0.0000, -0.0933,\n",
      "          -0.1246, -0.2793,  0.0000, -0.2750, -0.2881, -0.1801, -0.1995,\n",
      "          -2.2841, -0.1553, -0.1743,  0.0000,  0.0000,  0.0000, -0.1302,\n",
      "          -0.2062, -0.2616, -0.2404, -0.3119, -0.4275,  0.0000, -0.3638,\n",
      "          -0.3181, -0.3656, -1.6299, -0.2338,  0.0000,  0.0000, -0.2735,\n",
      "          -0.0345,  0.0000,  0.0000, -0.0443, -0.0212, -0.0581, -0.1050,\n",
      "          -0.0578, -0.4620, -0.4194, -0.3100, -0.5069, -1.7565, -0.2923,\n",
      "          -0.4512, -0.6066,  0.0000,  0.0000,  0.0000, -0.6226, -2.7805,\n",
      "           0.0000, -0.5209, -0.8365,  0.0000,  0.0000, -0.3053,  0.0000,\n",
      "          -0.0652, -0.0305, -0.0648, -0.6972, -0.0138, -0.0445,  0.0000,\n",
      "           0.0000, -0.0091, -0.0117, -0.0506, -0.0423, -0.0156, -0.0245,\n",
      "          -0.0039, -0.4180, -0.4482, -0.2985, -0.3966, -0.0030, -0.2344,\n",
      "          -0.3878, -1.0060, -0.4687,  0.0000,  0.0000, -1.3876, -0.1255,\n",
      "          -0.1978,  0.0000,  0.0000, -0.1785, -0.2630, -3.1640,  0.0000,\n",
      "           0.0000, -0.3625, -0.5917, -0.1590, -0.1666, -0.1894,  0.0000,\n",
      "           0.0000,  0.0000, -0.6286,  0.0000, -1.7027, -0.3088,  0.0000,\n",
      "          -0.3786, -0.0102,  0.0000, -0.2278,  0.0000, -0.1650, -0.1701,\n",
      "           0.0000, -0.1353, -0.1064, -0.1160, -0.1856, -0.2499, -0.1726,\n",
      "          -0.0845, -0.1043,  0.0000, -0.7034,  0.0000, -0.7247, -4.0869,\n",
      "           0.0000, -0.7430, -0.7095,  0.0000,  0.0000,  0.0000, -0.5247,\n",
      "          -0.3104,  0.0000, -0.9721, -3.2867,  0.0000, -0.0335,  0.0000,\n",
      "          -0.7345,  0.0000,  0.0000,  0.0000, -0.3241,  0.0000,  0.0000,\n",
      "          -0.0316,  0.0000,  0.0000,  0.0000,  0.0000, -1.3365,  0.0000,\n",
      "          -1.1431, -0.1486,  0.0000,  0.0000,  0.0000, -0.1316, -0.0271,\n",
      "          -0.2129,  0.0000,  0.0000, -0.1316,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.2026,  0.0000,  0.0000, -0.0718, -0.0704, -0.1375,\n",
      "           0.0000, -0.1573,  0.0000, -0.0979, -0.6466, -0.3167, -0.1927,\n",
      "          -0.1603,  0.0000, -0.2453,  0.0000, -0.9604, -0.1809, -0.1643,\n",
      "          -0.0576,  0.0000,  0.0000,  0.0000,  0.0000, -0.9719, -0.1997,\n",
      "          -0.1181, -0.2178, -0.3760,  0.0000,  0.0000,  0.0000, -1.6815,\n",
      "          -0.1451,  0.0000,  0.0000, -0.0276, -0.1506, -0.2331, -0.2834,\n",
      "          -0.4623, -0.2289, -0.3201, -0.3051,  0.0000, -0.4159, -0.4138,\n",
      "          -0.2095, -1.0106, -0.0364,  0.0000, -1.3679, -0.6603, -0.1276,\n",
      "           0.0000]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-03 *\n",
      "       [[-0.5968,  0.0417, -0.4461,  1.3529, -0.8698, -0.1272,  1.1241,\n",
      "         -0.8424,  0.3747]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 448, 512])\n",
      "tensor([[-2.9138e-05,  4.3937e-05, -6.9219e-05,  ..., -6.5857e-06,\n",
      "         -1.5045e-06,  6.4744e-07],\n",
      "        [ 4.9957e-05,  8.9927e-06, -2.9948e-05,  ...,  4.7773e-07,\n",
      "         -7.2953e-06, -7.4230e-07],\n",
      "        [ 1.0856e-04, -1.5545e-05,  1.8126e-04,  ...,  7.9232e-05,\n",
      "          3.4367e-05,  3.3210e-05],\n",
      "        ...,\n",
      "        [-1.0245e-04, -2.2202e-05,  6.5931e-05,  ..., -1.6907e-05,\n",
      "         -7.8340e-06,  1.1133e-05],\n",
      "        [-3.3401e-05, -8.6490e-05, -9.6401e-05,  ...,  1.0950e-05,\n",
      "         -5.7090e-06, -7.5966e-06],\n",
      "        [-1.9318e-05, -7.8723e-05, -7.4640e-05,  ..., -8.4741e-06,\n",
      "         -1.1962e-05, -1.5198e-07]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 448, 512])\n",
      "tensor([[-2.9138e-06,  4.3937e-06, -6.9219e-06,  ..., -6.5857e-07,\n",
      "         -1.5045e-07,  6.4744e-08],\n",
      "        [ 4.9957e-06,  8.9927e-07, -2.9948e-06,  ...,  4.7773e-08,\n",
      "         -7.2953e-07, -7.4230e-08],\n",
      "        [ 1.0856e-05, -1.5545e-06,  1.8126e-05,  ...,  7.9232e-06,\n",
      "          3.4367e-06,  3.3210e-06],\n",
      "        ...,\n",
      "        [ 9.2959e-06, -9.1683e-06, -1.6132e-05,  ..., -2.8513e-06,\n",
      "         -4.0909e-06, -4.6852e-06],\n",
      "        [ 2.0040e-05, -6.6791e-06, -1.4824e-05,  ...,  1.2930e-06,\n",
      "          2.4418e-07, -4.0908e-07],\n",
      "        [-2.8102e-07, -5.4699e-06,  7.3524e-06,  ..., -1.1395e-06,\n",
      "          1.7182e-07,  1.3749e-06]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 133 [17920/50000 (40%)]\tLoss: 0.170587, Accuracy: 93.55\n",
      "Train Epoch: 133 [20480/50000 (45%)]\tLoss: 0.196140, Accuracy: 92.19\n",
      "Train Epoch: 133 [23040/50000 (51%)]\tLoss: 0.215373, Accuracy: 91.99\n",
      "Train Epoch: 133 [25600/50000 (57%)]\tLoss: 0.200000, Accuracy: 94.14\n",
      "Train Epoch: 133 [28160/50000 (62%)]\tLoss: 0.286449, Accuracy: 90.43\n",
      "Train Epoch: 133 [30720/50000 (68%)]\tLoss: 0.195065, Accuracy: 93.16\n",
      "Train Epoch: 133 [33280/50000 (74%)]\tLoss: 0.156871, Accuracy: 95.31\n",
      "Train Epoch: 133 [35840/50000 (80%)]\tLoss: 0.166145, Accuracy: 93.75\n",
      "Train Epoch: 133 [38400/50000 (85%)]\tLoss: 0.232522, Accuracy: 92.19\n",
      "Train Epoch: 133 [40960/50000 (91%)]\tLoss: 0.203353, Accuracy: 94.14\n",
      "Train Epoch: 133 [43520/50000 (97%)]\tLoss: 0.233385, Accuracy: 92.58\n",
      "\n",
      "Validation set: Average loss: 0.6311, Accuracy: 4094/5000 (81.00%)\n",
      "\n",
      "the time of this epoch:[38.48120188713074 s]\n",
      "Train Epoch: 134 [0/50000 (0%)]\tLoss: 0.201566, Accuracy: 91.99\n",
      "Train Epoch: 134 [2560/50000 (6%)]\tLoss: 0.162186, Accuracy: 94.92\n",
      "Train Epoch: 134 [5120/50000 (11%)]\tLoss: 0.177228, Accuracy: 93.16\n",
      "Train Epoch: 134 [7680/50000 (17%)]\tLoss: 0.225340, Accuracy: 91.41\n",
      "Train Epoch: 134 [10240/50000 (23%)]\tLoss: 0.176305, Accuracy: 93.75\n",
      "Train Epoch: 134 [12800/50000 (28%)]\tLoss: 0.184092, Accuracy: 93.75\n",
      "Train Epoch: 134 [15360/50000 (34%)]\tLoss: 0.191536, Accuracy: 92.97\n",
      "Train Epoch: 134 [17920/50000 (40%)]\tLoss: 0.259587, Accuracy: 89.26\n",
      "Train Epoch: 134 [20480/50000 (45%)]\tLoss: 0.227010, Accuracy: 92.58\n",
      "Train Epoch: 134 [23040/50000 (51%)]\tLoss: 0.227120, Accuracy: 92.38\n",
      "Train Epoch: 134 [25600/50000 (57%)]\tLoss: 0.238989, Accuracy: 91.41\n",
      "Train Epoch: 134 [28160/50000 (62%)]\tLoss: 0.196410, Accuracy: 92.97\n",
      "Train Epoch: 134 [30720/50000 (68%)]\tLoss: 0.170692, Accuracy: 92.97\n",
      "Train Epoch: 134 [33280/50000 (74%)]\tLoss: 0.267421, Accuracy: 91.21\n",
      "Train Epoch: 134 [35840/50000 (80%)]\tLoss: 0.219573, Accuracy: 92.19\n",
      "Train Epoch: 134 [38400/50000 (85%)]\tLoss: 0.214395, Accuracy: 93.55\n",
      "Train Epoch: 134 [40960/50000 (91%)]\tLoss: 0.222129, Accuracy: 92.77\n",
      "Train Epoch: 134 [43520/50000 (97%)]\tLoss: 0.171136, Accuracy: 94.92\n",
      "\n",
      "Validation set: Average loss: 0.6447, Accuracy: 4019/5000 (80.00%)\n",
      "\n",
      "the time of this epoch:[35.4644136428833 s]\n",
      "\n",
      "Test set: Average loss: 0.7634, Accuracy: 7801/10000 (78.01%)\n",
      "\n",
      "Train Epoch: 135 [0/50000 (0%)]\tLoss: 0.178567, Accuracy: 94.14\n",
      "Train Epoch: 135 [2560/50000 (6%)]\tLoss: 0.169604, Accuracy: 95.12\n",
      "Train Epoch: 135 [5120/50000 (11%)]\tLoss: 0.196005, Accuracy: 93.75\n",
      "Train Epoch: 135 [7680/50000 (17%)]\tLoss: 0.198962, Accuracy: 92.38\n",
      "Train Epoch: 135 [10240/50000 (23%)]\tLoss: 0.156607, Accuracy: 94.92\n",
      "Train Epoch: 135 [12800/50000 (28%)]\tLoss: 0.187229, Accuracy: 93.75\n",
      "Train Epoch: 135 [15360/50000 (34%)]\tLoss: 0.163256, Accuracy: 94.14\n",
      "Train Epoch: 135 [17920/50000 (40%)]\tLoss: 0.215241, Accuracy: 92.38\n",
      "Train Epoch: 135 [20480/50000 (45%)]\tLoss: 0.171396, Accuracy: 93.16\n",
      "Train Epoch: 135 [23040/50000 (51%)]\tLoss: 0.225011, Accuracy: 92.58\n",
      "Train Epoch: 135 [25600/50000 (57%)]\tLoss: 0.271491, Accuracy: 90.62\n",
      "Train Epoch: 135 [28160/50000 (62%)]\tLoss: 0.227161, Accuracy: 92.38\n",
      "Train Epoch: 135 [30720/50000 (68%)]\tLoss: 0.165786, Accuracy: 93.75\n",
      "Train Epoch: 135 [33280/50000 (74%)]\tLoss: 0.244394, Accuracy: 91.02\n",
      "Train Epoch: 135 [35840/50000 (80%)]\tLoss: 0.181978, Accuracy: 93.36\n",
      "Train Epoch: 135 [38400/50000 (85%)]\tLoss: 0.234048, Accuracy: 91.80\n",
      "Train Epoch: 135 [40960/50000 (91%)]\tLoss: 0.223726, Accuracy: 93.36\n",
      "Train Epoch: 135 [43520/50000 (97%)]\tLoss: 0.286422, Accuracy: 90.23\n",
      "\n",
      "Validation set: Average loss: 0.7885, Accuracy: 3838/5000 (76.00%)\n",
      "\n",
      "the time of this epoch:[39.22245240211487 s]\n",
      "Train Epoch: 136 [0/50000 (0%)]\tLoss: 0.220629, Accuracy: 92.38\n",
      "Train Epoch: 136 [2560/50000 (6%)]\tLoss: 0.239662, Accuracy: 92.19\n",
      "Train Epoch: 136 [5120/50000 (11%)]\tLoss: 0.195158, Accuracy: 93.55\n",
      "Train Epoch: 136 [7680/50000 (17%)]\tLoss: 0.217601, Accuracy: 92.77\n",
      "Train Epoch: 136 [10240/50000 (23%)]\tLoss: 0.202029, Accuracy: 93.36\n",
      "Train Epoch: 136 [12800/50000 (28%)]\tLoss: 0.214433, Accuracy: 92.97\n",
      "Train Epoch: 136 [15360/50000 (34%)]\tLoss: 0.198926, Accuracy: 92.38\n",
      "Train Epoch: 136 [17920/50000 (40%)]\tLoss: 0.232809, Accuracy: 93.36\n",
      "Train Epoch: 136 [20480/50000 (45%)]\tLoss: 0.191139, Accuracy: 93.95\n",
      "Train Epoch: 136 [23040/50000 (51%)]\tLoss: 0.186558, Accuracy: 93.16\n",
      "Train Epoch: 136 [25600/50000 (57%)]\tLoss: 0.223525, Accuracy: 92.38\n",
      "Train Epoch: 136 [28160/50000 (62%)]\tLoss: 0.219850, Accuracy: 91.60\n",
      "Train Epoch: 136 [30720/50000 (68%)]\tLoss: 0.308009, Accuracy: 89.06\n",
      "Train Epoch: 136 [33280/50000 (74%)]\tLoss: 0.176666, Accuracy: 93.75\n",
      "Train Epoch: 136 [35840/50000 (80%)]\tLoss: 0.211546, Accuracy: 93.16\n",
      "Train Epoch: 136 [38400/50000 (85%)]\tLoss: 0.232293, Accuracy: 91.99\n",
      "Train Epoch: 136 [40960/50000 (91%)]\tLoss: 0.247601, Accuracy: 90.43\n",
      "Train Epoch: 136 [43520/50000 (97%)]\tLoss: 0.225906, Accuracy: 92.19\n",
      "\n",
      "Validation set: Average loss: 0.7554, Accuracy: 3869/5000 (77.00%)\n",
      "\n",
      "the time of this epoch:[35.70871448516846 s]\n",
      "\n",
      "Test set: Average loss: 0.7494, Accuracy: 7730/10000 (77.30%)\n",
      "\n",
      "Train Epoch: 137 [0/50000 (0%)]\tLoss: 0.196854, Accuracy: 94.14\n",
      "Train Epoch: 137 [2560/50000 (6%)]\tLoss: 0.194424, Accuracy: 92.77\n",
      "Train Epoch: 137 [5120/50000 (11%)]\tLoss: 0.199249, Accuracy: 92.97\n",
      "Train Epoch: 137 [7680/50000 (17%)]\tLoss: 0.195255, Accuracy: 92.97\n",
      "Train Epoch: 137 [10240/50000 (23%)]\tLoss: 0.159677, Accuracy: 94.34\n",
      "Train Epoch: 137 [12800/50000 (28%)]\tLoss: 0.220640, Accuracy: 91.60\n",
      "Train Epoch: 137 [15360/50000 (34%)]\tLoss: 0.284003, Accuracy: 90.04\n",
      "Train Epoch: 137 [17920/50000 (40%)]\tLoss: 0.247816, Accuracy: 91.99\n",
      "Train Epoch: 137 [20480/50000 (45%)]\tLoss: 0.203769, Accuracy: 92.58\n",
      "Train Epoch: 137 [23040/50000 (51%)]\tLoss: 0.208462, Accuracy: 93.16\n",
      "Train Epoch: 137 [25600/50000 (57%)]\tLoss: 0.198673, Accuracy: 93.16\n",
      "Train Epoch: 137 [28160/50000 (62%)]\tLoss: 0.200982, Accuracy: 93.75\n",
      "Train Epoch: 137 [30720/50000 (68%)]\tLoss: 0.200969, Accuracy: 92.58\n",
      "Train Epoch: 137 [33280/50000 (74%)]\tLoss: 0.259058, Accuracy: 90.82\n",
      "Train Epoch: 137 [35840/50000 (80%)]\tLoss: 0.241058, Accuracy: 91.21\n",
      "Train Epoch: 137 [38400/50000 (85%)]\tLoss: 0.235417, Accuracy: 91.21\n",
      "Train Epoch: 137 [40960/50000 (91%)]\tLoss: 0.283516, Accuracy: 89.26\n",
      "Train Epoch: 137 [43520/50000 (97%)]\tLoss: 0.207319, Accuracy: 92.58\n",
      "\n",
      "Validation set: Average loss: 0.6635, Accuracy: 4014/5000 (80.00%)\n",
      "\n",
      "the time of this epoch:[38.39884400367737 s]\n",
      "Train Epoch: 138 [0/50000 (0%)]\tLoss: 0.187606, Accuracy: 92.77\n",
      "Train Epoch: 138 [2560/50000 (6%)]\tLoss: 0.206235, Accuracy: 92.19\n",
      "Train Epoch: 138 [5120/50000 (11%)]\tLoss: 0.155881, Accuracy: 94.14\n",
      "Train Epoch: 138 [7680/50000 (17%)]\tLoss: 0.205898, Accuracy: 92.19\n",
      "Train Epoch: 138 [10240/50000 (23%)]\tLoss: 0.202546, Accuracy: 91.60\n",
      "Train Epoch: 138 [12800/50000 (28%)]\tLoss: 0.221524, Accuracy: 91.60\n",
      "Train Epoch: 138 [15360/50000 (34%)]\tLoss: 0.187841, Accuracy: 92.97\n",
      "Train Epoch: 138 [17920/50000 (40%)]\tLoss: 0.218911, Accuracy: 92.38\n",
      "Train Epoch: 138 [20480/50000 (45%)]\tLoss: 0.249813, Accuracy: 91.60\n",
      "Train Epoch: 138 [23040/50000 (51%)]\tLoss: 0.240081, Accuracy: 91.41\n",
      "Train Epoch: 138 [25600/50000 (57%)]\tLoss: 0.183119, Accuracy: 94.34\n",
      "Train Epoch: 138 [28160/50000 (62%)]\tLoss: 0.201449, Accuracy: 92.38\n",
      "Train Epoch: 138 [30720/50000 (68%)]\tLoss: 0.245928, Accuracy: 91.02\n",
      "Train Epoch: 138 [33280/50000 (74%)]\tLoss: 0.214519, Accuracy: 91.21\n",
      "Train Epoch: 138 [35840/50000 (80%)]\tLoss: 0.212163, Accuracy: 93.16\n",
      "Train Epoch: 138 [38400/50000 (85%)]\tLoss: 0.231720, Accuracy: 91.80\n",
      "Train Epoch: 138 [40960/50000 (91%)]\tLoss: 0.205455, Accuracy: 94.14\n",
      "Train Epoch: 138 [43520/50000 (97%)]\tLoss: 0.190507, Accuracy: 92.58\n",
      "\n",
      "Validation set: Average loss: 0.6130, Accuracy: 4065/5000 (81.00%)\n",
      "\n",
      "the time of this epoch:[35.28340935707092 s]\n",
      "\n",
      "Test set: Average loss: 0.6197, Accuracy: 8194/10000 (81.94%)\n",
      "\n",
      "Train Epoch: 139 [0/50000 (0%)]\tLoss: 0.212450, Accuracy: 92.38\n",
      "Train Epoch: 139 [2560/50000 (6%)]\tLoss: 0.177992, Accuracy: 92.97\n",
      "Train Epoch: 139 [5120/50000 (11%)]\tLoss: 0.185008, Accuracy: 92.38\n",
      "Train Epoch: 139 [7680/50000 (17%)]\tLoss: 0.175590, Accuracy: 94.14\n",
      "Train Epoch: 139 [10240/50000 (23%)]\tLoss: 0.187926, Accuracy: 93.36\n",
      "Train Epoch: 139 [12800/50000 (28%)]\tLoss: 0.258649, Accuracy: 91.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 139 [15360/50000 (34%)]\tLoss: 0.182507, Accuracy: 94.14\n",
      "Train Epoch: 139 [17920/50000 (40%)]\tLoss: 0.188391, Accuracy: 94.53\n",
      "Train Epoch: 139 [20480/50000 (45%)]\tLoss: 0.269184, Accuracy: 90.62\n",
      "Train Epoch: 139 [23040/50000 (51%)]\tLoss: 0.261026, Accuracy: 90.82\n",
      "Train Epoch: 139 [25600/50000 (57%)]\tLoss: 0.221002, Accuracy: 90.82\n",
      "Train Epoch: 139 [28160/50000 (62%)]\tLoss: 0.217815, Accuracy: 91.80\n",
      "Train Epoch: 139 [30720/50000 (68%)]\tLoss: 0.192677, Accuracy: 93.16\n",
      "Train Epoch: 139 [33280/50000 (74%)]\tLoss: 0.216620, Accuracy: 92.19\n",
      "Train Epoch: 139 [35840/50000 (80%)]\tLoss: 0.190240, Accuracy: 92.97\n",
      "Train Epoch: 139 [38400/50000 (85%)]\tLoss: 0.188410, Accuracy: 93.55\n",
      "Train Epoch: 139 [40960/50000 (91%)]\tLoss: 0.263744, Accuracy: 91.80\n",
      "Train Epoch: 139 [43520/50000 (97%)]\tLoss: 0.204308, Accuracy: 92.38\n",
      "\n",
      "Validation set: Average loss: 0.8149, Accuracy: 3821/5000 (76.00%)\n",
      "\n",
      "the time of this epoch:[38.3765230178833 s]\n",
      "Train Epoch: 140 [0/50000 (0%)]\tLoss: 0.201581, Accuracy: 94.14\n",
      "Train Epoch: 140 [2560/50000 (6%)]\tLoss: 0.152757, Accuracy: 95.70\n",
      "Train Epoch: 140 [5120/50000 (11%)]\tLoss: 0.170291, Accuracy: 94.34\n",
      "Train Epoch: 140 [7680/50000 (17%)]\tLoss: 0.192920, Accuracy: 93.16\n",
      "Train Epoch: 140 [10240/50000 (23%)]\tLoss: 0.244294, Accuracy: 91.60\n",
      "Train Epoch: 140 [12800/50000 (28%)]\tLoss: 0.148890, Accuracy: 95.12\n",
      "Train Epoch: 140 [15360/50000 (34%)]\tLoss: 0.229033, Accuracy: 92.77\n",
      "Train Epoch: 140 [17920/50000 (40%)]\tLoss: 0.236728, Accuracy: 90.82\n",
      "Train Epoch: 140 [20480/50000 (45%)]\tLoss: 0.270601, Accuracy: 90.23\n",
      "Train Epoch: 140 [23040/50000 (51%)]\tLoss: 0.215594, Accuracy: 92.58\n",
      "Train Epoch: 140 [25600/50000 (57%)]\tLoss: 0.251642, Accuracy: 91.41\n",
      "Train Epoch: 140 [28160/50000 (62%)]\tLoss: 0.239998, Accuracy: 92.38\n",
      "Train Epoch: 140 [30720/50000 (68%)]\tLoss: 0.201530, Accuracy: 92.77\n",
      "Train Epoch: 140 [33280/50000 (74%)]\tLoss: 0.212466, Accuracy: 92.58\n",
      "Train Epoch: 140 [35840/50000 (80%)]\tLoss: 0.215620, Accuracy: 93.16\n",
      "Train Epoch: 140 [38400/50000 (85%)]\tLoss: 0.221518, Accuracy: 91.21\n",
      "Train Epoch: 140 [40960/50000 (91%)]\tLoss: 0.215423, Accuracy: 90.04\n",
      "Train Epoch: 140 [43520/50000 (97%)]\tLoss: 0.220667, Accuracy: 92.19\n",
      "\n",
      "Validation set: Average loss: 0.7227, Accuracy: 3919/5000 (78.00%)\n",
      "\n",
      "the time of this epoch:[35.15682101249695 s]\n",
      "------------------------------\n",
      "before autoscale: torch.Size([1024, 1, 1])\n",
      "tensor([[[ 0.0731]],\n",
      "\n",
      "        [[ 0.0704]],\n",
      "\n",
      "        [[ 0.1191]],\n",
      "\n",
      "        [[ 0.0206]],\n",
      "\n",
      "        [[ 0.0148]],\n",
      "\n",
      "        [[ 0.0279]],\n",
      "\n",
      "        [[ 0.0099]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0492]],\n",
      "\n",
      "        [[ 0.0134]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[ 0.8743]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 1024])\n",
      "tensor([[[ 0.0639,  0.0615,  0.1041,  ...,  0.0012,  0.0002,  0.0004]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-03 *\n",
      "       [[ 5.5991,  1.2015,  3.2887, -0.8585,  0.2955, -0.5559,  1.0247,\n",
      "          2.3038,  3.9485]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 896, 1024])\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.0184,  0.0050,  0.0282,  ...,  0.0003,  0.0010,  0.0005],\n",
      "        [-0.1945, -0.1734, -0.1937,  ..., -0.0004, -0.0024, -0.0020],\n",
      "        [-0.0128,  0.0397,  0.0244,  ...,  0.0001,  0.0006, -0.0001],\n",
      "        ...,\n",
      "        [ 0.0085,  0.0088,  0.0044,  ...,  0.0005,  0.0008,  0.0001],\n",
      "        [ 0.0779,  0.0715,  0.0883,  ...,  0.0021,  0.0049,  0.0011],\n",
      "        [-0.0054,  0.0008, -0.0015,  ..., -0.0000, -0.0000,  0.0000]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 896, 1024])\n",
      "tensor(1.00000e-03 *\n",
      "       [[ 0.0184,  0.0050,  0.0282,  ...,  0.0003,  0.0010,  0.0005],\n",
      "        [-0.1945, -0.1734, -0.1937,  ..., -0.0004, -0.0024, -0.0020],\n",
      "        [-0.0128,  0.0397,  0.0244,  ...,  0.0001,  0.0006, -0.0001],\n",
      "        ...,\n",
      "        [-0.0509, -0.0979, -0.0570,  ..., -0.0011, -0.0014, -0.0003],\n",
      "        [-0.0052, -0.0012, -0.0079,  ...,  0.0000, -0.0002, -0.0001],\n",
      "        [ 0.0321,  0.0764,  0.0447,  ...,  0.0000,  0.0005,  0.0001]], device='cuda:0')\n",
      "\n",
      "Test set: Average loss: 0.8095, Accuracy: 7586/10000 (75.86%)\n",
      "\n",
      "Train Epoch: 141 [0/50000 (0%)]\tLoss: 0.145633, Accuracy: 95.12\n",
      "Train Epoch: 141 [2560/50000 (6%)]\tLoss: 0.208337, Accuracy: 93.36\n",
      "Train Epoch: 141 [5120/50000 (11%)]\tLoss: 0.135960, Accuracy: 96.09\n",
      "Train Epoch: 141 [7680/50000 (17%)]\tLoss: 0.213640, Accuracy: 92.38\n",
      "Train Epoch: 141 [10240/50000 (23%)]\tLoss: 0.197483, Accuracy: 94.14\n",
      "Train Epoch: 141 [12800/50000 (28%)]\tLoss: 0.175455, Accuracy: 92.97\n",
      "Train Epoch: 141 [15360/50000 (34%)]\tLoss: 0.169503, Accuracy: 93.95\n",
      "Train Epoch: 141 [17920/50000 (40%)]\tLoss: 0.207873, Accuracy: 92.77\n",
      "Train Epoch: 141 [20480/50000 (45%)]\tLoss: 0.227403, Accuracy: 92.19\n",
      "Train Epoch: 141 [23040/50000 (51%)]\tLoss: 0.168736, Accuracy: 94.34\n",
      "Train Epoch: 141 [25600/50000 (57%)]\tLoss: 0.256552, Accuracy: 90.04\n",
      "Train Epoch: 141 [28160/50000 (62%)]\tLoss: 0.175571, Accuracy: 94.73\n",
      "Train Epoch: 141 [30720/50000 (68%)]\tLoss: 0.183101, Accuracy: 93.75\n",
      "Train Epoch: 141 [33280/50000 (74%)]\tLoss: 0.202431, Accuracy: 93.16\n",
      "Train Epoch: 141 [35840/50000 (80%)]\tLoss: 0.212441, Accuracy: 91.60\n",
      "Train Epoch: 141 [38400/50000 (85%)]\tLoss: 0.194963, Accuracy: 93.16\n",
      "Train Epoch: 141 [40960/50000 (91%)]\tLoss: 0.289704, Accuracy: 89.26\n",
      "Train Epoch: 141 [43520/50000 (97%)]\tLoss: 0.163446, Accuracy: 95.51\n",
      "\n",
      "Validation set: Average loss: 0.8259, Accuracy: 3818/5000 (76.00%)\n",
      "\n",
      "the time of this epoch:[38.41941022872925 s]\n",
      "Train Epoch: 142 [0/50000 (0%)]\tLoss: 0.242272, Accuracy: 92.19\n",
      "Train Epoch: 142 [2560/50000 (6%)]\tLoss: 0.182598, Accuracy: 93.75\n",
      "Train Epoch: 142 [5120/50000 (11%)]\tLoss: 0.219797, Accuracy: 92.97\n",
      "Train Epoch: 142 [7680/50000 (17%)]\tLoss: 0.164490, Accuracy: 94.92\n",
      "Train Epoch: 142 [10240/50000 (23%)]\tLoss: 0.198051, Accuracy: 93.75\n",
      "Train Epoch: 142 [12800/50000 (28%)]\tLoss: 0.161567, Accuracy: 94.53\n",
      "Train Epoch: 142 [15360/50000 (34%)]\tLoss: 0.161967, Accuracy: 94.92\n",
      "Train Epoch: 142 [17920/50000 (40%)]\tLoss: 0.200287, Accuracy: 92.38\n",
      "Train Epoch: 142 [20480/50000 (45%)]\tLoss: 0.210123, Accuracy: 93.95\n",
      "Train Epoch: 142 [23040/50000 (51%)]\tLoss: 0.181204, Accuracy: 92.77\n",
      "Train Epoch: 142 [25600/50000 (57%)]\tLoss: 0.227995, Accuracy: 92.58\n",
      "Train Epoch: 142 [28160/50000 (62%)]\tLoss: 0.233269, Accuracy: 91.80\n",
      "Train Epoch: 142 [30720/50000 (68%)]\tLoss: 0.199367, Accuracy: 92.97\n",
      "Train Epoch: 142 [33280/50000 (74%)]\tLoss: 0.189502, Accuracy: 93.95\n",
      "Train Epoch: 142 [35840/50000 (80%)]\tLoss: 0.212789, Accuracy: 91.80\n",
      "Train Epoch: 142 [38400/50000 (85%)]\tLoss: 0.204077, Accuracy: 93.36\n",
      "Train Epoch: 142 [40960/50000 (91%)]\tLoss: 0.218587, Accuracy: 93.16\n",
      "Train Epoch: 142 [43520/50000 (97%)]\tLoss: 0.259062, Accuracy: 91.02\n",
      "\n",
      "Validation set: Average loss: 0.7447, Accuracy: 3922/5000 (78.00%)\n",
      "\n",
      "the time of this epoch:[35.12209749221802 s]\n",
      "\n",
      "Test set: Average loss: 0.7857, Accuracy: 7778/10000 (77.78%)\n",
      "\n",
      "Train Epoch: 143 [0/50000 (0%)]\tLoss: 0.186915, Accuracy: 93.75\n",
      "Train Epoch: 143 [2560/50000 (6%)]\tLoss: 0.206364, Accuracy: 91.80\n",
      "Train Epoch: 143 [5120/50000 (11%)]\tLoss: 0.133123, Accuracy: 95.90\n",
      "Train Epoch: 143 [7680/50000 (17%)]\tLoss: 0.204404, Accuracy: 92.97\n",
      "Train Epoch: 143 [10240/50000 (23%)]\tLoss: 0.168572, Accuracy: 94.53\n",
      "Train Epoch: 143 [12800/50000 (28%)]\tLoss: 0.167340, Accuracy: 95.31\n",
      "Train Epoch: 143 [15360/50000 (34%)]\tLoss: 0.184998, Accuracy: 94.14\n",
      "Train Epoch: 143 [17920/50000 (40%)]\tLoss: 0.153590, Accuracy: 93.95\n",
      "Train Epoch: 143 [20480/50000 (45%)]\tLoss: 0.170101, Accuracy: 94.14\n",
      "Train Epoch: 143 [23040/50000 (51%)]\tLoss: 0.192255, Accuracy: 94.14\n",
      "Train Epoch: 143 [25600/50000 (57%)]\tLoss: 0.233015, Accuracy: 91.60\n",
      "Train Epoch: 143 [28160/50000 (62%)]\tLoss: 0.225461, Accuracy: 91.80\n",
      "Train Epoch: 143 [30720/50000 (68%)]\tLoss: 0.236617, Accuracy: 91.99\n",
      "Train Epoch: 143 [33280/50000 (74%)]\tLoss: 0.212394, Accuracy: 93.36\n",
      "Train Epoch: 143 [35840/50000 (80%)]\tLoss: 0.210109, Accuracy: 93.16\n",
      "Train Epoch: 143 [38400/50000 (85%)]\tLoss: 0.221057, Accuracy: 92.77\n",
      "Train Epoch: 143 [40960/50000 (91%)]\tLoss: 0.237946, Accuracy: 91.60\n",
      "Train Epoch: 143 [43520/50000 (97%)]\tLoss: 0.201087, Accuracy: 93.55\n",
      "\n",
      "Validation set: Average loss: 0.5487, Accuracy: 4220/5000 (84.00%)\n",
      "\n",
      "the time of this epoch:[38.50163745880127 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 144 [0/50000 (0%)]\tLoss: 0.187874, Accuracy: 94.34\n",
      "Train Epoch: 144 [2560/50000 (6%)]\tLoss: 0.230385, Accuracy: 92.38\n",
      "Train Epoch: 144 [5120/50000 (11%)]\tLoss: 0.194239, Accuracy: 93.36\n",
      "Train Epoch: 144 [7680/50000 (17%)]\tLoss: 0.186531, Accuracy: 93.95\n",
      "Train Epoch: 144 [10240/50000 (23%)]\tLoss: 0.221538, Accuracy: 91.99\n",
      "Train Epoch: 144 [12800/50000 (28%)]\tLoss: 0.203281, Accuracy: 92.77\n",
      "Train Epoch: 144 [15360/50000 (34%)]\tLoss: 0.192174, Accuracy: 94.14\n",
      "Train Epoch: 144 [17920/50000 (40%)]\tLoss: 0.194429, Accuracy: 92.58\n",
      "Train Epoch: 144 [20480/50000 (45%)]\tLoss: 0.185794, Accuracy: 93.75\n",
      "Train Epoch: 144 [23040/50000 (51%)]\tLoss: 0.178092, Accuracy: 94.34\n",
      "Train Epoch: 144 [25600/50000 (57%)]\tLoss: 0.206204, Accuracy: 91.99\n",
      "Train Epoch: 144 [28160/50000 (62%)]\tLoss: 0.238176, Accuracy: 91.02\n",
      "Train Epoch: 144 [30720/50000 (68%)]\tLoss: 0.237012, Accuracy: 91.21\n",
      "Train Epoch: 144 [33280/50000 (74%)]\tLoss: 0.191844, Accuracy: 92.58\n",
      "Train Epoch: 144 [35840/50000 (80%)]\tLoss: 0.242936, Accuracy: 91.02\n",
      "Train Epoch: 144 [38400/50000 (85%)]\tLoss: 0.240422, Accuracy: 92.77\n",
      "Train Epoch: 144 [40960/50000 (91%)]\tLoss: 0.230720, Accuracy: 91.80\n",
      "Train Epoch: 144 [43520/50000 (97%)]\tLoss: 0.289055, Accuracy: 90.04\n",
      "\n",
      "Validation set: Average loss: 0.6166, Accuracy: 4087/5000 (81.00%)\n",
      "\n",
      "the time of this epoch:[35.08667778968811 s]\n",
      "\n",
      "Test set: Average loss: 0.6452, Accuracy: 8127/10000 (81.27%)\n",
      "\n",
      "Train Epoch: 145 [0/50000 (0%)]\tLoss: 0.198555, Accuracy: 93.16\n",
      "Train Epoch: 145 [2560/50000 (6%)]\tLoss: 0.169420, Accuracy: 94.14\n",
      "Train Epoch: 145 [5120/50000 (11%)]\tLoss: 0.187812, Accuracy: 95.51\n",
      "Train Epoch: 145 [7680/50000 (17%)]\tLoss: 0.158919, Accuracy: 94.73\n",
      "Train Epoch: 145 [10240/50000 (23%)]\tLoss: 0.190293, Accuracy: 93.95\n",
      "Train Epoch: 145 [12800/50000 (28%)]\tLoss: 0.162318, Accuracy: 93.95\n",
      "Train Epoch: 145 [15360/50000 (34%)]\tLoss: 0.212888, Accuracy: 92.58\n",
      "Train Epoch: 145 [17920/50000 (40%)]\tLoss: 0.190265, Accuracy: 93.55\n",
      "Train Epoch: 145 [20480/50000 (45%)]\tLoss: 0.224916, Accuracy: 91.80\n",
      "Train Epoch: 145 [23040/50000 (51%)]\tLoss: 0.213003, Accuracy: 91.21\n",
      "Train Epoch: 145 [25600/50000 (57%)]\tLoss: 0.179809, Accuracy: 94.14\n",
      "Train Epoch: 145 [28160/50000 (62%)]\tLoss: 0.177224, Accuracy: 93.55\n",
      "Train Epoch: 145 [30720/50000 (68%)]\tLoss: 0.235497, Accuracy: 91.60\n",
      "Train Epoch: 145 [33280/50000 (74%)]\tLoss: 0.231008, Accuracy: 91.60\n",
      "Train Epoch: 145 [35840/50000 (80%)]\tLoss: 0.299354, Accuracy: 90.62\n",
      "Train Epoch: 145 [38400/50000 (85%)]\tLoss: 0.166114, Accuracy: 93.36\n",
      "Train Epoch: 145 [40960/50000 (91%)]\tLoss: 0.275628, Accuracy: 91.41\n",
      "Train Epoch: 145 [43520/50000 (97%)]\tLoss: 0.250161, Accuracy: 92.19\n",
      "------------------------------\n",
      "before autoscale: torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.0000]],\n",
      "\n",
      "        [[ 0.0914]],\n",
      "\n",
      "        [[ 0.0371]],\n",
      "\n",
      "        [[ 0.0400]],\n",
      "\n",
      "        [[ 0.3227]],\n",
      "\n",
      "        [[ 0.3627]],\n",
      "\n",
      "        [[ 0.3720]],\n",
      "\n",
      "        [[ 0.1347]],\n",
      "\n",
      "        [[ 0.0646]],\n",
      "\n",
      "        [[ 0.2960]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[-0.2723]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 512])\n",
      "tensor([[[ 0.0000, -0.0249, -0.0101, -0.0109, -0.0879, -0.0988, -0.1013,\n",
      "          -0.0367, -0.0176, -0.0806, -0.0397, -0.0135, -0.0780, -0.0461,\n",
      "          -0.0619, -0.0434, -0.0101, -0.0122, -0.0449, -0.1085, -0.0974,\n",
      "          -0.0300, -0.0948, -0.0185, -0.0546, -0.0261, -0.0445, -0.0539,\n",
      "           0.0000, -0.0270, -0.0318, -0.0472, -0.0020, -0.0302, -0.0214,\n",
      "          -0.0908, -0.0759,  0.0000, -0.0010, -0.2002, -0.0959,  0.0000,\n",
      "          -0.0862, -0.0634, -0.0295, -0.0082, -0.0112, -0.0746, -0.0049,\n",
      "          -0.0536,  0.0000, -0.0618, -0.0008, -0.1040, -0.0329, -0.0555,\n",
      "           0.0000,  0.0000, -0.0049,  0.0000, -0.0495, -0.0322, -0.0652,\n",
      "           0.0000, -0.0248, -0.0180, -0.0092, -0.0010, -0.0026, -0.0184,\n",
      "          -0.0040,  0.0000,  0.0000,  0.0000, -0.0028,  0.0000, -0.0001,\n",
      "          -0.0010, -0.0008, -0.0013, -0.0015, -0.0077, -0.0013,  0.0000,\n",
      "          -0.0019, -0.0020, -0.0001,  0.0000, -0.0001,  0.0000,  0.0000,\n",
      "          -0.0001,  0.0000,  0.0000,  0.0000,  0.0000, -0.0084,  0.0000,\n",
      "          -0.0002, -0.0002, -0.0004, -0.0003,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0094,  0.0000,  0.0000,  0.0000,  0.0000, -0.0002,\n",
      "          -0.0005,  0.0000,  0.0000,  0.0000, -0.0009,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
      "          -0.0002, -0.0001, -0.0000,  0.0000, -0.0000, -0.0001,  0.0000,\n",
      "           0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0001,\n",
      "           0.0000, -0.0010,  0.0000,  0.0000, -0.0009, -0.0058,  0.0000,\n",
      "          -0.0006,  0.0000,  0.0000, -0.0009,  0.0000, -0.0233, -0.0149,\n",
      "          -0.0013, -0.0019,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000, -0.0005,  0.0000,  0.0000, -0.0022, -0.0019,\n",
      "          -0.0004, -0.0004, -0.0006,  0.0000, -0.0011, -0.0011, -0.0013,\n",
      "          -0.0016, -0.0096, -0.0014,  0.0000, -0.0037, -0.0038, -0.0021,\n",
      "           0.0000, -0.0119,  0.0000,  0.0000, -0.0025, -0.0034, -0.0002,\n",
      "          -0.0001, -0.0000, -0.0000, -0.0000, -0.0000, -0.0001, -0.0001,\n",
      "           0.0000,  0.0000,  0.0000, -0.0004, -0.0159,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000, -0.0011, -0.0048, -0.0010,  0.0000, -0.0013,\n",
      "           0.0000,  0.0000, -0.0000, -0.0001,  0.0000, -0.0000,  0.0000,\n",
      "          -0.0000, -0.0001, -0.0001, -0.0001, -0.0001,  0.0000, -0.0000,\n",
      "          -0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
      "          -0.0000,  0.0000,  0.0000, -0.0015, -0.0020, -0.0192,  0.0000,\n",
      "           0.0000,  0.0000, -0.0024, -0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0000, -0.0000, -0.0001, -0.0001,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0000, -0.0004,  0.0000, -0.0003, -0.0002, -0.0004,  0.0000,\n",
      "          -0.0013, -0.0020, -0.0045, -0.0250,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0023, -0.0000, -0.0000, -0.0000,  0.0000, -0.0002,  0.0000,\n",
      "          -0.0024, -0.0040, -0.0037, -0.0242, -0.0032, -0.0035, -0.0045,\n",
      "          -0.0046, -0.0010, -0.0008,  0.0000, -0.0023, -0.0073, -0.0031,\n",
      "          -0.0123, -0.0033, -0.0036,  0.0000, -0.0036, -0.0007, -0.0010,\n",
      "           0.0000, -0.0056, -0.0010, -0.0011, -0.0016,  0.0000, -0.0001,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0185, -0.0052,  0.0000,  0.0000, -0.0053, -0.0014,  0.0000,\n",
      "          -0.0000, -0.0009,  0.0000, -0.0010,  0.0000,  0.0000, -0.0006,\n",
      "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0001,\n",
      "           0.0000, -0.0010, -0.0019, -0.0017, -0.0179, -0.0020, -0.0035,\n",
      "           0.0000, -0.0039, -0.0027, -0.0211,  0.0000,  0.0000, -0.0023,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0001,  0.0000,  0.0000,\n",
      "          -0.0014, -0.0019,  0.0000, -0.0203,  0.0000, -0.0020, -0.0026,\n",
      "          -0.0035,  0.0000, -0.0005, -0.0005, -0.0049, -0.0008, -0.0005,\n",
      "           0.0000, -0.0008, -0.0002, -0.0002, -0.0001, -0.0001, -0.0001,\n",
      "           0.0000, -0.0001,  0.0000, -0.0000, -0.0009,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0001, -0.0000,  0.0000,\n",
      "          -0.0000, -0.0002, -0.0001, -0.0001, -0.0007, -0.0006, -0.0006,\n",
      "          -0.0009,  0.0000, -0.0004,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0109,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0041,\n",
      "          -0.0122,  0.0000, -0.0015,  0.0000, -0.0027, -0.0000, -0.0000,\n",
      "           0.0000, -0.0002,  0.0000,  0.0000, -0.0107,  0.0000, -0.6387,\n",
      "          -0.0157,  0.0000, -0.0124,  0.0000, -0.0165,  0.0000, -0.0036,\n",
      "          -0.0022,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
      "           0.0000,  0.0000, -0.0002, -0.0001,  0.0000, -0.0002, -0.0001,\n",
      "          -0.0001, -0.0001,  0.0000,  0.0000,  0.0000, -0.0004, -0.0006,\n",
      "           0.0000, -0.0011, -0.0039, -0.0015, -0.0038,  0.0000,  0.0000,\n",
      "           0.0000, -0.0012,  0.0000, -0.0000, -0.0001,  0.0000, -0.0001,\n",
      "          -0.0001,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0195,\n",
      "           0.0000, -0.0020, -0.0028,  0.0000, -0.0008,  0.0000, -0.0008,\n",
      "          -0.0009, -0.0026,  0.0000, -0.0025,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0000, -0.0008,  0.0000,  0.0000,  0.0000, -0.0009,\n",
      "          -0.0010, -0.0058,  0.0000, -0.0010,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0000, -0.0003, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0011, -0.0005, -0.0052,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-04 *\n",
      "       [[ 1.6213,  2.7917,  0.7220,  1.7029,  3.4985, -1.7015,  5.5690,\n",
      "          4.7890, -1.5090]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 448, 512])\n",
      "tensor([[ 6.6568e-06, -4.0234e-05, -8.6875e-05,  ..., -6.9812e-07,\n",
      "         -1.5268e-06, -8.3986e-07],\n",
      "        [ 2.4610e-05,  8.0963e-06,  1.0111e-05,  ...,  2.1215e-06,\n",
      "          2.7877e-06,  2.6957e-06],\n",
      "        [ 2.0217e-05,  3.5322e-05,  6.2198e-05,  ...,  2.2973e-06,\n",
      "          2.0992e-06,  1.6612e-07],\n",
      "        ...,\n",
      "        [ 6.5173e-06, -6.0233e-06,  1.2295e-05,  ...,  1.9125e-06,\n",
      "          8.6270e-07,  2.9735e-06],\n",
      "        [ 4.3377e-06,  7.9774e-06,  5.4057e-05,  ..., -1.8154e-06,\n",
      "         -3.4491e-09, -2.4936e-06],\n",
      "        [-5.8048e-05, -3.2482e-05, -4.2735e-05,  ..., -7.5501e-07,\n",
      "         -1.8774e-06, -2.0000e-06]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 448, 512])\n",
      "tensor([[ 6.6568e-07, -4.0234e-06, -8.6875e-06,  ..., -6.9812e-08,\n",
      "         -1.5268e-07, -8.3986e-08],\n",
      "        [ 2.4610e-06,  8.0963e-07,  1.0111e-06,  ...,  2.1215e-07,\n",
      "          2.7877e-07,  2.6957e-07],\n",
      "        [ 2.0217e-06,  3.5322e-06,  6.2198e-06,  ...,  2.2973e-07,\n",
      "          2.0992e-07,  1.6612e-08],\n",
      "        ...,\n",
      "        [-1.5839e-05, -2.1884e-05, -3.6592e-05,  ..., -7.4332e-08,\n",
      "         -1.3314e-07, -1.4676e-07],\n",
      "        [-2.1258e-04, -3.1470e-04, -4.4175e-04,  ..., -7.1160e-06,\n",
      "         -3.8074e-06, -5.6536e-06],\n",
      "        [-8.4538e-06, -1.4791e-05, -2.1769e-05,  ..., -3.1975e-07,\n",
      "         -2.4014e-07, -1.3964e-07]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.6497, Accuracy: 4041/5000 (80.00%)\n",
      "\n",
      "the time of this epoch:[38.69142961502075 s]\n",
      "Train Epoch: 146 [0/50000 (0%)]\tLoss: 0.164448, Accuracy: 93.95\n",
      "Train Epoch: 146 [2560/50000 (6%)]\tLoss: 0.155941, Accuracy: 94.92\n",
      "Train Epoch: 146 [5120/50000 (11%)]\tLoss: 0.227947, Accuracy: 92.58\n",
      "Train Epoch: 146 [7680/50000 (17%)]\tLoss: 0.259557, Accuracy: 91.41\n",
      "Train Epoch: 146 [10240/50000 (23%)]\tLoss: 0.206495, Accuracy: 92.58\n",
      "Train Epoch: 146 [12800/50000 (28%)]\tLoss: 0.192634, Accuracy: 93.16\n",
      "Train Epoch: 146 [15360/50000 (34%)]\tLoss: 0.260633, Accuracy: 90.04\n",
      "Train Epoch: 146 [17920/50000 (40%)]\tLoss: 0.230168, Accuracy: 92.38\n",
      "Train Epoch: 146 [20480/50000 (45%)]\tLoss: 0.148254, Accuracy: 94.34\n",
      "Train Epoch: 146 [23040/50000 (51%)]\tLoss: 0.227852, Accuracy: 92.77\n",
      "Train Epoch: 146 [25600/50000 (57%)]\tLoss: 0.210945, Accuracy: 93.16\n",
      "Train Epoch: 146 [28160/50000 (62%)]\tLoss: 0.213467, Accuracy: 92.97\n",
      "Train Epoch: 146 [30720/50000 (68%)]\tLoss: 0.196103, Accuracy: 93.55\n",
      "Train Epoch: 146 [33280/50000 (74%)]\tLoss: 0.207951, Accuracy: 94.14\n",
      "Train Epoch: 146 [35840/50000 (80%)]\tLoss: 0.184375, Accuracy: 93.95\n",
      "Train Epoch: 146 [38400/50000 (85%)]\tLoss: 0.227230, Accuracy: 93.16\n",
      "Train Epoch: 146 [40960/50000 (91%)]\tLoss: 0.176629, Accuracy: 93.95\n",
      "Train Epoch: 146 [43520/50000 (97%)]\tLoss: 0.291234, Accuracy: 88.67\n",
      "\n",
      "Validation set: Average loss: 0.7023, Accuracy: 3961/5000 (79.00%)\n",
      "\n",
      "the time of this epoch:[35.45760989189148 s]\n",
      "\n",
      "Test set: Average loss: 0.8213, Accuracy: 7665/10000 (76.65%)\n",
      "\n",
      "Train Epoch: 147 [0/50000 (0%)]\tLoss: 0.171912, Accuracy: 93.55\n",
      "Train Epoch: 147 [2560/50000 (6%)]\tLoss: 0.188278, Accuracy: 92.97\n",
      "Train Epoch: 147 [5120/50000 (11%)]\tLoss: 0.172298, Accuracy: 94.34\n",
      "Train Epoch: 147 [7680/50000 (17%)]\tLoss: 0.216356, Accuracy: 93.55\n",
      "Train Epoch: 147 [10240/50000 (23%)]\tLoss: 0.191124, Accuracy: 94.14\n",
      "Train Epoch: 147 [12800/50000 (28%)]\tLoss: 0.180616, Accuracy: 93.55\n",
      "Train Epoch: 147 [15360/50000 (34%)]\tLoss: 0.263115, Accuracy: 91.80\n",
      "Train Epoch: 147 [17920/50000 (40%)]\tLoss: 0.251164, Accuracy: 90.23\n",
      "Train Epoch: 147 [20480/50000 (45%)]\tLoss: 0.230419, Accuracy: 91.99\n",
      "Train Epoch: 147 [23040/50000 (51%)]\tLoss: 0.188759, Accuracy: 94.14\n",
      "Train Epoch: 147 [25600/50000 (57%)]\tLoss: 0.263425, Accuracy: 90.62\n",
      "Train Epoch: 147 [28160/50000 (62%)]\tLoss: 0.215505, Accuracy: 91.41\n",
      "Train Epoch: 147 [30720/50000 (68%)]\tLoss: 0.222843, Accuracy: 91.21\n",
      "Train Epoch: 147 [33280/50000 (74%)]\tLoss: 0.216236, Accuracy: 93.16\n",
      "Train Epoch: 147 [35840/50000 (80%)]\tLoss: 0.215264, Accuracy: 91.99\n",
      "Train Epoch: 147 [38400/50000 (85%)]\tLoss: 0.224083, Accuracy: 93.16\n",
      "Train Epoch: 147 [40960/50000 (91%)]\tLoss: 0.201427, Accuracy: 94.34\n",
      "Train Epoch: 147 [43520/50000 (97%)]\tLoss: 0.214194, Accuracy: 92.19\n",
      "\n",
      "Validation set: Average loss: 0.8671, Accuracy: 3780/5000 (75.00%)\n",
      "\n",
      "the time of this epoch:[38.82077360153198 s]\n",
      "Train Epoch: 148 [0/50000 (0%)]\tLoss: 0.236681, Accuracy: 91.60\n",
      "Train Epoch: 148 [2560/50000 (6%)]\tLoss: 0.246210, Accuracy: 92.19\n",
      "Train Epoch: 148 [5120/50000 (11%)]\tLoss: 0.157649, Accuracy: 95.51\n",
      "Train Epoch: 148 [7680/50000 (17%)]\tLoss: 0.142861, Accuracy: 96.09\n",
      "Train Epoch: 148 [10240/50000 (23%)]\tLoss: 0.206714, Accuracy: 92.58\n",
      "Train Epoch: 148 [12800/50000 (28%)]\tLoss: 0.255717, Accuracy: 91.80\n",
      "Train Epoch: 148 [15360/50000 (34%)]\tLoss: 0.190059, Accuracy: 92.77\n",
      "Train Epoch: 148 [17920/50000 (40%)]\tLoss: 0.189005, Accuracy: 93.95\n",
      "Train Epoch: 148 [20480/50000 (45%)]\tLoss: 0.232691, Accuracy: 91.21\n",
      "Train Epoch: 148 [23040/50000 (51%)]\tLoss: 0.197516, Accuracy: 92.97\n",
      "Train Epoch: 148 [25600/50000 (57%)]\tLoss: 0.259936, Accuracy: 90.62\n",
      "Train Epoch: 148 [28160/50000 (62%)]\tLoss: 0.194679, Accuracy: 92.58\n",
      "Train Epoch: 148 [30720/50000 (68%)]\tLoss: 0.168225, Accuracy: 93.55\n",
      "Train Epoch: 148 [33280/50000 (74%)]\tLoss: 0.204731, Accuracy: 92.58\n",
      "Train Epoch: 148 [35840/50000 (80%)]\tLoss: 0.209101, Accuracy: 93.55\n",
      "Train Epoch: 148 [38400/50000 (85%)]\tLoss: 0.272152, Accuracy: 91.41\n",
      "Train Epoch: 148 [40960/50000 (91%)]\tLoss: 0.239415, Accuracy: 91.02\n",
      "Train Epoch: 148 [43520/50000 (97%)]\tLoss: 0.227297, Accuracy: 91.80\n",
      "\n",
      "Validation set: Average loss: 0.6470, Accuracy: 4074/5000 (81.00%)\n",
      "\n",
      "the time of this epoch:[35.466742277145386 s]\n",
      "\n",
      "Test set: Average loss: 0.6500, Accuracy: 8178/10000 (81.78%)\n",
      "\n",
      "Train Epoch: 149 [0/50000 (0%)]\tLoss: 0.178232, Accuracy: 92.77\n",
      "Train Epoch: 149 [2560/50000 (6%)]\tLoss: 0.201582, Accuracy: 93.16\n",
      "Train Epoch: 149 [5120/50000 (11%)]\tLoss: 0.191221, Accuracy: 92.38\n",
      "Train Epoch: 149 [7680/50000 (17%)]\tLoss: 0.270972, Accuracy: 90.23\n",
      "Train Epoch: 149 [10240/50000 (23%)]\tLoss: 0.146625, Accuracy: 95.12\n",
      "Train Epoch: 149 [12800/50000 (28%)]\tLoss: 0.253748, Accuracy: 89.06\n",
      "Train Epoch: 149 [15360/50000 (34%)]\tLoss: 0.191617, Accuracy: 92.58\n",
      "Train Epoch: 149 [17920/50000 (40%)]\tLoss: 0.224098, Accuracy: 91.21\n",
      "Train Epoch: 149 [20480/50000 (45%)]\tLoss: 0.210481, Accuracy: 92.58\n",
      "Train Epoch: 149 [23040/50000 (51%)]\tLoss: 0.203757, Accuracy: 92.58\n",
      "Train Epoch: 149 [25600/50000 (57%)]\tLoss: 0.222978, Accuracy: 93.16\n",
      "Train Epoch: 149 [28160/50000 (62%)]\tLoss: 0.194229, Accuracy: 93.16\n",
      "Train Epoch: 149 [30720/50000 (68%)]\tLoss: 0.189074, Accuracy: 92.38\n",
      "Train Epoch: 149 [33280/50000 (74%)]\tLoss: 0.168606, Accuracy: 94.34\n",
      "Train Epoch: 149 [35840/50000 (80%)]\tLoss: 0.200960, Accuracy: 94.34\n",
      "Train Epoch: 149 [38400/50000 (85%)]\tLoss: 0.256362, Accuracy: 91.21\n",
      "Train Epoch: 149 [40960/50000 (91%)]\tLoss: 0.192181, Accuracy: 93.55\n",
      "Train Epoch: 149 [43520/50000 (97%)]\tLoss: 0.153679, Accuracy: 94.34\n",
      "\n",
      "Validation set: Average loss: 0.6870, Accuracy: 4021/5000 (80.00%)\n",
      "\n",
      "the time of this epoch:[38.78018260002136 s]\n",
      "Train Epoch: 150 [0/50000 (0%)]\tLoss: 0.226490, Accuracy: 92.19\n",
      "Train Epoch: 150 [2560/50000 (6%)]\tLoss: 0.193141, Accuracy: 94.14\n",
      "Train Epoch: 150 [5120/50000 (11%)]\tLoss: 0.160229, Accuracy: 94.73\n",
      "Train Epoch: 150 [7680/50000 (17%)]\tLoss: 0.185318, Accuracy: 93.95\n",
      "Train Epoch: 150 [10240/50000 (23%)]\tLoss: 0.195388, Accuracy: 93.55\n",
      "Train Epoch: 150 [12800/50000 (28%)]\tLoss: 0.163574, Accuracy: 94.14\n",
      "Train Epoch: 150 [15360/50000 (34%)]\tLoss: 0.219311, Accuracy: 92.77\n",
      "Train Epoch: 150 [17920/50000 (40%)]\tLoss: 0.207674, Accuracy: 92.97\n",
      "Train Epoch: 150 [20480/50000 (45%)]\tLoss: 0.188551, Accuracy: 93.95\n",
      "Train Epoch: 150 [23040/50000 (51%)]\tLoss: 0.203407, Accuracy: 92.97\n",
      "Train Epoch: 150 [25600/50000 (57%)]\tLoss: 0.240810, Accuracy: 91.99\n",
      "Train Epoch: 150 [28160/50000 (62%)]\tLoss: 0.203568, Accuracy: 93.36\n",
      "Train Epoch: 150 [30720/50000 (68%)]\tLoss: 0.253199, Accuracy: 91.60\n",
      "Train Epoch: 150 [33280/50000 (74%)]\tLoss: 0.201686, Accuracy: 94.14\n",
      "Train Epoch: 150 [35840/50000 (80%)]\tLoss: 0.202226, Accuracy: 91.80\n",
      "Train Epoch: 150 [38400/50000 (85%)]\tLoss: 0.265435, Accuracy: 90.82\n",
      "Train Epoch: 150 [40960/50000 (91%)]\tLoss: 0.281560, Accuracy: 89.26\n",
      "Train Epoch: 150 [43520/50000 (97%)]\tLoss: 0.224054, Accuracy: 92.19\n",
      "\n",
      "Validation set: Average loss: 0.9873, Accuracy: 3677/5000 (73.00%)\n",
      "\n",
      "the time of this epoch:[35.464558124542236 s]\n",
      "\n",
      "Test set: Average loss: 0.9996, Accuracy: 7423/10000 (74.23%)\n",
      "\n",
      "Train Epoch: 151 [0/50000 (0%)]\tLoss: 0.226147, Accuracy: 92.38\n",
      "Train Epoch: 151 [2560/50000 (6%)]\tLoss: 0.178299, Accuracy: 93.55\n",
      "Train Epoch: 151 [5120/50000 (11%)]\tLoss: 0.150292, Accuracy: 94.14\n",
      "Train Epoch: 151 [7680/50000 (17%)]\tLoss: 0.118102, Accuracy: 95.70\n",
      "Train Epoch: 151 [10240/50000 (23%)]\tLoss: 0.155503, Accuracy: 94.53\n",
      "Train Epoch: 151 [12800/50000 (28%)]\tLoss: 0.159438, Accuracy: 94.73\n",
      "Train Epoch: 151 [15360/50000 (34%)]\tLoss: 0.155986, Accuracy: 94.92\n",
      "Train Epoch: 151 [17920/50000 (40%)]\tLoss: 0.117789, Accuracy: 95.90\n",
      "Train Epoch: 151 [20480/50000 (45%)]\tLoss: 0.106470, Accuracy: 96.29\n",
      "Train Epoch: 151 [23040/50000 (51%)]\tLoss: 0.131870, Accuracy: 95.51\n",
      "Train Epoch: 151 [25600/50000 (57%)]\tLoss: 0.115732, Accuracy: 96.09\n",
      "Train Epoch: 151 [28160/50000 (62%)]\tLoss: 0.135059, Accuracy: 95.70\n",
      "Train Epoch: 151 [30720/50000 (68%)]\tLoss: 0.099377, Accuracy: 96.88\n",
      "Train Epoch: 151 [33280/50000 (74%)]\tLoss: 0.093682, Accuracy: 97.46\n",
      "Train Epoch: 151 [35840/50000 (80%)]\tLoss: 0.129077, Accuracy: 95.70\n",
      "Train Epoch: 151 [38400/50000 (85%)]\tLoss: 0.101792, Accuracy: 96.09\n",
      "Train Epoch: 151 [40960/50000 (91%)]\tLoss: 0.100620, Accuracy: 96.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 151 [43520/50000 (97%)]\tLoss: 0.085887, Accuracy: 97.66\n",
      "\n",
      "Validation set: Average loss: 0.5105, Accuracy: 4216/5000 (84.00%)\n",
      "\n",
      "the time of this epoch:[38.76736640930176 s]\n",
      "Train Epoch: 152 [0/50000 (0%)]\tLoss: 0.081184, Accuracy: 97.85\n",
      "Train Epoch: 152 [2560/50000 (6%)]\tLoss: 0.087103, Accuracy: 97.66\n",
      "Train Epoch: 152 [5120/50000 (11%)]\tLoss: 0.089252, Accuracy: 97.27\n",
      "Train Epoch: 152 [7680/50000 (17%)]\tLoss: 0.113182, Accuracy: 95.70\n",
      "Train Epoch: 152 [10240/50000 (23%)]\tLoss: 0.086568, Accuracy: 97.66\n",
      "Train Epoch: 152 [12800/50000 (28%)]\tLoss: 0.092068, Accuracy: 97.66\n",
      "Train Epoch: 152 [15360/50000 (34%)]\tLoss: 0.075645, Accuracy: 98.05\n",
      "Train Epoch: 152 [17920/50000 (40%)]\tLoss: 0.067991, Accuracy: 97.66\n",
      "Train Epoch: 152 [20480/50000 (45%)]\tLoss: 0.069839, Accuracy: 97.85\n",
      "Train Epoch: 152 [23040/50000 (51%)]\tLoss: 0.074882, Accuracy: 98.05\n",
      "Train Epoch: 152 [25600/50000 (57%)]\tLoss: 0.070569, Accuracy: 97.46\n",
      "Train Epoch: 152 [28160/50000 (62%)]\tLoss: 0.067619, Accuracy: 97.85\n",
      "Train Epoch: 152 [30720/50000 (68%)]\tLoss: 0.093914, Accuracy: 97.27\n",
      "Train Epoch: 152 [33280/50000 (74%)]\tLoss: 0.065819, Accuracy: 98.24\n",
      "Train Epoch: 152 [35840/50000 (80%)]\tLoss: 0.100408, Accuracy: 96.09\n",
      "Train Epoch: 152 [38400/50000 (85%)]\tLoss: 0.092966, Accuracy: 96.29\n",
      "Train Epoch: 152 [40960/50000 (91%)]\tLoss: 0.076295, Accuracy: 97.07\n",
      "Train Epoch: 152 [43520/50000 (97%)]\tLoss: 0.058521, Accuracy: 98.83\n",
      "\n",
      "Validation set: Average loss: 0.3879, Accuracy: 4411/5000 (88.00%)\n",
      "\n",
      "the time of this epoch:[35.41981840133667 s]\n",
      "------------------------------\n",
      "before autoscale: torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.0050]],\n",
      "\n",
      "        [[ 0.0200]],\n",
      "\n",
      "        [[ 0.0146]],\n",
      "\n",
      "        [[ 0.0264]],\n",
      "\n",
      "        [[ 0.0430]],\n",
      "\n",
      "        [[ 0.0001]],\n",
      "\n",
      "        [[ 0.5465]],\n",
      "\n",
      "        [[ 0.0179]],\n",
      "\n",
      "        [[ 0.0088]],\n",
      "\n",
      "        [[ 0.0000]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[ 0.3680]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 512])\n",
      "tensor([[[ 0.0019,  0.0074,  0.0054,  0.0097,  0.0158,  0.0000,  0.2011,\n",
      "           0.0066,  0.0033,  0.0000,  0.0398,  0.0224,  0.0000,  0.0002,\n",
      "           0.0191,  0.0256,  0.0052,  0.0558,  0.0000,  0.0431,  0.0019,\n",
      "           0.0030,  0.0283,  0.0572,  0.0160,  0.0246,  0.0537,  0.0045,\n",
      "           0.0000,  0.0711,  0.0676,  0.0029,  0.0434,  0.0637,  0.0217,\n",
      "           0.0000,  0.0520,  0.0201,  0.0302,  0.0104,  0.0000,  0.0000,\n",
      "           0.2941,  0.0367,  0.0044,  0.0807,  0.0043,  0.0231,  0.0029,\n",
      "           0.0000,  0.0201,  0.0365,  0.0467,  0.0113,  0.0725,  0.0182,\n",
      "           0.0115,  0.0425,  0.0162,  0.0000,  0.0842,  0.0289,  0.0133,\n",
      "           0.0175,  0.0000,  0.0000,  0.0000,  0.0094,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0002,  0.0001,  0.0002,  0.0001,  0.0003,\n",
      "           0.0001,  0.0000,  0.0004,  0.0000,  0.0001,  0.0001,  0.0001,\n",
      "           0.0000,  0.0040,  0.0019,  0.0000,  0.0295,  0.0019,  0.0075,\n",
      "           0.0036,  0.0030,  0.0000,  0.0000,  0.0003,  0.0002,  0.0001,\n",
      "           0.0000,  0.0001,  0.0000,  0.0003,  0.0000,  0.0003,  0.0001,\n",
      "           0.0003,  0.0000,  0.0003,  0.0002,  0.0002,  0.0002,  0.0002,\n",
      "           0.0003,  0.0003,  0.0001,  0.0004,  0.0001,  0.0004,  0.0000,\n",
      "           0.0002,  0.0000,  0.0000,  0.0001,  0.0000,  0.0000,  0.0000,\n",
      "           0.0007,  0.0000,  0.0032,  0.0009,  0.0000,  0.0000,  0.0014,\n",
      "           0.0001,  0.0000,  0.0037,  0.0000,  0.0047,  0.0070,  0.0371,\n",
      "           0.0062,  0.0081,  0.0074,  0.0062,  0.0005,  0.0001,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0001,  0.0000,  0.0000,  0.0002,  0.0000,  0.0011,  0.0000,\n",
      "           0.0000,  0.0008,  0.0008,  0.0001,  0.0000,  0.0001,  0.0000,\n",
      "           0.0000,  0.0001,  0.0000,  0.0000,  0.0000,  0.0000,  0.0001,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0092,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0002,  0.0001,  0.0005,\n",
      "           0.0003,  0.0004,  0.0002,  0.0000,  0.0064,  0.0000,  0.0000,\n",
      "           0.0930,  0.0050,  0.0061,  0.0000,  0.0069,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0006,  0.0000,  0.0003,  0.0000,  0.0002,\n",
      "           0.0001,  0.0001,  0.0001,  0.0002,  0.0001,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0001,  0.0000,  0.0000,  0.0000,\n",
      "           0.0001,  0.0001,  0.0004,  0.0003,  0.0000,  0.0001,  0.0002,\n",
      "           0.0002,  0.0001,  0.0000,  0.0001,  0.0000,  0.0000,  0.0004,\n",
      "           0.0000,  0.0007,  0.0005,  0.0009,  0.0000,  0.0000,  0.0000,\n",
      "           0.0013,  0.0000,  0.0001,  0.0002,  0.0001,  0.0002,  0.0000,\n",
      "           0.0002,  0.0000,  0.0001,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0180,  0.0000,  0.0002,  0.0000,  0.0000,  0.0153,  0.0016,\n",
      "           0.0033,  0.0033,  0.0033,  0.0007,  0.0025,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0001,  0.0001,  0.0001,  0.0000,  0.0002,\n",
      "           0.0003,  0.0002,  0.0000,  0.0002,  0.0003,  0.0000,  0.0020,\n",
      "           0.0019,  0.0000,  0.0142,  0.0000,  0.0000,  0.0022,  0.0024,\n",
      "           0.0001,  0.0003,  0.0001,  0.0002,  0.0001,  0.0002,  0.0001,\n",
      "           0.0000,  0.0000,  0.0003,  0.0003,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0005,  0.0000,  0.0000,  0.0000,  0.0001,\n",
      "           0.0003,  0.0000,  0.0001,  0.0000,  0.0003,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0001,  0.0000,  0.0000,  0.0003,  0.0004,\n",
      "           0.0000,  0.0000,  0.0003,  0.0000,  0.0007,  0.0000,  0.0000,\n",
      "           0.0005,  0.0000,  0.0000,  0.0000,  0.0000,  0.0006,  0.0000,\n",
      "           0.0003,  0.0000,  0.0004,  0.0003,  0.0001,  0.0000,  0.0003,\n",
      "           0.0000,  0.0004,  0.0000,  0.0003,  0.0000,  0.0002,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0017,  0.0000,  0.0000,  0.0000,\n",
      "           0.0002,  0.0003,  0.0000,  0.0000,  0.0003,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0079,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0045,  0.0000,  0.0077,  0.0388,  0.0081,  0.0126,\n",
      "           0.0235,  0.0093,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0003,  0.0000,  0.0002,  0.0000,  0.0004,  0.0000,  0.0001,\n",
      "           0.0002,  0.0001,  0.0000,  0.0003,  0.0000,  0.0001,  0.0001,\n",
      "           0.0000,  0.0001,  0.0003,  0.0001,  0.0000,  0.0003,  0.0005,\n",
      "           0.0002,  0.0000,  0.0000,  0.0007,  0.0005,  0.0000,  0.0005,\n",
      "           0.0006,  0.0003,  0.0000,  0.0000,  0.0000,  0.0031,  0.0000,\n",
      "           0.0000,  0.0145,  0.0033,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0001,  0.0000,  0.0000,  0.0001,\n",
      "           0.0001,  0.0000,  0.0000,  0.0001,  0.0000,  0.0047,  0.0039,\n",
      "           0.0000,  0.0491,  0.0000,  0.0076,  0.0070,  0.0070,  0.0002,\n",
      "           0.0000,  0.0002,  0.0000,  0.0000,  0.0000,  0.0004,  0.0001,\n",
      "           0.0000,  0.0030,  0.0027,  0.0000,  0.0147,  0.0022,  0.0000,\n",
      "           0.0000,  0.0125,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0001,  0.0001,  0.0000,  0.0015,  0.0000,  0.0016,\n",
      "           0.0021,  0.0105,  0.0016,  0.0026,  0.0029,  0.0027,  0.0000,\n",
      "           0.0000,  0.0000,  0.0001,  0.0000,  0.0000,  0.0001,  0.0000,\n",
      "           0.0005,  0.0000,  0.0000,  0.0000,  0.0000,  0.0002,  0.0006,\n",
      "           0.0003,  0.0000,  0.0000,  0.0000,  0.0000,  0.0002,  0.0001,\n",
      "           0.0001]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-04 *\n",
      "       [[-1.2809, -2.2429, -3.1958,  0.9495,  3.9987,  1.2627,  3.4577,\n",
      "          4.2128, -1.0988]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 896, 512])\n",
      "tensor([[ 5.8879e-06,  1.3826e-05, -1.3128e-05,  ...,  1.1715e-07,\n",
      "          6.0335e-08,  9.8500e-09],\n",
      "        [ 8.3765e-06,  8.9492e-06,  5.1018e-05,  ...,  5.5224e-08,\n",
      "          1.0192e-07,  4.2553e-08],\n",
      "        [ 1.5311e-07, -2.9291e-06,  1.4539e-05,  ..., -9.9120e-08,\n",
      "          1.8124e-08,  1.5679e-08],\n",
      "        ...,\n",
      "        [ 5.3193e-06,  8.1875e-06,  1.9384e-05,  ...,  1.1837e-07,\n",
      "          8.6288e-08,  1.1933e-07],\n",
      "        [-6.4485e-06, -5.2570e-06, -4.5178e-05,  ..., -7.9879e-08,\n",
      "          1.6471e-08, -3.3396e-08],\n",
      "        [ 4.7421e-04,  3.8384e-04,  2.7660e-03,  ...,  7.2287e-08,\n",
      "          3.3687e-06,  5.9733e-06]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 896, 512])\n",
      "tensor([[ 5.8879e-07,  1.3826e-06, -1.3128e-06,  ...,  1.1715e-08,\n",
      "          6.0335e-09,  9.8500e-10],\n",
      "        [ 8.3765e-07,  8.9492e-07,  5.1018e-06,  ...,  5.5224e-09,\n",
      "          1.0192e-08,  4.2553e-09],\n",
      "        [ 1.5311e-08, -2.9291e-07,  1.4539e-06,  ..., -9.9120e-09,\n",
      "          1.8124e-09,  1.5679e-09],\n",
      "        ...,\n",
      "        [-9.5752e-08, -3.5902e-07,  4.0983e-06,  ..., -8.1536e-10,\n",
      "         -2.5372e-09, -1.1739e-09],\n",
      "        [-4.4056e-07, -5.5441e-07, -6.1472e-07,  ..., -1.1208e-08,\n",
      "         -7.3448e-10,  3.9970e-09],\n",
      "        [ 1.2485e-07, -1.0671e-07, -7.4430e-07,  ..., -5.0201e-10,\n",
      "         -1.7359e-09, -5.9282e-09]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4250, Accuracy: 8741/10000 (87.41%)\n",
      "\n",
      "Train Epoch: 153 [0/50000 (0%)]\tLoss: 0.078889, Accuracy: 97.46\n",
      "Train Epoch: 153 [2560/50000 (6%)]\tLoss: 0.089512, Accuracy: 96.48\n",
      "Train Epoch: 153 [5120/50000 (11%)]\tLoss: 0.076369, Accuracy: 97.07\n",
      "Train Epoch: 153 [7680/50000 (17%)]\tLoss: 0.071619, Accuracy: 97.46\n",
      "Train Epoch: 153 [10240/50000 (23%)]\tLoss: 0.064165, Accuracy: 97.27\n",
      "Train Epoch: 153 [12800/50000 (28%)]\tLoss: 0.066064, Accuracy: 98.05\n",
      "Train Epoch: 153 [15360/50000 (34%)]\tLoss: 0.078980, Accuracy: 97.07\n",
      "Train Epoch: 153 [17920/50000 (40%)]\tLoss: 0.068332, Accuracy: 98.05\n",
      "Train Epoch: 153 [20480/50000 (45%)]\tLoss: 0.068080, Accuracy: 97.85\n",
      "Train Epoch: 153 [23040/50000 (51%)]\tLoss: 0.077270, Accuracy: 97.66\n",
      "Train Epoch: 153 [25600/50000 (57%)]\tLoss: 0.102292, Accuracy: 97.07\n",
      "Train Epoch: 153 [28160/50000 (62%)]\tLoss: 0.090376, Accuracy: 96.88\n",
      "Train Epoch: 153 [30720/50000 (68%)]\tLoss: 0.066515, Accuracy: 97.66\n",
      "Train Epoch: 153 [33280/50000 (74%)]\tLoss: 0.078148, Accuracy: 97.07\n",
      "Train Epoch: 153 [35840/50000 (80%)]\tLoss: 0.074052, Accuracy: 97.07\n",
      "Train Epoch: 153 [38400/50000 (85%)]\tLoss: 0.071327, Accuracy: 97.85\n",
      "Train Epoch: 153 [40960/50000 (91%)]\tLoss: 0.057725, Accuracy: 97.85\n",
      "Train Epoch: 153 [43520/50000 (97%)]\tLoss: 0.034090, Accuracy: 99.61\n",
      "\n",
      "Validation set: Average loss: 0.3704, Accuracy: 4454/5000 (89.00%)\n",
      "\n",
      "the time of this epoch:[38.77729296684265 s]\n",
      "Train Epoch: 154 [0/50000 (0%)]\tLoss: 0.049036, Accuracy: 98.24\n",
      "Train Epoch: 154 [2560/50000 (6%)]\tLoss: 0.066436, Accuracy: 97.85\n",
      "Train Epoch: 154 [5120/50000 (11%)]\tLoss: 0.057232, Accuracy: 97.66\n",
      "Train Epoch: 154 [7680/50000 (17%)]\tLoss: 0.054876, Accuracy: 98.63\n",
      "Train Epoch: 154 [10240/50000 (23%)]\tLoss: 0.066959, Accuracy: 98.05\n",
      "Train Epoch: 154 [12800/50000 (28%)]\tLoss: 0.061241, Accuracy: 98.44\n",
      "Train Epoch: 154 [15360/50000 (34%)]\tLoss: 0.032383, Accuracy: 99.61\n",
      "Train Epoch: 154 [17920/50000 (40%)]\tLoss: 0.057599, Accuracy: 98.05\n",
      "Train Epoch: 154 [20480/50000 (45%)]\tLoss: 0.041477, Accuracy: 99.41\n",
      "Train Epoch: 154 [23040/50000 (51%)]\tLoss: 0.057631, Accuracy: 98.44\n",
      "Train Epoch: 154 [25600/50000 (57%)]\tLoss: 0.094400, Accuracy: 96.88\n",
      "Train Epoch: 154 [28160/50000 (62%)]\tLoss: 0.069079, Accuracy: 97.85\n",
      "Train Epoch: 154 [30720/50000 (68%)]\tLoss: 0.057646, Accuracy: 97.66\n",
      "Train Epoch: 154 [33280/50000 (74%)]\tLoss: 0.068913, Accuracy: 97.46\n",
      "Train Epoch: 154 [35840/50000 (80%)]\tLoss: 0.060173, Accuracy: 97.85\n",
      "Train Epoch: 154 [38400/50000 (85%)]\tLoss: 0.044898, Accuracy: 98.24\n",
      "Train Epoch: 154 [40960/50000 (91%)]\tLoss: 0.072835, Accuracy: 97.46\n",
      "Train Epoch: 154 [43520/50000 (97%)]\tLoss: 0.060011, Accuracy: 97.66\n",
      "\n",
      "Validation set: Average loss: 0.3240, Accuracy: 4537/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[35.48623514175415 s]\n",
      "\n",
      "Test set: Average loss: 0.3858, Accuracy: 8922/10000 (89.22%)\n",
      "\n",
      "Train Epoch: 155 [0/50000 (0%)]\tLoss: 0.038266, Accuracy: 98.83\n",
      "Train Epoch: 155 [2560/50000 (6%)]\tLoss: 0.051930, Accuracy: 98.05\n",
      "Train Epoch: 155 [5120/50000 (11%)]\tLoss: 0.045262, Accuracy: 98.83\n",
      "Train Epoch: 155 [7680/50000 (17%)]\tLoss: 0.064682, Accuracy: 97.85\n",
      "Train Epoch: 155 [10240/50000 (23%)]\tLoss: 0.044678, Accuracy: 98.44\n",
      "Train Epoch: 155 [12800/50000 (28%)]\tLoss: 0.023922, Accuracy: 99.61\n",
      "Train Epoch: 155 [15360/50000 (34%)]\tLoss: 0.041835, Accuracy: 98.83\n",
      "Train Epoch: 155 [17920/50000 (40%)]\tLoss: 0.033840, Accuracy: 99.61\n",
      "Train Epoch: 155 [20480/50000 (45%)]\tLoss: 0.069512, Accuracy: 98.24\n",
      "Train Epoch: 155 [23040/50000 (51%)]\tLoss: 0.083934, Accuracy: 97.46\n",
      "Train Epoch: 155 [25600/50000 (57%)]\tLoss: 0.052489, Accuracy: 97.85\n",
      "Train Epoch: 155 [28160/50000 (62%)]\tLoss: 0.042110, Accuracy: 98.63\n",
      "Train Epoch: 155 [30720/50000 (68%)]\tLoss: 0.063032, Accuracy: 97.46\n",
      "Train Epoch: 155 [33280/50000 (74%)]\tLoss: 0.038670, Accuracy: 98.63\n",
      "Train Epoch: 155 [35840/50000 (80%)]\tLoss: 0.044923, Accuracy: 98.24\n",
      "Train Epoch: 155 [38400/50000 (85%)]\tLoss: 0.069974, Accuracy: 97.46\n",
      "Train Epoch: 155 [40960/50000 (91%)]\tLoss: 0.058302, Accuracy: 97.46\n",
      "Train Epoch: 155 [43520/50000 (97%)]\tLoss: 0.069562, Accuracy: 98.05\n",
      "------------------------------\n",
      "before autoscale: torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.0072]],\n",
      "\n",
      "        [[ 0.0047]],\n",
      "\n",
      "        [[ 0.0347]],\n",
      "\n",
      "        [[ 0.0218]],\n",
      "\n",
      "        [[ 0.0840]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.4074]],\n",
      "\n",
      "        [[ 0.0588]],\n",
      "\n",
      "        [[ 0.0124]],\n",
      "\n",
      "        [[ 0.0132]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[ 0.3608]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 512])\n",
      "tensor([[[ 0.0026,  0.0017,  0.0125,  0.0079,  0.0303,  0.0000,  0.1470,\n",
      "           0.0212,  0.0045,  0.0048,  0.0470,  0.0224,  0.0000,  0.0000,\n",
      "           0.0198,  0.0242,  0.0026,  0.0557,  0.0002,  0.0407,  0.0484,\n",
      "           0.0011,  0.0133,  0.0569,  0.0272,  0.0179,  0.0564,  0.0021,\n",
      "           0.0033,  0.0692,  0.0630,  0.0017,  0.0491,  0.0505,  0.0296,\n",
      "           0.0000,  0.0500,  0.0180,  0.0274,  0.0070,  0.0000,  0.0000,\n",
      "           0.2335,  0.0500,  0.0031,  0.0896,  0.0019,  0.0335,  0.0022,\n",
      "           0.0000,  0.0305,  0.0330,  0.0514,  0.0149,  0.0632,  0.0192,\n",
      "           0.0117,  0.0424,  0.0149,  0.0000,  0.0826,  0.0296,  0.0197,\n",
      "           0.0172,  0.0000,  0.0000,  0.0000,  0.0090,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0002,  0.0001,  0.0002,  0.0001,  0.0003,\n",
      "           0.0001,  0.0000,  0.0004,  0.0000,  0.0001,  0.0001,  0.0001,\n",
      "           0.0000,  0.0039,  0.0019,  0.0000,  0.0342,  0.0019,  0.0038,\n",
      "           0.0035,  0.0029,  0.0000,  0.0000,  0.0003,  0.0002,  0.0001,\n",
      "           0.0000,  0.0001,  0.0000,  0.0003,  0.0000,  0.0003,  0.0001,\n",
      "           0.0003,  0.0000,  0.0002,  0.0002,  0.0002,  0.0002,  0.0002,\n",
      "           0.0003,  0.0003,  0.0001,  0.0004,  0.0001,  0.0003,  0.0000,\n",
      "           0.0002,  0.0000,  0.0000,  0.0001,  0.0000,  0.0000,  0.0000,\n",
      "           0.0007,  0.0000,  0.0037,  0.0008,  0.0000,  0.0000,  0.0013,\n",
      "           0.0001,  0.0000,  0.0036,  0.0000,  0.0046,  0.0080,  0.0423,\n",
      "           0.0060,  0.0079,  0.0073,  0.0061,  0.0005,  0.0001,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0001,  0.0000,  0.0000,  0.0002,  0.0000,  0.0011,  0.0000,\n",
      "           0.0000,  0.0008,  0.0007,  0.0001,  0.0000,  0.0001,  0.0000,\n",
      "           0.0000,  0.0001,  0.0000,  0.0000,  0.0000,  0.0000,  0.0001,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0086,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0002,  0.0001,  0.0005,\n",
      "           0.0003,  0.0004,  0.0002,  0.0000,  0.0062,  0.0000,  0.0000,\n",
      "           0.1035,  0.0048,  0.0057,  0.0000,  0.0067,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0006,  0.0000,  0.0003,  0.0000,  0.0002,\n",
      "           0.0001,  0.0001,  0.0001,  0.0002,  0.0001,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0001,  0.0000,  0.0000,  0.0000,\n",
      "           0.0001,  0.0001,  0.0004,  0.0002,  0.0000,  0.0001,  0.0002,\n",
      "           0.0002,  0.0001,  0.0000,  0.0001,  0.0000,  0.0000,  0.0004,\n",
      "           0.0000,  0.0007,  0.0005,  0.0009,  0.0000,  0.0000,  0.0000,\n",
      "           0.0013,  0.0000,  0.0001,  0.0002,  0.0001,  0.0002,  0.0000,\n",
      "           0.0002,  0.0000,  0.0001,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0167,  0.0000,  0.0001,  0.0000,  0.0000,  0.0173,  0.0016,\n",
      "           0.0032,  0.0032,  0.0033,  0.0007,  0.0028,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0001,  0.0001,  0.0001,  0.0000,  0.0002,\n",
      "           0.0003,  0.0002,  0.0000,  0.0002,  0.0003,  0.0000,  0.0020,\n",
      "           0.0018,  0.0000,  0.0173,  0.0000,  0.0000,  0.0022,  0.0023,\n",
      "           0.0001,  0.0003,  0.0001,  0.0002,  0.0001,  0.0002,  0.0000,\n",
      "           0.0000,  0.0000,  0.0003,  0.0003,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0005,  0.0000,  0.0000,  0.0000,  0.0001,\n",
      "           0.0003,  0.0000,  0.0001,  0.0000,  0.0002,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0001,  0.0000,  0.0000,  0.0003,  0.0004,\n",
      "           0.0000,  0.0000,  0.0003,  0.0000,  0.0006,  0.0000,  0.0000,\n",
      "           0.0005,  0.0000,  0.0000,  0.0000,  0.0000,  0.0006,  0.0000,\n",
      "           0.0003,  0.0000,  0.0004,  0.0003,  0.0001,  0.0000,  0.0003,\n",
      "           0.0000,  0.0004,  0.0000,  0.0003,  0.0000,  0.0001,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0016,  0.0000,  0.0000,  0.0000,\n",
      "           0.0002,  0.0002,  0.0000,  0.0000,  0.0003,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0039,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0046,  0.0000,  0.0075,  0.0435,  0.0080,  0.0149,\n",
      "           0.0276,  0.0091,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0003,  0.0000,  0.0002,  0.0000,  0.0003,  0.0000,  0.0001,\n",
      "           0.0002,  0.0001,  0.0000,  0.0002,  0.0000,  0.0001,  0.0001,\n",
      "           0.0000,  0.0001,  0.0003,  0.0001,  0.0000,  0.0003,  0.0005,\n",
      "           0.0002,  0.0000,  0.0000,  0.0007,  0.0005,  0.0000,  0.0005,\n",
      "           0.0006,  0.0003,  0.0000,  0.0000,  0.0000,  0.0030,  0.0000,\n",
      "           0.0000,  0.0187,  0.0032,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0001,  0.0000,  0.0000,  0.0001,\n",
      "           0.0001,  0.0000,  0.0000,  0.0001,  0.0000,  0.0046,  0.0039,\n",
      "           0.0000,  0.0561,  0.0000,  0.0074,  0.0069,  0.0068,  0.0002,\n",
      "           0.0000,  0.0002,  0.0000,  0.0000,  0.0000,  0.0004,  0.0001,\n",
      "           0.0000,  0.0030,  0.0026,  0.0000,  0.0198,  0.0022,  0.0000,\n",
      "           0.0000,  0.0052,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0001,  0.0001,  0.0000,  0.0014,  0.0000,  0.0016,\n",
      "           0.0021,  0.0136,  0.0016,  0.0026,  0.0019,  0.0027,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0001,  0.0000,\n",
      "           0.0005,  0.0000,  0.0000,  0.0000,  0.0000,  0.0002,  0.0006,\n",
      "           0.0003,  0.0000,  0.0000,  0.0000,  0.0000,  0.0002,  0.0001,\n",
      "           0.0001]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-04 *\n",
      "       [[-1.2641, -2.2134, -3.1539,  0.9371,  3.9463,  1.2462,  3.4123,\n",
      "          4.1575, -1.0844]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 896, 512])\n",
      "tensor([[ 5.4954e-06,  1.7756e-05, -3.3385e-07,  ...,  1.1187e-07,\n",
      "          5.7615e-08,  9.4050e-09],\n",
      "        [ 9.8632e-06,  1.3287e-05,  3.6862e-05,  ...,  5.2734e-08,\n",
      "          9.7325e-08,  4.0635e-08],\n",
      "        [-7.1731e-07,  1.4692e-06,  1.0975e-06,  ..., -9.4651e-08,\n",
      "          1.7306e-08,  1.4974e-08],\n",
      "        ...,\n",
      "        [ 6.9198e-06,  7.9350e-06,  2.3225e-05,  ...,  1.1304e-07,\n",
      "          8.2398e-08,  1.1395e-07],\n",
      "        [-9.9470e-06, -4.8400e-06, -3.9812e-05,  ..., -7.6278e-08,\n",
      "          1.5728e-08, -3.1889e-08],\n",
      "        [ 4.7071e-04,  7.9899e-04,  1.8243e-03,  ...,  6.5527e-08,\n",
      "          3.2104e-06,  5.7027e-06]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 896, 512])\n",
      "tensor([[ 5.4954e-07,  1.7756e-06, -3.3385e-08,  ...,  1.1187e-08,\n",
      "          5.7615e-09,  9.4050e-10],\n",
      "        [ 9.8632e-07,  1.3287e-06,  3.6862e-06,  ...,  5.2734e-09,\n",
      "          9.7325e-09,  4.0635e-09],\n",
      "        [-7.1731e-08,  1.4692e-07,  1.0975e-07,  ..., -9.4651e-09,\n",
      "          1.7306e-09,  1.4974e-09],\n",
      "        ...,\n",
      "        [ 4.9316e-07, -9.5324e-07,  2.9771e-06,  ..., -7.7865e-10,\n",
      "         -2.4227e-09, -1.1210e-09],\n",
      "        [-4.6098e-07, -4.9287e-07, -1.3722e-06,  ..., -1.0703e-08,\n",
      "         -7.0131e-10,  3.8170e-09],\n",
      "        [-1.3283e-07,  1.6784e-07, -5.4382e-07,  ..., -4.7933e-10,\n",
      "         -1.6578e-09, -5.6609e-09]], device='cuda:0')\n",
      "\n",
      "Validation set: Average loss: 0.3584, Accuracy: 4494/5000 (89.00%)\n",
      "\n",
      "the time of this epoch:[38.77193593978882 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 156 [0/50000 (0%)]\tLoss: 0.046028, Accuracy: 98.83\n",
      "Train Epoch: 156 [2560/50000 (6%)]\tLoss: 0.044587, Accuracy: 98.63\n",
      "Train Epoch: 156 [5120/50000 (11%)]\tLoss: 0.044393, Accuracy: 98.44\n",
      "Train Epoch: 156 [7680/50000 (17%)]\tLoss: 0.070338, Accuracy: 97.85\n",
      "Train Epoch: 156 [10240/50000 (23%)]\tLoss: 0.031941, Accuracy: 99.22\n",
      "Train Epoch: 156 [12800/50000 (28%)]\tLoss: 0.036957, Accuracy: 98.83\n",
      "Train Epoch: 156 [15360/50000 (34%)]\tLoss: 0.048311, Accuracy: 98.83\n",
      "Train Epoch: 156 [17920/50000 (40%)]\tLoss: 0.030374, Accuracy: 98.63\n",
      "Train Epoch: 156 [20480/50000 (45%)]\tLoss: 0.040037, Accuracy: 99.02\n",
      "Train Epoch: 156 [23040/50000 (51%)]\tLoss: 0.036543, Accuracy: 98.83\n",
      "Train Epoch: 156 [25600/50000 (57%)]\tLoss: 0.045866, Accuracy: 98.63\n",
      "Train Epoch: 156 [28160/50000 (62%)]\tLoss: 0.029587, Accuracy: 99.41\n",
      "Train Epoch: 156 [30720/50000 (68%)]\tLoss: 0.032593, Accuracy: 99.22\n",
      "Train Epoch: 156 [33280/50000 (74%)]\tLoss: 0.046764, Accuracy: 98.44\n",
      "Train Epoch: 156 [35840/50000 (80%)]\tLoss: 0.073432, Accuracy: 98.24\n",
      "Train Epoch: 156 [38400/50000 (85%)]\tLoss: 0.051655, Accuracy: 98.63\n",
      "Train Epoch: 156 [40960/50000 (91%)]\tLoss: 0.051702, Accuracy: 98.44\n",
      "Train Epoch: 156 [43520/50000 (97%)]\tLoss: 0.051100, Accuracy: 98.63\n",
      "------------------------------\n",
      "before autoscale: torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.0000]],\n",
      "\n",
      "        [[ 0.3532]],\n",
      "\n",
      "        [[ 0.1930]],\n",
      "\n",
      "        [[ 0.0378]],\n",
      "\n",
      "        [[ 0.1866]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0002]],\n",
      "\n",
      "        [[ 0.1997]],\n",
      "\n",
      "        [[ 0.1159]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[-0.4211]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 512])\n",
      "tensor([[[ 0.0000, -0.1488, -0.0813, -0.0159, -0.0786,  0.0000,  0.0000,\n",
      "          -0.0001, -0.0841, -0.0488, -0.0532, -0.0652, -0.0083, -0.0834,\n",
      "          -0.0840, -0.0659,  0.0000, -0.0737, -0.0350, -0.0008,  0.0000,\n",
      "          -0.0788, -0.2573, -0.0856, -0.0174, -0.0022, -0.0116,  0.0000,\n",
      "          -0.0641, -0.0544, -0.0782, -0.1153,  0.0000, -0.0754, -0.0166,\n",
      "          -0.0023,  0.0000, -0.0048, -0.1368, -0.0142, -0.0729, -0.0152,\n",
      "          -0.0919, -0.0017, -0.0723, -0.0076, -0.0618, -0.0351, -0.0917,\n",
      "          -0.0080, -0.0453,  0.0000, -0.0686, -0.0759, -0.0502, -0.0959,\n",
      "          -0.0021, -0.0198, -0.0006, -0.1940, -0.0249, -0.0958, -0.1517,\n",
      "          -0.0543,  0.0000,  0.0000,  0.0000, -0.0074,  0.0000,  0.0000,\n",
      "           0.0000, -0.0013,  0.0000,  0.0000, -0.0008, -0.0003, -0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0011, -0.0035, -0.0001,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0001,\n",
      "          -0.0000, -0.0001, -0.0001,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0106,  0.0000,\n",
      "          -0.0001,  0.0000,  0.0000, -0.0002,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0001,  0.0000, -0.0004, -0.0000,\n",
      "          -0.0001, -0.0002,  0.0000, -0.0001, -0.0001, -0.0001, -0.0000,\n",
      "          -0.0002, -0.0001,  0.0000,  0.0000,  0.0000, -0.0006,  0.0000,\n",
      "          -0.0043,  0.0000,  0.0000, -0.0060, -0.0003,  0.0000,  0.0000,\n",
      "          -0.0054,  0.0000, -0.0001,  0.0000, -0.0001, -0.0000, -0.0001,\n",
      "          -0.0005,  0.0000,  0.0000, -0.0007,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0000, -0.0001,  0.0000,  0.0000, -0.0001,  0.0000,\n",
      "           0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,\n",
      "          -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0004,\n",
      "          -0.0001,  0.0000, -0.0001, -0.0001, -0.0001, -0.0002, -0.0001,\n",
      "           0.0000, -0.0001, -0.0001, -0.0001, -0.0001,  0.0000, -0.0001,\n",
      "          -0.0002, -0.0001,  0.0000,  0.0000, -0.0002, -0.0000,  0.0000,\n",
      "           0.0000, -0.0005, -0.0000,  0.0000,  0.0000, -0.0001,  0.0000,\n",
      "           0.0000, -0.0001, -0.0000,  0.0000,  0.0000, -0.0002,  0.0000,\n",
      "           0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0002,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0105,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0001,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0005,\n",
      "          -0.0019,  0.0000,  0.0000, -0.0050,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0052,  0.0000, -0.0026,  0.0000,  0.0000, -0.0044, -0.0070,\n",
      "           0.0000,  0.0000, -0.0076,  0.0000, -0.0002, -0.0006,  0.0000,\n",
      "          -0.0000, -0.0015, -0.0003,  0.0000, -0.0017, -0.0050, -0.0007,\n",
      "           0.0000, -0.0036,  0.0000, -0.0002,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
      "          -0.0001,  0.0000, -0.0002,  0.0000, -0.0001,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0001, -0.0000, -0.0001, -0.0002,\n",
      "           0.0000, -0.0001,  0.0000, -0.0001,  0.0000,  0.0000, -0.0000,\n",
      "           0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000,\n",
      "           0.0000, -0.0001, -0.0002, -0.0001, -0.0002,  0.0000, -0.0002,\n",
      "           0.0000,  0.0000,  0.0000, -0.0001,  0.0000, -0.0002,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0104,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0008,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0000,  0.0000,  0.0000, -0.0015, -0.0047, -0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0001, -0.0000, -0.0001,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0003,  0.0000,\n",
      "           0.0000, -0.0030,  0.0000,  0.0000, -0.0041,  0.0000, -0.0001,\n",
      "          -0.0001,  0.0000, -0.0001,  0.0000,  0.0000,  0.0000, -0.0001,\n",
      "           0.0000, -0.0000, -0.0001, -0.0013,  0.0000,  0.0000, -0.0027,\n",
      "          -0.0039,  0.0000,  0.0000,  0.0000, -0.0049, -0.0060,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0010,  0.0000, -0.0013,  0.0000,\n",
      "          -0.0041, -0.0045,  0.0000, -0.0039,  0.0000,  0.0000, -0.0023,\n",
      "          -0.0042,  0.0000,  0.0000,  0.0000, -0.0025,  0.0000,  0.0000,\n",
      "          -0.0067, -0.0004,  0.0000,  0.0000,  0.0000,  0.0000, -0.0046,\n",
      "          -0.0004,  0.0000,  0.0000, -0.0085, -0.0029,  0.0000,  0.0000,\n",
      "           0.0000, -0.0047,  0.0000,  0.0000,  0.0000, -0.0077, -0.0032,\n",
      "           0.0000,  0.0000,  0.0000, -0.0010,  0.0000,  0.0000, -0.0008,\n",
      "           0.0000,  0.0000, -0.0001,  0.0000, -0.0000,  0.0000, -0.0003,\n",
      "          -0.0001,  0.0000, -0.0002, -0.0001, -0.0001,  0.0000, -0.0002,\n",
      "          -0.0002,  0.0000, -0.0001, -0.0000, -0.0005,  0.0000, -0.0001,\n",
      "           0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0012,  0.0000,\n",
      "           0.0000, -0.0024, -0.0047,  0.0000,  0.0000, -0.0044,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0048, -0.0006,  0.0000,  0.0000,\n",
      "           0.0000, -0.0001, -0.0001,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0021, -0.0054,  0.0000,  0.0000,  0.0000,  0.0000, -0.0001,\n",
      "          -0.0001,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
      "           0.0000, -0.0001,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,\n",
      "          -0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
      "           0.0000]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-04 *\n",
      "       [[-3.1915,  1.3719,  3.8598, -0.6474,  1.2672, -2.5447, -2.1658,\n",
      "         -2.7287, -0.1622]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 448, 512])\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.0061,  0.0027,  0.0020,  ..., -0.0000, -0.0000,  0.0000],\n",
      "        [-0.0020,  0.0029,  0.0005,  ...,  0.0000, -0.0000, -0.0000],\n",
      "        [ 0.5139,  0.5456,  0.4697,  ...,  0.0002,  0.0002,  0.0001],\n",
      "        ...,\n",
      "        [-0.0027,  0.0002,  0.0108,  ...,  0.0000,  0.0000, -0.0000],\n",
      "        [ 0.0027,  0.0015,  0.0055,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0003,  0.0007,  0.0016,  ...,  0.0000,  0.0000,  0.0000]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 448, 512])\n",
      "tensor(1.00000e-03 *\n",
      "       [[ 0.0061,  0.0027,  0.0020,  ..., -0.0000, -0.0000,  0.0000],\n",
      "        [-0.0020,  0.0029,  0.0005,  ...,  0.0000, -0.0000, -0.0000],\n",
      "        [ 0.5139,  0.5456,  0.4697,  ...,  0.0002,  0.0002,  0.0001],\n",
      "        ...,\n",
      "        [ 0.0059, -0.0048, -0.0122,  ..., -0.0000, -0.0000,  0.0000],\n",
      "        [-0.0112, -0.0035, -0.0105,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0069,  0.0117,  0.0263,  ...,  0.0000,  0.0000,  0.0000]], device='cuda:0')\n",
      "\n",
      "Validation set: Average loss: 0.3512, Accuracy: 4512/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[35.4978973865509 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4094, Accuracy: 8888/10000 (88.88%)\n",
      "\n",
      "Train Epoch: 157 [0/50000 (0%)]\tLoss: 0.062597, Accuracy: 97.66\n",
      "Train Epoch: 157 [2560/50000 (6%)]\tLoss: 0.034073, Accuracy: 99.22\n",
      "Train Epoch: 157 [5120/50000 (11%)]\tLoss: 0.034652, Accuracy: 98.63\n",
      "Train Epoch: 157 [7680/50000 (17%)]\tLoss: 0.052749, Accuracy: 98.63\n",
      "Train Epoch: 157 [10240/50000 (23%)]\tLoss: 0.056525, Accuracy: 98.24\n",
      "Train Epoch: 157 [12800/50000 (28%)]\tLoss: 0.045210, Accuracy: 98.63\n",
      "Train Epoch: 157 [15360/50000 (34%)]\tLoss: 0.033496, Accuracy: 98.83\n",
      "Train Epoch: 157 [17920/50000 (40%)]\tLoss: 0.042123, Accuracy: 98.63\n",
      "Train Epoch: 157 [20480/50000 (45%)]\tLoss: 0.037397, Accuracy: 98.83\n",
      "Train Epoch: 157 [23040/50000 (51%)]\tLoss: 0.049152, Accuracy: 98.44\n",
      "Train Epoch: 157 [25600/50000 (57%)]\tLoss: 0.036991, Accuracy: 98.83\n",
      "Train Epoch: 157 [28160/50000 (62%)]\tLoss: 0.047079, Accuracy: 99.02\n",
      "Train Epoch: 157 [30720/50000 (68%)]\tLoss: 0.079023, Accuracy: 96.88\n",
      "Train Epoch: 157 [33280/50000 (74%)]\tLoss: 0.052751, Accuracy: 98.24\n",
      "Train Epoch: 157 [35840/50000 (80%)]\tLoss: 0.037580, Accuracy: 98.63\n",
      "Train Epoch: 157 [38400/50000 (85%)]\tLoss: 0.025057, Accuracy: 99.22\n",
      "Train Epoch: 157 [40960/50000 (91%)]\tLoss: 0.036029, Accuracy: 98.83\n",
      "Train Epoch: 157 [43520/50000 (97%)]\tLoss: 0.048395, Accuracy: 98.63\n",
      "\n",
      "Validation set: Average loss: 0.3554, Accuracy: 4508/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[39.14513802528381 s]\n",
      "Train Epoch: 158 [0/50000 (0%)]\tLoss: 0.061923, Accuracy: 97.85\n",
      "Train Epoch: 158 [2560/50000 (6%)]\tLoss: 0.023168, Accuracy: 99.22\n",
      "Train Epoch: 158 [5120/50000 (11%)]\tLoss: 0.049578, Accuracy: 98.05\n",
      "Train Epoch: 158 [7680/50000 (17%)]\tLoss: 0.034530, Accuracy: 99.22\n",
      "Train Epoch: 158 [10240/50000 (23%)]\tLoss: 0.020261, Accuracy: 99.41\n",
      "Train Epoch: 158 [12800/50000 (28%)]\tLoss: 0.052574, Accuracy: 98.44\n",
      "Train Epoch: 158 [15360/50000 (34%)]\tLoss: 0.068482, Accuracy: 97.66\n",
      "Train Epoch: 158 [17920/50000 (40%)]\tLoss: 0.025339, Accuracy: 99.02\n",
      "Train Epoch: 158 [20480/50000 (45%)]\tLoss: 0.030158, Accuracy: 98.44\n",
      "Train Epoch: 158 [23040/50000 (51%)]\tLoss: 0.040203, Accuracy: 99.02\n",
      "Train Epoch: 158 [25600/50000 (57%)]\tLoss: 0.028214, Accuracy: 99.41\n",
      "Train Epoch: 158 [28160/50000 (62%)]\tLoss: 0.031766, Accuracy: 99.22\n",
      "Train Epoch: 158 [30720/50000 (68%)]\tLoss: 0.036626, Accuracy: 98.83\n",
      "Train Epoch: 158 [33280/50000 (74%)]\tLoss: 0.030887, Accuracy: 99.02\n",
      "Train Epoch: 158 [35840/50000 (80%)]\tLoss: 0.025605, Accuracy: 99.02\n",
      "Train Epoch: 158 [38400/50000 (85%)]\tLoss: 0.031156, Accuracy: 99.02\n",
      "Train Epoch: 158 [40960/50000 (91%)]\tLoss: 0.028613, Accuracy: 98.63\n",
      "Train Epoch: 158 [43520/50000 (97%)]\tLoss: 0.043102, Accuracy: 98.44\n",
      "\n",
      "Validation set: Average loss: 0.3696, Accuracy: 4475/5000 (89.00%)\n",
      "\n",
      "the time of this epoch:[36.05056977272034 s]\n",
      "\n",
      "Test set: Average loss: 0.3792, Accuracy: 9017/10000 (90.17%)\n",
      "\n",
      "Train Epoch: 159 [0/50000 (0%)]\tLoss: 0.023253, Accuracy: 99.61\n",
      "Train Epoch: 159 [2560/50000 (6%)]\tLoss: 0.020320, Accuracy: 99.61\n",
      "Train Epoch: 159 [5120/50000 (11%)]\tLoss: 0.040285, Accuracy: 99.02\n",
      "Train Epoch: 159 [7680/50000 (17%)]\tLoss: 0.051936, Accuracy: 98.83\n",
      "Train Epoch: 159 [10240/50000 (23%)]\tLoss: 0.033635, Accuracy: 99.02\n",
      "Train Epoch: 159 [12800/50000 (28%)]\tLoss: 0.037276, Accuracy: 98.44\n",
      "Train Epoch: 159 [15360/50000 (34%)]\tLoss: 0.015258, Accuracy: 99.80\n",
      "Train Epoch: 159 [17920/50000 (40%)]\tLoss: 0.032507, Accuracy: 98.44\n",
      "Train Epoch: 159 [20480/50000 (45%)]\tLoss: 0.032993, Accuracy: 99.22\n",
      "Train Epoch: 159 [23040/50000 (51%)]\tLoss: 0.028269, Accuracy: 99.22\n",
      "Train Epoch: 159 [25600/50000 (57%)]\tLoss: 0.029366, Accuracy: 99.02\n",
      "Train Epoch: 159 [28160/50000 (62%)]\tLoss: 0.037864, Accuracy: 98.83\n",
      "Train Epoch: 159 [30720/50000 (68%)]\tLoss: 0.015918, Accuracy: 99.61\n",
      "Train Epoch: 159 [33280/50000 (74%)]\tLoss: 0.049436, Accuracy: 98.83\n",
      "Train Epoch: 159 [35840/50000 (80%)]\tLoss: 0.048761, Accuracy: 98.63\n",
      "Train Epoch: 159 [38400/50000 (85%)]\tLoss: 0.049333, Accuracy: 98.63\n",
      "Train Epoch: 159 [40960/50000 (91%)]\tLoss: 0.041016, Accuracy: 98.83\n",
      "Train Epoch: 159 [43520/50000 (97%)]\tLoss: 0.047283, Accuracy: 98.24\n",
      "\n",
      "Validation set: Average loss: 0.3949, Accuracy: 4484/5000 (89.00%)\n",
      "\n",
      "the time of this epoch:[38.83847117424011 s]\n",
      "Train Epoch: 160 [0/50000 (0%)]\tLoss: 0.021619, Accuracy: 99.41\n",
      "Train Epoch: 160 [2560/50000 (6%)]\tLoss: 0.026227, Accuracy: 99.22\n",
      "Train Epoch: 160 [5120/50000 (11%)]\tLoss: 0.035918, Accuracy: 98.44\n",
      "Train Epoch: 160 [7680/50000 (17%)]\tLoss: 0.029135, Accuracy: 99.02\n",
      "Train Epoch: 160 [10240/50000 (23%)]\tLoss: 0.052000, Accuracy: 99.02\n",
      "Train Epoch: 160 [12800/50000 (28%)]\tLoss: 0.029070, Accuracy: 99.22\n",
      "Train Epoch: 160 [15360/50000 (34%)]\tLoss: 0.042422, Accuracy: 98.63\n",
      "Train Epoch: 160 [17920/50000 (40%)]\tLoss: 0.041393, Accuracy: 99.02\n",
      "Train Epoch: 160 [20480/50000 (45%)]\tLoss: 0.043061, Accuracy: 98.44\n",
      "Train Epoch: 160 [23040/50000 (51%)]\tLoss: 0.046027, Accuracy: 98.05\n",
      "Train Epoch: 160 [25600/50000 (57%)]\tLoss: 0.031935, Accuracy: 99.02\n",
      "Train Epoch: 160 [28160/50000 (62%)]\tLoss: 0.029184, Accuracy: 99.22\n",
      "Train Epoch: 160 [30720/50000 (68%)]\tLoss: 0.041640, Accuracy: 99.22\n",
      "Train Epoch: 160 [33280/50000 (74%)]\tLoss: 0.039595, Accuracy: 98.83\n",
      "Train Epoch: 160 [35840/50000 (80%)]\tLoss: 0.039171, Accuracy: 98.83\n",
      "Train Epoch: 160 [38400/50000 (85%)]\tLoss: 0.035124, Accuracy: 98.63\n",
      "Train Epoch: 160 [40960/50000 (91%)]\tLoss: 0.031069, Accuracy: 99.02\n",
      "Train Epoch: 160 [43520/50000 (97%)]\tLoss: 0.032531, Accuracy: 99.02\n",
      "\n",
      "Validation set: Average loss: 0.3725, Accuracy: 4526/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[35.48505735397339 s]\n",
      "\n",
      "Test set: Average loss: 0.4140, Accuracy: 8962/10000 (89.62%)\n",
      "\n",
      "Train Epoch: 161 [0/50000 (0%)]\tLoss: 0.033337, Accuracy: 98.83\n",
      "Train Epoch: 161 [2560/50000 (6%)]\tLoss: 0.029883, Accuracy: 99.02\n",
      "Train Epoch: 161 [5120/50000 (11%)]\tLoss: 0.043981, Accuracy: 98.83\n",
      "Train Epoch: 161 [7680/50000 (17%)]\tLoss: 0.026147, Accuracy: 99.22\n",
      "Train Epoch: 161 [10240/50000 (23%)]\tLoss: 0.019012, Accuracy: 99.22\n",
      "Train Epoch: 161 [12800/50000 (28%)]\tLoss: 0.020002, Accuracy: 99.22\n",
      "Train Epoch: 161 [15360/50000 (34%)]\tLoss: 0.021305, Accuracy: 99.22\n",
      "Train Epoch: 161 [17920/50000 (40%)]\tLoss: 0.034596, Accuracy: 99.22\n",
      "Train Epoch: 161 [20480/50000 (45%)]\tLoss: 0.058600, Accuracy: 97.85\n",
      "Train Epoch: 161 [23040/50000 (51%)]\tLoss: 0.027147, Accuracy: 98.63\n",
      "Train Epoch: 161 [25600/50000 (57%)]\tLoss: 0.017765, Accuracy: 99.80\n",
      "Train Epoch: 161 [28160/50000 (62%)]\tLoss: 0.029817, Accuracy: 99.41\n",
      "Train Epoch: 161 [30720/50000 (68%)]\tLoss: 0.026468, Accuracy: 99.41\n",
      "Train Epoch: 161 [33280/50000 (74%)]\tLoss: 0.037725, Accuracy: 98.83\n",
      "Train Epoch: 161 [35840/50000 (80%)]\tLoss: 0.032949, Accuracy: 99.41\n",
      "Train Epoch: 161 [38400/50000 (85%)]\tLoss: 0.020385, Accuracy: 99.41\n",
      "Train Epoch: 161 [40960/50000 (91%)]\tLoss: 0.033380, Accuracy: 98.83\n",
      "Train Epoch: 161 [43520/50000 (97%)]\tLoss: 0.041352, Accuracy: 98.83\n",
      "\n",
      "Validation set: Average loss: 0.3728, Accuracy: 4536/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[38.85848140716553 s]\n",
      "Train Epoch: 162 [0/50000 (0%)]\tLoss: 0.023988, Accuracy: 99.41\n",
      "Train Epoch: 162 [2560/50000 (6%)]\tLoss: 0.033468, Accuracy: 99.02\n",
      "Train Epoch: 162 [5120/50000 (11%)]\tLoss: 0.030341, Accuracy: 99.22\n",
      "Train Epoch: 162 [7680/50000 (17%)]\tLoss: 0.041166, Accuracy: 98.83\n",
      "Train Epoch: 162 [10240/50000 (23%)]\tLoss: 0.034118, Accuracy: 99.22\n",
      "Train Epoch: 162 [12800/50000 (28%)]\tLoss: 0.018911, Accuracy: 99.41\n",
      "Train Epoch: 162 [15360/50000 (34%)]\tLoss: 0.041265, Accuracy: 98.63\n",
      "Train Epoch: 162 [17920/50000 (40%)]\tLoss: 0.049960, Accuracy: 98.83\n",
      "Train Epoch: 162 [20480/50000 (45%)]\tLoss: 0.028971, Accuracy: 99.22\n",
      "Train Epoch: 162 [23040/50000 (51%)]\tLoss: 0.025287, Accuracy: 99.61\n",
      "Train Epoch: 162 [25600/50000 (57%)]\tLoss: 0.034197, Accuracy: 98.63\n",
      "Train Epoch: 162 [28160/50000 (62%)]\tLoss: 0.022450, Accuracy: 99.41\n",
      "Train Epoch: 162 [30720/50000 (68%)]\tLoss: 0.036914, Accuracy: 98.44\n",
      "Train Epoch: 162 [33280/50000 (74%)]\tLoss: 0.028483, Accuracy: 99.61\n",
      "Train Epoch: 162 [35840/50000 (80%)]\tLoss: 0.027891, Accuracy: 98.83\n",
      "Train Epoch: 162 [38400/50000 (85%)]\tLoss: 0.042552, Accuracy: 98.63\n",
      "Train Epoch: 162 [40960/50000 (91%)]\tLoss: 0.019322, Accuracy: 99.61\n",
      "Train Epoch: 162 [43520/50000 (97%)]\tLoss: 0.018320, Accuracy: 99.61\n",
      "\n",
      "Validation set: Average loss: 0.3484, Accuracy: 4550/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[35.47402238845825 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3933, Accuracy: 9028/10000 (90.28%)\n",
      "\n",
      "Train Epoch: 163 [0/50000 (0%)]\tLoss: 0.020050, Accuracy: 99.61\n",
      "Train Epoch: 163 [2560/50000 (6%)]\tLoss: 0.015254, Accuracy: 99.61\n",
      "Train Epoch: 163 [5120/50000 (11%)]\tLoss: 0.029047, Accuracy: 98.83\n",
      "Train Epoch: 163 [7680/50000 (17%)]\tLoss: 0.025417, Accuracy: 99.41\n",
      "Train Epoch: 163 [10240/50000 (23%)]\tLoss: 0.017379, Accuracy: 99.61\n",
      "Train Epoch: 163 [12800/50000 (28%)]\tLoss: 0.025979, Accuracy: 99.41\n",
      "Train Epoch: 163 [15360/50000 (34%)]\tLoss: 0.060701, Accuracy: 98.05\n",
      "Train Epoch: 163 [17920/50000 (40%)]\tLoss: 0.047172, Accuracy: 98.44\n",
      "Train Epoch: 163 [20480/50000 (45%)]\tLoss: 0.018225, Accuracy: 99.41\n",
      "Train Epoch: 163 [23040/50000 (51%)]\tLoss: 0.018613, Accuracy: 99.22\n",
      "Train Epoch: 163 [25600/50000 (57%)]\tLoss: 0.015413, Accuracy: 99.80\n",
      "Train Epoch: 163 [28160/50000 (62%)]\tLoss: 0.020085, Accuracy: 99.61\n",
      "Train Epoch: 163 [30720/50000 (68%)]\tLoss: 0.037271, Accuracy: 99.02\n",
      "Train Epoch: 163 [33280/50000 (74%)]\tLoss: 0.044819, Accuracy: 98.63\n",
      "Train Epoch: 163 [35840/50000 (80%)]\tLoss: 0.049944, Accuracy: 98.44\n",
      "Train Epoch: 163 [38400/50000 (85%)]\tLoss: 0.016738, Accuracy: 99.41\n",
      "Train Epoch: 163 [40960/50000 (91%)]\tLoss: 0.021581, Accuracy: 99.41\n",
      "Train Epoch: 163 [43520/50000 (97%)]\tLoss: 0.022068, Accuracy: 99.41\n",
      "\n",
      "Validation set: Average loss: 0.3707, Accuracy: 4533/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[38.80419898033142 s]\n",
      "Train Epoch: 164 [0/50000 (0%)]\tLoss: 0.030816, Accuracy: 98.63\n",
      "Train Epoch: 164 [2560/50000 (6%)]\tLoss: 0.011949, Accuracy: 99.80\n",
      "Train Epoch: 164 [5120/50000 (11%)]\tLoss: 0.034343, Accuracy: 99.02\n",
      "Train Epoch: 164 [7680/50000 (17%)]\tLoss: 0.010088, Accuracy: 100.00\n",
      "Train Epoch: 164 [10240/50000 (23%)]\tLoss: 0.016490, Accuracy: 99.41\n",
      "Train Epoch: 164 [12800/50000 (28%)]\tLoss: 0.010423, Accuracy: 99.80\n",
      "Train Epoch: 164 [15360/50000 (34%)]\tLoss: 0.013274, Accuracy: 99.41\n",
      "Train Epoch: 164 [17920/50000 (40%)]\tLoss: 0.029291, Accuracy: 99.22\n",
      "Train Epoch: 164 [20480/50000 (45%)]\tLoss: 0.024980, Accuracy: 99.02\n",
      "Train Epoch: 164 [23040/50000 (51%)]\tLoss: 0.030163, Accuracy: 99.02\n",
      "Train Epoch: 164 [25600/50000 (57%)]\tLoss: 0.021383, Accuracy: 99.41\n",
      "Train Epoch: 164 [28160/50000 (62%)]\tLoss: 0.023529, Accuracy: 99.61\n",
      "Train Epoch: 164 [30720/50000 (68%)]\tLoss: 0.039398, Accuracy: 98.83\n",
      "Train Epoch: 164 [33280/50000 (74%)]\tLoss: 0.021452, Accuracy: 99.41\n",
      "Train Epoch: 164 [35840/50000 (80%)]\tLoss: 0.011321, Accuracy: 100.00\n",
      "Train Epoch: 164 [38400/50000 (85%)]\tLoss: 0.019510, Accuracy: 99.41\n",
      "Train Epoch: 164 [40960/50000 (91%)]\tLoss: 0.037259, Accuracy: 98.44\n",
      "Train Epoch: 164 [43520/50000 (97%)]\tLoss: 0.026273, Accuracy: 98.63\n",
      "\n",
      "Validation set: Average loss: 0.3735, Accuracy: 4532/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[35.47404503822327 s]\n",
      "\n",
      "Test set: Average loss: 0.3685, Accuracy: 9105/10000 (91.05%)\n",
      "\n",
      "Train Epoch: 165 [0/50000 (0%)]\tLoss: 0.046915, Accuracy: 97.85\n",
      "Train Epoch: 165 [2560/50000 (6%)]\tLoss: 0.019926, Accuracy: 99.22\n",
      "Train Epoch: 165 [5120/50000 (11%)]\tLoss: 0.017211, Accuracy: 99.22\n",
      "Train Epoch: 165 [7680/50000 (17%)]\tLoss: 0.017642, Accuracy: 99.61\n",
      "Train Epoch: 165 [10240/50000 (23%)]\tLoss: 0.018915, Accuracy: 99.41\n",
      "Train Epoch: 165 [12800/50000 (28%)]\tLoss: 0.017111, Accuracy: 99.41\n",
      "Train Epoch: 165 [15360/50000 (34%)]\tLoss: 0.012684, Accuracy: 99.61\n",
      "Train Epoch: 165 [17920/50000 (40%)]\tLoss: 0.015323, Accuracy: 99.80\n",
      "Train Epoch: 165 [20480/50000 (45%)]\tLoss: 0.027890, Accuracy: 99.02\n",
      "Train Epoch: 165 [23040/50000 (51%)]\tLoss: 0.025485, Accuracy: 98.83\n",
      "Train Epoch: 165 [25600/50000 (57%)]\tLoss: 0.017220, Accuracy: 99.41\n",
      "Train Epoch: 165 [28160/50000 (62%)]\tLoss: 0.012943, Accuracy: 100.00\n",
      "Train Epoch: 165 [30720/50000 (68%)]\tLoss: 0.030758, Accuracy: 99.41\n",
      "Train Epoch: 165 [33280/50000 (74%)]\tLoss: 0.031334, Accuracy: 99.22\n",
      "Train Epoch: 165 [35840/50000 (80%)]\tLoss: 0.047084, Accuracy: 98.44\n",
      "Train Epoch: 165 [38400/50000 (85%)]\tLoss: 0.021749, Accuracy: 99.02\n",
      "Train Epoch: 165 [40960/50000 (91%)]\tLoss: 0.012864, Accuracy: 99.61\n",
      "Train Epoch: 165 [43520/50000 (97%)]\tLoss: 0.015495, Accuracy: 99.61\n",
      "\n",
      "Validation set: Average loss: 0.3679, Accuracy: 4546/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[39.1515166759491 s]\n",
      "Train Epoch: 166 [0/50000 (0%)]\tLoss: 0.035515, Accuracy: 99.22\n",
      "Train Epoch: 166 [2560/50000 (6%)]\tLoss: 0.019824, Accuracy: 99.41\n",
      "Train Epoch: 166 [5120/50000 (11%)]\tLoss: 0.029299, Accuracy: 99.02\n",
      "Train Epoch: 166 [7680/50000 (17%)]\tLoss: 0.030173, Accuracy: 98.83\n",
      "Train Epoch: 166 [10240/50000 (23%)]\tLoss: 0.009810, Accuracy: 99.61\n",
      "Train Epoch: 166 [12800/50000 (28%)]\tLoss: 0.015983, Accuracy: 99.41\n",
      "Train Epoch: 166 [15360/50000 (34%)]\tLoss: 0.023777, Accuracy: 99.22\n",
      "Train Epoch: 166 [17920/50000 (40%)]\tLoss: 0.030619, Accuracy: 99.41\n",
      "Train Epoch: 166 [20480/50000 (45%)]\tLoss: 0.014503, Accuracy: 99.61\n",
      "Train Epoch: 166 [23040/50000 (51%)]\tLoss: 0.019772, Accuracy: 99.80\n",
      "Train Epoch: 166 [25600/50000 (57%)]\tLoss: 0.029167, Accuracy: 99.41\n",
      "Train Epoch: 166 [28160/50000 (62%)]\tLoss: 0.026767, Accuracy: 99.22\n",
      "Train Epoch: 166 [30720/50000 (68%)]\tLoss: 0.023507, Accuracy: 99.41\n",
      "Train Epoch: 166 [33280/50000 (74%)]\tLoss: 0.032237, Accuracy: 98.63\n",
      "Train Epoch: 166 [35840/50000 (80%)]\tLoss: 0.029607, Accuracy: 99.61\n",
      "Train Epoch: 166 [38400/50000 (85%)]\tLoss: 0.018153, Accuracy: 99.61\n",
      "Train Epoch: 166 [40960/50000 (91%)]\tLoss: 0.034264, Accuracy: 99.41\n",
      "Train Epoch: 166 [43520/50000 (97%)]\tLoss: 0.032825, Accuracy: 98.63\n",
      "\n",
      "Validation set: Average loss: 0.3747, Accuracy: 4552/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[35.74187898635864 s]\n",
      "\n",
      "Test set: Average loss: 0.3916, Accuracy: 9062/10000 (90.62%)\n",
      "\n",
      "Train Epoch: 167 [0/50000 (0%)]\tLoss: 0.021628, Accuracy: 99.41\n",
      "Train Epoch: 167 [2560/50000 (6%)]\tLoss: 0.019551, Accuracy: 99.22\n",
      "Train Epoch: 167 [5120/50000 (11%)]\tLoss: 0.015418, Accuracy: 99.41\n",
      "Train Epoch: 167 [7680/50000 (17%)]\tLoss: 0.022029, Accuracy: 99.02\n",
      "Train Epoch: 167 [10240/50000 (23%)]\tLoss: 0.027636, Accuracy: 99.02\n",
      "Train Epoch: 167 [12800/50000 (28%)]\tLoss: 0.019945, Accuracy: 99.61\n",
      "Train Epoch: 167 [15360/50000 (34%)]\tLoss: 0.027968, Accuracy: 99.41\n",
      "Train Epoch: 167 [17920/50000 (40%)]\tLoss: 0.017830, Accuracy: 99.22\n",
      "Train Epoch: 167 [20480/50000 (45%)]\tLoss: 0.011499, Accuracy: 99.80\n",
      "Train Epoch: 167 [23040/50000 (51%)]\tLoss: 0.013786, Accuracy: 99.80\n",
      "Train Epoch: 167 [25600/50000 (57%)]\tLoss: 0.015800, Accuracy: 99.61\n",
      "Train Epoch: 167 [28160/50000 (62%)]\tLoss: 0.024897, Accuracy: 99.22\n",
      "Train Epoch: 167 [30720/50000 (68%)]\tLoss: 0.022769, Accuracy: 99.41\n",
      "Train Epoch: 167 [33280/50000 (74%)]\tLoss: 0.019452, Accuracy: 99.61\n",
      "Train Epoch: 167 [35840/50000 (80%)]\tLoss: 0.020807, Accuracy: 99.22\n",
      "Train Epoch: 167 [38400/50000 (85%)]\tLoss: 0.021657, Accuracy: 99.41\n",
      "Train Epoch: 167 [40960/50000 (91%)]\tLoss: 0.023155, Accuracy: 98.83\n",
      "Train Epoch: 167 [43520/50000 (97%)]\tLoss: 0.025294, Accuracy: 99.22\n",
      "\n",
      "Validation set: Average loss: 0.3507, Accuracy: 4576/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[38.41432285308838 s]\n",
      "Train Epoch: 168 [0/50000 (0%)]\tLoss: 0.019850, Accuracy: 99.61\n",
      "Train Epoch: 168 [2560/50000 (6%)]\tLoss: 0.022672, Accuracy: 99.02\n",
      "Train Epoch: 168 [5120/50000 (11%)]\tLoss: 0.038742, Accuracy: 98.44\n",
      "Train Epoch: 168 [7680/50000 (17%)]\tLoss: 0.016783, Accuracy: 99.41\n",
      "Train Epoch: 168 [10240/50000 (23%)]\tLoss: 0.025041, Accuracy: 99.22\n",
      "Train Epoch: 168 [12800/50000 (28%)]\tLoss: 0.034951, Accuracy: 98.44\n",
      "Train Epoch: 168 [15360/50000 (34%)]\tLoss: 0.022526, Accuracy: 99.61\n",
      "Train Epoch: 168 [17920/50000 (40%)]\tLoss: 0.011008, Accuracy: 99.80\n",
      "Train Epoch: 168 [20480/50000 (45%)]\tLoss: 0.020847, Accuracy: 99.41\n",
      "Train Epoch: 168 [23040/50000 (51%)]\tLoss: 0.013578, Accuracy: 99.80\n",
      "Train Epoch: 168 [25600/50000 (57%)]\tLoss: 0.018133, Accuracy: 99.61\n",
      "Train Epoch: 168 [28160/50000 (62%)]\tLoss: 0.035625, Accuracy: 99.02\n",
      "Train Epoch: 168 [30720/50000 (68%)]\tLoss: 0.019503, Accuracy: 99.41\n",
      "Train Epoch: 168 [33280/50000 (74%)]\tLoss: 0.026278, Accuracy: 99.02\n",
      "Train Epoch: 168 [35840/50000 (80%)]\tLoss: 0.029786, Accuracy: 98.83\n",
      "Train Epoch: 168 [38400/50000 (85%)]\tLoss: 0.015143, Accuracy: 99.61\n",
      "Train Epoch: 168 [40960/50000 (91%)]\tLoss: 0.022854, Accuracy: 99.41\n",
      "Train Epoch: 168 [43520/50000 (97%)]\tLoss: 0.030606, Accuracy: 99.41\n",
      "\n",
      "Validation set: Average loss: 0.3742, Accuracy: 4558/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[36.1033833026886 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4061, Accuracy: 9061/10000 (90.61%)\n",
      "\n",
      "Train Epoch: 169 [0/50000 (0%)]\tLoss: 0.010147, Accuracy: 99.80\n",
      "Train Epoch: 169 [2560/50000 (6%)]\tLoss: 0.027120, Accuracy: 99.22\n",
      "Train Epoch: 169 [5120/50000 (11%)]\tLoss: 0.016197, Accuracy: 99.61\n",
      "Train Epoch: 169 [7680/50000 (17%)]\tLoss: 0.027600, Accuracy: 98.83\n",
      "Train Epoch: 169 [10240/50000 (23%)]\tLoss: 0.015481, Accuracy: 99.80\n",
      "Train Epoch: 169 [12800/50000 (28%)]\tLoss: 0.020209, Accuracy: 99.41\n",
      "Train Epoch: 169 [15360/50000 (34%)]\tLoss: 0.013598, Accuracy: 99.61\n",
      "Train Epoch: 169 [17920/50000 (40%)]\tLoss: 0.017281, Accuracy: 99.61\n",
      "Train Epoch: 169 [20480/50000 (45%)]\tLoss: 0.035892, Accuracy: 98.63\n",
      "Train Epoch: 169 [23040/50000 (51%)]\tLoss: 0.026522, Accuracy: 99.02\n",
      "Train Epoch: 169 [25600/50000 (57%)]\tLoss: 0.011948, Accuracy: 99.61\n",
      "Train Epoch: 169 [28160/50000 (62%)]\tLoss: 0.021591, Accuracy: 99.41\n",
      "Train Epoch: 169 [30720/50000 (68%)]\tLoss: 0.030090, Accuracy: 99.02\n",
      "Train Epoch: 169 [33280/50000 (74%)]\tLoss: 0.022379, Accuracy: 99.02\n",
      "Train Epoch: 169 [35840/50000 (80%)]\tLoss: 0.019826, Accuracy: 99.22\n",
      "Train Epoch: 169 [38400/50000 (85%)]\tLoss: 0.015880, Accuracy: 99.41\n",
      "Train Epoch: 169 [40960/50000 (91%)]\tLoss: 0.027330, Accuracy: 98.83\n",
      "Train Epoch: 169 [43520/50000 (97%)]\tLoss: 0.018895, Accuracy: 99.22\n",
      "------------------------------\n",
      "before autoscale: torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.0457]],\n",
      "\n",
      "        [[ 0.0992]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0133]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.1118]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0529]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.1702]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[-0.3583]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 512])\n",
      "tensor([[[-0.0164, -0.0355,  0.0000, -0.0048,  0.0000, -0.0401,  0.0000,\n",
      "          -0.0190,  0.0000, -0.0610, -0.0034, -0.0136, -0.0238, -0.0159,\n",
      "          -0.0360, -0.1050, -0.0075, -0.0242, -0.0094, -0.0587, -0.0677,\n",
      "          -0.0608, -0.0596, -0.0042, -0.0350, -0.0351, -0.0426,  0.0000,\n",
      "          -0.0396, -0.0123, -0.0075, -0.0026,  0.0000,  0.0000, -0.0186,\n",
      "           0.0000,  0.0000,  0.0000, -0.0523,  0.0000, -0.0367,  0.0000,\n",
      "          -0.0050, -0.0351, -0.0222, -0.0271,  0.0000, -0.0322, -0.0370,\n",
      "          -0.0769,  0.0000,  0.0000,  0.0000,  0.0000, -0.1064,  0.0000,\n",
      "          -0.0341,  0.0000,  0.0000, -0.0004, -0.0755,  0.0000,  0.0000,\n",
      "           0.0000, -0.0312, -0.0254, -0.0464, -0.0682,  0.0000, -0.0297,\n",
      "          -0.0032,  0.0000, -0.0348,  0.0000,  0.0000, -0.0371, -0.0053,\n",
      "          -0.0659,  0.0000,  0.0000, -0.0210, -0.0310,  0.0000, -0.0056,\n",
      "          -0.0511,  0.0000, -0.0072,  0.0000, -0.0190,  0.0000, -0.0506,\n",
      "          -0.0456, -0.0855, -0.0015,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0205, -0.0479, -0.0101, -0.0109,  0.0000, -0.0411, -0.0490,\n",
      "          -0.0083, -0.0486,  0.0000,  0.0000, -0.0602, -0.1017, -0.0163,\n",
      "          -0.0386,  0.0000,  0.0000, -0.0823, -0.0038,  0.0000,  0.0000,\n",
      "          -0.0099,  0.0000, -0.0204, -0.0140, -0.0674,  0.0000,  0.0000,\n",
      "           0.0000, -0.0015,  0.0000,  0.0000, -0.0611,  0.0000, -0.0224,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0397, -0.0347,\n",
      "           0.0000, -0.0013,  0.0000,  0.0000, -0.0200, -0.0475, -0.0114,\n",
      "          -0.0094, -0.0813, -0.0975,  0.0000, -0.0031, -0.0354, -0.0257,\n",
      "           0.0000,  0.0000, -0.0241, -0.0448,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0859, -0.1063, -0.0504, -0.0771, -0.0014, -0.0380,\n",
      "          -0.0292,  0.0000,  0.0000, -0.0261,  0.0000, -0.0578,  0.0000,\n",
      "          -0.0129, -0.0232, -0.0228, -0.0262,  0.0000,  0.0000, -0.0097,\n",
      "          -0.0551,  0.0000, -0.0042, -0.0443, -0.0357, -0.0059,  0.0000,\n",
      "           0.0000, -0.0113, -0.0166, -0.0233,  0.0000,  0.0000, -0.0341,\n",
      "          -0.0380, -0.0052,  0.0000, -0.0146,  0.0000, -0.0498, -0.0986,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,\n",
      "           0.0000, -0.0111,  0.0000, -0.0106,  0.0000, -0.0240, -0.0985,\n",
      "           0.0000, -0.0353,  0.0000, -0.0276, -0.0543, -0.0419, -0.0725,\n",
      "           0.0000, -0.0139, -0.0005, -0.0506,  0.0000, -0.0130, -0.0742,\n",
      "           0.0000, -0.0226, -0.0197,  0.0000, -0.0070, -0.0486, -0.0157,\n",
      "          -0.0825,  0.0000, -0.0165, -0.0310, -0.0065, -0.0175, -0.0355,\n",
      "           0.0000, -0.0606,  0.0000, -0.0323,  0.0000, -0.0157,  0.0000,\n",
      "           0.0000, -0.0001,  0.0000, -0.0285, -0.0159, -0.0172, -0.0623,\n",
      "          -0.0661, -0.0326,  0.0000, -0.0170, -0.0876,  0.0000, -0.0512,\n",
      "          -0.0055,  0.0000,  0.0000, -0.1119,  0.0000,  0.0000, -0.0191,\n",
      "          -0.0418, -0.0313,  0.0000, -0.0770, -0.0141, -0.0278, -0.1151,\n",
      "          -0.0866, -0.0520,  0.0000,  0.0000, -0.0516, -0.0694,  0.0000,\n",
      "          -0.0206,  0.0000,  0.0000,  0.0000,  0.0000, -0.0179,  0.0000,\n",
      "           0.0000, -0.0156, -0.0172,  0.0000, -0.0666, -0.0124, -0.0219,\n",
      "          -0.0222, -0.0032, -0.0468, -0.0095,  0.0000, -0.0177,  0.0000,\n",
      "          -0.0773, -0.0800,  0.0000, -0.0211, -0.0647, -0.0062,  0.0000,\n",
      "           0.0000,  0.0000, -0.1200,  0.0000, -0.0360,  0.0000, -0.0367,\n",
      "           0.0000, -0.0118, -0.0547,  0.0000,  0.0000, -0.0529, -0.0194,\n",
      "           0.0000, -0.0049,  0.0000, -0.0130, -0.0533, -0.0064,  0.0000,\n",
      "          -0.0107,  0.0000,  0.0000, -0.0182,  0.0000, -0.0063,  0.0000,\n",
      "           0.0000, -0.0171,  0.0000, -0.0902,  0.0000, -0.0008,  0.0000,\n",
      "           0.0000, -0.0570, -0.0666,  0.0000,  0.0000, -0.0106, -0.0239,\n",
      "          -0.0172, -0.0491, -0.0955, -0.0124, -0.0019, -0.0325, -0.0609,\n",
      "           0.0000, -0.0455, -0.0335, -0.0379,  0.0000, -0.0348, -0.0137,\n",
      "          -0.0003, -0.0581,  0.0000,  0.0000, -0.0160,  0.0000, -0.0671,\n",
      "          -0.0213,  0.0000,  0.0000, -0.0226, -0.0388,  0.0000,  0.0000,\n",
      "           0.0000, -0.0077, -0.0054, -0.0443, -0.0082,  0.0000,  0.0000,\n",
      "           0.0000, -0.0280,  0.0000, -0.0363,  0.0000, -0.0672, -0.0228,\n",
      "          -0.0864, -0.0259,  0.0000, -0.0356, -0.0141, -0.0251,  0.0000,\n",
      "          -0.0252, -0.0115,  0.0000,  0.0000, -0.0111, -0.0570,  0.0000,\n",
      "          -0.0600, -0.0311, -0.0605, -0.0108, -0.0100,  0.0000,  0.0000,\n",
      "           0.0000, -0.0776,  0.0000,  0.0000,  0.0000, -0.0351, -0.0124,\n",
      "          -0.0029, -0.0562,  0.0000, -0.0614, -0.0387, -0.0144, -0.0552,\n",
      "          -0.0000,  0.0000, -0.0195, -0.0487,  0.0000,  0.0000, -0.0661,\n",
      "          -0.0067,  0.0000,  0.0000,  0.0000,  0.0000, -0.0166,  0.0000,\n",
      "           0.0000,  0.0000, -0.0610,  0.0000, -0.0641,  0.0000,  0.0000,\n",
      "           0.0000, -0.0167,  0.0000,  0.0000, -0.0106, -0.0132, -0.0713,\n",
      "          -0.0030,  0.0000, -0.0448,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0504,  0.0000,  0.0000, -0.0152, -0.0186,  0.0000, -0.0769,\n",
      "           0.0000,  0.0000, -0.0576,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0437, -0.0311, -0.0000,  0.0000, -0.0889, -0.0790,\n",
      "           0.0000, -0.0599, -0.0142, -0.0323, -0.0291, -0.0112, -0.0278,\n",
      "          -0.0081,  0.0000,  0.0000, -0.0990,  0.0000, -0.0519, -0.0425,\n",
      "          -0.0426,  0.0000,  0.0000, -0.0560,  0.0000, -0.0255,  0.0000,\n",
      "          -0.0120]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-02 *\n",
      "       [[ 2.7089,  2.2456,  0.3877,  5.0241,  1.7666,  4.5965,  3.9820,\n",
      "          0.7897, -1.9787]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 448, 512])\n",
      "tensor([[-1.9608e-03, -8.4732e-04, -2.3849e-03,  ..., -1.1469e-03,\n",
      "         -3.0925e-03, -1.8288e-03],\n",
      "        [-4.2088e-06,  5.8491e-06, -3.1792e-06,  ..., -2.9019e-06,\n",
      "         -2.2457e-05,  6.8540e-06],\n",
      "        [ 6.7766e-06,  1.0322e-05,  2.5820e-05,  ...,  2.5681e-05,\n",
      "          1.1456e-05,  8.8838e-06],\n",
      "        ...,\n",
      "        [-5.1287e-05, -1.0404e-04, -9.6323e-05,  ..., -8.6215e-05,\n",
      "         -1.2716e-04, -1.4364e-04],\n",
      "        [-2.4480e-05, -4.4271e-05, -2.0970e-05,  ..., -3.8614e-05,\n",
      "         -1.2358e-05, -5.2945e-05],\n",
      "        [ 4.5211e-06,  1.0358e-05,  2.0717e-05,  ...,  2.4839e-05,\n",
      "         -4.9692e-06,  2.0261e-05]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 448, 512])\n",
      "tensor([[-1.9608e-04, -8.4732e-05, -2.3849e-04,  ..., -1.1469e-04,\n",
      "         -3.0924e-04, -1.8288e-04],\n",
      "        [-4.2088e-07,  5.8491e-07, -3.1792e-07,  ..., -2.9019e-07,\n",
      "         -2.2457e-06,  6.8540e-07],\n",
      "        [ 6.7766e-07,  1.0322e-06,  2.5820e-06,  ...,  2.5681e-06,\n",
      "          1.1456e-06,  8.8838e-07],\n",
      "        ...,\n",
      "        [-8.5444e-05, -1.7192e-04, -2.0904e-04,  ..., -1.7461e-04,\n",
      "         -1.8483e-04, -1.3773e-04],\n",
      "        [ 1.4793e-06, -5.1319e-07,  3.8832e-06,  ...,  2.9027e-07,\n",
      "          4.5134e-06,  3.0564e-06],\n",
      "        [-8.6440e-07,  1.1102e-06,  1.6599e-06,  ...,  5.8929e-07,\n",
      "          7.9045e-07,  7.9549e-07]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.3728, Accuracy: 4578/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[40.376749992370605 s]\n",
      "Train Epoch: 170 [0/50000 (0%)]\tLoss: 0.020733, Accuracy: 99.41\n",
      "Train Epoch: 170 [2560/50000 (6%)]\tLoss: 0.015705, Accuracy: 99.41\n",
      "Train Epoch: 170 [5120/50000 (11%)]\tLoss: 0.030124, Accuracy: 99.22\n",
      "Train Epoch: 170 [7680/50000 (17%)]\tLoss: 0.013446, Accuracy: 99.41\n",
      "Train Epoch: 170 [10240/50000 (23%)]\tLoss: 0.009612, Accuracy: 99.61\n",
      "Train Epoch: 170 [12800/50000 (28%)]\tLoss: 0.007424, Accuracy: 100.00\n",
      "Train Epoch: 170 [15360/50000 (34%)]\tLoss: 0.016319, Accuracy: 99.80\n",
      "Train Epoch: 170 [17920/50000 (40%)]\tLoss: 0.011144, Accuracy: 99.61\n",
      "Train Epoch: 170 [20480/50000 (45%)]\tLoss: 0.032990, Accuracy: 98.44\n",
      "Train Epoch: 170 [23040/50000 (51%)]\tLoss: 0.024672, Accuracy: 99.22\n",
      "Train Epoch: 170 [25600/50000 (57%)]\tLoss: 0.022250, Accuracy: 99.41\n",
      "Train Epoch: 170 [28160/50000 (62%)]\tLoss: 0.005851, Accuracy: 99.80\n",
      "Train Epoch: 170 [30720/50000 (68%)]\tLoss: 0.024407, Accuracy: 99.22\n",
      "Train Epoch: 170 [33280/50000 (74%)]\tLoss: 0.049988, Accuracy: 98.05\n",
      "Train Epoch: 170 [35840/50000 (80%)]\tLoss: 0.029177, Accuracy: 98.83\n",
      "Train Epoch: 170 [38400/50000 (85%)]\tLoss: 0.017380, Accuracy: 99.41\n",
      "Train Epoch: 170 [40960/50000 (91%)]\tLoss: 0.015953, Accuracy: 99.61\n",
      "Train Epoch: 170 [43520/50000 (97%)]\tLoss: 0.021939, Accuracy: 99.02\n",
      "\n",
      "Validation set: Average loss: 0.3856, Accuracy: 4537/5000 (90.00%)\n",
      "\n",
      "the time of this epoch:[35.32252359390259 s]\n",
      "\n",
      "Test set: Average loss: 0.3973, Accuracy: 9089/10000 (90.89%)\n",
      "\n",
      "Train Epoch: 171 [0/50000 (0%)]\tLoss: 0.017423, Accuracy: 99.80\n",
      "Train Epoch: 171 [2560/50000 (6%)]\tLoss: 0.023597, Accuracy: 98.83\n",
      "Train Epoch: 171 [5120/50000 (11%)]\tLoss: 0.011150, Accuracy: 99.61\n",
      "Train Epoch: 171 [7680/50000 (17%)]\tLoss: 0.010566, Accuracy: 99.80\n",
      "Train Epoch: 171 [10240/50000 (23%)]\tLoss: 0.022279, Accuracy: 99.41\n",
      "Train Epoch: 171 [12800/50000 (28%)]\tLoss: 0.028067, Accuracy: 99.22\n",
      "Train Epoch: 171 [15360/50000 (34%)]\tLoss: 0.009859, Accuracy: 99.80\n",
      "Train Epoch: 171 [17920/50000 (40%)]\tLoss: 0.021373, Accuracy: 99.41\n",
      "Train Epoch: 171 [20480/50000 (45%)]\tLoss: 0.015309, Accuracy: 99.61\n",
      "Train Epoch: 171 [23040/50000 (51%)]\tLoss: 0.019728, Accuracy: 99.02\n",
      "Train Epoch: 171 [25600/50000 (57%)]\tLoss: 0.025885, Accuracy: 99.41\n",
      "Train Epoch: 171 [28160/50000 (62%)]\tLoss: 0.014959, Accuracy: 99.80\n",
      "Train Epoch: 171 [30720/50000 (68%)]\tLoss: 0.014606, Accuracy: 99.41\n",
      "Train Epoch: 171 [33280/50000 (74%)]\tLoss: 0.015758, Accuracy: 99.61\n",
      "Train Epoch: 171 [35840/50000 (80%)]\tLoss: 0.026781, Accuracy: 99.22\n",
      "Train Epoch: 171 [38400/50000 (85%)]\tLoss: 0.017261, Accuracy: 99.61\n",
      "Train Epoch: 171 [40960/50000 (91%)]\tLoss: 0.018648, Accuracy: 99.02\n",
      "Train Epoch: 171 [43520/50000 (97%)]\tLoss: 0.015911, Accuracy: 99.61\n",
      "\n",
      "Validation set: Average loss: 0.3743, Accuracy: 4560/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[39.59134006500244 s]\n",
      "Train Epoch: 172 [0/50000 (0%)]\tLoss: 0.021899, Accuracy: 99.41\n",
      "Train Epoch: 172 [2560/50000 (6%)]\tLoss: 0.019931, Accuracy: 99.22\n",
      "Train Epoch: 172 [5120/50000 (11%)]\tLoss: 0.009226, Accuracy: 100.00\n",
      "Train Epoch: 172 [7680/50000 (17%)]\tLoss: 0.024905, Accuracy: 99.22\n",
      "Train Epoch: 172 [10240/50000 (23%)]\tLoss: 0.023719, Accuracy: 99.22\n",
      "Train Epoch: 172 [12800/50000 (28%)]\tLoss: 0.010567, Accuracy: 99.41\n",
      "Train Epoch: 172 [15360/50000 (34%)]\tLoss: 0.023493, Accuracy: 99.41\n",
      "Train Epoch: 172 [17920/50000 (40%)]\tLoss: 0.012952, Accuracy: 99.61\n",
      "Train Epoch: 172 [20480/50000 (45%)]\tLoss: 0.006495, Accuracy: 99.80\n",
      "Train Epoch: 172 [23040/50000 (51%)]\tLoss: 0.038071, Accuracy: 99.02\n",
      "Train Epoch: 172 [25600/50000 (57%)]\tLoss: 0.011714, Accuracy: 99.61\n",
      "Train Epoch: 172 [28160/50000 (62%)]\tLoss: 0.023685, Accuracy: 99.22\n",
      "Train Epoch: 172 [30720/50000 (68%)]\tLoss: 0.012908, Accuracy: 99.80\n",
      "Train Epoch: 172 [33280/50000 (74%)]\tLoss: 0.007727, Accuracy: 100.00\n",
      "Train Epoch: 172 [35840/50000 (80%)]\tLoss: 0.031863, Accuracy: 99.22\n",
      "Train Epoch: 172 [38400/50000 (85%)]\tLoss: 0.011704, Accuracy: 99.61\n",
      "Train Epoch: 172 [40960/50000 (91%)]\tLoss: 0.034962, Accuracy: 99.22\n",
      "Train Epoch: 172 [43520/50000 (97%)]\tLoss: 0.005100, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3588, Accuracy: 4582/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[36.761168479919434 s]\n",
      "\n",
      "Test set: Average loss: 0.3978, Accuracy: 9056/10000 (90.56%)\n",
      "\n",
      "Train Epoch: 173 [0/50000 (0%)]\tLoss: 0.019989, Accuracy: 99.41\n",
      "Train Epoch: 173 [2560/50000 (6%)]\tLoss: 0.014924, Accuracy: 99.61\n",
      "Train Epoch: 173 [5120/50000 (11%)]\tLoss: 0.022396, Accuracy: 99.41\n",
      "Train Epoch: 173 [7680/50000 (17%)]\tLoss: 0.022493, Accuracy: 99.02\n",
      "Train Epoch: 173 [10240/50000 (23%)]\tLoss: 0.016667, Accuracy: 99.22\n",
      "Train Epoch: 173 [12800/50000 (28%)]\tLoss: 0.015914, Accuracy: 99.61\n",
      "Train Epoch: 173 [15360/50000 (34%)]\tLoss: 0.019692, Accuracy: 99.02\n",
      "Train Epoch: 173 [17920/50000 (40%)]\tLoss: 0.012885, Accuracy: 99.41\n",
      "Train Epoch: 173 [20480/50000 (45%)]\tLoss: 0.027673, Accuracy: 99.22\n",
      "Train Epoch: 173 [23040/50000 (51%)]\tLoss: 0.007801, Accuracy: 100.00\n",
      "Train Epoch: 173 [25600/50000 (57%)]\tLoss: 0.030503, Accuracy: 98.63\n",
      "Train Epoch: 173 [28160/50000 (62%)]\tLoss: 0.012844, Accuracy: 99.61\n",
      "Train Epoch: 173 [30720/50000 (68%)]\tLoss: 0.006694, Accuracy: 99.80\n",
      "Train Epoch: 173 [33280/50000 (74%)]\tLoss: 0.031979, Accuracy: 99.02\n",
      "Train Epoch: 173 [35840/50000 (80%)]\tLoss: 0.014514, Accuracy: 99.61\n",
      "Train Epoch: 173 [38400/50000 (85%)]\tLoss: 0.009551, Accuracy: 100.00\n",
      "Train Epoch: 173 [40960/50000 (91%)]\tLoss: 0.018906, Accuracy: 99.61\n",
      "Train Epoch: 173 [43520/50000 (97%)]\tLoss: 0.022626, Accuracy: 99.22\n",
      "\n",
      "Validation set: Average loss: 0.3902, Accuracy: 4565/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[38.93568563461304 s]\n",
      "Train Epoch: 174 [0/50000 (0%)]\tLoss: 0.021287, Accuracy: 99.02\n",
      "Train Epoch: 174 [2560/50000 (6%)]\tLoss: 0.013403, Accuracy: 99.61\n",
      "Train Epoch: 174 [5120/50000 (11%)]\tLoss: 0.016751, Accuracy: 99.61\n",
      "Train Epoch: 174 [7680/50000 (17%)]\tLoss: 0.011678, Accuracy: 99.61\n",
      "Train Epoch: 174 [10240/50000 (23%)]\tLoss: 0.015130, Accuracy: 99.61\n",
      "Train Epoch: 174 [12800/50000 (28%)]\tLoss: 0.031223, Accuracy: 98.83\n",
      "Train Epoch: 174 [15360/50000 (34%)]\tLoss: 0.012653, Accuracy: 99.41\n",
      "Train Epoch: 174 [17920/50000 (40%)]\tLoss: 0.013608, Accuracy: 99.80\n",
      "Train Epoch: 174 [20480/50000 (45%)]\tLoss: 0.016935, Accuracy: 99.22\n",
      "Train Epoch: 174 [23040/50000 (51%)]\tLoss: 0.036821, Accuracy: 99.22\n",
      "Train Epoch: 174 [25600/50000 (57%)]\tLoss: 0.020901, Accuracy: 99.41\n",
      "Train Epoch: 174 [28160/50000 (62%)]\tLoss: 0.029547, Accuracy: 99.02\n",
      "Train Epoch: 174 [30720/50000 (68%)]\tLoss: 0.020632, Accuracy: 99.61\n",
      "Train Epoch: 174 [33280/50000 (74%)]\tLoss: 0.016270, Accuracy: 99.22\n",
      "Train Epoch: 174 [35840/50000 (80%)]\tLoss: 0.009909, Accuracy: 99.80\n",
      "Train Epoch: 174 [38400/50000 (85%)]\tLoss: 0.011866, Accuracy: 99.61\n",
      "Train Epoch: 174 [40960/50000 (91%)]\tLoss: 0.018382, Accuracy: 99.41\n",
      "Train Epoch: 174 [43520/50000 (97%)]\tLoss: 0.032315, Accuracy: 98.63\n",
      "\n",
      "Validation set: Average loss: 0.3694, Accuracy: 4579/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[35.158034801483154 s]\n",
      "\n",
      "Test set: Average loss: 0.3819, Accuracy: 9136/10000 (91.36%)\n",
      "\n",
      "Train Epoch: 175 [0/50000 (0%)]\tLoss: 0.016520, Accuracy: 99.41\n",
      "Train Epoch: 175 [2560/50000 (6%)]\tLoss: 0.015486, Accuracy: 99.61\n",
      "Train Epoch: 175 [5120/50000 (11%)]\tLoss: 0.006905, Accuracy: 100.00\n",
      "Train Epoch: 175 [7680/50000 (17%)]\tLoss: 0.015081, Accuracy: 99.61\n",
      "Train Epoch: 175 [10240/50000 (23%)]\tLoss: 0.013344, Accuracy: 99.80\n",
      "Train Epoch: 175 [12800/50000 (28%)]\tLoss: 0.015262, Accuracy: 99.61\n",
      "Train Epoch: 175 [15360/50000 (34%)]\tLoss: 0.010795, Accuracy: 99.41\n",
      "Train Epoch: 175 [17920/50000 (40%)]\tLoss: 0.010503, Accuracy: 99.61\n",
      "Train Epoch: 175 [20480/50000 (45%)]\tLoss: 0.018100, Accuracy: 99.22\n",
      "Train Epoch: 175 [23040/50000 (51%)]\tLoss: 0.006850, Accuracy: 100.00\n",
      "Train Epoch: 175 [25600/50000 (57%)]\tLoss: 0.010353, Accuracy: 99.41\n",
      "Train Epoch: 175 [28160/50000 (62%)]\tLoss: 0.029409, Accuracy: 98.83\n",
      "Train Epoch: 175 [30720/50000 (68%)]\tLoss: 0.029218, Accuracy: 99.02\n",
      "Train Epoch: 175 [33280/50000 (74%)]\tLoss: 0.020581, Accuracy: 99.61\n",
      "Train Epoch: 175 [35840/50000 (80%)]\tLoss: 0.012910, Accuracy: 99.80\n",
      "Train Epoch: 175 [38400/50000 (85%)]\tLoss: 0.014076, Accuracy: 99.80\n",
      "Train Epoch: 175 [40960/50000 (91%)]\tLoss: 0.026087, Accuracy: 99.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "before autoscale: torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.0000]],\n",
      "\n",
      "        [[ 0.3003]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0640]],\n",
      "\n",
      "        [[ 0.0274]],\n",
      "\n",
      "        [[ 0.4209]],\n",
      "\n",
      "        [[ 0.0053]],\n",
      "\n",
      "        [[ 0.2747]],\n",
      "\n",
      "        [[ 0.3996]],\n",
      "\n",
      "        [[ 0.2354]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[-0.2557]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 512])\n",
      "tensor([[[ 0.0000, -0.0768,  0.0000, -0.0164, -0.0070, -0.1076, -0.0014,\n",
      "          -0.0703, -0.1022, -0.0602, -0.0654,  0.0000, -0.0644, -0.0578,\n",
      "           0.0000,  0.0000, -0.0791, -0.0085,  0.0000, -0.0770, -0.0410,\n",
      "          -0.0666, -0.0885, -0.0163, -0.0555, -0.0900, -0.0074, -0.0374,\n",
      "           0.0000, -0.0226, -0.0653, -0.0477, -0.0094, -0.0033, -0.0190,\n",
      "          -0.0491, -0.0781,  0.0000,  0.0000, -0.0013, -0.0836, -0.0038,\n",
      "          -0.0925, -0.0757, -0.0154, -0.0855, -0.0091, -0.0477, -0.0040,\n",
      "          -0.0849, -0.0012, -0.0848, -0.0054, -0.1129, -0.0936, -0.0786,\n",
      "           0.0000,  0.0000,  0.0000, -0.0027, -0.0725, -0.0717, -0.0684,\n",
      "          -0.0118, -0.0166, -0.0136, -0.0071, -0.0001, -0.0022, -0.0056,\n",
      "          -0.0026,  0.0000,  0.0000,  0.0000, -0.0021,  0.0000, -0.0001,\n",
      "          -0.0008, -0.0006, -0.0011, -0.0012, -0.0027, -0.0011,  0.0000,\n",
      "          -0.0015, -0.0016, -0.0001,  0.0000, -0.0001,  0.0000,  0.0000,\n",
      "          -0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0039,  0.0000,\n",
      "          -0.0001, -0.0001, -0.0002, -0.0002,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0049,  0.0000,  0.0000,  0.0000,  0.0000, -0.0001,\n",
      "          -0.0004,  0.0000,  0.0000,  0.0000, -0.0052,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
      "          -0.0001, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,\n",
      "           0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
      "           0.0000, -0.0008,  0.0000,  0.0000, -0.0009, -0.0023,  0.0000,\n",
      "          -0.0041,  0.0000,  0.0000, -0.0005,  0.0000, -0.0089, -0.0094,\n",
      "          -0.0008, -0.0011,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000, -0.0004,  0.0000,  0.0000, -0.0016, -0.0008,\n",
      "          -0.0003, -0.0003, -0.0004,  0.0000, -0.0010, -0.0008, -0.0011,\n",
      "          -0.0014, -0.0030, -0.0013,  0.0000, -0.0032, -0.0032, -0.0019,\n",
      "           0.0000, -0.0041,  0.0000,  0.0000, -0.0022, -0.0029, -0.0001,\n",
      "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0001,\n",
      "           0.0000,  0.0000,  0.0000, -0.0001, -0.0039,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000, -0.0009, -0.0018, -0.0008,  0.0000, -0.0010,\n",
      "           0.0000,  0.0000, -0.0000, -0.0001,  0.0000, -0.0000,  0.0000,\n",
      "          -0.0000, -0.0001, -0.0001, -0.0000, -0.0000,  0.0000, -0.0000,\n",
      "          -0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
      "          -0.0000,  0.0000,  0.0000, -0.0013, -0.0017, -0.0053,  0.0000,\n",
      "           0.0000,  0.0000, -0.0021, -0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0000, -0.0000, -0.0001, -0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0000, -0.0002,  0.0000, -0.0002, -0.0001, -0.0002,  0.0000,\n",
      "          -0.0010, -0.0016, -0.0018, -0.0198,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0019, -0.0000, -0.0000, -0.0000,  0.0000, -0.0002,  0.0000,\n",
      "          -0.0017, -0.0029, -0.0026, -0.0071, -0.0025, -0.0025, -0.0032,\n",
      "          -0.0034, -0.0008, -0.0007,  0.0000, -0.0020, -0.0040, -0.0027,\n",
      "          -0.0047, -0.0028, -0.0029,  0.0000, -0.0029, -0.0005, -0.0008,\n",
      "           0.0000, -0.0019, -0.0008, -0.0008, -0.0012,  0.0000, -0.0001,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0039, -0.0015,  0.0000,  0.0000, -0.0038, -0.0011,  0.0000,\n",
      "          -0.0000, -0.0006,  0.0000, -0.0007,  0.0000,  0.0000, -0.0004,\n",
      "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0001,\n",
      "           0.0000, -0.0007, -0.0015, -0.0014, -0.0129, -0.0017, -0.0014,\n",
      "           0.0000, -0.0028, -0.0018, -0.0029,  0.0000,  0.0000, -0.0013,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0001,  0.0000,  0.0000,\n",
      "          -0.0011, -0.0014,  0.0000, -0.0038,  0.0000, -0.0013, -0.0018,\n",
      "          -0.0026,  0.0000, -0.0004, -0.0004, -0.0021, -0.0006, -0.0004,\n",
      "           0.0000, -0.0006, -0.0001, -0.0001, -0.0000, -0.0000, -0.0000,\n",
      "           0.0000, -0.0001,  0.0000, -0.0000, -0.0006,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0001, -0.0000,  0.0000,\n",
      "          -0.0000, -0.0001, -0.0000, -0.0000, -0.0005, -0.0004, -0.0004,\n",
      "          -0.0006,  0.0000, -0.0003,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0032,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0032,\n",
      "          -0.0041,  0.0000, -0.0011,  0.0000, -0.0021, -0.0000, -0.0000,\n",
      "           0.0000, -0.0001,  0.0000,  0.0000, -0.0047,  0.0000, -0.2027,\n",
      "          -0.0043,  0.0000, -0.0041,  0.0000, -0.0068,  0.0000, -0.0029,\n",
      "          -0.0020,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
      "           0.0000,  0.0000, -0.0001, -0.0001,  0.0000, -0.0002, -0.0000,\n",
      "          -0.0000, -0.0001,  0.0000,  0.0000,  0.0000, -0.0003, -0.0004,\n",
      "           0.0000, -0.0008, -0.0020, -0.0012, -0.0014,  0.0000,  0.0000,\n",
      "           0.0000, -0.0009,  0.0000, -0.0000, -0.0001,  0.0000, -0.0001,\n",
      "          -0.0001,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0043,\n",
      "           0.0000, -0.0016, -0.0022,  0.0000, -0.0006,  0.0000, -0.0006,\n",
      "          -0.0007, -0.0018,  0.0000, -0.0017,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0067, -0.0007,  0.0000,  0.0000,  0.0000, -0.0008,\n",
      "          -0.0009, -0.0031,  0.0000, -0.0008,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0000, -0.0002, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0037, -0.0005, -0.0021,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-04 *\n",
      "       [[ 1.1646,  2.0053,  0.5187,  1.2232,  2.5130, -1.2222,  4.0002,\n",
      "          3.4400, -1.0839]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 448, 512])\n",
      "tensor([[ 4.5149e-06, -1.6582e-05, -4.7070e-05,  ..., -6.3460e-07,\n",
      "         -4.8204e-07, -2.4760e-07],\n",
      "        [-1.7071e-05,  2.2000e-05, -1.1519e-05,  ...,  1.9214e-06,\n",
      "          9.2429e-07,  7.9473e-07],\n",
      "        [ 3.0091e-05,  1.5336e-05,  2.2352e-06,  ...,  8.3038e-07,\n",
      "          6.2520e-07,  4.8975e-08],\n",
      "        ...,\n",
      "        [ 6.9362e-07,  3.7107e-05,  1.4256e-06,  ...,  1.9093e-06,\n",
      "          3.6735e-07,  8.7665e-07],\n",
      "        [ 3.1511e-05, -1.3331e-05,  2.3573e-05,  ..., -1.6362e-06,\n",
      "         -9.5782e-08, -7.3516e-07],\n",
      "        [-2.9999e-05, -1.9632e-05, -1.2152e-06,  ..., -1.1768e-06,\n",
      "         -6.2949e-07, -5.8962e-07]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 448, 512])\n",
      "tensor([[ 4.5149e-07, -1.6582e-06, -4.7070e-06,  ..., -6.3460e-08,\n",
      "         -4.8204e-08, -2.4760e-08],\n",
      "        [-1.7071e-06,  2.2000e-06, -1.1519e-06,  ...,  1.9214e-07,\n",
      "          9.2429e-08,  7.9473e-08],\n",
      "        [ 3.0091e-06,  1.5336e-06,  2.2352e-07,  ...,  8.3038e-08,\n",
      "          6.2520e-08,  4.8975e-09],\n",
      "        ...,\n",
      "        [-5.8147e-06, -1.4224e-05, -1.1671e-05,  ..., -9.1793e-08,\n",
      "         -4.4839e-08, -4.3277e-08],\n",
      "        [-1.0682e-04, -1.9837e-04, -2.1289e-04,  ..., -5.2476e-06,\n",
      "         -1.5749e-06, -1.7901e-06],\n",
      "        [-2.3140e-06, -6.4211e-06, -6.9313e-06,  ..., -1.6505e-07,\n",
      "         -7.6105e-08, -4.1170e-08]], device='cuda:0')\n",
      "Train Epoch: 175 [43520/50000 (97%)]\tLoss: 0.025412, Accuracy: 98.83\n",
      "\n",
      "Validation set: Average loss: 0.3932, Accuracy: 4560/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[38.46636700630188 s]\n",
      "Train Epoch: 176 [0/50000 (0%)]\tLoss: 0.012021, Accuracy: 99.41\n",
      "Train Epoch: 176 [2560/50000 (6%)]\tLoss: 0.016686, Accuracy: 99.41\n",
      "Train Epoch: 176 [5120/50000 (11%)]\tLoss: 0.019111, Accuracy: 99.02\n",
      "Train Epoch: 176 [7680/50000 (17%)]\tLoss: 0.011359, Accuracy: 99.61\n",
      "Train Epoch: 176 [10240/50000 (23%)]\tLoss: 0.016830, Accuracy: 99.41\n",
      "Train Epoch: 176 [12800/50000 (28%)]\tLoss: 0.008528, Accuracy: 99.80\n",
      "Train Epoch: 176 [15360/50000 (34%)]\tLoss: 0.006244, Accuracy: 100.00\n",
      "Train Epoch: 176 [17920/50000 (40%)]\tLoss: 0.031588, Accuracy: 99.02\n",
      "Train Epoch: 176 [20480/50000 (45%)]\tLoss: 0.009208, Accuracy: 99.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 176 [23040/50000 (51%)]\tLoss: 0.006680, Accuracy: 99.80\n",
      "Train Epoch: 176 [25600/50000 (57%)]\tLoss: 0.015048, Accuracy: 99.41\n",
      "Train Epoch: 176 [28160/50000 (62%)]\tLoss: 0.012433, Accuracy: 99.41\n",
      "Train Epoch: 176 [30720/50000 (68%)]\tLoss: 0.014914, Accuracy: 99.61\n",
      "Train Epoch: 176 [33280/50000 (74%)]\tLoss: 0.005714, Accuracy: 99.80\n",
      "Train Epoch: 176 [35840/50000 (80%)]\tLoss: 0.018124, Accuracy: 99.61\n",
      "Train Epoch: 176 [38400/50000 (85%)]\tLoss: 0.007934, Accuracy: 99.61\n",
      "Train Epoch: 176 [40960/50000 (91%)]\tLoss: 0.012134, Accuracy: 99.61\n",
      "Train Epoch: 176 [43520/50000 (97%)]\tLoss: 0.025501, Accuracy: 99.22\n",
      "\n",
      "Validation set: Average loss: 0.3797, Accuracy: 4571/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[35.113646507263184 s]\n",
      "\n",
      "Test set: Average loss: 0.3981, Accuracy: 9091/10000 (90.91%)\n",
      "\n",
      "Train Epoch: 177 [0/50000 (0%)]\tLoss: 0.009257, Accuracy: 99.80\n",
      "Train Epoch: 177 [2560/50000 (6%)]\tLoss: 0.012737, Accuracy: 99.80\n",
      "Train Epoch: 177 [5120/50000 (11%)]\tLoss: 0.012600, Accuracy: 99.61\n",
      "Train Epoch: 177 [7680/50000 (17%)]\tLoss: 0.015857, Accuracy: 99.61\n",
      "Train Epoch: 177 [10240/50000 (23%)]\tLoss: 0.028376, Accuracy: 98.83\n",
      "Train Epoch: 177 [12800/50000 (28%)]\tLoss: 0.011071, Accuracy: 99.80\n",
      "Train Epoch: 177 [15360/50000 (34%)]\tLoss: 0.013779, Accuracy: 99.41\n",
      "Train Epoch: 177 [17920/50000 (40%)]\tLoss: 0.008491, Accuracy: 100.00\n",
      "Train Epoch: 177 [20480/50000 (45%)]\tLoss: 0.021022, Accuracy: 99.41\n",
      "Train Epoch: 177 [23040/50000 (51%)]\tLoss: 0.018581, Accuracy: 99.41\n",
      "Train Epoch: 177 [25600/50000 (57%)]\tLoss: 0.015931, Accuracy: 99.61\n",
      "Train Epoch: 177 [28160/50000 (62%)]\tLoss: 0.018301, Accuracy: 99.22\n",
      "Train Epoch: 177 [30720/50000 (68%)]\tLoss: 0.017880, Accuracy: 99.22\n",
      "Train Epoch: 177 [33280/50000 (74%)]\tLoss: 0.018788, Accuracy: 99.41\n",
      "Train Epoch: 177 [35840/50000 (80%)]\tLoss: 0.009732, Accuracy: 99.80\n",
      "Train Epoch: 177 [38400/50000 (85%)]\tLoss: 0.017897, Accuracy: 99.41\n",
      "Train Epoch: 177 [40960/50000 (91%)]\tLoss: 0.007062, Accuracy: 99.80\n",
      "Train Epoch: 177 [43520/50000 (97%)]\tLoss: 0.011407, Accuracy: 99.61\n",
      "\n",
      "Validation set: Average loss: 0.3702, Accuracy: 4609/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[38.437599182128906 s]\n",
      "Train Epoch: 178 [0/50000 (0%)]\tLoss: 0.006682, Accuracy: 99.80\n",
      "Train Epoch: 178 [2560/50000 (6%)]\tLoss: 0.006529, Accuracy: 100.00\n",
      "Train Epoch: 178 [5120/50000 (11%)]\tLoss: 0.007311, Accuracy: 100.00\n",
      "Train Epoch: 178 [7680/50000 (17%)]\tLoss: 0.017316, Accuracy: 99.22\n",
      "Train Epoch: 178 [10240/50000 (23%)]\tLoss: 0.022415, Accuracy: 99.61\n",
      "Train Epoch: 178 [12800/50000 (28%)]\tLoss: 0.011768, Accuracy: 99.80\n",
      "Train Epoch: 178 [15360/50000 (34%)]\tLoss: 0.007323, Accuracy: 99.80\n",
      "Train Epoch: 178 [17920/50000 (40%)]\tLoss: 0.019114, Accuracy: 99.61\n",
      "Train Epoch: 178 [20480/50000 (45%)]\tLoss: 0.013419, Accuracy: 99.61\n",
      "Train Epoch: 178 [23040/50000 (51%)]\tLoss: 0.015568, Accuracy: 99.61\n",
      "Train Epoch: 178 [25600/50000 (57%)]\tLoss: 0.019261, Accuracy: 99.22\n",
      "Train Epoch: 178 [28160/50000 (62%)]\tLoss: 0.016871, Accuracy: 99.22\n",
      "Train Epoch: 178 [30720/50000 (68%)]\tLoss: 0.012025, Accuracy: 99.61\n",
      "Train Epoch: 178 [33280/50000 (74%)]\tLoss: 0.005582, Accuracy: 100.00\n",
      "Train Epoch: 178 [35840/50000 (80%)]\tLoss: 0.020680, Accuracy: 99.61\n",
      "Train Epoch: 178 [38400/50000 (85%)]\tLoss: 0.008918, Accuracy: 99.80\n",
      "Train Epoch: 178 [40960/50000 (91%)]\tLoss: 0.020719, Accuracy: 99.22\n",
      "Train Epoch: 178 [43520/50000 (97%)]\tLoss: 0.007160, Accuracy: 99.80\n",
      "\n",
      "Validation set: Average loss: 0.3823, Accuracy: 4571/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[35.3431613445282 s]\n",
      "------------------------------\n",
      "before autoscale: torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.0000]],\n",
      "\n",
      "        [[ 0.0008]],\n",
      "\n",
      "        [[ 0.0154]],\n",
      "\n",
      "        [[ 0.0079]],\n",
      "\n",
      "        [[ 0.0602]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.4160]],\n",
      "\n",
      "        [[ 0.0015]],\n",
      "\n",
      "        [[ 0.0079]],\n",
      "\n",
      "        [[ 0.0014]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[ 0.3305]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 512])\n",
      "tensor([[[ 0.0000,  0.0003,  0.0051,  0.0026,  0.0199,  0.0000,  0.1375,\n",
      "           0.0005,  0.0026,  0.0005,  0.0455,  0.0162,  0.0000,  0.0000,\n",
      "           0.0148,  0.0244,  0.0017,  0.0482,  0.0002,  0.0263,  0.0000,\n",
      "           0.0002,  0.0149,  0.0546,  0.0224,  0.0169,  0.0568,  0.0002,\n",
      "           0.0000,  0.0614,  0.0683,  0.0004,  0.0262,  0.0536,  0.0126,\n",
      "           0.0000,  0.0419,  0.0038,  0.0209,  0.0114,  0.0000,  0.0000,\n",
      "           0.2198,  0.0366,  0.0110,  0.0730,  0.0008,  0.0256,  0.0034,\n",
      "           0.0000,  0.0026,  0.0297,  0.0170,  0.0113,  0.0583,  0.0052,\n",
      "           0.0020,  0.0296,  0.0040,  0.0000,  0.0703,  0.0223,  0.0024,\n",
      "           0.0129,  0.0000,  0.0000,  0.0000,  0.0076,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0001,  0.0001,  0.0002,  0.0001,  0.0002,\n",
      "           0.0001,  0.0000,  0.0003,  0.0000,  0.0001,  0.0001,  0.0001,\n",
      "           0.0000,  0.0033,  0.0016,  0.0000,  0.0157,  0.0016,  0.0047,\n",
      "           0.0030,  0.0024,  0.0000,  0.0000,  0.0003,  0.0001,  0.0001,\n",
      "           0.0000,  0.0001,  0.0000,  0.0002,  0.0000,  0.0002,  0.0001,\n",
      "           0.0002,  0.0000,  0.0002,  0.0001,  0.0002,  0.0002,  0.0002,\n",
      "           0.0002,  0.0002,  0.0001,  0.0003,  0.0001,  0.0003,  0.0000,\n",
      "           0.0002,  0.0000,  0.0000,  0.0001,  0.0000,  0.0000,  0.0000,\n",
      "           0.0006,  0.0000,  0.0024,  0.0007,  0.0000,  0.0000,  0.0011,\n",
      "           0.0001,  0.0000,  0.0031,  0.0000,  0.0039,  0.0056,  0.0195,\n",
      "           0.0051,  0.0066,  0.0061,  0.0051,  0.0004,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0001,  0.0000,  0.0000,  0.0002,  0.0000,  0.0009,  0.0000,\n",
      "           0.0000,  0.0006,  0.0006,  0.0001,  0.0000,  0.0001,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0001,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0066,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0001,  0.0001,  0.0004,\n",
      "           0.0003,  0.0003,  0.0001,  0.0000,  0.0053,  0.0000,  0.0000,\n",
      "           0.0259,  0.0041,  0.0049,  0.0000,  0.0057,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0005,  0.0000,  0.0002,  0.0000,  0.0002,\n",
      "           0.0001,  0.0001,  0.0001,  0.0002,  0.0001,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0001,  0.0000,  0.0000,  0.0000,\n",
      "           0.0001,  0.0000,  0.0003,  0.0002,  0.0000,  0.0001,  0.0002,\n",
      "           0.0002,  0.0001,  0.0000,  0.0001,  0.0000,  0.0000,  0.0003,\n",
      "           0.0000,  0.0006,  0.0004,  0.0007,  0.0000,  0.0000,  0.0000,\n",
      "           0.0011,  0.0000,  0.0001,  0.0002,  0.0001,  0.0002,  0.0000,\n",
      "           0.0002,  0.0000,  0.0001,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0135,  0.0000,  0.0000,  0.0000,  0.0000,  0.0090,  0.0014,\n",
      "           0.0027,  0.0027,  0.0027,  0.0006,  0.0018,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0001,  0.0001,  0.0001,  0.0000,  0.0001,\n",
      "           0.0002,  0.0001,  0.0000,  0.0001,  0.0003,  0.0000,  0.0016,\n",
      "           0.0015,  0.0000,  0.0041,  0.0000,  0.0000,  0.0018,  0.0020,\n",
      "           0.0001,  0.0003,  0.0001,  0.0002,  0.0001,  0.0002,  0.0000,\n",
      "           0.0000,  0.0000,  0.0003,  0.0002,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0004,  0.0000,  0.0000,  0.0000,  0.0001,\n",
      "           0.0002,  0.0000,  0.0001,  0.0000,  0.0002,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0001,  0.0000,  0.0000,  0.0002,  0.0003,\n",
      "           0.0000,  0.0000,  0.0003,  0.0000,  0.0005,  0.0000,  0.0000,\n",
      "           0.0004,  0.0000,  0.0000,  0.0000,  0.0000,  0.0005,  0.0000,\n",
      "           0.0002,  0.0000,  0.0003,  0.0002,  0.0001,  0.0000,  0.0002,\n",
      "           0.0000,  0.0003,  0.0000,  0.0003,  0.0000,  0.0001,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0014,  0.0000,  0.0000,  0.0000,\n",
      "           0.0002,  0.0002,  0.0000,  0.0000,  0.0002,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0053,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0037,  0.0000,  0.0063,  0.0198,  0.0068,  0.0085,\n",
      "           0.0052,  0.0077,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0002,  0.0000,  0.0002,  0.0000,  0.0003,  0.0000,  0.0001,\n",
      "           0.0002,  0.0001,  0.0000,  0.0002,  0.0000,  0.0001,  0.0001,\n",
      "           0.0000,  0.0001,  0.0002,  0.0001,  0.0000,  0.0003,  0.0004,\n",
      "           0.0001,  0.0000,  0.0000,  0.0006,  0.0004,  0.0000,  0.0004,\n",
      "           0.0005,  0.0003,  0.0000,  0.0000,  0.0000,  0.0026,  0.0000,\n",
      "           0.0000,  0.0058,  0.0028,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0001,  0.0000,  0.0000,  0.0001,\n",
      "           0.0001,  0.0000,  0.0000,  0.0001,  0.0000,  0.0039,  0.0033,\n",
      "           0.0000,  0.0232,  0.0000,  0.0063,  0.0058,  0.0058,  0.0001,\n",
      "           0.0000,  0.0001,  0.0000,  0.0000,  0.0000,  0.0003,  0.0001,\n",
      "           0.0000,  0.0025,  0.0023,  0.0000,  0.0062,  0.0019,  0.0000,\n",
      "           0.0000,  0.0078,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0001,  0.0001,  0.0000,  0.0012,  0.0000,  0.0013,\n",
      "           0.0018,  0.0065,  0.0014,  0.0022,  0.0016,  0.0023,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0001,  0.0000,\n",
      "           0.0004,  0.0000,  0.0000,  0.0000,  0.0000,  0.0001,  0.0005,\n",
      "           0.0003,  0.0000,  0.0000,  0.0000,  0.0000,  0.0001,  0.0001,\n",
      "           0.0001]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-04 *\n",
      "       [[-1.1424, -2.0003, -2.8502,  0.8468,  3.5663,  1.1262,  3.0838,\n",
      "          3.7572, -0.9800]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 896, 512])\n",
      "tensor([[ 6.3362e-07,  8.9533e-06, -5.1998e-06,  ...,  8.3663e-08,\n",
      "          4.3085e-08,  7.0304e-09],\n",
      "        [ 4.6187e-06,  6.8546e-06,  2.9064e-05,  ...,  3.9440e-08,\n",
      "          7.2785e-08,  3.0384e-08],\n",
      "        [ 6.5361e-07,  1.4819e-06,  4.5680e-06,  ..., -7.0789e-08,\n",
      "          1.2949e-08,  1.1196e-08],\n",
      "        ...,\n",
      "        [ 2.3498e-06,  2.7041e-06,  1.2902e-05,  ...,  8.4536e-08,\n",
      "          6.1620e-08,  8.5224e-08],\n",
      "        [-4.6857e-06, -2.4695e-06, -3.0245e-05,  ..., -5.7047e-08,\n",
      "          1.1769e-08, -2.3854e-08],\n",
      "        [ 2.4132e-04,  4.5230e-04,  1.4782e-03,  ...,  5.7991e-08,\n",
      "          2.4012e-06,  4.2731e-06]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 896, 512])\n",
      "tensor([[ 6.3362e-08,  8.9533e-07, -5.1998e-07,  ...,  8.3663e-09,\n",
      "          4.3085e-09,  7.0304e-10],\n",
      "        [ 4.6187e-07,  6.8546e-07,  2.9064e-06,  ...,  3.9440e-09,\n",
      "          7.2785e-09,  3.0384e-09],\n",
      "        [ 6.5361e-08,  1.4819e-07,  4.5680e-07,  ..., -7.0789e-09,\n",
      "          1.2949e-09,  1.1196e-09],\n",
      "        ...,\n",
      "        [ 3.4077e-07, -4.8191e-07,  2.6454e-06,  ..., -5.8177e-10,\n",
      "         -1.8119e-09, -8.3869e-10],\n",
      "        [-1.2912e-07, -1.6101e-07, -7.2484e-07,  ..., -8.0041e-09,\n",
      "         -5.2386e-10,  2.8544e-09],\n",
      "        [-6.4984e-08,  5.5502e-08, -4.5668e-07,  ..., -3.5907e-10,\n",
      "         -1.2398e-09, -4.2333e-09]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "before autoscale: torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.0000]],\n",
      "\n",
      "        [[ 0.0209]],\n",
      "\n",
      "        [[ 0.2438]],\n",
      "\n",
      "        [[ 0.1745]],\n",
      "\n",
      "        [[ 0.1616]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0279]],\n",
      "\n",
      "        [[ 0.1919]],\n",
      "\n",
      "        [[ 0.0806]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[-0.3889]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 512])\n",
      "tensor([[[ 0.0000, -0.0081, -0.0948, -0.0679, -0.0628,  0.0000,  0.0000,\n",
      "          -0.0108, -0.0746, -0.0313, -0.0295, -0.0494, -0.0160, -0.0405,\n",
      "          -0.0647, -0.0086,  0.0000, -0.0185, -0.0187, -0.0007,  0.0000,\n",
      "          -0.0590, -0.1872, -0.0776, -0.0321, -0.0441, -0.0030,  0.0000,\n",
      "          -0.0327, -0.0231, -0.0616, -0.0422, -0.1854, -0.0184, -0.0234,\n",
      "          -0.0028,  0.0000, -0.0292, -0.1107, -0.0184, -0.0228, -0.0578,\n",
      "          -0.0653, -0.0462, -0.0312, -0.0013, -0.0101, -0.0311, -0.0754,\n",
      "          -0.0211, -0.0832, -0.0001, -0.0054, -0.0657, -0.0448, -0.0738,\n",
      "          -0.0016, -0.0104, -0.0272, -0.0002, -0.0209, -0.0424, -0.0228,\n",
      "          -0.0908,  0.0000,  0.0000,  0.0000, -0.0062,  0.0000,  0.0000,\n",
      "           0.0000, -0.0014,  0.0000,  0.0000, -0.0007, -0.0003, -0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0009, -0.0046, -0.0001,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0001,\n",
      "          -0.0000, -0.0001, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000, -0.0615,  0.0000,  0.0000, -0.0106,  0.0000,\n",
      "          -0.0001,  0.0000,  0.0000, -0.0001,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0001,  0.0000, -0.0004, -0.0000,\n",
      "          -0.0001, -0.0002,  0.0000, -0.0001, -0.0001, -0.0001, -0.0000,\n",
      "          -0.0001, -0.0001,  0.0000,  0.0000,  0.0000, -0.0005,  0.0000,\n",
      "          -0.0063,  0.0000,  0.0000, -0.0053, -0.0240,  0.0000,  0.0000,\n",
      "          -0.0052,  0.0000, -0.0001,  0.0000, -0.0001, -0.0000, -0.0001,\n",
      "          -0.0004,  0.0000,  0.0000, -0.0005,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0000, -0.0001,  0.0000,  0.0000, -0.0001,  0.0000,\n",
      "           0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,\n",
      "          -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0003,\n",
      "          -0.0001,  0.0000, -0.0001, -0.0001, -0.0001, -0.0002, -0.0001,\n",
      "           0.0000, -0.0000, -0.0001, -0.0001, -0.0001,  0.0000, -0.0001,\n",
      "          -0.0002, -0.0001,  0.0000,  0.0000, -0.0002, -0.0000,  0.0000,\n",
      "           0.0000, -0.0004, -0.0000,  0.0000,  0.0000, -0.0001,  0.0000,\n",
      "           0.0000, -0.0001, -0.0000,  0.0000,  0.0000, -0.0001,  0.0000,\n",
      "           0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0002,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0005,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0001,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0004,\n",
      "          -0.0021,  0.0000,  0.0000, -0.0045, -0.0531,  0.0000,  0.0000,\n",
      "          -0.0057,  0.0000, -0.0024,  0.0000,  0.0000, -0.0038, -0.0289,\n",
      "           0.0000,  0.0000, -0.0068,  0.0000, -0.0001, -0.0005,  0.0000,\n",
      "          -0.0000, -0.0014, -0.0003,  0.0000, -0.0015, -0.0118, -0.0006,\n",
      "           0.0000, -0.0032,  0.0000, -0.0001,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
      "          -0.0001,  0.0000, -0.0002,  0.0000, -0.0001,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0001, -0.0000, -0.0001, -0.0001,\n",
      "           0.0000, -0.0001,  0.0000, -0.0001,  0.0000,  0.0000, -0.0000,\n",
      "           0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000,\n",
      "           0.0000, -0.0001, -0.0001, -0.0001, -0.0002,  0.0000, -0.0002,\n",
      "           0.0000,  0.0000,  0.0000, -0.0001,  0.0000, -0.0002,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0006,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0000,  0.0000,  0.0000, -0.0014, -0.0042, -0.0258,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0001, -0.0000, -0.0001,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0365,  0.0000,\n",
      "           0.0000, -0.0111,  0.0000,  0.0000, -0.0036,  0.0000, -0.0000,\n",
      "          -0.0001,  0.0000, -0.0001,  0.0000,  0.0000,  0.0000, -0.0001,\n",
      "           0.0000, -0.0000, -0.0001, -0.0012,  0.0000,  0.0000, -0.0023,\n",
      "          -0.0151,  0.0000,  0.0000,  0.0000, -0.0043, -0.0192,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0009,  0.0000, -0.0011,  0.0000,\n",
      "          -0.0099, -0.0033,  0.0000, -0.0035,  0.0000,  0.0000, -0.0020,\n",
      "          -0.0133,  0.0000,  0.0000,  0.0000, -0.0022,  0.0000,  0.0000,\n",
      "          -0.0004, -0.0004,  0.0000,  0.0000,  0.0000,  0.0000, -0.0041,\n",
      "          -0.0333,  0.0000,  0.0000, -0.0081, -0.0027,  0.0000,  0.0000,\n",
      "           0.0000, -0.0042, -0.0460,  0.0000,  0.0000, -0.0077, -0.0031,\n",
      "           0.0000,  0.0000,  0.0000, -0.0010,  0.0000,  0.0000, -0.0007,\n",
      "           0.0000,  0.0000, -0.0001,  0.0000, -0.0000,  0.0000, -0.0003,\n",
      "          -0.0001,  0.0000, -0.0002, -0.0001, -0.0001,  0.0000, -0.0002,\n",
      "          -0.0002,  0.0000, -0.0001, -0.0000, -0.0004,  0.0000, -0.0001,\n",
      "           0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0010,  0.0000,\n",
      "           0.0000, -0.0020, -0.0109,  0.0000,  0.0000, -0.0039,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0074, -0.0005,  0.0000,  0.0000,\n",
      "           0.0000, -0.0000, -0.0001,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0156, -0.0243,  0.0000,  0.0000,  0.0000,  0.0000, -0.0001,\n",
      "          -0.0001,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
      "           0.0000, -0.0001,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,\n",
      "          -0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
      "           0.0000]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-04 *\n",
      "       [[-2.8969,  1.2452,  3.5035, -0.5877,  1.1503, -2.3098, -1.9659,\n",
      "         -2.4768, -0.1472]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 448, 512])\n",
      "tensor([[ 3.8246e-05,  4.9872e-05,  1.7605e-05,  ..., -1.5564e-08,\n",
      "         -9.5476e-09,  5.7904e-10],\n",
      "        [ 8.2719e-07, -3.2082e-06,  2.5173e-05,  ...,  4.8753e-09,\n",
      "         -3.4722e-09, -1.1914e-08],\n",
      "        [ 4.3736e-03,  2.3726e-03,  9.5068e-04,  ...,  1.2453e-06,\n",
      "          1.6638e-06,  9.1469e-07],\n",
      "        ...,\n",
      "        [ 1.3893e-05, -2.7703e-05,  3.2946e-05,  ...,  3.4081e-09,\n",
      "          1.3742e-08, -9.8056e-09],\n",
      "        [-6.1759e-06,  1.5170e-05,  3.4441e-05,  ...,  1.4232e-09,\n",
      "          7.8644e-09,  1.3977e-08],\n",
      "        [-1.5208e-05,  5.9332e-06,  1.4654e-05,  ...,  4.9966e-09,\n",
      "          8.8337e-09,  7.1817e-09]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 448, 512])\n",
      "tensor([[ 3.8246e-06,  4.9872e-06,  1.7605e-06,  ..., -1.5564e-09,\n",
      "         -9.5476e-10,  5.7904e-11],\n",
      "        [ 8.2719e-08, -3.2082e-07,  2.5173e-06,  ...,  4.8753e-10,\n",
      "         -3.4722e-10, -1.1914e-09],\n",
      "        [ 4.3736e-04,  2.3726e-04,  9.5068e-05,  ...,  1.2453e-07,\n",
      "          1.6638e-07,  9.1469e-08],\n",
      "        ...,\n",
      "        [ 5.1904e-06, -4.6723e-07,  3.9426e-07,  ..., -3.3473e-09,\n",
      "         -1.0564e-09,  1.1506e-09],\n",
      "        [-5.4580e-06, -5.7166e-06, -5.8980e-06,  ..., -9.0301e-10,\n",
      "         -2.5311e-09, -3.6052e-09],\n",
      "        [-1.9376e-05, -9.5588e-06,  6.7962e-08,  ...,  1.2227e-08,\n",
      "          1.5276e-08,  1.6923e-08]], device='cuda:0')\n",
      "\n",
      "Test set: Average loss: 0.3896, Accuracy: 9137/10000 (91.37%)\n",
      "\n",
      "Train Epoch: 179 [0/50000 (0%)]\tLoss: 0.012937, Accuracy: 99.61\n",
      "Train Epoch: 179 [2560/50000 (6%)]\tLoss: 0.005178, Accuracy: 100.00\n",
      "Train Epoch: 179 [5120/50000 (11%)]\tLoss: 0.014886, Accuracy: 99.61\n",
      "Train Epoch: 179 [7680/50000 (17%)]\tLoss: 0.017222, Accuracy: 99.61\n",
      "Train Epoch: 179 [10240/50000 (23%)]\tLoss: 0.012224, Accuracy: 99.61\n",
      "Train Epoch: 179 [12800/50000 (28%)]\tLoss: 0.022456, Accuracy: 99.22\n",
      "Train Epoch: 179 [15360/50000 (34%)]\tLoss: 0.005746, Accuracy: 99.80\n",
      "Train Epoch: 179 [17920/50000 (40%)]\tLoss: 0.013875, Accuracy: 99.61\n",
      "Train Epoch: 179 [20480/50000 (45%)]\tLoss: 0.004129, Accuracy: 100.00\n",
      "Train Epoch: 179 [23040/50000 (51%)]\tLoss: 0.008488, Accuracy: 99.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 179 [25600/50000 (57%)]\tLoss: 0.008810, Accuracy: 99.80\n",
      "Train Epoch: 179 [28160/50000 (62%)]\tLoss: 0.003753, Accuracy: 100.00\n",
      "Train Epoch: 179 [30720/50000 (68%)]\tLoss: 0.014481, Accuracy: 99.61\n",
      "Train Epoch: 179 [33280/50000 (74%)]\tLoss: 0.014924, Accuracy: 99.61\n",
      "Train Epoch: 179 [35840/50000 (80%)]\tLoss: 0.006612, Accuracy: 99.80\n",
      "Train Epoch: 179 [38400/50000 (85%)]\tLoss: 0.010511, Accuracy: 99.80\n",
      "Train Epoch: 179 [40960/50000 (91%)]\tLoss: 0.008082, Accuracy: 99.80\n",
      "Train Epoch: 179 [43520/50000 (97%)]\tLoss: 0.011732, Accuracy: 99.61\n",
      "\n",
      "Validation set: Average loss: 0.3697, Accuracy: 4585/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[38.494062423706055 s]\n",
      "Train Epoch: 180 [0/50000 (0%)]\tLoss: 0.013239, Accuracy: 99.61\n",
      "Train Epoch: 180 [2560/50000 (6%)]\tLoss: 0.016358, Accuracy: 99.22\n",
      "Train Epoch: 180 [5120/50000 (11%)]\tLoss: 0.005712, Accuracy: 99.80\n",
      "Train Epoch: 180 [7680/50000 (17%)]\tLoss: 0.011766, Accuracy: 99.41\n",
      "Train Epoch: 180 [10240/50000 (23%)]\tLoss: 0.011537, Accuracy: 99.61\n",
      "Train Epoch: 180 [12800/50000 (28%)]\tLoss: 0.008398, Accuracy: 99.80\n",
      "Train Epoch: 180 [15360/50000 (34%)]\tLoss: 0.034624, Accuracy: 99.22\n",
      "Train Epoch: 180 [17920/50000 (40%)]\tLoss: 0.017560, Accuracy: 99.22\n",
      "Train Epoch: 180 [20480/50000 (45%)]\tLoss: 0.011824, Accuracy: 99.61\n",
      "Train Epoch: 180 [23040/50000 (51%)]\tLoss: 0.012162, Accuracy: 99.61\n",
      "Train Epoch: 180 [25600/50000 (57%)]\tLoss: 0.014680, Accuracy: 99.61\n",
      "Train Epoch: 180 [28160/50000 (62%)]\tLoss: 0.020520, Accuracy: 99.22\n",
      "Train Epoch: 180 [30720/50000 (68%)]\tLoss: 0.019736, Accuracy: 99.41\n",
      "Train Epoch: 180 [33280/50000 (74%)]\tLoss: 0.014599, Accuracy: 99.61\n",
      "Train Epoch: 180 [35840/50000 (80%)]\tLoss: 0.009547, Accuracy: 99.61\n",
      "Train Epoch: 180 [38400/50000 (85%)]\tLoss: 0.024301, Accuracy: 99.02\n",
      "Train Epoch: 180 [40960/50000 (91%)]\tLoss: 0.009176, Accuracy: 99.80\n",
      "Train Epoch: 180 [43520/50000 (97%)]\tLoss: 0.023465, Accuracy: 98.83\n",
      "------------------------------\n",
      "before autoscale: torch.Size([1024, 1, 1])\n",
      "tensor([[[ 0.0024]],\n",
      "\n",
      "        [[ 0.0029]],\n",
      "\n",
      "        [[ 0.0788]],\n",
      "\n",
      "        [[ 0.0481]],\n",
      "\n",
      "        [[ 0.0070]],\n",
      "\n",
      "        [[ 0.0538]],\n",
      "\n",
      "        [[ 0.1751]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0474]],\n",
      "\n",
      "        [[ 0.0142]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[ 0.7075]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 1024])\n",
      "tensor([[[ 0.0017,  0.0020,  0.0558,  ...,  0.0006,  0.0001,  0.0002]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-03 *\n",
      "       [[ 3.2375,  0.7280,  1.9138, -0.4582,  0.2145, -0.2813,  0.6274,\n",
      "          1.3442,  2.2907]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 896, 1024])\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.0092,  0.0099,  0.0343,  ...,  0.0001,  0.0003,  0.0001],\n",
      "        [-0.0577, -0.0744, -0.1051,  ..., -0.0003, -0.0008, -0.0006],\n",
      "        [-0.0073, -0.0066, -0.0230,  ...,  0.0000,  0.0002, -0.0000],\n",
      "        ...,\n",
      "        [ 0.0012,  0.0062,  0.0166,  ...,  0.0001,  0.0002,  0.0000],\n",
      "        [ 0.0296,  0.0472,  0.1077,  ...,  0.0007,  0.0014,  0.0004],\n",
      "        [-0.0013, -0.0010, -0.0056,  ..., -0.0000, -0.0000,  0.0000]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 896, 1024])\n",
      "tensor(1.00000e-03 *\n",
      "       [[ 0.0092,  0.0099,  0.0343,  ...,  0.0001,  0.0003,  0.0001],\n",
      "        [-0.0577, -0.0744, -0.1051,  ..., -0.0003, -0.0008, -0.0006],\n",
      "        [-0.0073, -0.0066, -0.0230,  ...,  0.0000,  0.0002, -0.0000],\n",
      "        ...,\n",
      "        [-0.0092, -0.0317, -0.0600,  ..., -0.0003, -0.0004, -0.0001],\n",
      "        [-0.0033, -0.0009, -0.0052,  ...,  0.0000, -0.0001, -0.0000],\n",
      "        [ 0.0061,  0.0151,  0.0197,  ...,  0.0000,  0.0001,  0.0000]], device='cuda:0')\n",
      "\n",
      "Validation set: Average loss: 0.3748, Accuracy: 4589/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[35.253329277038574 s]\n",
      "------------------------------\n",
      "before autoscale: torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.0000]],\n",
      "\n",
      "        [[ 0.2711]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0393]],\n",
      "\n",
      "        [[ 0.0195]],\n",
      "\n",
      "        [[ 0.2798]],\n",
      "\n",
      "        [[ 0.4113]],\n",
      "\n",
      "        [[ 0.0623]],\n",
      "\n",
      "        [[ 0.0655]],\n",
      "\n",
      "        [[ 0.1064]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[-0.2481]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 512])\n",
      "tensor([[[ 0.0000, -0.0673,  0.0000, -0.0097, -0.0048, -0.0694, -0.1021,\n",
      "          -0.0154, -0.0162, -0.0264, -0.0209, -0.0088, -0.0629, -0.0635,\n",
      "          -0.0008, -0.1173, -0.0285, -0.0429, -0.0049, -0.0734, -0.0069,\n",
      "          -0.0304, -0.0579, -0.0419, -0.0537, -0.0700, -0.0163, -0.0948,\n",
      "           0.0000, -0.0216, -0.0350, -0.0285, -0.0017, -0.0323, -0.0181,\n",
      "          -0.0503, -0.0709,  0.0000, -0.0043, -0.0028, -0.0411, -0.0232,\n",
      "          -0.0507, -0.0647, -0.0141, -0.0241,  0.0000, -0.0248, -0.0037,\n",
      "          -0.0691, -0.0040, -0.0755, -0.0133, -0.0868, -0.0142, -0.0291,\n",
      "           0.0000,  0.0000, -0.0121,  0.0000, -0.0444, -0.0576, -0.0679,\n",
      "          -0.0001, -0.0173, -0.0129, -0.0069, -0.0001, -0.0021, -0.0055,\n",
      "          -0.0026,  0.0000,  0.0000,  0.0000, -0.0020,  0.0000, -0.0000,\n",
      "          -0.0008, -0.0006, -0.0010, -0.0012, -0.0030, -0.0011,  0.0000,\n",
      "          -0.0014, -0.0015, -0.0001,  0.0000, -0.0001,  0.0000,  0.0000,\n",
      "          -0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0041,  0.0000,\n",
      "          -0.0001, -0.0001, -0.0002, -0.0002,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0055,  0.0000,  0.0000,  0.0000,  0.0000, -0.0001,\n",
      "          -0.0004,  0.0000,  0.0000,  0.0000, -0.0043,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
      "          -0.0001, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,\n",
      "           0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
      "           0.0000, -0.0007,  0.0000,  0.0000, -0.0008, -0.0028,  0.0000,\n",
      "          -0.0033,  0.0000,  0.0000, -0.0004,  0.0000, -0.0099, -0.0097,\n",
      "          -0.0008, -0.0010,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000, -0.0004,  0.0000,  0.0000, -0.0015, -0.0008,\n",
      "          -0.0003, -0.0003, -0.0004,  0.0000, -0.0009, -0.0008, -0.0011,\n",
      "          -0.0014, -0.0041, -0.0012,  0.0000, -0.0031, -0.0031, -0.0019,\n",
      "           0.0000, -0.0101,  0.0000,  0.0000, -0.0021, -0.0028, -0.0001,\n",
      "          -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0001,\n",
      "           0.0000,  0.0000,  0.0000, -0.0001, -0.0068,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000, -0.0009, -0.0021, -0.0008,  0.0000, -0.0010,\n",
      "           0.0000,  0.0000, -0.0000, -0.0001,  0.0000, -0.0000,  0.0000,\n",
      "          -0.0000, -0.0001, -0.0001, -0.0000, -0.0000,  0.0000, -0.0000,\n",
      "          -0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
      "          -0.0000,  0.0000,  0.0000, -0.0013, -0.0017, -0.0115,  0.0000,\n",
      "           0.0000,  0.0000, -0.0020, -0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0000, -0.0000, -0.0001, -0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0000, -0.0002,  0.0000, -0.0002, -0.0001, -0.0002,  0.0000,\n",
      "          -0.0010, -0.0016, -0.0018, -0.0207,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0018, -0.0000, -0.0000, -0.0000,  0.0000, -0.0002,  0.0000,\n",
      "          -0.0016, -0.0028, -0.0025, -0.0120, -0.0024, -0.0024, -0.0031,\n",
      "          -0.0033, -0.0008, -0.0006,  0.0000, -0.0019, -0.0035, -0.0026,\n",
      "          -0.0065, -0.0027, -0.0028,  0.0000, -0.0028, -0.0005, -0.0008,\n",
      "           0.0000, -0.0020, -0.0008, -0.0008, -0.0012,  0.0000, -0.0001,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0042, -0.0017,  0.0000,  0.0000, -0.0036, -0.0011,  0.0000,\n",
      "          -0.0000, -0.0006,  0.0000, -0.0007,  0.0000,  0.0000, -0.0004,\n",
      "           0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "           0.0000, -0.0007, -0.0014, -0.0013, -0.0135, -0.0016, -0.0015,\n",
      "           0.0000, -0.0027, -0.0017, -0.0036,  0.0000,  0.0000, -0.0013,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0001,  0.0000,  0.0000,\n",
      "          -0.0010, -0.0013,  0.0000, -0.0049,  0.0000, -0.0013, -0.0018,\n",
      "          -0.0025,  0.0000, -0.0004, -0.0004, -0.0024, -0.0005, -0.0004,\n",
      "           0.0000, -0.0005, -0.0001, -0.0001, -0.0000, -0.0000, -0.0000,\n",
      "           0.0000, -0.0001,  0.0000, -0.0000, -0.0006,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0001, -0.0000,  0.0000,\n",
      "          -0.0000, -0.0001, -0.0000, -0.0000, -0.0004, -0.0004, -0.0004,\n",
      "          -0.0006,  0.0000, -0.0003,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0045,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0031,\n",
      "          -0.0048,  0.0000, -0.0011,  0.0000, -0.0020, -0.0000, -0.0000,\n",
      "           0.0000, -0.0001,  0.0000,  0.0000, -0.0047,  0.0000, -0.0982,\n",
      "          -0.0069,  0.0000, -0.0058,  0.0000, -0.0103,  0.0000, -0.0028,\n",
      "          -0.0019,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
      "           0.0000,  0.0000, -0.0001, -0.0000,  0.0000, -0.0001, -0.0000,\n",
      "          -0.0000, -0.0001,  0.0000,  0.0000,  0.0000, -0.0003, -0.0004,\n",
      "           0.0000, -0.0008, -0.0019, -0.0011, -0.0014,  0.0000,  0.0000,\n",
      "           0.0000, -0.0009,  0.0000, -0.0000, -0.0001,  0.0000, -0.0001,\n",
      "          -0.0001,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0082,\n",
      "           0.0000, -0.0015, -0.0021,  0.0000, -0.0005,  0.0000, -0.0006,\n",
      "          -0.0006, -0.0017,  0.0000, -0.0016,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0047, -0.0007,  0.0000,  0.0000,  0.0000, -0.0007,\n",
      "          -0.0008, -0.0030,  0.0000, -0.0008,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0000, -0.0002, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0032, -0.0005, -0.0025,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-04 *\n",
      "       [[ 1.1390,  1.9611,  0.5072,  1.1962,  2.4577, -1.1953,  3.9122,\n",
      "          3.3642, -1.0601]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 448, 512])\n",
      "tensor([[ 5.2760e-06, -1.4611e-05, -2.1316e-05,  ..., -5.8787e-07,\n",
      "         -5.4770e-07, -2.8759e-07],\n",
      "        [-1.4070e-05,  1.2246e-05,  2.4525e-05,  ...,  1.7834e-06,\n",
      "          1.0344e-06,  9.2308e-07],\n",
      "        [ 2.5005e-05,  1.1279e-05, -3.8964e-06,  ...,  9.0889e-07,\n",
      "          7.2376e-07,  5.6885e-08],\n",
      "        ...,\n",
      "        [ 1.6323e-06,  3.0161e-05,  1.1391e-05,  ...,  1.7553e-06,\n",
      "          3.8351e-07,  1.0182e-06],\n",
      "        [ 2.6499e-05, -1.0008e-05,  4.9689e-07,  ..., -1.5231e-06,\n",
      "         -7.5049e-08, -8.5390e-07],\n",
      "        [-2.5814e-05, -7.6795e-06, -4.0086e-05,  ..., -1.0371e-06,\n",
      "         -7.0213e-07, -6.8485e-07]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 448, 512])\n",
      "tensor([[ 5.2760e-07, -1.4611e-06, -2.1316e-06,  ..., -5.8787e-08,\n",
      "         -5.4770e-08, -2.8759e-08],\n",
      "        [-1.4070e-06,  1.2246e-06,  2.4525e-06,  ...,  1.7834e-07,\n",
      "          1.0344e-07,  9.2308e-08],\n",
      "        [ 2.5005e-06,  1.1279e-06, -3.8964e-07,  ...,  9.0889e-08,\n",
      "          7.2376e-08,  5.6885e-09],\n",
      "        ...,\n",
      "        [-4.6602e-06, -9.3250e-06, -1.7868e-05,  ..., -8.2477e-08,\n",
      "         -4.9950e-08, -5.0267e-08],\n",
      "        [-8.5193e-05, -1.3050e-04, -2.9049e-04,  ..., -5.1107e-06,\n",
      "         -1.7428e-06, -2.0822e-06],\n",
      "        [-1.6664e-06, -3.9217e-06, -9.6128e-06,  ..., -1.6709e-07,\n",
      "         -8.6370e-08, -4.7820e-08]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4076, Accuracy: 9114/10000 (91.14%)\n",
      "\n",
      "Train Epoch: 181 [0/50000 (0%)]\tLoss: 0.020023, Accuracy: 99.41\n",
      "Train Epoch: 181 [2560/50000 (6%)]\tLoss: 0.031187, Accuracy: 99.02\n",
      "Train Epoch: 181 [5120/50000 (11%)]\tLoss: 0.012929, Accuracy: 99.41\n",
      "Train Epoch: 181 [7680/50000 (17%)]\tLoss: 0.004828, Accuracy: 100.00\n",
      "Train Epoch: 181 [10240/50000 (23%)]\tLoss: 0.016333, Accuracy: 99.41\n",
      "Train Epoch: 181 [12800/50000 (28%)]\tLoss: 0.007381, Accuracy: 100.00\n",
      "Train Epoch: 181 [15360/50000 (34%)]\tLoss: 0.022458, Accuracy: 99.22\n",
      "Train Epoch: 181 [17920/50000 (40%)]\tLoss: 0.012882, Accuracy: 99.41\n",
      "Train Epoch: 181 [20480/50000 (45%)]\tLoss: 0.007343, Accuracy: 100.00\n",
      "Train Epoch: 181 [23040/50000 (51%)]\tLoss: 0.026474, Accuracy: 99.22\n",
      "Train Epoch: 181 [25600/50000 (57%)]\tLoss: 0.027917, Accuracy: 98.83\n",
      "Train Epoch: 181 [28160/50000 (62%)]\tLoss: 0.019370, Accuracy: 99.41\n",
      "Train Epoch: 181 [30720/50000 (68%)]\tLoss: 0.006832, Accuracy: 100.00\n",
      "Train Epoch: 181 [33280/50000 (74%)]\tLoss: 0.008161, Accuracy: 100.00\n",
      "Train Epoch: 181 [35840/50000 (80%)]\tLoss: 0.004003, Accuracy: 100.00\n",
      "Train Epoch: 181 [38400/50000 (85%)]\tLoss: 0.017781, Accuracy: 99.41\n",
      "Train Epoch: 181 [40960/50000 (91%)]\tLoss: 0.005501, Accuracy: 100.00\n",
      "Train Epoch: 181 [43520/50000 (97%)]\tLoss: 0.027216, Accuracy: 99.02\n",
      "\n",
      "Validation set: Average loss: 0.3953, Accuracy: 4565/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[38.500861406326294 s]\n",
      "Train Epoch: 182 [0/50000 (0%)]\tLoss: 0.009137, Accuracy: 99.80\n",
      "Train Epoch: 182 [2560/50000 (6%)]\tLoss: 0.008537, Accuracy: 99.80\n",
      "Train Epoch: 182 [5120/50000 (11%)]\tLoss: 0.013058, Accuracy: 99.41\n",
      "Train Epoch: 182 [7680/50000 (17%)]\tLoss: 0.014276, Accuracy: 99.41\n",
      "Train Epoch: 182 [10240/50000 (23%)]\tLoss: 0.010562, Accuracy: 99.80\n",
      "Train Epoch: 182 [12800/50000 (28%)]\tLoss: 0.023647, Accuracy: 99.22\n",
      "Train Epoch: 182 [15360/50000 (34%)]\tLoss: 0.019412, Accuracy: 99.41\n",
      "Train Epoch: 182 [17920/50000 (40%)]\tLoss: 0.004109, Accuracy: 100.00\n",
      "Train Epoch: 182 [20480/50000 (45%)]\tLoss: 0.016002, Accuracy: 99.61\n",
      "Train Epoch: 182 [23040/50000 (51%)]\tLoss: 0.022502, Accuracy: 99.22\n",
      "Train Epoch: 182 [25600/50000 (57%)]\tLoss: 0.015841, Accuracy: 99.61\n",
      "Train Epoch: 182 [28160/50000 (62%)]\tLoss: 0.007144, Accuracy: 99.80\n",
      "Train Epoch: 182 [30720/50000 (68%)]\tLoss: 0.011475, Accuracy: 99.41\n",
      "Train Epoch: 182 [33280/50000 (74%)]\tLoss: 0.017065, Accuracy: 99.41\n",
      "Train Epoch: 182 [35840/50000 (80%)]\tLoss: 0.010383, Accuracy: 100.00\n",
      "Train Epoch: 182 [38400/50000 (85%)]\tLoss: 0.019378, Accuracy: 99.22\n",
      "Train Epoch: 182 [40960/50000 (91%)]\tLoss: 0.015702, Accuracy: 99.61\n",
      "Train Epoch: 182 [43520/50000 (97%)]\tLoss: 0.011171, Accuracy: 99.80\n",
      "\n",
      "Validation set: Average loss: 0.3852, Accuracy: 4586/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[35.217023611068726 s]\n",
      "------------------------------\n",
      "before autoscale: torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.0000]],\n",
      "\n",
      "        [[ 0.0039]],\n",
      "\n",
      "        [[ 0.1172]],\n",
      "\n",
      "        [[ 0.0857]],\n",
      "\n",
      "        [[ 0.0762]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.1930]],\n",
      "\n",
      "        [[ 0.0402]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[-0.3851]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 512])\n",
      "tensor([[[ 0.0000, -0.0015, -0.0452, -0.0330, -0.0294,  0.0000,  0.0000,\n",
      "           0.0000, -0.0743, -0.0155, -0.0442, -0.0966, -0.0125, -0.0114,\n",
      "          -0.0204,  0.0000,  0.0000, -0.0242, -0.0197, -0.0023, -0.0930,\n",
      "          -0.0369, -0.3111, -0.0473, -0.0013, -0.0044, -0.0091,  0.0000,\n",
      "          -0.0329, -0.0537, -0.0395, -0.0203, -0.0171, -0.0316, -0.0031,\n",
      "          -0.0136,  0.0000,  0.0000, -0.1154,  0.0000, -0.0191, -0.0151,\n",
      "          -0.0492,  0.0000, -0.0351, -0.0762,  0.0000, -0.1408, -0.0455,\n",
      "          -0.0195, -0.0645, -0.0097, -0.0077, -0.0454, -0.0437, -0.0395,\n",
      "          -0.0070, -0.0091, -0.0002,  0.0000, -0.0141, -0.0542,  0.0000,\n",
      "          -0.0633,  0.0000,  0.0000,  0.0000, -0.0060,  0.0000,  0.0000,\n",
      "           0.0000, -0.0012,  0.0000,  0.0000, -0.0006, -0.0003, -0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0009, -0.0038, -0.0001,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0001,\n",
      "          -0.0000, -0.0001, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000, -0.0164,  0.0000,  0.0000, -0.0107,  0.0000,\n",
      "          -0.0001,  0.0000,  0.0000, -0.0001,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0001,  0.0000, -0.0003, -0.0000,\n",
      "          -0.0001, -0.0002,  0.0000, -0.0001, -0.0001, -0.0001, -0.0000,\n",
      "          -0.0001, -0.0001,  0.0000,  0.0000,  0.0000, -0.0005,  0.0000,\n",
      "          -0.0051,  0.0000,  0.0000, -0.0051, -0.0108,  0.0000,  0.0000,\n",
      "          -0.0051,  0.0000, -0.0001,  0.0000, -0.0001, -0.0000, -0.0001,\n",
      "          -0.0004,  0.0000,  0.0000, -0.0005,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0000, -0.0001,  0.0000,  0.0000, -0.0001,  0.0000,\n",
      "           0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,\n",
      "          -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0003,\n",
      "          -0.0001,  0.0000, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001,\n",
      "           0.0000, -0.0000, -0.0001, -0.0001, -0.0001,  0.0000, -0.0001,\n",
      "          -0.0002, -0.0001,  0.0000,  0.0000, -0.0002, -0.0000,  0.0000,\n",
      "           0.0000, -0.0004, -0.0000,  0.0000,  0.0000, -0.0001,  0.0000,\n",
      "           0.0000, -0.0001, -0.0000,  0.0000,  0.0000, -0.0001,  0.0000,\n",
      "           0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0002,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0018,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0004,\n",
      "          -0.0021,  0.0000,  0.0000, -0.0044, -0.0172,  0.0000,  0.0000,\n",
      "          -0.0058,  0.0000, -0.0024,  0.0000,  0.0000, -0.0037, -0.0184,\n",
      "           0.0000,  0.0000, -0.0066,  0.0000, -0.0001, -0.0005,  0.0000,\n",
      "          -0.0000, -0.0013, -0.0003,  0.0000, -0.0014, -0.0077, -0.0005,\n",
      "           0.0000, -0.0032,  0.0000, -0.0001,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
      "          -0.0001,  0.0000, -0.0002,  0.0000, -0.0001,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0001, -0.0000, -0.0001, -0.0001,\n",
      "           0.0000, -0.0001,  0.0000, -0.0001,  0.0000,  0.0000, -0.0000,\n",
      "           0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000,\n",
      "           0.0000, -0.0001, -0.0001, -0.0001, -0.0002,  0.0000, -0.0002,\n",
      "           0.0000,  0.0000,  0.0000, -0.0001,  0.0000, -0.0002,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.0006,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0000,  0.0000,  0.0000, -0.0014, -0.0041, -0.0076,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0001, -0.0000, -0.0001,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0138,  0.0000,\n",
      "           0.0000, -0.0066,  0.0000,  0.0000, -0.0035,  0.0000, -0.0000,\n",
      "          -0.0001,  0.0000, -0.0001,  0.0000,  0.0000,  0.0000, -0.0001,\n",
      "           0.0000, -0.0000, -0.0001, -0.0012,  0.0000,  0.0000, -0.0023,\n",
      "          -0.0093,  0.0000,  0.0000,  0.0000, -0.0042, -0.0137,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0009,  0.0000, -0.0011,  0.0000,\n",
      "          -0.0063, -0.0034,  0.0000, -0.0035,  0.0000,  0.0000, -0.0019,\n",
      "          -0.0083,  0.0000,  0.0000,  0.0000, -0.0021,  0.0000,  0.0000,\n",
      "          -0.0014, -0.0004,  0.0000,  0.0000,  0.0000,  0.0000, -0.0040,\n",
      "          -0.0123,  0.0000,  0.0000, -0.0081, -0.0027,  0.0000,  0.0000,\n",
      "           0.0000, -0.0041, -0.0164,  0.0000,  0.0000, -0.0076, -0.0031,\n",
      "           0.0000,  0.0000,  0.0000, -0.0009,  0.0000,  0.0000, -0.0007,\n",
      "           0.0000,  0.0000, -0.0001,  0.0000, -0.0000,  0.0000, -0.0003,\n",
      "          -0.0001,  0.0000, -0.0002, -0.0001, -0.0001,  0.0000, -0.0002,\n",
      "          -0.0002,  0.0000, -0.0001, -0.0000, -0.0004,  0.0000, -0.0001,\n",
      "           0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0010,  0.0000,\n",
      "           0.0000, -0.0020, -0.0069,  0.0000,  0.0000, -0.0038,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000, -0.0059, -0.0005,  0.0000,  0.0000,\n",
      "           0.0000, -0.0000, -0.0001,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0078, -0.0169,  0.0000,  0.0000,  0.0000,  0.0000, -0.0001,\n",
      "          -0.0001,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
      "           0.0000, -0.0001,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,\n",
      "          -0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
      "           0.0000]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-04 *\n",
      "       [[-2.8464,  1.2235,  3.4424, -0.5774,  1.1302, -2.2695, -1.9316,\n",
      "         -2.4336, -0.1446]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 448, 512])\n",
      "tensor([[ 1.7526e-05,  2.3601e-05,  8.1496e-06,  ..., -1.4879e-08,\n",
      "         -9.1261e-09,  5.5492e-10],\n",
      "        [ 7.1618e-07, -1.9724e-06,  1.2034e-05,  ...,  4.6608e-09,\n",
      "         -3.3190e-09, -1.1390e-08],\n",
      "        [ 2.0723e-03,  1.0823e-03,  4.0118e-04,  ...,  1.1968e-06,\n",
      "          1.5796e-06,  8.8850e-07],\n",
      "        ...,\n",
      "        [ 7.0793e-06, -1.3334e-05,  1.4230e-05,  ...,  3.2560e-09,\n",
      "          1.3137e-08, -9.3743e-09],\n",
      "        [-3.3407e-06,  7.1250e-06,  1.5748e-05,  ...,  1.3596e-09,\n",
      "          7.5182e-09,  1.3361e-08],\n",
      "        [-7.2509e-06,  2.7787e-06,  6.8096e-06,  ...,  4.7764e-09,\n",
      "          8.4445e-09,  6.8647e-09]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 448, 512])\n",
      "tensor([[ 1.7526e-06,  2.3601e-06,  8.1496e-07,  ..., -1.4879e-09,\n",
      "         -9.1261e-10,  5.5492e-11],\n",
      "        [ 7.1618e-08, -1.9724e-07,  1.2034e-06,  ...,  4.6608e-10,\n",
      "         -3.3190e-10, -1.1390e-09],\n",
      "        [ 2.0723e-04,  1.0823e-04,  4.0118e-05,  ...,  1.1968e-07,\n",
      "          1.5796e-07,  8.8850e-08],\n",
      "        ...,\n",
      "        [ 2.4069e-06, -1.4968e-07,  3.6276e-07,  ..., -3.1996e-09,\n",
      "         -1.0095e-09,  1.0999e-09],\n",
      "        [-2.4625e-06, -2.7053e-06, -2.6788e-06,  ..., -8.6312e-10,\n",
      "         -2.4196e-09, -3.4463e-09],\n",
      "        [-9.2400e-06, -4.7727e-06, -3.2332e-07,  ...,  1.1687e-08,\n",
      "          1.4602e-08,  1.6177e-08]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4123, Accuracy: 9111/10000 (91.11%)\n",
      "\n",
      "Train Epoch: 183 [0/50000 (0%)]\tLoss: 0.011262, Accuracy: 99.41\n",
      "Train Epoch: 183 [2560/50000 (6%)]\tLoss: 0.008518, Accuracy: 100.00\n",
      "Train Epoch: 183 [5120/50000 (11%)]\tLoss: 0.009371, Accuracy: 99.61\n",
      "Train Epoch: 183 [7680/50000 (17%)]\tLoss: 0.012660, Accuracy: 99.41\n",
      "Train Epoch: 183 [10240/50000 (23%)]\tLoss: 0.010567, Accuracy: 99.80\n",
      "Train Epoch: 183 [12800/50000 (28%)]\tLoss: 0.010528, Accuracy: 99.80\n",
      "Train Epoch: 183 [15360/50000 (34%)]\tLoss: 0.019033, Accuracy: 99.61\n",
      "Train Epoch: 183 [17920/50000 (40%)]\tLoss: 0.007669, Accuracy: 99.61\n",
      "Train Epoch: 183 [20480/50000 (45%)]\tLoss: 0.011601, Accuracy: 99.61\n",
      "Train Epoch: 183 [23040/50000 (51%)]\tLoss: 0.013186, Accuracy: 99.22\n",
      "Train Epoch: 183 [25600/50000 (57%)]\tLoss: 0.009110, Accuracy: 99.61\n",
      "Train Epoch: 183 [28160/50000 (62%)]\tLoss: 0.008783, Accuracy: 99.61\n",
      "Train Epoch: 183 [30720/50000 (68%)]\tLoss: 0.030429, Accuracy: 99.02\n",
      "Train Epoch: 183 [33280/50000 (74%)]\tLoss: 0.021339, Accuracy: 98.83\n",
      "Train Epoch: 183 [35840/50000 (80%)]\tLoss: 0.017435, Accuracy: 99.61\n",
      "Train Epoch: 183 [38400/50000 (85%)]\tLoss: 0.014349, Accuracy: 99.22\n",
      "Train Epoch: 183 [40960/50000 (91%)]\tLoss: 0.012677, Accuracy: 99.22\n",
      "Train Epoch: 183 [43520/50000 (97%)]\tLoss: 0.029259, Accuracy: 99.41\n",
      "\n",
      "Validation set: Average loss: 0.3907, Accuracy: 4566/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[38.4364550113678 s]\n",
      "Train Epoch: 184 [0/50000 (0%)]\tLoss: 0.015216, Accuracy: 99.80\n",
      "Train Epoch: 184 [2560/50000 (6%)]\tLoss: 0.020633, Accuracy: 99.61\n",
      "Train Epoch: 184 [5120/50000 (11%)]\tLoss: 0.009226, Accuracy: 99.61\n",
      "Train Epoch: 184 [7680/50000 (17%)]\tLoss: 0.009702, Accuracy: 99.80\n",
      "Train Epoch: 184 [10240/50000 (23%)]\tLoss: 0.006967, Accuracy: 99.80\n",
      "Train Epoch: 184 [12800/50000 (28%)]\tLoss: 0.007778, Accuracy: 100.00\n",
      "Train Epoch: 184 [15360/50000 (34%)]\tLoss: 0.018033, Accuracy: 99.61\n",
      "Train Epoch: 184 [17920/50000 (40%)]\tLoss: 0.013153, Accuracy: 99.61\n",
      "Train Epoch: 184 [20480/50000 (45%)]\tLoss: 0.030927, Accuracy: 99.22\n",
      "Train Epoch: 184 [23040/50000 (51%)]\tLoss: 0.015193, Accuracy: 99.61\n",
      "Train Epoch: 184 [25600/50000 (57%)]\tLoss: 0.007921, Accuracy: 99.61\n",
      "Train Epoch: 184 [28160/50000 (62%)]\tLoss: 0.007949, Accuracy: 100.00\n",
      "Train Epoch: 184 [30720/50000 (68%)]\tLoss: 0.012564, Accuracy: 99.80\n",
      "Train Epoch: 184 [33280/50000 (74%)]\tLoss: 0.017025, Accuracy: 99.80\n",
      "Train Epoch: 184 [35840/50000 (80%)]\tLoss: 0.028757, Accuracy: 99.02\n",
      "Train Epoch: 184 [38400/50000 (85%)]\tLoss: 0.009118, Accuracy: 99.61\n",
      "Train Epoch: 184 [40960/50000 (91%)]\tLoss: 0.018099, Accuracy: 99.41\n",
      "Train Epoch: 184 [43520/50000 (97%)]\tLoss: 0.011711, Accuracy: 99.80\n",
      "\n",
      "Validation set: Average loss: 0.3820, Accuracy: 4587/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[35.36292552947998 s]\n",
      "\n",
      "Test set: Average loss: 0.3853, Accuracy: 9149/10000 (91.49%)\n",
      "\n",
      "Train Epoch: 185 [0/50000 (0%)]\tLoss: 0.004847, Accuracy: 100.00\n",
      "Train Epoch: 185 [2560/50000 (6%)]\tLoss: 0.004878, Accuracy: 99.80\n",
      "Train Epoch: 185 [5120/50000 (11%)]\tLoss: 0.012606, Accuracy: 99.61\n",
      "Train Epoch: 185 [7680/50000 (17%)]\tLoss: 0.014070, Accuracy: 99.61\n",
      "Train Epoch: 185 [10240/50000 (23%)]\tLoss: 0.009207, Accuracy: 99.80\n",
      "Train Epoch: 185 [12800/50000 (28%)]\tLoss: 0.014399, Accuracy: 99.61\n",
      "Train Epoch: 185 [15360/50000 (34%)]\tLoss: 0.016599, Accuracy: 99.61\n",
      "Train Epoch: 185 [17920/50000 (40%)]\tLoss: 0.020367, Accuracy: 99.02\n",
      "Train Epoch: 185 [20480/50000 (45%)]\tLoss: 0.023447, Accuracy: 98.83\n",
      "Train Epoch: 185 [23040/50000 (51%)]\tLoss: 0.010892, Accuracy: 99.80\n",
      "Train Epoch: 185 [25600/50000 (57%)]\tLoss: 0.009423, Accuracy: 99.80\n",
      "Train Epoch: 185 [28160/50000 (62%)]\tLoss: 0.015565, Accuracy: 99.61\n",
      "Train Epoch: 185 [30720/50000 (68%)]\tLoss: 0.013901, Accuracy: 99.22\n",
      "Train Epoch: 185 [33280/50000 (74%)]\tLoss: 0.005463, Accuracy: 100.00\n",
      "Train Epoch: 185 [35840/50000 (80%)]\tLoss: 0.018391, Accuracy: 99.22\n",
      "Train Epoch: 185 [38400/50000 (85%)]\tLoss: 0.011902, Accuracy: 99.41\n",
      "Train Epoch: 185 [40960/50000 (91%)]\tLoss: 0.018845, Accuracy: 99.41\n",
      "Train Epoch: 185 [43520/50000 (97%)]\tLoss: 0.007253, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3915, Accuracy: 4567/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[38.78148818016052 s]\n",
      "Train Epoch: 186 [0/50000 (0%)]\tLoss: 0.021134, Accuracy: 99.41\n",
      "Train Epoch: 186 [2560/50000 (6%)]\tLoss: 0.010936, Accuracy: 99.80\n",
      "Train Epoch: 186 [5120/50000 (11%)]\tLoss: 0.005374, Accuracy: 100.00\n",
      "Train Epoch: 186 [7680/50000 (17%)]\tLoss: 0.011673, Accuracy: 99.61\n",
      "Train Epoch: 186 [10240/50000 (23%)]\tLoss: 0.007324, Accuracy: 100.00\n",
      "Train Epoch: 186 [12800/50000 (28%)]\tLoss: 0.012056, Accuracy: 99.61\n",
      "Train Epoch: 186 [15360/50000 (34%)]\tLoss: 0.003826, Accuracy: 100.00\n",
      "Train Epoch: 186 [17920/50000 (40%)]\tLoss: 0.014170, Accuracy: 99.61\n",
      "Train Epoch: 186 [20480/50000 (45%)]\tLoss: 0.005106, Accuracy: 100.00\n",
      "Train Epoch: 186 [23040/50000 (51%)]\tLoss: 0.008737, Accuracy: 99.80\n",
      "Train Epoch: 186 [25600/50000 (57%)]\tLoss: 0.019972, Accuracy: 99.61\n",
      "Train Epoch: 186 [28160/50000 (62%)]\tLoss: 0.008012, Accuracy: 99.80\n",
      "Train Epoch: 186 [30720/50000 (68%)]\tLoss: 0.011734, Accuracy: 99.41\n",
      "Train Epoch: 186 [33280/50000 (74%)]\tLoss: 0.007715, Accuracy: 99.80\n",
      "Train Epoch: 186 [35840/50000 (80%)]\tLoss: 0.022514, Accuracy: 99.02\n",
      "Train Epoch: 186 [38400/50000 (85%)]\tLoss: 0.009731, Accuracy: 99.80\n",
      "Train Epoch: 186 [40960/50000 (91%)]\tLoss: 0.037289, Accuracy: 98.83\n",
      "Train Epoch: 186 [43520/50000 (97%)]\tLoss: 0.015543, Accuracy: 99.61\n",
      "\n",
      "Validation set: Average loss: 0.3892, Accuracy: 4578/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[35.69637203216553 s]\n",
      "\n",
      "Test set: Average loss: 0.3870, Accuracy: 9163/10000 (91.63%)\n",
      "\n",
      "Train Epoch: 187 [0/50000 (0%)]\tLoss: 0.006759, Accuracy: 99.80\n",
      "Train Epoch: 187 [2560/50000 (6%)]\tLoss: 0.011745, Accuracy: 99.41\n",
      "Train Epoch: 187 [5120/50000 (11%)]\tLoss: 0.018419, Accuracy: 99.61\n",
      "Train Epoch: 187 [7680/50000 (17%)]\tLoss: 0.029462, Accuracy: 99.41\n",
      "Train Epoch: 187 [10240/50000 (23%)]\tLoss: 0.010122, Accuracy: 99.61\n",
      "Train Epoch: 187 [12800/50000 (28%)]\tLoss: 0.017939, Accuracy: 99.41\n",
      "Train Epoch: 187 [15360/50000 (34%)]\tLoss: 0.018492, Accuracy: 99.22\n",
      "Train Epoch: 187 [17920/50000 (40%)]\tLoss: 0.021749, Accuracy: 98.83\n",
      "Train Epoch: 187 [20480/50000 (45%)]\tLoss: 0.034613, Accuracy: 99.22\n",
      "Train Epoch: 187 [23040/50000 (51%)]\tLoss: 0.006628, Accuracy: 99.80\n",
      "Train Epoch: 187 [25600/50000 (57%)]\tLoss: 0.009146, Accuracy: 99.80\n",
      "Train Epoch: 187 [28160/50000 (62%)]\tLoss: 0.009158, Accuracy: 99.80\n",
      "Train Epoch: 187 [30720/50000 (68%)]\tLoss: 0.012019, Accuracy: 99.80\n",
      "Train Epoch: 187 [33280/50000 (74%)]\tLoss: 0.005038, Accuracy: 100.00\n",
      "Train Epoch: 187 [35840/50000 (80%)]\tLoss: 0.018030, Accuracy: 99.41\n",
      "Train Epoch: 187 [38400/50000 (85%)]\tLoss: 0.017588, Accuracy: 99.22\n",
      "Train Epoch: 187 [40960/50000 (91%)]\tLoss: 0.012152, Accuracy: 99.61\n",
      "Train Epoch: 187 [43520/50000 (97%)]\tLoss: 0.011841, Accuracy: 99.61\n",
      "\n",
      "Validation set: Average loss: 0.3797, Accuracy: 4591/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[38.442261695861816 s]\n",
      "Train Epoch: 188 [0/50000 (0%)]\tLoss: 0.006110, Accuracy: 99.80\n",
      "Train Epoch: 188 [2560/50000 (6%)]\tLoss: 0.017192, Accuracy: 99.41\n",
      "Train Epoch: 188 [5120/50000 (11%)]\tLoss: 0.010835, Accuracy: 99.41\n",
      "Train Epoch: 188 [7680/50000 (17%)]\tLoss: 0.003897, Accuracy: 100.00\n",
      "Train Epoch: 188 [10240/50000 (23%)]\tLoss: 0.012186, Accuracy: 99.80\n",
      "Train Epoch: 188 [12800/50000 (28%)]\tLoss: 0.016446, Accuracy: 99.61\n",
      "Train Epoch: 188 [15360/50000 (34%)]\tLoss: 0.005171, Accuracy: 100.00\n",
      "Train Epoch: 188 [17920/50000 (40%)]\tLoss: 0.005510, Accuracy: 99.80\n",
      "Train Epoch: 188 [20480/50000 (45%)]\tLoss: 0.024409, Accuracy: 99.41\n",
      "Train Epoch: 188 [23040/50000 (51%)]\tLoss: 0.024459, Accuracy: 99.22\n",
      "Train Epoch: 188 [25600/50000 (57%)]\tLoss: 0.006716, Accuracy: 100.00\n",
      "Train Epoch: 188 [28160/50000 (62%)]\tLoss: 0.006056, Accuracy: 100.00\n",
      "Train Epoch: 188 [30720/50000 (68%)]\tLoss: 0.003035, Accuracy: 100.00\n",
      "Train Epoch: 188 [33280/50000 (74%)]\tLoss: 0.005598, Accuracy: 100.00\n",
      "Train Epoch: 188 [35840/50000 (80%)]\tLoss: 0.013315, Accuracy: 99.61\n",
      "Train Epoch: 188 [38400/50000 (85%)]\tLoss: 0.008421, Accuracy: 99.61\n",
      "Train Epoch: 188 [40960/50000 (91%)]\tLoss: 0.011386, Accuracy: 99.80\n",
      "Train Epoch: 188 [43520/50000 (97%)]\tLoss: 0.007695, Accuracy: 99.61\n",
      "\n",
      "Validation set: Average loss: 0.3742, Accuracy: 4580/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[35.16592597961426 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4058, Accuracy: 9168/10000 (91.68%)\n",
      "\n",
      "Train Epoch: 189 [0/50000 (0%)]\tLoss: 0.004845, Accuracy: 100.00\n",
      "Train Epoch: 189 [2560/50000 (6%)]\tLoss: 0.015739, Accuracy: 99.41\n",
      "Train Epoch: 189 [5120/50000 (11%)]\tLoss: 0.012518, Accuracy: 99.80\n",
      "Train Epoch: 189 [7680/50000 (17%)]\tLoss: 0.018057, Accuracy: 99.41\n",
      "Train Epoch: 189 [10240/50000 (23%)]\tLoss: 0.013298, Accuracy: 99.61\n",
      "Train Epoch: 189 [12800/50000 (28%)]\tLoss: 0.013253, Accuracy: 99.41\n",
      "Train Epoch: 189 [15360/50000 (34%)]\tLoss: 0.039279, Accuracy: 98.83\n",
      "Train Epoch: 189 [17920/50000 (40%)]\tLoss: 0.022421, Accuracy: 99.61\n",
      "Train Epoch: 189 [20480/50000 (45%)]\tLoss: 0.019402, Accuracy: 99.41\n",
      "Train Epoch: 189 [23040/50000 (51%)]\tLoss: 0.005790, Accuracy: 99.80\n",
      "Train Epoch: 189 [25600/50000 (57%)]\tLoss: 0.011565, Accuracy: 99.80\n",
      "Train Epoch: 189 [28160/50000 (62%)]\tLoss: 0.017518, Accuracy: 98.83\n",
      "Train Epoch: 189 [30720/50000 (68%)]\tLoss: 0.018354, Accuracy: 99.22\n",
      "Train Epoch: 189 [33280/50000 (74%)]\tLoss: 0.010819, Accuracy: 99.80\n",
      "Train Epoch: 189 [35840/50000 (80%)]\tLoss: 0.015369, Accuracy: 99.61\n",
      "Train Epoch: 189 [38400/50000 (85%)]\tLoss: 0.016690, Accuracy: 99.61\n",
      "Train Epoch: 189 [40960/50000 (91%)]\tLoss: 0.007273, Accuracy: 100.00\n",
      "Train Epoch: 189 [43520/50000 (97%)]\tLoss: 0.015093, Accuracy: 99.61\n",
      "\n",
      "Validation set: Average loss: 0.3671, Accuracy: 4586/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[38.45427346229553 s]\n",
      "Train Epoch: 190 [0/50000 (0%)]\tLoss: 0.007525, Accuracy: 99.80\n",
      "Train Epoch: 190 [2560/50000 (6%)]\tLoss: 0.024352, Accuracy: 99.02\n",
      "Train Epoch: 190 [5120/50000 (11%)]\tLoss: 0.011983, Accuracy: 99.61\n",
      "Train Epoch: 190 [7680/50000 (17%)]\tLoss: 0.018011, Accuracy: 99.61\n",
      "Train Epoch: 190 [10240/50000 (23%)]\tLoss: 0.016393, Accuracy: 99.41\n",
      "Train Epoch: 190 [12800/50000 (28%)]\tLoss: 0.004097, Accuracy: 100.00\n",
      "Train Epoch: 190 [15360/50000 (34%)]\tLoss: 0.021942, Accuracy: 99.61\n",
      "Train Epoch: 190 [17920/50000 (40%)]\tLoss: 0.003241, Accuracy: 100.00\n",
      "Train Epoch: 190 [20480/50000 (45%)]\tLoss: 0.025058, Accuracy: 99.02\n",
      "Train Epoch: 190 [23040/50000 (51%)]\tLoss: 0.014883, Accuracy: 99.80\n",
      "Train Epoch: 190 [25600/50000 (57%)]\tLoss: 0.013525, Accuracy: 99.80\n",
      "Train Epoch: 190 [28160/50000 (62%)]\tLoss: 0.021829, Accuracy: 99.22\n",
      "Train Epoch: 190 [30720/50000 (68%)]\tLoss: 0.010596, Accuracy: 99.61\n",
      "Train Epoch: 190 [33280/50000 (74%)]\tLoss: 0.005790, Accuracy: 99.80\n",
      "Train Epoch: 190 [35840/50000 (80%)]\tLoss: 0.011982, Accuracy: 99.41\n",
      "Train Epoch: 190 [38400/50000 (85%)]\tLoss: 0.020341, Accuracy: 99.22\n",
      "Train Epoch: 190 [40960/50000 (91%)]\tLoss: 0.026946, Accuracy: 99.22\n",
      "Train Epoch: 190 [43520/50000 (97%)]\tLoss: 0.005291, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3778, Accuracy: 4587/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[35.15716242790222 s]\n",
      "\n",
      "Test set: Average loss: 0.4300, Accuracy: 9078/10000 (90.78%)\n",
      "\n",
      "Train Epoch: 191 [0/50000 (0%)]\tLoss: 0.005188, Accuracy: 100.00\n",
      "Train Epoch: 191 [2560/50000 (6%)]\tLoss: 0.004645, Accuracy: 100.00\n",
      "Train Epoch: 191 [5120/50000 (11%)]\tLoss: 0.005480, Accuracy: 100.00\n",
      "Train Epoch: 191 [7680/50000 (17%)]\tLoss: 0.006965, Accuracy: 99.80\n",
      "Train Epoch: 191 [10240/50000 (23%)]\tLoss: 0.013658, Accuracy: 99.41\n",
      "Train Epoch: 191 [12800/50000 (28%)]\tLoss: 0.014466, Accuracy: 99.80\n",
      "Train Epoch: 191 [15360/50000 (34%)]\tLoss: 0.008444, Accuracy: 99.80\n",
      "Train Epoch: 191 [17920/50000 (40%)]\tLoss: 0.027298, Accuracy: 98.83\n",
      "Train Epoch: 191 [20480/50000 (45%)]\tLoss: 0.011830, Accuracy: 99.61\n",
      "Train Epoch: 191 [23040/50000 (51%)]\tLoss: 0.010567, Accuracy: 99.41\n",
      "Train Epoch: 191 [25600/50000 (57%)]\tLoss: 0.027958, Accuracy: 99.02\n",
      "Train Epoch: 191 [28160/50000 (62%)]\tLoss: 0.008111, Accuracy: 99.80\n",
      "Train Epoch: 191 [30720/50000 (68%)]\tLoss: 0.009809, Accuracy: 99.61\n",
      "Train Epoch: 191 [33280/50000 (74%)]\tLoss: 0.014294, Accuracy: 99.61\n",
      "Train Epoch: 191 [35840/50000 (80%)]\tLoss: 0.011510, Accuracy: 99.61\n",
      "Train Epoch: 191 [38400/50000 (85%)]\tLoss: 0.013863, Accuracy: 99.41\n",
      "Train Epoch: 191 [40960/50000 (91%)]\tLoss: 0.007980, Accuracy: 99.80\n",
      "Train Epoch: 191 [43520/50000 (97%)]\tLoss: 0.015529, Accuracy: 99.61\n",
      "\n",
      "Validation set: Average loss: 0.3617, Accuracy: 4592/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[38.415497064590454 s]\n",
      "Train Epoch: 192 [0/50000 (0%)]\tLoss: 0.005189, Accuracy: 99.80\n",
      "Train Epoch: 192 [2560/50000 (6%)]\tLoss: 0.007222, Accuracy: 99.80\n",
      "Train Epoch: 192 [5120/50000 (11%)]\tLoss: 0.006743, Accuracy: 100.00\n",
      "Train Epoch: 192 [7680/50000 (17%)]\tLoss: 0.011831, Accuracy: 99.80\n",
      "Train Epoch: 192 [10240/50000 (23%)]\tLoss: 0.007363, Accuracy: 99.80\n",
      "Train Epoch: 192 [12800/50000 (28%)]\tLoss: 0.014479, Accuracy: 99.41\n",
      "Train Epoch: 192 [15360/50000 (34%)]\tLoss: 0.007524, Accuracy: 99.80\n",
      "Train Epoch: 192 [17920/50000 (40%)]\tLoss: 0.018715, Accuracy: 99.22\n",
      "Train Epoch: 192 [20480/50000 (45%)]\tLoss: 0.021427, Accuracy: 99.41\n",
      "Train Epoch: 192 [23040/50000 (51%)]\tLoss: 0.012290, Accuracy: 99.22\n",
      "Train Epoch: 192 [25600/50000 (57%)]\tLoss: 0.022538, Accuracy: 99.02\n",
      "Train Epoch: 192 [28160/50000 (62%)]\tLoss: 0.027707, Accuracy: 99.22\n",
      "Train Epoch: 192 [30720/50000 (68%)]\tLoss: 0.006506, Accuracy: 100.00\n",
      "Train Epoch: 192 [33280/50000 (74%)]\tLoss: 0.020215, Accuracy: 99.41\n",
      "Train Epoch: 192 [35840/50000 (80%)]\tLoss: 0.007087, Accuracy: 99.80\n",
      "Train Epoch: 192 [38400/50000 (85%)]\tLoss: 0.016015, Accuracy: 99.80\n",
      "Train Epoch: 192 [40960/50000 (91%)]\tLoss: 0.013084, Accuracy: 99.80\n",
      "Train Epoch: 192 [43520/50000 (97%)]\tLoss: 0.019354, Accuracy: 99.02\n",
      "\n",
      "Validation set: Average loss: 0.3806, Accuracy: 4590/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[35.14816069602966 s]\n",
      "\n",
      "Test set: Average loss: 0.3983, Accuracy: 9125/10000 (91.25%)\n",
      "\n",
      "Train Epoch: 193 [0/50000 (0%)]\tLoss: 0.017324, Accuracy: 99.41\n",
      "Train Epoch: 193 [2560/50000 (6%)]\tLoss: 0.024927, Accuracy: 99.02\n",
      "Train Epoch: 193 [5120/50000 (11%)]\tLoss: 0.018887, Accuracy: 99.22\n",
      "Train Epoch: 193 [7680/50000 (17%)]\tLoss: 0.015678, Accuracy: 99.41\n",
      "Train Epoch: 193 [10240/50000 (23%)]\tLoss: 0.008845, Accuracy: 99.80\n",
      "Train Epoch: 193 [12800/50000 (28%)]\tLoss: 0.019575, Accuracy: 99.61\n",
      "Train Epoch: 193 [15360/50000 (34%)]\tLoss: 0.045445, Accuracy: 99.02\n",
      "Train Epoch: 193 [17920/50000 (40%)]\tLoss: 0.007218, Accuracy: 99.80\n",
      "Train Epoch: 193 [20480/50000 (45%)]\tLoss: 0.020187, Accuracy: 99.41\n",
      "Train Epoch: 193 [23040/50000 (51%)]\tLoss: 0.013142, Accuracy: 99.61\n",
      "Train Epoch: 193 [25600/50000 (57%)]\tLoss: 0.011592, Accuracy: 99.61\n",
      "Train Epoch: 193 [28160/50000 (62%)]\tLoss: 0.004233, Accuracy: 100.00\n",
      "Train Epoch: 193 [30720/50000 (68%)]\tLoss: 0.016152, Accuracy: 99.41\n",
      "Train Epoch: 193 [33280/50000 (74%)]\tLoss: 0.018909, Accuracy: 99.02\n",
      "Train Epoch: 193 [35840/50000 (80%)]\tLoss: 0.023705, Accuracy: 99.22\n",
      "Train Epoch: 193 [38400/50000 (85%)]\tLoss: 0.012355, Accuracy: 99.41\n",
      "Train Epoch: 193 [40960/50000 (91%)]\tLoss: 0.009640, Accuracy: 99.80\n",
      "Train Epoch: 193 [43520/50000 (97%)]\tLoss: 0.006941, Accuracy: 99.80\n",
      "\n",
      "Validation set: Average loss: 0.3690, Accuracy: 4590/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[38.462629556655884 s]\n",
      "Train Epoch: 194 [0/50000 (0%)]\tLoss: 0.005792, Accuracy: 99.80\n",
      "Train Epoch: 194 [2560/50000 (6%)]\tLoss: 0.012893, Accuracy: 99.22\n",
      "Train Epoch: 194 [5120/50000 (11%)]\tLoss: 0.029090, Accuracy: 98.63\n",
      "Train Epoch: 194 [7680/50000 (17%)]\tLoss: 0.015324, Accuracy: 99.61\n",
      "Train Epoch: 194 [10240/50000 (23%)]\tLoss: 0.025324, Accuracy: 99.22\n",
      "Train Epoch: 194 [12800/50000 (28%)]\tLoss: 0.013982, Accuracy: 99.80\n",
      "Train Epoch: 194 [15360/50000 (34%)]\tLoss: 0.006272, Accuracy: 99.80\n",
      "Train Epoch: 194 [17920/50000 (40%)]\tLoss: 0.012673, Accuracy: 99.80\n",
      "Train Epoch: 194 [20480/50000 (45%)]\tLoss: 0.014062, Accuracy: 99.80\n",
      "Train Epoch: 194 [23040/50000 (51%)]\tLoss: 0.025690, Accuracy: 99.02\n",
      "Train Epoch: 194 [25600/50000 (57%)]\tLoss: 0.012954, Accuracy: 99.61\n",
      "Train Epoch: 194 [28160/50000 (62%)]\tLoss: 0.014265, Accuracy: 99.61\n",
      "Train Epoch: 194 [30720/50000 (68%)]\tLoss: 0.021807, Accuracy: 99.02\n",
      "Train Epoch: 194 [33280/50000 (74%)]\tLoss: 0.005432, Accuracy: 99.80\n",
      "Train Epoch: 194 [35840/50000 (80%)]\tLoss: 0.018088, Accuracy: 99.22\n",
      "Train Epoch: 194 [38400/50000 (85%)]\tLoss: 0.009857, Accuracy: 99.61\n",
      "Train Epoch: 194 [40960/50000 (91%)]\tLoss: 0.005273, Accuracy: 99.80\n",
      "Train Epoch: 194 [43520/50000 (97%)]\tLoss: 0.002797, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3817, Accuracy: 4586/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[35.130794286727905 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4006, Accuracy: 9132/10000 (91.32%)\n",
      "\n",
      "Train Epoch: 195 [0/50000 (0%)]\tLoss: 0.002406, Accuracy: 100.00\n",
      "Train Epoch: 195 [2560/50000 (6%)]\tLoss: 0.005959, Accuracy: 99.80\n",
      "Train Epoch: 195 [5120/50000 (11%)]\tLoss: 0.005751, Accuracy: 99.80\n",
      "Train Epoch: 195 [7680/50000 (17%)]\tLoss: 0.016486, Accuracy: 99.41\n",
      "Train Epoch: 195 [10240/50000 (23%)]\tLoss: 0.012169, Accuracy: 99.80\n",
      "Train Epoch: 195 [12800/50000 (28%)]\tLoss: 0.010057, Accuracy: 99.61\n",
      "Train Epoch: 195 [15360/50000 (34%)]\tLoss: 0.019845, Accuracy: 99.02\n",
      "Train Epoch: 195 [17920/50000 (40%)]\tLoss: 0.008044, Accuracy: 100.00\n",
      "Train Epoch: 195 [20480/50000 (45%)]\tLoss: 0.014487, Accuracy: 99.61\n",
      "Train Epoch: 195 [23040/50000 (51%)]\tLoss: 0.017878, Accuracy: 99.22\n",
      "Train Epoch: 195 [25600/50000 (57%)]\tLoss: 0.015453, Accuracy: 99.80\n",
      "Train Epoch: 195 [28160/50000 (62%)]\tLoss: 0.019680, Accuracy: 99.22\n",
      "Train Epoch: 195 [30720/50000 (68%)]\tLoss: 0.024947, Accuracy: 99.61\n",
      "Train Epoch: 195 [33280/50000 (74%)]\tLoss: 0.006127, Accuracy: 100.00\n",
      "Train Epoch: 195 [35840/50000 (80%)]\tLoss: 0.006759, Accuracy: 100.00\n",
      "Train Epoch: 195 [38400/50000 (85%)]\tLoss: 0.007905, Accuracy: 100.00\n",
      "Train Epoch: 195 [40960/50000 (91%)]\tLoss: 0.016446, Accuracy: 99.61\n",
      "Train Epoch: 195 [43520/50000 (97%)]\tLoss: 0.004950, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3886, Accuracy: 4574/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[38.47966718673706 s]\n",
      "Train Epoch: 196 [0/50000 (0%)]\tLoss: 0.010348, Accuracy: 99.41\n",
      "Train Epoch: 196 [2560/50000 (6%)]\tLoss: 0.014150, Accuracy: 99.80\n",
      "Train Epoch: 196 [5120/50000 (11%)]\tLoss: 0.015484, Accuracy: 99.61\n",
      "Train Epoch: 196 [7680/50000 (17%)]\tLoss: 0.013346, Accuracy: 99.41\n",
      "Train Epoch: 196 [10240/50000 (23%)]\tLoss: 0.020359, Accuracy: 99.41\n",
      "Train Epoch: 196 [12800/50000 (28%)]\tLoss: 0.015868, Accuracy: 99.22\n",
      "Train Epoch: 196 [15360/50000 (34%)]\tLoss: 0.022077, Accuracy: 99.41\n",
      "Train Epoch: 196 [17920/50000 (40%)]\tLoss: 0.010948, Accuracy: 99.80\n",
      "Train Epoch: 196 [20480/50000 (45%)]\tLoss: 0.013730, Accuracy: 99.41\n",
      "Train Epoch: 196 [23040/50000 (51%)]\tLoss: 0.008015, Accuracy: 99.61\n",
      "Train Epoch: 196 [25600/50000 (57%)]\tLoss: 0.017138, Accuracy: 99.41\n",
      "Train Epoch: 196 [28160/50000 (62%)]\tLoss: 0.033193, Accuracy: 99.22\n",
      "Train Epoch: 196 [30720/50000 (68%)]\tLoss: 0.010214, Accuracy: 99.61\n",
      "Train Epoch: 196 [33280/50000 (74%)]\tLoss: 0.005254, Accuracy: 100.00\n",
      "Train Epoch: 196 [35840/50000 (80%)]\tLoss: 0.009840, Accuracy: 99.61\n",
      "Train Epoch: 196 [38400/50000 (85%)]\tLoss: 0.005851, Accuracy: 100.00\n",
      "Train Epoch: 196 [40960/50000 (91%)]\tLoss: 0.008173, Accuracy: 99.61\n",
      "------------------------------\n",
      "before autoscale: torch.Size([512, 1, 1])\n",
      "tensor([[[ 0.0000]],\n",
      "\n",
      "        [[ 0.2281]],\n",
      "\n",
      "        [[ 0.0074]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.2818]],\n",
      "\n",
      "        [[ 0.3010]],\n",
      "\n",
      "        [[ 0.0748]],\n",
      "\n",
      "        [[ 0.0249]],\n",
      "\n",
      "        [[ 0.0053]],\n",
      "\n",
      "        [[ 0.2790]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[-0.2466]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 512])\n",
      "tensor(1.00000e-02 *\n",
      "       [[[ 0.0000, -5.6242, -0.1830,  0.0000, -6.9492, -7.4234, -1.8441,\n",
      "          -0.6146, -0.1312, -6.8803, -3.9660, -2.0438, -7.1735, -5.2895,\n",
      "          -0.3102,  0.0000, -3.1951,  0.0000, -1.9120, -7.5294, -1.2103,\n",
      "          -5.1636, -8.3514, -3.0176, -4.5507, -4.9913, -0.6396, -7.0158,\n",
      "           0.0000, -2.0184, -1.6422, -5.2410, -0.1683, -0.0338, -1.6982,\n",
      "          -2.5952, -7.0699,  0.0000,  0.0000, -6.5694, -7.1541, -0.0345,\n",
      "          -6.1425, -5.2519, -1.6838, -4.2220,  0.0000, -6.9807, -0.3973,\n",
      "          -6.5179,  0.0000, -3.8824,  0.0000, -9.9421, -5.2944, -7.1352,\n",
      "           0.0000, -0.0519, -1.4077, -0.5042, -8.3330, -4.3459, -5.3476,\n",
      "          -0.0166, -1.5039, -1.1811, -0.6165, -0.0056, -0.2015, -0.4833,\n",
      "          -0.1977,  0.0000,  0.0000,  0.0000, -0.1840,  0.0000, -0.0046,\n",
      "          -0.0727, -0.0538, -0.0949, -0.1110, -0.1788, -0.0988,  0.0000,\n",
      "          -0.1311, -0.1396, -0.0051,  0.0000, -0.0057,  0.0000,  0.0000,\n",
      "          -0.0039,  0.0000,  0.0000,  0.0000,  0.0000, -0.3560,  0.0000,\n",
      "          -0.0072, -0.0089, -0.0177, -0.0158,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.5376,  0.0000,  0.0000,  0.0000,  0.0000, -0.0091,\n",
      "          -0.0342,  0.0000,  0.0000,  0.0000, -0.5883,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0024,  0.0000,  0.0000,\n",
      "          -0.0093, -0.0035, -0.0000,  0.0000, -0.0006, -0.0039,  0.0000,\n",
      "           0.0000,  0.0000, -0.0009, -0.0011,  0.0000, -0.0022, -0.0038,\n",
      "           0.0000, -0.0686,  0.0000,  0.0000, -0.0797, -0.1659,  0.0000,\n",
      "          -0.5853,  0.0000,  0.0000, -0.0407,  0.0000, -0.9433, -0.5353,\n",
      "          -0.0720, -0.0942,  0.0000,  0.0000, -0.0023,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000, -0.0338,  0.0000,  0.0000, -0.1386, -0.0574,\n",
      "          -0.0300, -0.0279, -0.0386,  0.0000, -0.0885, -0.0765, -0.1048,\n",
      "          -0.1305, -0.3327, -0.1176,  0.0000, -0.2904, -0.2925, -0.1762,\n",
      "           0.0000, -1.2124,  0.0000,  0.0000, -0.2010, -0.2620, -0.0101,\n",
      "          -0.0039, -0.0028, -0.0025, -0.0019, -0.0018, -0.0041, -0.0056,\n",
      "           0.0000,  0.0000,  0.0000, -0.0118, -0.8694,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000, -0.0819, -0.1245, -0.0740,  0.0000, -0.0914,\n",
      "           0.0000,  0.0000, -0.0004, -0.0071,  0.0000, -0.0001,  0.0000,\n",
      "          -0.0012, -0.0074, -0.0062, -0.0037, -0.0033,  0.0000, -0.0005,\n",
      "          -0.0020,  0.0000, -0.0027, -0.0023,  0.0000, -0.0025, -0.0008,\n",
      "          -0.0001,  0.0000,  0.0000, -0.1231, -0.1578, -0.8005,  0.0000,\n",
      "           0.0000,  0.0000, -0.1877, -0.0017,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0009, -0.0012, -0.0052, -0.0038,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0008, -0.0216,  0.0000, -0.0162, -0.0099, -0.0217,  0.0000,\n",
      "          -0.0882, -0.1472, -0.1146, -0.9971,  0.0000,  0.0000,  0.0000,\n",
      "          -0.1660, -0.0024, -0.0017, -0.0025,  0.0000, -0.0143,  0.0000,\n",
      "          -0.1481, -0.2526, -0.2301, -0.8329, -0.2160, -0.2194, -0.2827,\n",
      "          -0.2989, -0.0760, -0.0593,  0.0000, -0.1777, -0.2882, -0.2429,\n",
      "          -0.4295, -0.2576, -0.2628,  0.0000, -0.2606, -0.0479, -0.0736,\n",
      "           0.0000, -0.1113, -0.0752, -0.0729, -0.1070,  0.0000, -0.0061,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.4838, -0.0964,  0.0000,  0.0000, -0.3366, -0.0979,  0.0000,\n",
      "          -0.0024, -0.0556,  0.0000, -0.0618,  0.0000,  0.0000, -0.0376,\n",
      "           0.0000,  0.0000,  0.0000, -0.0029, -0.0010, -0.0004, -0.0045,\n",
      "           0.0000, -0.0620, -0.1305, -0.1225, -0.7485, -0.1466, -0.1014,\n",
      "           0.0000, -0.2460, -0.1612, -0.5155,  0.0000,  0.0000, -0.1181,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0057,  0.0000,  0.0000,\n",
      "          -0.0980, -0.1255,  0.0000, -0.5120,  0.0000, -0.1197, -0.1655,\n",
      "          -0.2305,  0.0000, -0.0344, -0.0345, -0.1619, -0.0494, -0.0334,\n",
      "           0.0000, -0.0506, -0.0107, -0.0092, -0.0035, -0.0031, -0.0040,\n",
      "           0.0000, -0.0068,  0.0000, -0.0004, -0.0532,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000,  0.0000, -0.0077, -0.0011,  0.0000,\n",
      "          -0.0005, -0.0090, -0.0033, -0.0031, -0.0416, -0.0368, -0.0368,\n",
      "          -0.0510,  0.0000, -0.0233,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          -0.5149,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2887,\n",
      "          -0.3190,  0.0000, -0.0993,  0.0000, -0.1888, -0.0012, -0.0015,\n",
      "           0.0000, -0.0117,  0.0000,  0.0000, -0.3418,  0.0000, -7.5760,\n",
      "          -0.5323,  0.0000, -0.4111,  0.0000, -0.9011,  0.0000, -0.2620,\n",
      "          -0.1820,  0.0000,  0.0000, -0.0009,  0.0000,  0.0000, -0.0017,\n",
      "           0.0000,  0.0000, -0.0129, -0.0045,  0.0000, -0.0135, -0.0031,\n",
      "          -0.0036, -0.0050,  0.0000,  0.0000,  0.0000, -0.0259, -0.0370,\n",
      "           0.0000, -0.0736, -0.1645, -0.1021, -0.0821,  0.0000,  0.0000,\n",
      "           0.0000, -0.0819,  0.0000, -0.0023, -0.0085,  0.0000, -0.0071,\n",
      "          -0.0050,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.4991,\n",
      "           0.0000, -0.1392, -0.1979,  0.0000, -0.0507,  0.0000, -0.0530,\n",
      "          -0.0579, -0.1330,  0.0000, -0.1497,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.8205, -0.0685,  0.0000,  0.0000,  0.0000, -0.0683,\n",
      "          -0.0777, -0.2156,  0.0000, -0.0725,  0.0000,  0.0000,  0.0000,\n",
      "          -0.0015, -0.0177, -0.0016,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000, -0.4836, -0.0446, -0.1577,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-04 *\n",
      "       [[ 1.0617,  1.8280,  0.4728,  1.1151,  2.2909, -1.1142,  3.6467,\n",
      "          3.1359, -0.9881]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 448, 512])\n",
      "tensor([[ 1.2466e-05, -2.7137e-05, -5.3489e-05,  ..., -6.6953e-07,\n",
      "         -3.3573e-07, -1.6747e-07],\n",
      "        [ 7.7060e-06,  1.5303e-06, -2.2024e-06,  ...,  2.0465e-06,\n",
      "          6.5625e-07,  5.3754e-07],\n",
      "        [ 1.9024e-05,  1.7076e-05,  1.7412e-05,  ...,  6.2991e-07,\n",
      "          4.2479e-07,  3.3126e-08],\n",
      "        ...,\n",
      "        [ 6.2183e-06,  8.4326e-06,  1.2943e-05,  ...,  2.0899e-06,\n",
      "          2.8275e-07,  5.9295e-07],\n",
      "        [ 1.1866e-05, -3.2698e-06,  3.2017e-05,  ..., -1.7679e-06,\n",
      "         -9.3534e-08, -4.9725e-07],\n",
      "        [-4.3841e-05, -4.2890e-06, -3.3808e-06,  ..., -1.3480e-06,\n",
      "         -4.4883e-07, -3.9881e-07]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 448, 512])\n",
      "tensor([[ 1.2466e-06, -2.7137e-06, -5.3489e-06,  ..., -6.6953e-08,\n",
      "         -3.3573e-08, -1.6747e-08],\n",
      "        [ 7.7060e-07,  1.5303e-07, -2.2024e-07,  ...,  2.0465e-07,\n",
      "          6.5625e-08,  5.3754e-08],\n",
      "        [ 1.9024e-06,  1.7076e-06,  1.7412e-06,  ...,  6.2991e-08,\n",
      "          4.2479e-08,  3.3126e-09],\n",
      "        ...,\n",
      "        [-9.1441e-06, -1.0621e-05, -1.5031e-05,  ..., -1.0255e-07,\n",
      "         -3.2022e-08, -2.9273e-08],\n",
      "        [-1.4446e-04, -1.7646e-04, -1.9770e-04,  ..., -5.2488e-06,\n",
      "         -1.1452e-06, -1.2218e-06],\n",
      "        [-4.0923e-06, -6.7802e-06, -8.1812e-06,  ..., -1.5143e-07,\n",
      "         -5.3086e-08, -2.7847e-08]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 196 [43520/50000 (97%)]\tLoss: 0.017171, Accuracy: 99.22\n",
      "\n",
      "Validation set: Average loss: 0.3831, Accuracy: 4595/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[35.1677668094635 s]\n",
      "\n",
      "Test set: Average loss: 0.4080, Accuracy: 9130/10000 (91.30%)\n",
      "\n",
      "Train Epoch: 197 [0/50000 (0%)]\tLoss: 0.024896, Accuracy: 99.02\n",
      "Train Epoch: 197 [2560/50000 (6%)]\tLoss: 0.005837, Accuracy: 100.00\n",
      "Train Epoch: 197 [5120/50000 (11%)]\tLoss: 0.018768, Accuracy: 99.41\n",
      "Train Epoch: 197 [7680/50000 (17%)]\tLoss: 0.008573, Accuracy: 99.61\n",
      "Train Epoch: 197 [10240/50000 (23%)]\tLoss: 0.006655, Accuracy: 99.80\n",
      "Train Epoch: 197 [12800/50000 (28%)]\tLoss: 0.008763, Accuracy: 99.80\n",
      "Train Epoch: 197 [15360/50000 (34%)]\tLoss: 0.009570, Accuracy: 99.61\n",
      "Train Epoch: 197 [17920/50000 (40%)]\tLoss: 0.017100, Accuracy: 99.22\n",
      "Train Epoch: 197 [20480/50000 (45%)]\tLoss: 0.022555, Accuracy: 99.61\n",
      "Train Epoch: 197 [23040/50000 (51%)]\tLoss: 0.014030, Accuracy: 99.61\n",
      "Train Epoch: 197 [25600/50000 (57%)]\tLoss: 0.014067, Accuracy: 99.61\n",
      "Train Epoch: 197 [28160/50000 (62%)]\tLoss: 0.023724, Accuracy: 99.41\n",
      "Train Epoch: 197 [30720/50000 (68%)]\tLoss: 0.004853, Accuracy: 100.00\n",
      "Train Epoch: 197 [33280/50000 (74%)]\tLoss: 0.026189, Accuracy: 99.02\n",
      "Train Epoch: 197 [35840/50000 (80%)]\tLoss: 0.016411, Accuracy: 99.61\n",
      "Train Epoch: 197 [38400/50000 (85%)]\tLoss: 0.014866, Accuracy: 99.61\n",
      "Train Epoch: 197 [40960/50000 (91%)]\tLoss: 0.007985, Accuracy: 99.80\n",
      "Train Epoch: 197 [43520/50000 (97%)]\tLoss: 0.016638, Accuracy: 99.41\n",
      "\n",
      "Validation set: Average loss: 0.3828, Accuracy: 4583/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[38.506463289260864 s]\n",
      "Train Epoch: 198 [0/50000 (0%)]\tLoss: 0.005839, Accuracy: 100.00\n",
      "Train Epoch: 198 [2560/50000 (6%)]\tLoss: 0.015549, Accuracy: 99.41\n",
      "Train Epoch: 198 [5120/50000 (11%)]\tLoss: 0.017258, Accuracy: 99.41\n",
      "Train Epoch: 198 [7680/50000 (17%)]\tLoss: 0.010646, Accuracy: 99.61\n",
      "Train Epoch: 198 [10240/50000 (23%)]\tLoss: 0.011664, Accuracy: 99.61\n",
      "Train Epoch: 198 [12800/50000 (28%)]\tLoss: 0.019276, Accuracy: 99.41\n",
      "Train Epoch: 198 [15360/50000 (34%)]\tLoss: 0.013505, Accuracy: 99.41\n",
      "Train Epoch: 198 [17920/50000 (40%)]\tLoss: 0.009191, Accuracy: 99.61\n",
      "Train Epoch: 198 [20480/50000 (45%)]\tLoss: 0.009551, Accuracy: 99.61\n",
      "Train Epoch: 198 [23040/50000 (51%)]\tLoss: 0.003301, Accuracy: 100.00\n",
      "Train Epoch: 198 [25600/50000 (57%)]\tLoss: 0.009838, Accuracy: 99.61\n",
      "Train Epoch: 198 [28160/50000 (62%)]\tLoss: 0.004429, Accuracy: 100.00\n",
      "Train Epoch: 198 [30720/50000 (68%)]\tLoss: 0.009766, Accuracy: 99.80\n",
      "Train Epoch: 198 [33280/50000 (74%)]\tLoss: 0.006319, Accuracy: 99.80\n",
      "Train Epoch: 198 [35840/50000 (80%)]\tLoss: 0.011272, Accuracy: 99.61\n",
      "Train Epoch: 198 [38400/50000 (85%)]\tLoss: 0.019824, Accuracy: 98.83\n",
      "Train Epoch: 198 [40960/50000 (91%)]\tLoss: 0.008891, Accuracy: 99.61\n",
      "Train Epoch: 198 [43520/50000 (97%)]\tLoss: 0.009593, Accuracy: 99.80\n",
      "\n",
      "Validation set: Average loss: 0.3708, Accuracy: 4587/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[35.35181260108948 s]\n",
      "\n",
      "Test set: Average loss: 0.3916, Accuracy: 9154/10000 (91.54%)\n",
      "\n",
      "Train Epoch: 199 [0/50000 (0%)]\tLoss: 0.010402, Accuracy: 99.80\n",
      "Train Epoch: 199 [2560/50000 (6%)]\tLoss: 0.005748, Accuracy: 99.80\n",
      "Train Epoch: 199 [5120/50000 (11%)]\tLoss: 0.013133, Accuracy: 99.41\n",
      "Train Epoch: 199 [7680/50000 (17%)]\tLoss: 0.004234, Accuracy: 100.00\n",
      "Train Epoch: 199 [10240/50000 (23%)]\tLoss: 0.007140, Accuracy: 100.00\n",
      "Train Epoch: 199 [12800/50000 (28%)]\tLoss: 0.018270, Accuracy: 99.22\n",
      "Train Epoch: 199 [15360/50000 (34%)]\tLoss: 0.018529, Accuracy: 99.41\n",
      "Train Epoch: 199 [17920/50000 (40%)]\tLoss: 0.003974, Accuracy: 100.00\n",
      "Train Epoch: 199 [20480/50000 (45%)]\tLoss: 0.008541, Accuracy: 99.80\n",
      "Train Epoch: 199 [23040/50000 (51%)]\tLoss: 0.009336, Accuracy: 99.80\n",
      "Train Epoch: 199 [25600/50000 (57%)]\tLoss: 0.019239, Accuracy: 99.61\n",
      "Train Epoch: 199 [28160/50000 (62%)]\tLoss: 0.010383, Accuracy: 99.41\n",
      "Train Epoch: 199 [30720/50000 (68%)]\tLoss: 0.007508, Accuracy: 99.80\n",
      "Train Epoch: 199 [33280/50000 (74%)]\tLoss: 0.022688, Accuracy: 99.41\n",
      "Train Epoch: 199 [35840/50000 (80%)]\tLoss: 0.009535, Accuracy: 99.80\n",
      "Train Epoch: 199 [38400/50000 (85%)]\tLoss: 0.003398, Accuracy: 100.00\n",
      "Train Epoch: 199 [40960/50000 (91%)]\tLoss: 0.007557, Accuracy: 99.80\n",
      "Train Epoch: 199 [43520/50000 (97%)]\tLoss: 0.022549, Accuracy: 99.61\n",
      "\n",
      "Validation set: Average loss: 0.3914, Accuracy: 4574/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[38.75825834274292 s]\n",
      "Train Epoch: 200 [0/50000 (0%)]\tLoss: 0.005719, Accuracy: 100.00\n",
      "Train Epoch: 200 [2560/50000 (6%)]\tLoss: 0.004545, Accuracy: 100.00\n",
      "Train Epoch: 200 [5120/50000 (11%)]\tLoss: 0.011304, Accuracy: 99.61\n",
      "Train Epoch: 200 [7680/50000 (17%)]\tLoss: 0.005883, Accuracy: 99.80\n",
      "Train Epoch: 200 [10240/50000 (23%)]\tLoss: 0.008198, Accuracy: 99.80\n",
      "Train Epoch: 200 [12800/50000 (28%)]\tLoss: 0.013994, Accuracy: 99.61\n",
      "Train Epoch: 200 [15360/50000 (34%)]\tLoss: 0.023101, Accuracy: 99.61\n",
      "Train Epoch: 200 [17920/50000 (40%)]\tLoss: 0.029970, Accuracy: 99.22\n",
      "Train Epoch: 200 [20480/50000 (45%)]\tLoss: 0.009274, Accuracy: 99.61\n",
      "Train Epoch: 200 [23040/50000 (51%)]\tLoss: 0.021816, Accuracy: 99.41\n",
      "Train Epoch: 200 [25600/50000 (57%)]\tLoss: 0.016506, Accuracy: 99.41\n",
      "Train Epoch: 200 [28160/50000 (62%)]\tLoss: 0.018309, Accuracy: 99.22\n",
      "Train Epoch: 200 [30720/50000 (68%)]\tLoss: 0.033243, Accuracy: 98.83\n",
      "Train Epoch: 200 [33280/50000 (74%)]\tLoss: 0.005764, Accuracy: 100.00\n",
      "Train Epoch: 200 [35840/50000 (80%)]\tLoss: 0.017791, Accuracy: 99.41\n",
      "Train Epoch: 200 [38400/50000 (85%)]\tLoss: 0.014424, Accuracy: 99.22\n",
      "Train Epoch: 200 [40960/50000 (91%)]\tLoss: 0.008870, Accuracy: 99.80\n",
      "Train Epoch: 200 [43520/50000 (97%)]\tLoss: 0.015040, Accuracy: 99.61\n",
      "\n",
      "Validation set: Average loss: 0.3908, Accuracy: 4582/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[35.47610592842102 s]\n",
      "\n",
      "Test set: Average loss: 0.4037, Accuracy: 9138/10000 (91.38%)\n",
      "\n",
      "Train Epoch: 201 [0/50000 (0%)]\tLoss: 0.003772, Accuracy: 100.00\n",
      "Train Epoch: 201 [2560/50000 (6%)]\tLoss: 0.004442, Accuracy: 99.80\n",
      "Train Epoch: 201 [5120/50000 (11%)]\tLoss: 0.003467, Accuracy: 100.00\n",
      "Train Epoch: 201 [7680/50000 (17%)]\tLoss: 0.020754, Accuracy: 98.83\n",
      "Train Epoch: 201 [10240/50000 (23%)]\tLoss: 0.014385, Accuracy: 99.61\n",
      "Train Epoch: 201 [12800/50000 (28%)]\tLoss: 0.005403, Accuracy: 100.00\n",
      "Train Epoch: 201 [15360/50000 (34%)]\tLoss: 0.010091, Accuracy: 99.41\n",
      "Train Epoch: 201 [17920/50000 (40%)]\tLoss: 0.013457, Accuracy: 99.61\n",
      "Train Epoch: 201 [20480/50000 (45%)]\tLoss: 0.009939, Accuracy: 99.61\n",
      "Train Epoch: 201 [23040/50000 (51%)]\tLoss: 0.019036, Accuracy: 99.61\n",
      "Train Epoch: 201 [25600/50000 (57%)]\tLoss: 0.006903, Accuracy: 100.00\n",
      "Train Epoch: 201 [28160/50000 (62%)]\tLoss: 0.010361, Accuracy: 99.61\n",
      "Train Epoch: 201 [30720/50000 (68%)]\tLoss: 0.013533, Accuracy: 99.80\n",
      "Train Epoch: 201 [33280/50000 (74%)]\tLoss: 0.013738, Accuracy: 99.61\n",
      "Train Epoch: 201 [35840/50000 (80%)]\tLoss: 0.004772, Accuracy: 99.80\n",
      "Train Epoch: 201 [38400/50000 (85%)]\tLoss: 0.013513, Accuracy: 99.61\n",
      "Train Epoch: 201 [40960/50000 (91%)]\tLoss: 0.009602, Accuracy: 99.80\n",
      "Train Epoch: 201 [43520/50000 (97%)]\tLoss: 0.007908, Accuracy: 99.80\n",
      "\n",
      "Validation set: Average loss: 0.3799, Accuracy: 4596/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[38.763413429260254 s]\n",
      "Train Epoch: 202 [0/50000 (0%)]\tLoss: 0.020103, Accuracy: 99.61\n",
      "Train Epoch: 202 [2560/50000 (6%)]\tLoss: 0.007085, Accuracy: 100.00\n",
      "Train Epoch: 202 [5120/50000 (11%)]\tLoss: 0.006063, Accuracy: 99.80\n",
      "Train Epoch: 202 [7680/50000 (17%)]\tLoss: 0.004777, Accuracy: 100.00\n",
      "Train Epoch: 202 [10240/50000 (23%)]\tLoss: 0.003500, Accuracy: 100.00\n",
      "Train Epoch: 202 [12800/50000 (28%)]\tLoss: 0.004341, Accuracy: 100.00\n",
      "Train Epoch: 202 [15360/50000 (34%)]\tLoss: 0.004642, Accuracy: 100.00\n",
      "Train Epoch: 202 [17920/50000 (40%)]\tLoss: 0.004565, Accuracy: 100.00\n",
      "Train Epoch: 202 [20480/50000 (45%)]\tLoss: 0.017677, Accuracy: 99.80\n",
      "Train Epoch: 202 [23040/50000 (51%)]\tLoss: 0.006568, Accuracy: 99.80\n",
      "Train Epoch: 202 [25600/50000 (57%)]\tLoss: 0.003376, Accuracy: 100.00\n",
      "Train Epoch: 202 [28160/50000 (62%)]\tLoss: 0.008166, Accuracy: 99.80\n",
      "Train Epoch: 202 [30720/50000 (68%)]\tLoss: 0.010600, Accuracy: 99.61\n",
      "Train Epoch: 202 [33280/50000 (74%)]\tLoss: 0.005764, Accuracy: 99.80\n",
      "Train Epoch: 202 [35840/50000 (80%)]\tLoss: 0.016770, Accuracy: 99.80\n",
      "Train Epoch: 202 [38400/50000 (85%)]\tLoss: 0.004783, Accuracy: 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 202 [40960/50000 (91%)]\tLoss: 0.008730, Accuracy: 99.80\n",
      "Train Epoch: 202 [43520/50000 (97%)]\tLoss: 0.003202, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3664, Accuracy: 4606/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[35.45813035964966 s]\n",
      "\n",
      "Test set: Average loss: 0.3841, Accuracy: 9158/10000 (91.58%)\n",
      "\n",
      "Train Epoch: 203 [0/50000 (0%)]\tLoss: 0.004464, Accuracy: 99.80\n",
      "Train Epoch: 203 [2560/50000 (6%)]\tLoss: 0.002448, Accuracy: 100.00\n",
      "Train Epoch: 203 [5120/50000 (11%)]\tLoss: 0.005915, Accuracy: 99.61\n",
      "Train Epoch: 203 [7680/50000 (17%)]\tLoss: 0.009835, Accuracy: 99.80\n",
      "Train Epoch: 203 [10240/50000 (23%)]\tLoss: 0.003594, Accuracy: 100.00\n",
      "Train Epoch: 203 [12800/50000 (28%)]\tLoss: 0.014311, Accuracy: 99.22\n",
      "Train Epoch: 203 [15360/50000 (34%)]\tLoss: 0.004977, Accuracy: 100.00\n",
      "Train Epoch: 203 [17920/50000 (40%)]\tLoss: 0.006174, Accuracy: 100.00\n",
      "Train Epoch: 203 [20480/50000 (45%)]\tLoss: 0.005006, Accuracy: 99.80\n",
      "Train Epoch: 203 [23040/50000 (51%)]\tLoss: 0.007401, Accuracy: 99.80\n",
      "Train Epoch: 203 [25600/50000 (57%)]\tLoss: 0.008573, Accuracy: 99.80\n",
      "Train Epoch: 203 [28160/50000 (62%)]\tLoss: 0.008004, Accuracy: 99.80\n",
      "Train Epoch: 203 [30720/50000 (68%)]\tLoss: 0.003563, Accuracy: 99.80\n",
      "Train Epoch: 203 [33280/50000 (74%)]\tLoss: 0.003794, Accuracy: 100.00\n",
      "Train Epoch: 203 [35840/50000 (80%)]\tLoss: 0.014692, Accuracy: 99.41\n",
      "------------------------------\n",
      "before autoscale: torch.Size([1024, 1, 1])\n",
      "tensor([[[ 0.0006]],\n",
      "\n",
      "        [[ 0.0853]],\n",
      "\n",
      "        [[ 0.0771]],\n",
      "\n",
      "        [[ 0.0046]],\n",
      "\n",
      "        [[ 0.1890]],\n",
      "\n",
      "        [[ 0.0378]],\n",
      "\n",
      "        [[ 0.0243]],\n",
      "\n",
      "        [[ 0.0000]],\n",
      "\n",
      "        [[ 0.0411]],\n",
      "\n",
      "        [[ 0.0134]]], device='cuda:0')\n",
      "autoScale weight: Parameter containing:\n",
      "tensor([[[ 0.6613]]], device='cuda:0')\n",
      "autoScale bias: None\n",
      "after autoscale w[0]: torch.Size([1, 1, 1024])\n",
      "tensor([[[ 0.0004,  0.0564,  0.0510,  ...,  0.0005,  0.0001,  0.0002]]], device='cuda:0')\n",
      "------------------------------\n",
      "==============================\n",
      "conv1D weight[0]: tensor(1.00000e-03 *\n",
      "       [[ 2.9628,  0.6669,  1.7519, -0.4183,  0.1975, -0.2565,  0.5750,\n",
      "          1.2305,  2.0966]], device='cuda:0')\n",
      "conv1D bias[0]: None\n",
      "after conv1D w[0]: torch.Size([1, 896, 1024])\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.0281,  0.0206,  0.0123,  ...,  0.0001,  0.0002,  0.0001],\n",
      "        [-0.1127, -0.0951, -0.1331,  ..., -0.0002, -0.0006, -0.0005],\n",
      "        [-0.0221, -0.0099,  0.0072,  ...,  0.0000,  0.0001, -0.0000],\n",
      "        ...,\n",
      "        [ 0.0152,  0.0052,  0.0023,  ...,  0.0001,  0.0002,  0.0000],\n",
      "        [ 0.1007,  0.0584,  0.0704,  ...,  0.0005,  0.0011,  0.0003],\n",
      "        [-0.0034, -0.0038, -0.0013,  ..., -0.0000, -0.0000,  0.0000]], device='cuda:0')\n",
      "==============================\n",
      "torch.Size([1, 896, 1024])\n",
      "tensor(1.00000e-03 *\n",
      "       [[ 0.0281,  0.0206,  0.0123,  ...,  0.0001,  0.0002,  0.0001],\n",
      "        [-0.1127, -0.0951, -0.1331,  ..., -0.0002, -0.0006, -0.0005],\n",
      "        [-0.0221, -0.0099,  0.0072,  ...,  0.0000,  0.0001, -0.0000],\n",
      "        ...,\n",
      "        [-0.0557, -0.0403, -0.0263,  ..., -0.0002, -0.0003, -0.0001],\n",
      "        [-0.0041, -0.0037, -0.0070,  ...,  0.0000, -0.0000, -0.0000],\n",
      "        [ 0.0167,  0.0288,  0.0201,  ...,  0.0000,  0.0001,  0.0000]], device='cuda:0')\n",
      "Train Epoch: 203 [38400/50000 (85%)]\tLoss: 0.004775, Accuracy: 99.80\n",
      "Train Epoch: 203 [40960/50000 (91%)]\tLoss: 0.010158, Accuracy: 99.61\n",
      "Train Epoch: 203 [43520/50000 (97%)]\tLoss: 0.003977, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3802, Accuracy: 4590/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[39.03009390830994 s]\n",
      "Train Epoch: 204 [0/50000 (0%)]\tLoss: 0.014986, Accuracy: 99.22\n",
      "Train Epoch: 204 [2560/50000 (6%)]\tLoss: 0.008781, Accuracy: 99.80\n",
      "Train Epoch: 204 [5120/50000 (11%)]\tLoss: 0.012682, Accuracy: 99.61\n",
      "Train Epoch: 204 [7680/50000 (17%)]\tLoss: 0.013492, Accuracy: 99.41\n",
      "Train Epoch: 204 [10240/50000 (23%)]\tLoss: 0.004002, Accuracy: 100.00\n",
      "Train Epoch: 204 [12800/50000 (28%)]\tLoss: 0.009474, Accuracy: 99.61\n",
      "Train Epoch: 204 [15360/50000 (34%)]\tLoss: 0.005034, Accuracy: 100.00\n",
      "Train Epoch: 204 [17920/50000 (40%)]\tLoss: 0.011490, Accuracy: 99.61\n",
      "Train Epoch: 204 [20480/50000 (45%)]\tLoss: 0.004941, Accuracy: 99.80\n",
      "Train Epoch: 204 [23040/50000 (51%)]\tLoss: 0.005655, Accuracy: 99.80\n",
      "Train Epoch: 204 [25600/50000 (57%)]\tLoss: 0.005130, Accuracy: 99.80\n",
      "Train Epoch: 204 [28160/50000 (62%)]\tLoss: 0.008560, Accuracy: 99.80\n",
      "Train Epoch: 204 [30720/50000 (68%)]\tLoss: 0.013828, Accuracy: 99.80\n",
      "Train Epoch: 204 [33280/50000 (74%)]\tLoss: 0.005139, Accuracy: 99.80\n",
      "Train Epoch: 204 [35840/50000 (80%)]\tLoss: 0.002681, Accuracy: 100.00\n",
      "Train Epoch: 204 [38400/50000 (85%)]\tLoss: 0.006288, Accuracy: 99.61\n",
      "Train Epoch: 204 [40960/50000 (91%)]\tLoss: 0.005132, Accuracy: 100.00\n",
      "Train Epoch: 204 [43520/50000 (97%)]\tLoss: 0.004051, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3717, Accuracy: 4607/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[36.80980968475342 s]\n",
      "\n",
      "Test set: Average loss: 0.3829, Accuracy: 9183/10000 (91.83%)\n",
      "\n",
      "Train Epoch: 205 [0/50000 (0%)]\tLoss: 0.017541, Accuracy: 99.61\n",
      "Train Epoch: 205 [2560/50000 (6%)]\tLoss: 0.006654, Accuracy: 99.80\n",
      "Train Epoch: 205 [5120/50000 (11%)]\tLoss: 0.006713, Accuracy: 99.80\n",
      "Train Epoch: 205 [7680/50000 (17%)]\tLoss: 0.001921, Accuracy: 100.00\n",
      "Train Epoch: 205 [10240/50000 (23%)]\tLoss: 0.003737, Accuracy: 100.00\n",
      "Train Epoch: 205 [12800/50000 (28%)]\tLoss: 0.008535, Accuracy: 99.80\n",
      "Train Epoch: 205 [15360/50000 (34%)]\tLoss: 0.019879, Accuracy: 99.41\n",
      "Train Epoch: 205 [17920/50000 (40%)]\tLoss: 0.004555, Accuracy: 100.00\n",
      "Train Epoch: 205 [20480/50000 (45%)]\tLoss: 0.003407, Accuracy: 100.00\n",
      "Train Epoch: 205 [23040/50000 (51%)]\tLoss: 0.002378, Accuracy: 100.00\n",
      "Train Epoch: 205 [25600/50000 (57%)]\tLoss: 0.002734, Accuracy: 100.00\n",
      "Train Epoch: 205 [28160/50000 (62%)]\tLoss: 0.003129, Accuracy: 100.00\n",
      "Train Epoch: 205 [30720/50000 (68%)]\tLoss: 0.012614, Accuracy: 99.61\n",
      "Train Epoch: 205 [33280/50000 (74%)]\tLoss: 0.009959, Accuracy: 99.80\n",
      "Train Epoch: 205 [35840/50000 (80%)]\tLoss: 0.005030, Accuracy: 100.00\n",
      "Train Epoch: 205 [38400/50000 (85%)]\tLoss: 0.007756, Accuracy: 99.61\n",
      "Train Epoch: 205 [40960/50000 (91%)]\tLoss: 0.011083, Accuracy: 99.61\n",
      "Train Epoch: 205 [43520/50000 (97%)]\tLoss: 0.003102, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3612, Accuracy: 4615/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[40.28736996650696 s]\n",
      "Train Epoch: 206 [0/50000 (0%)]\tLoss: 0.008177, Accuracy: 99.80\n",
      "Train Epoch: 206 [2560/50000 (6%)]\tLoss: 0.005163, Accuracy: 99.80\n",
      "Train Epoch: 206 [5120/50000 (11%)]\tLoss: 0.007980, Accuracy: 99.61\n",
      "Train Epoch: 206 [7680/50000 (17%)]\tLoss: 0.003525, Accuracy: 100.00\n",
      "Train Epoch: 206 [10240/50000 (23%)]\tLoss: 0.003432, Accuracy: 100.00\n",
      "Train Epoch: 206 [12800/50000 (28%)]\tLoss: 0.009319, Accuracy: 99.61\n",
      "Train Epoch: 206 [15360/50000 (34%)]\tLoss: 0.006981, Accuracy: 99.80\n",
      "Train Epoch: 206 [17920/50000 (40%)]\tLoss: 0.013037, Accuracy: 99.41\n",
      "Train Epoch: 206 [20480/50000 (45%)]\tLoss: 0.003789, Accuracy: 99.80\n",
      "Train Epoch: 206 [23040/50000 (51%)]\tLoss: 0.013996, Accuracy: 99.80\n",
      "Train Epoch: 206 [25600/50000 (57%)]\tLoss: 0.011177, Accuracy: 99.61\n",
      "Train Epoch: 206 [28160/50000 (62%)]\tLoss: 0.006134, Accuracy: 99.80\n",
      "Train Epoch: 206 [30720/50000 (68%)]\tLoss: 0.011468, Accuracy: 99.61\n",
      "Train Epoch: 206 [33280/50000 (74%)]\tLoss: 0.004196, Accuracy: 100.00\n",
      "Train Epoch: 206 [35840/50000 (80%)]\tLoss: 0.004932, Accuracy: 99.80\n",
      "Train Epoch: 206 [38400/50000 (85%)]\tLoss: 0.010508, Accuracy: 99.80\n",
      "Train Epoch: 206 [40960/50000 (91%)]\tLoss: 0.009953, Accuracy: 99.61\n",
      "Train Epoch: 206 [43520/50000 (97%)]\tLoss: 0.005667, Accuracy: 99.80\n",
      "\n",
      "Validation set: Average loss: 0.3682, Accuracy: 4608/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[36.1517379283905 s]\n",
      "\n",
      "Test set: Average loss: 0.3798, Accuracy: 9190/10000 (91.90%)\n",
      "\n",
      "Train Epoch: 207 [0/50000 (0%)]\tLoss: 0.009198, Accuracy: 99.41\n",
      "Train Epoch: 207 [2560/50000 (6%)]\tLoss: 0.008393, Accuracy: 99.80\n",
      "Train Epoch: 207 [5120/50000 (11%)]\tLoss: 0.003897, Accuracy: 100.00\n",
      "Train Epoch: 207 [7680/50000 (17%)]\tLoss: 0.002838, Accuracy: 100.00\n",
      "Train Epoch: 207 [10240/50000 (23%)]\tLoss: 0.003750, Accuracy: 100.00\n",
      "Train Epoch: 207 [12800/50000 (28%)]\tLoss: 0.007434, Accuracy: 99.80\n",
      "Train Epoch: 207 [15360/50000 (34%)]\tLoss: 0.005125, Accuracy: 100.00\n",
      "Train Epoch: 207 [17920/50000 (40%)]\tLoss: 0.005122, Accuracy: 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 207 [20480/50000 (45%)]\tLoss: 0.002493, Accuracy: 100.00\n",
      "Train Epoch: 207 [23040/50000 (51%)]\tLoss: 0.012251, Accuracy: 99.80\n",
      "Train Epoch: 207 [25600/50000 (57%)]\tLoss: 0.005769, Accuracy: 99.80\n",
      "Train Epoch: 207 [28160/50000 (62%)]\tLoss: 0.004309, Accuracy: 99.80\n",
      "Train Epoch: 207 [30720/50000 (68%)]\tLoss: 0.006695, Accuracy: 99.80\n",
      "Train Epoch: 207 [33280/50000 (74%)]\tLoss: 0.004611, Accuracy: 99.80\n",
      "Train Epoch: 207 [35840/50000 (80%)]\tLoss: 0.018924, Accuracy: 99.80\n",
      "Train Epoch: 207 [38400/50000 (85%)]\tLoss: 0.010481, Accuracy: 99.80\n",
      "Train Epoch: 207 [40960/50000 (91%)]\tLoss: 0.004830, Accuracy: 100.00\n",
      "Train Epoch: 207 [43520/50000 (97%)]\tLoss: 0.004053, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3590, Accuracy: 4624/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[38.44679093360901 s]\n",
      "Train Epoch: 208 [0/50000 (0%)]\tLoss: 0.002469, Accuracy: 100.00\n",
      "Train Epoch: 208 [2560/50000 (6%)]\tLoss: 0.014400, Accuracy: 99.22\n",
      "Train Epoch: 208 [5120/50000 (11%)]\tLoss: 0.010198, Accuracy: 99.80\n",
      "Train Epoch: 208 [7680/50000 (17%)]\tLoss: 0.026185, Accuracy: 99.22\n",
      "Train Epoch: 208 [10240/50000 (23%)]\tLoss: 0.003589, Accuracy: 100.00\n",
      "Train Epoch: 208 [12800/50000 (28%)]\tLoss: 0.003076, Accuracy: 100.00\n",
      "Train Epoch: 208 [15360/50000 (34%)]\tLoss: 0.006127, Accuracy: 99.80\n",
      "Train Epoch: 208 [17920/50000 (40%)]\tLoss: 0.002836, Accuracy: 100.00\n",
      "Train Epoch: 208 [20480/50000 (45%)]\tLoss: 0.003946, Accuracy: 100.00\n",
      "Train Epoch: 208 [23040/50000 (51%)]\tLoss: 0.006642, Accuracy: 99.80\n",
      "Train Epoch: 208 [25600/50000 (57%)]\tLoss: 0.010721, Accuracy: 99.41\n",
      "Train Epoch: 208 [28160/50000 (62%)]\tLoss: 0.003677, Accuracy: 100.00\n",
      "Train Epoch: 208 [30720/50000 (68%)]\tLoss: 0.005443, Accuracy: 100.00\n",
      "Train Epoch: 208 [33280/50000 (74%)]\tLoss: 0.003713, Accuracy: 100.00\n",
      "Train Epoch: 208 [35840/50000 (80%)]\tLoss: 0.006515, Accuracy: 99.80\n",
      "Train Epoch: 208 [38400/50000 (85%)]\tLoss: 0.007364, Accuracy: 100.00\n",
      "Train Epoch: 208 [40960/50000 (91%)]\tLoss: 0.005155, Accuracy: 99.80\n",
      "Train Epoch: 208 [43520/50000 (97%)]\tLoss: 0.006672, Accuracy: 99.61\n",
      "\n",
      "Validation set: Average loss: 0.3695, Accuracy: 4603/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[35.10796523094177 s]\n",
      "\n",
      "Test set: Average loss: 0.3859, Accuracy: 9184/10000 (91.84%)\n",
      "\n",
      "Train Epoch: 209 [0/50000 (0%)]\tLoss: 0.006729, Accuracy: 99.80\n",
      "Train Epoch: 209 [2560/50000 (6%)]\tLoss: 0.005550, Accuracy: 99.80\n",
      "Train Epoch: 209 [5120/50000 (11%)]\tLoss: 0.006510, Accuracy: 99.80\n",
      "Train Epoch: 209 [7680/50000 (17%)]\tLoss: 0.017462, Accuracy: 99.41\n",
      "Train Epoch: 209 [10240/50000 (23%)]\tLoss: 0.004073, Accuracy: 100.00\n",
      "Train Epoch: 209 [12800/50000 (28%)]\tLoss: 0.003539, Accuracy: 100.00\n",
      "Train Epoch: 209 [15360/50000 (34%)]\tLoss: 0.003646, Accuracy: 99.80\n",
      "Train Epoch: 209 [17920/50000 (40%)]\tLoss: 0.003017, Accuracy: 100.00\n",
      "Train Epoch: 209 [20480/50000 (45%)]\tLoss: 0.003974, Accuracy: 100.00\n",
      "Train Epoch: 209 [23040/50000 (51%)]\tLoss: 0.006143, Accuracy: 99.80\n",
      "Train Epoch: 209 [25600/50000 (57%)]\tLoss: 0.001765, Accuracy: 100.00\n",
      "Train Epoch: 209 [28160/50000 (62%)]\tLoss: 0.003564, Accuracy: 100.00\n",
      "Train Epoch: 209 [30720/50000 (68%)]\tLoss: 0.007012, Accuracy: 99.80\n",
      "Train Epoch: 209 [33280/50000 (74%)]\tLoss: 0.006907, Accuracy: 99.80\n",
      "Train Epoch: 209 [35840/50000 (80%)]\tLoss: 0.009094, Accuracy: 99.80\n",
      "Train Epoch: 209 [38400/50000 (85%)]\tLoss: 0.007549, Accuracy: 99.80\n",
      "Train Epoch: 209 [40960/50000 (91%)]\tLoss: 0.002048, Accuracy: 100.00\n",
      "Train Epoch: 209 [43520/50000 (97%)]\tLoss: 0.004620, Accuracy: 99.80\n",
      "\n",
      "Validation set: Average loss: 0.3626, Accuracy: 4606/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[38.42090058326721 s]\n",
      "Train Epoch: 210 [0/50000 (0%)]\tLoss: 0.007110, Accuracy: 99.80\n",
      "Train Epoch: 210 [2560/50000 (6%)]\tLoss: 0.009726, Accuracy: 99.80\n",
      "Train Epoch: 210 [5120/50000 (11%)]\tLoss: 0.003556, Accuracy: 100.00\n",
      "Train Epoch: 210 [7680/50000 (17%)]\tLoss: 0.004388, Accuracy: 100.00\n",
      "Train Epoch: 210 [10240/50000 (23%)]\tLoss: 0.004344, Accuracy: 100.00\n",
      "Train Epoch: 210 [12800/50000 (28%)]\tLoss: 0.006039, Accuracy: 100.00\n",
      "Train Epoch: 210 [15360/50000 (34%)]\tLoss: 0.002706, Accuracy: 100.00\n",
      "Train Epoch: 210 [17920/50000 (40%)]\tLoss: 0.005106, Accuracy: 99.80\n",
      "Train Epoch: 210 [20480/50000 (45%)]\tLoss: 0.017970, Accuracy: 99.61\n",
      "Train Epoch: 210 [23040/50000 (51%)]\tLoss: 0.005434, Accuracy: 100.00\n",
      "Train Epoch: 210 [25600/50000 (57%)]\tLoss: 0.001888, Accuracy: 100.00\n",
      "Train Epoch: 210 [28160/50000 (62%)]\tLoss: 0.002947, Accuracy: 100.00\n",
      "Train Epoch: 210 [30720/50000 (68%)]\tLoss: 0.007507, Accuracy: 99.80\n",
      "Train Epoch: 210 [33280/50000 (74%)]\tLoss: 0.008107, Accuracy: 99.80\n",
      "Train Epoch: 210 [35840/50000 (80%)]\tLoss: 0.003756, Accuracy: 100.00\n",
      "Train Epoch: 210 [38400/50000 (85%)]\tLoss: 0.001954, Accuracy: 100.00\n",
      "Train Epoch: 210 [40960/50000 (91%)]\tLoss: 0.002628, Accuracy: 100.00\n",
      "Train Epoch: 210 [43520/50000 (97%)]\tLoss: 0.002612, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3693, Accuracy: 4616/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[35.13800072669983 s]\n",
      "\n",
      "Test set: Average loss: 0.3800, Accuracy: 9185/10000 (91.85%)\n",
      "\n",
      "Train Epoch: 211 [0/50000 (0%)]\tLoss: 0.014625, Accuracy: 99.61\n",
      "Train Epoch: 211 [2560/50000 (6%)]\tLoss: 0.002201, Accuracy: 100.00\n",
      "Train Epoch: 211 [5120/50000 (11%)]\tLoss: 0.003274, Accuracy: 100.00\n",
      "Train Epoch: 211 [7680/50000 (17%)]\tLoss: 0.012054, Accuracy: 99.61\n",
      "Train Epoch: 211 [10240/50000 (23%)]\tLoss: 0.002809, Accuracy: 100.00\n",
      "Train Epoch: 211 [12800/50000 (28%)]\tLoss: 0.018820, Accuracy: 99.61\n",
      "Train Epoch: 211 [15360/50000 (34%)]\tLoss: 0.005649, Accuracy: 99.80\n",
      "Train Epoch: 211 [17920/50000 (40%)]\tLoss: 0.002304, Accuracy: 100.00\n",
      "Train Epoch: 211 [20480/50000 (45%)]\tLoss: 0.002494, Accuracy: 100.00\n",
      "Train Epoch: 211 [23040/50000 (51%)]\tLoss: 0.004272, Accuracy: 99.80\n",
      "Train Epoch: 211 [25600/50000 (57%)]\tLoss: 0.006330, Accuracy: 99.80\n",
      "Train Epoch: 211 [28160/50000 (62%)]\tLoss: 0.014408, Accuracy: 99.80\n",
      "Train Epoch: 211 [30720/50000 (68%)]\tLoss: 0.005656, Accuracy: 99.80\n",
      "Train Epoch: 211 [33280/50000 (74%)]\tLoss: 0.002033, Accuracy: 100.00\n",
      "Train Epoch: 211 [35840/50000 (80%)]\tLoss: 0.002934, Accuracy: 100.00\n",
      "Train Epoch: 211 [38400/50000 (85%)]\tLoss: 0.005087, Accuracy: 99.80\n",
      "Train Epoch: 211 [40960/50000 (91%)]\tLoss: 0.004500, Accuracy: 99.80\n",
      "Train Epoch: 211 [43520/50000 (97%)]\tLoss: 0.002544, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3549, Accuracy: 4620/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[38.48271703720093 s]\n",
      "Train Epoch: 212 [0/50000 (0%)]\tLoss: 0.003072, Accuracy: 100.00\n",
      "Train Epoch: 212 [2560/50000 (6%)]\tLoss: 0.002145, Accuracy: 100.00\n",
      "Train Epoch: 212 [5120/50000 (11%)]\tLoss: 0.008748, Accuracy: 99.61\n",
      "Train Epoch: 212 [7680/50000 (17%)]\tLoss: 0.002227, Accuracy: 100.00\n",
      "Train Epoch: 212 [10240/50000 (23%)]\tLoss: 0.006978, Accuracy: 99.80\n",
      "Train Epoch: 212 [12800/50000 (28%)]\tLoss: 0.010065, Accuracy: 99.80\n",
      "Train Epoch: 212 [15360/50000 (34%)]\tLoss: 0.002455, Accuracy: 100.00\n",
      "Train Epoch: 212 [17920/50000 (40%)]\tLoss: 0.003131, Accuracy: 100.00\n",
      "Train Epoch: 212 [20480/50000 (45%)]\tLoss: 0.009336, Accuracy: 99.80\n",
      "Train Epoch: 212 [23040/50000 (51%)]\tLoss: 0.004462, Accuracy: 99.80\n",
      "Train Epoch: 212 [25600/50000 (57%)]\tLoss: 0.001819, Accuracy: 100.00\n",
      "Train Epoch: 212 [28160/50000 (62%)]\tLoss: 0.008966, Accuracy: 99.80\n",
      "Train Epoch: 212 [30720/50000 (68%)]\tLoss: 0.012553, Accuracy: 99.61\n",
      "Train Epoch: 212 [33280/50000 (74%)]\tLoss: 0.006691, Accuracy: 99.80\n",
      "Train Epoch: 212 [35840/50000 (80%)]\tLoss: 0.008340, Accuracy: 99.80\n",
      "Train Epoch: 212 [38400/50000 (85%)]\tLoss: 0.007870, Accuracy: 99.80\n",
      "Train Epoch: 212 [40960/50000 (91%)]\tLoss: 0.001990, Accuracy: 100.00\n",
      "Train Epoch: 212 [43520/50000 (97%)]\tLoss: 0.003260, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3556, Accuracy: 4625/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[35.14083743095398 s]\n",
      "\n",
      "Test set: Average loss: 0.3742, Accuracy: 9196/10000 (91.96%)\n",
      "\n",
      "Train Epoch: 213 [0/50000 (0%)]\tLoss: 0.006278, Accuracy: 99.80\n",
      "Train Epoch: 213 [2560/50000 (6%)]\tLoss: 0.003416, Accuracy: 100.00\n",
      "Train Epoch: 213 [5120/50000 (11%)]\tLoss: 0.003247, Accuracy: 100.00\n",
      "Train Epoch: 213 [7680/50000 (17%)]\tLoss: 0.017670, Accuracy: 99.41\n",
      "Train Epoch: 213 [10240/50000 (23%)]\tLoss: 0.003930, Accuracy: 100.00\n",
      "Train Epoch: 213 [12800/50000 (28%)]\tLoss: 0.003709, Accuracy: 100.00\n",
      "Train Epoch: 213 [15360/50000 (34%)]\tLoss: 0.008512, Accuracy: 99.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 213 [17920/50000 (40%)]\tLoss: 0.002809, Accuracy: 100.00\n",
      "Train Epoch: 213 [20480/50000 (45%)]\tLoss: 0.014883, Accuracy: 99.61\n",
      "Train Epoch: 213 [23040/50000 (51%)]\tLoss: 0.003435, Accuracy: 100.00\n",
      "Train Epoch: 213 [25600/50000 (57%)]\tLoss: 0.001998, Accuracy: 100.00\n",
      "Train Epoch: 213 [28160/50000 (62%)]\tLoss: 0.002373, Accuracy: 100.00\n",
      "Train Epoch: 213 [30720/50000 (68%)]\tLoss: 0.006523, Accuracy: 99.80\n",
      "Train Epoch: 213 [33280/50000 (74%)]\tLoss: 0.005784, Accuracy: 99.80\n",
      "Train Epoch: 213 [35840/50000 (80%)]\tLoss: 0.005443, Accuracy: 99.80\n",
      "Train Epoch: 213 [38400/50000 (85%)]\tLoss: 0.002079, Accuracy: 100.00\n",
      "Train Epoch: 213 [40960/50000 (91%)]\tLoss: 0.002498, Accuracy: 100.00\n",
      "Train Epoch: 213 [43520/50000 (97%)]\tLoss: 0.002565, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3716, Accuracy: 4605/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[38.57472085952759 s]\n",
      "Train Epoch: 214 [0/50000 (0%)]\tLoss: 0.005448, Accuracy: 99.80\n",
      "Train Epoch: 214 [2560/50000 (6%)]\tLoss: 0.003592, Accuracy: 100.00\n",
      "Train Epoch: 214 [5120/50000 (11%)]\tLoss: 0.009451, Accuracy: 99.61\n",
      "Train Epoch: 214 [7680/50000 (17%)]\tLoss: 0.008308, Accuracy: 99.61\n",
      "Train Epoch: 214 [10240/50000 (23%)]\tLoss: 0.004129, Accuracy: 100.00\n",
      "Train Epoch: 214 [12800/50000 (28%)]\tLoss: 0.001806, Accuracy: 100.00\n",
      "Train Epoch: 214 [15360/50000 (34%)]\tLoss: 0.002758, Accuracy: 100.00\n",
      "Train Epoch: 214 [17920/50000 (40%)]\tLoss: 0.005220, Accuracy: 99.80\n",
      "Train Epoch: 214 [20480/50000 (45%)]\tLoss: 0.001671, Accuracy: 100.00\n",
      "Train Epoch: 214 [23040/50000 (51%)]\tLoss: 0.011935, Accuracy: 99.61\n",
      "Train Epoch: 214 [25600/50000 (57%)]\tLoss: 0.001617, Accuracy: 100.00\n",
      "Train Epoch: 214 [28160/50000 (62%)]\tLoss: 0.005717, Accuracy: 99.80\n",
      "Train Epoch: 214 [30720/50000 (68%)]\tLoss: 0.007711, Accuracy: 99.61\n",
      "Train Epoch: 214 [33280/50000 (74%)]\tLoss: 0.003097, Accuracy: 100.00\n",
      "Train Epoch: 214 [35840/50000 (80%)]\tLoss: 0.003757, Accuracy: 100.00\n",
      "Train Epoch: 214 [38400/50000 (85%)]\tLoss: 0.009404, Accuracy: 99.80\n",
      "Train Epoch: 214 [40960/50000 (91%)]\tLoss: 0.002139, Accuracy: 100.00\n",
      "Train Epoch: 214 [43520/50000 (97%)]\tLoss: 0.003636, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3804, Accuracy: 4602/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[35.33272123336792 s]\n",
      "\n",
      "Test set: Average loss: 0.3816, Accuracy: 9203/10000 (92.03%)\n",
      "\n",
      "Train Epoch: 215 [0/50000 (0%)]\tLoss: 0.003900, Accuracy: 99.80\n",
      "Train Epoch: 215 [2560/50000 (6%)]\tLoss: 0.002316, Accuracy: 100.00\n",
      "Train Epoch: 215 [5120/50000 (11%)]\tLoss: 0.002215, Accuracy: 100.00\n",
      "Train Epoch: 215 [7680/50000 (17%)]\tLoss: 0.010324, Accuracy: 99.80\n",
      "Train Epoch: 215 [10240/50000 (23%)]\tLoss: 0.004004, Accuracy: 100.00\n",
      "Train Epoch: 215 [12800/50000 (28%)]\tLoss: 0.002766, Accuracy: 100.00\n",
      "Train Epoch: 215 [15360/50000 (34%)]\tLoss: 0.007241, Accuracy: 99.80\n",
      "Train Epoch: 215 [17920/50000 (40%)]\tLoss: 0.007426, Accuracy: 99.80\n",
      "Train Epoch: 215 [20480/50000 (45%)]\tLoss: 0.006680, Accuracy: 99.80\n",
      "Train Epoch: 215 [23040/50000 (51%)]\tLoss: 0.003497, Accuracy: 100.00\n",
      "Train Epoch: 215 [25600/50000 (57%)]\tLoss: 0.002260, Accuracy: 100.00\n",
      "Train Epoch: 215 [28160/50000 (62%)]\tLoss: 0.001931, Accuracy: 100.00\n",
      "Train Epoch: 215 [30720/50000 (68%)]\tLoss: 0.003629, Accuracy: 99.80\n",
      "Train Epoch: 215 [33280/50000 (74%)]\tLoss: 0.006956, Accuracy: 99.80\n",
      "Train Epoch: 215 [35840/50000 (80%)]\tLoss: 0.009855, Accuracy: 99.61\n",
      "Train Epoch: 215 [38400/50000 (85%)]\tLoss: 0.007545, Accuracy: 99.80\n",
      "Train Epoch: 215 [40960/50000 (91%)]\tLoss: 0.007404, Accuracy: 99.80\n",
      "Train Epoch: 215 [43520/50000 (97%)]\tLoss: 0.009843, Accuracy: 99.61\n",
      "\n",
      "Validation set: Average loss: 0.3666, Accuracy: 4611/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[38.436715841293335 s]\n",
      "Train Epoch: 216 [0/50000 (0%)]\tLoss: 0.011378, Accuracy: 99.61\n",
      "Train Epoch: 216 [2560/50000 (6%)]\tLoss: 0.002465, Accuracy: 100.00\n",
      "Train Epoch: 216 [5120/50000 (11%)]\tLoss: 0.002698, Accuracy: 100.00\n",
      "Train Epoch: 216 [7680/50000 (17%)]\tLoss: 0.018825, Accuracy: 99.61\n",
      "Train Epoch: 216 [10240/50000 (23%)]\tLoss: 0.003535, Accuracy: 99.80\n",
      "Train Epoch: 216 [12800/50000 (28%)]\tLoss: 0.009962, Accuracy: 99.61\n",
      "Train Epoch: 216 [15360/50000 (34%)]\tLoss: 0.006197, Accuracy: 100.00\n",
      "Train Epoch: 216 [17920/50000 (40%)]\tLoss: 0.009450, Accuracy: 99.80\n",
      "Train Epoch: 216 [20480/50000 (45%)]\tLoss: 0.002218, Accuracy: 100.00\n",
      "Train Epoch: 216 [23040/50000 (51%)]\tLoss: 0.003821, Accuracy: 99.80\n",
      "Train Epoch: 216 [25600/50000 (57%)]\tLoss: 0.007499, Accuracy: 99.80\n",
      "Train Epoch: 216 [28160/50000 (62%)]\tLoss: 0.015491, Accuracy: 99.61\n",
      "Train Epoch: 216 [30720/50000 (68%)]\tLoss: 0.002138, Accuracy: 100.00\n",
      "Train Epoch: 216 [33280/50000 (74%)]\tLoss: 0.008335, Accuracy: 99.61\n",
      "Train Epoch: 216 [35840/50000 (80%)]\tLoss: 0.004133, Accuracy: 100.00\n",
      "Train Epoch: 216 [38400/50000 (85%)]\tLoss: 0.005762, Accuracy: 99.80\n",
      "Train Epoch: 216 [40960/50000 (91%)]\tLoss: 0.006659, Accuracy: 99.80\n",
      "Train Epoch: 216 [43520/50000 (97%)]\tLoss: 0.018993, Accuracy: 99.41\n",
      "\n",
      "Validation set: Average loss: 0.3683, Accuracy: 4616/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[36.008541107177734 s]\n",
      "\n",
      "Test set: Average loss: 0.3783, Accuracy: 9220/10000 (92.20%)\n",
      "\n",
      "Train Epoch: 217 [0/50000 (0%)]\tLoss: 0.002729, Accuracy: 100.00\n",
      "Train Epoch: 217 [2560/50000 (6%)]\tLoss: 0.001960, Accuracy: 100.00\n",
      "Train Epoch: 217 [5120/50000 (11%)]\tLoss: 0.006331, Accuracy: 99.80\n",
      "Train Epoch: 217 [7680/50000 (17%)]\tLoss: 0.002618, Accuracy: 100.00\n",
      "Train Epoch: 217 [10240/50000 (23%)]\tLoss: 0.001878, Accuracy: 100.00\n",
      "Train Epoch: 217 [12800/50000 (28%)]\tLoss: 0.005318, Accuracy: 99.80\n",
      "Train Epoch: 217 [15360/50000 (34%)]\tLoss: 0.002388, Accuracy: 100.00\n",
      "Train Epoch: 217 [17920/50000 (40%)]\tLoss: 0.003862, Accuracy: 99.80\n",
      "Train Epoch: 217 [20480/50000 (45%)]\tLoss: 0.002246, Accuracy: 100.00\n",
      "Train Epoch: 217 [23040/50000 (51%)]\tLoss: 0.001599, Accuracy: 100.00\n",
      "Train Epoch: 217 [25600/50000 (57%)]\tLoss: 0.011068, Accuracy: 99.61\n",
      "Train Epoch: 217 [28160/50000 (62%)]\tLoss: 0.006623, Accuracy: 99.80\n",
      "Train Epoch: 217 [30720/50000 (68%)]\tLoss: 0.003987, Accuracy: 99.80\n",
      "Train Epoch: 217 [33280/50000 (74%)]\tLoss: 0.003766, Accuracy: 100.00\n",
      "Train Epoch: 217 [35840/50000 (80%)]\tLoss: 0.002301, Accuracy: 100.00\n",
      "Train Epoch: 217 [38400/50000 (85%)]\tLoss: 0.003209, Accuracy: 100.00\n",
      "Train Epoch: 217 [40960/50000 (91%)]\tLoss: 0.004172, Accuracy: 100.00\n",
      "Train Epoch: 217 [43520/50000 (97%)]\tLoss: 0.015719, Accuracy: 99.61\n",
      "\n",
      "Validation set: Average loss: 0.3656, Accuracy: 4625/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[40.800644636154175 s]\n",
      "Train Epoch: 218 [0/50000 (0%)]\tLoss: 0.002275, Accuracy: 100.00\n",
      "Train Epoch: 218 [2560/50000 (6%)]\tLoss: 0.004278, Accuracy: 100.00\n",
      "Train Epoch: 218 [5120/50000 (11%)]\tLoss: 0.001734, Accuracy: 100.00\n",
      "Train Epoch: 218 [7680/50000 (17%)]\tLoss: 0.005516, Accuracy: 99.80\n",
      "Train Epoch: 218 [10240/50000 (23%)]\tLoss: 0.020183, Accuracy: 99.41\n",
      "Train Epoch: 218 [12800/50000 (28%)]\tLoss: 0.006303, Accuracy: 99.80\n",
      "Train Epoch: 218 [15360/50000 (34%)]\tLoss: 0.003997, Accuracy: 100.00\n",
      "Train Epoch: 218 [17920/50000 (40%)]\tLoss: 0.002197, Accuracy: 100.00\n",
      "Train Epoch: 218 [20480/50000 (45%)]\tLoss: 0.003068, Accuracy: 100.00\n",
      "Train Epoch: 218 [23040/50000 (51%)]\tLoss: 0.002422, Accuracy: 100.00\n",
      "Train Epoch: 218 [25600/50000 (57%)]\tLoss: 0.004928, Accuracy: 99.80\n",
      "Train Epoch: 218 [28160/50000 (62%)]\tLoss: 0.002779, Accuracy: 100.00\n",
      "Train Epoch: 218 [30720/50000 (68%)]\tLoss: 0.004113, Accuracy: 99.80\n",
      "Train Epoch: 218 [33280/50000 (74%)]\tLoss: 0.004308, Accuracy: 100.00\n",
      "Train Epoch: 218 [35840/50000 (80%)]\tLoss: 0.001644, Accuracy: 100.00\n",
      "Train Epoch: 218 [38400/50000 (85%)]\tLoss: 0.003739, Accuracy: 99.80\n",
      "Train Epoch: 218 [40960/50000 (91%)]\tLoss: 0.005515, Accuracy: 100.00\n",
      "Train Epoch: 218 [43520/50000 (97%)]\tLoss: 0.002716, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3688, Accuracy: 4612/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[37.50612807273865 s]\n",
      "\n",
      "Test set: Average loss: 0.3787, Accuracy: 9196/10000 (91.96%)\n",
      "\n",
      "Train Epoch: 219 [0/50000 (0%)]\tLoss: 0.002015, Accuracy: 100.00\n",
      "Train Epoch: 219 [2560/50000 (6%)]\tLoss: 0.006047, Accuracy: 99.80\n",
      "Train Epoch: 219 [5120/50000 (11%)]\tLoss: 0.004398, Accuracy: 100.00\n",
      "Train Epoch: 219 [7680/50000 (17%)]\tLoss: 0.007981, Accuracy: 99.61\n",
      "Train Epoch: 219 [10240/50000 (23%)]\tLoss: 0.003215, Accuracy: 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 219 [12800/50000 (28%)]\tLoss: 0.003593, Accuracy: 99.80\n",
      "Train Epoch: 219 [15360/50000 (34%)]\tLoss: 0.002124, Accuracy: 100.00\n",
      "Train Epoch: 219 [17920/50000 (40%)]\tLoss: 0.002591, Accuracy: 100.00\n",
      "Train Epoch: 219 [20480/50000 (45%)]\tLoss: 0.003661, Accuracy: 99.80\n",
      "Train Epoch: 219 [23040/50000 (51%)]\tLoss: 0.001689, Accuracy: 100.00\n",
      "Train Epoch: 219 [25600/50000 (57%)]\tLoss: 0.004376, Accuracy: 99.80\n",
      "Train Epoch: 219 [28160/50000 (62%)]\tLoss: 0.005406, Accuracy: 99.80\n",
      "Train Epoch: 219 [30720/50000 (68%)]\tLoss: 0.007333, Accuracy: 100.00\n",
      "Train Epoch: 219 [33280/50000 (74%)]\tLoss: 0.002378, Accuracy: 100.00\n",
      "Train Epoch: 219 [35840/50000 (80%)]\tLoss: 0.015782, Accuracy: 99.61\n",
      "Train Epoch: 219 [38400/50000 (85%)]\tLoss: 0.002892, Accuracy: 100.00\n",
      "Train Epoch: 219 [40960/50000 (91%)]\tLoss: 0.002729, Accuracy: 100.00\n",
      "Train Epoch: 219 [43520/50000 (97%)]\tLoss: 0.002433, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3576, Accuracy: 4620/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[39.830055952072144 s]\n",
      "Train Epoch: 220 [0/50000 (0%)]\tLoss: 0.006108, Accuracy: 99.61\n",
      "Train Epoch: 220 [2560/50000 (6%)]\tLoss: 0.004680, Accuracy: 100.00\n",
      "Train Epoch: 220 [5120/50000 (11%)]\tLoss: 0.008099, Accuracy: 99.61\n",
      "Train Epoch: 220 [7680/50000 (17%)]\tLoss: 0.016515, Accuracy: 99.80\n",
      "Train Epoch: 220 [10240/50000 (23%)]\tLoss: 0.005212, Accuracy: 100.00\n",
      "Train Epoch: 220 [12800/50000 (28%)]\tLoss: 0.006027, Accuracy: 100.00\n",
      "Train Epoch: 220 [15360/50000 (34%)]\tLoss: 0.011682, Accuracy: 99.80\n",
      "Train Epoch: 220 [17920/50000 (40%)]\tLoss: 0.004190, Accuracy: 99.80\n",
      "Train Epoch: 220 [20480/50000 (45%)]\tLoss: 0.013479, Accuracy: 99.61\n",
      "Train Epoch: 220 [23040/50000 (51%)]\tLoss: 0.010415, Accuracy: 99.61\n",
      "Train Epoch: 220 [25600/50000 (57%)]\tLoss: 0.003684, Accuracy: 100.00\n",
      "Train Epoch: 220 [28160/50000 (62%)]\tLoss: 0.005669, Accuracy: 99.80\n",
      "Train Epoch: 220 [30720/50000 (68%)]\tLoss: 0.005946, Accuracy: 99.61\n",
      "Train Epoch: 220 [33280/50000 (74%)]\tLoss: 0.009741, Accuracy: 99.41\n",
      "Train Epoch: 220 [35840/50000 (80%)]\tLoss: 0.003358, Accuracy: 100.00\n",
      "Train Epoch: 220 [38400/50000 (85%)]\tLoss: 0.009164, Accuracy: 99.61\n",
      "Train Epoch: 220 [40960/50000 (91%)]\tLoss: 0.005735, Accuracy: 99.61\n",
      "Train Epoch: 220 [43520/50000 (97%)]\tLoss: 0.001634, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3748, Accuracy: 4613/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[35.84798288345337 s]\n",
      "\n",
      "Test set: Average loss: 0.3822, Accuracy: 9205/10000 (92.05%)\n",
      "\n",
      "Train Epoch: 221 [0/50000 (0%)]\tLoss: 0.001599, Accuracy: 100.00\n",
      "Train Epoch: 221 [2560/50000 (6%)]\tLoss: 0.002365, Accuracy: 100.00\n",
      "Train Epoch: 221 [5120/50000 (11%)]\tLoss: 0.001878, Accuracy: 100.00\n",
      "Train Epoch: 221 [7680/50000 (17%)]\tLoss: 0.002762, Accuracy: 100.00\n",
      "Train Epoch: 221 [10240/50000 (23%)]\tLoss: 0.002332, Accuracy: 100.00\n",
      "Train Epoch: 221 [12800/50000 (28%)]\tLoss: 0.005717, Accuracy: 99.80\n",
      "Train Epoch: 221 [15360/50000 (34%)]\tLoss: 0.003723, Accuracy: 100.00\n",
      "Train Epoch: 221 [17920/50000 (40%)]\tLoss: 0.001599, Accuracy: 100.00\n",
      "Train Epoch: 221 [20480/50000 (45%)]\tLoss: 0.003980, Accuracy: 99.80\n",
      "Train Epoch: 221 [23040/50000 (51%)]\tLoss: 0.003413, Accuracy: 100.00\n",
      "Train Epoch: 221 [25600/50000 (57%)]\tLoss: 0.001900, Accuracy: 100.00\n",
      "Train Epoch: 221 [28160/50000 (62%)]\tLoss: 0.005671, Accuracy: 100.00\n",
      "Train Epoch: 221 [30720/50000 (68%)]\tLoss: 0.006818, Accuracy: 99.80\n",
      "Train Epoch: 221 [33280/50000 (74%)]\tLoss: 0.007225, Accuracy: 99.80\n",
      "Train Epoch: 221 [35840/50000 (80%)]\tLoss: 0.003446, Accuracy: 100.00\n",
      "Train Epoch: 221 [38400/50000 (85%)]\tLoss: 0.005764, Accuracy: 99.61\n",
      "Train Epoch: 221 [40960/50000 (91%)]\tLoss: 0.001853, Accuracy: 100.00\n",
      "Train Epoch: 221 [43520/50000 (97%)]\tLoss: 0.001665, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3734, Accuracy: 4605/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[38.799949407577515 s]\n",
      "Train Epoch: 222 [0/50000 (0%)]\tLoss: 0.002905, Accuracy: 100.00\n",
      "Train Epoch: 222 [2560/50000 (6%)]\tLoss: 0.004427, Accuracy: 99.80\n",
      "Train Epoch: 222 [5120/50000 (11%)]\tLoss: 0.009683, Accuracy: 99.80\n",
      "Train Epoch: 222 [7680/50000 (17%)]\tLoss: 0.002167, Accuracy: 100.00\n",
      "Train Epoch: 222 [10240/50000 (23%)]\tLoss: 0.002081, Accuracy: 100.00\n",
      "Train Epoch: 222 [12800/50000 (28%)]\tLoss: 0.004904, Accuracy: 99.80\n",
      "Train Epoch: 222 [15360/50000 (34%)]\tLoss: 0.004295, Accuracy: 100.00\n",
      "Train Epoch: 222 [17920/50000 (40%)]\tLoss: 0.002062, Accuracy: 100.00\n",
      "Train Epoch: 222 [20480/50000 (45%)]\tLoss: 0.007008, Accuracy: 99.80\n",
      "Train Epoch: 222 [23040/50000 (51%)]\tLoss: 0.004665, Accuracy: 99.80\n",
      "Train Epoch: 222 [25600/50000 (57%)]\tLoss: 0.002369, Accuracy: 100.00\n",
      "Train Epoch: 222 [28160/50000 (62%)]\tLoss: 0.004909, Accuracy: 99.80\n",
      "Train Epoch: 222 [30720/50000 (68%)]\tLoss: 0.003750, Accuracy: 100.00\n",
      "Train Epoch: 222 [33280/50000 (74%)]\tLoss: 0.011023, Accuracy: 99.80\n",
      "Train Epoch: 222 [35840/50000 (80%)]\tLoss: 0.008033, Accuracy: 99.61\n",
      "Train Epoch: 222 [38400/50000 (85%)]\tLoss: 0.002190, Accuracy: 100.00\n",
      "Train Epoch: 222 [40960/50000 (91%)]\tLoss: 0.003248, Accuracy: 100.00\n",
      "Train Epoch: 222 [43520/50000 (97%)]\tLoss: 0.003877, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3623, Accuracy: 4614/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[36.850236892700195 s]\n",
      "\n",
      "Test set: Average loss: 0.3829, Accuracy: 9198/10000 (91.98%)\n",
      "\n",
      "Train Epoch: 223 [0/50000 (0%)]\tLoss: 0.005753, Accuracy: 99.80\n",
      "Train Epoch: 223 [2560/50000 (6%)]\tLoss: 0.003098, Accuracy: 100.00\n",
      "Train Epoch: 223 [5120/50000 (11%)]\tLoss: 0.008854, Accuracy: 99.80\n",
      "Train Epoch: 223 [7680/50000 (17%)]\tLoss: 0.003297, Accuracy: 100.00\n",
      "Train Epoch: 223 [10240/50000 (23%)]\tLoss: 0.006003, Accuracy: 100.00\n",
      "Train Epoch: 223 [12800/50000 (28%)]\tLoss: 0.014131, Accuracy: 99.61\n",
      "Train Epoch: 223 [15360/50000 (34%)]\tLoss: 0.003640, Accuracy: 100.00\n",
      "Train Epoch: 223 [17920/50000 (40%)]\tLoss: 0.009367, Accuracy: 99.61\n",
      "Train Epoch: 223 [20480/50000 (45%)]\tLoss: 0.003216, Accuracy: 100.00\n",
      "Train Epoch: 223 [23040/50000 (51%)]\tLoss: 0.003733, Accuracy: 100.00\n",
      "Train Epoch: 223 [25600/50000 (57%)]\tLoss: 0.005062, Accuracy: 100.00\n",
      "Train Epoch: 223 [28160/50000 (62%)]\tLoss: 0.004355, Accuracy: 100.00\n",
      "Train Epoch: 223 [30720/50000 (68%)]\tLoss: 0.003690, Accuracy: 100.00\n",
      "Train Epoch: 223 [33280/50000 (74%)]\tLoss: 0.005500, Accuracy: 100.00\n",
      "Train Epoch: 223 [35840/50000 (80%)]\tLoss: 0.003215, Accuracy: 100.00\n",
      "Train Epoch: 223 [38400/50000 (85%)]\tLoss: 0.002253, Accuracy: 100.00\n",
      "Train Epoch: 223 [40960/50000 (91%)]\tLoss: 0.003541, Accuracy: 99.80\n",
      "Train Epoch: 223 [43520/50000 (97%)]\tLoss: 0.006059, Accuracy: 99.80\n",
      "\n",
      "Validation set: Average loss: 0.3614, Accuracy: 4626/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[41.19436264038086 s]\n",
      "Train Epoch: 224 [0/50000 (0%)]\tLoss: 0.003016, Accuracy: 100.00\n",
      "Train Epoch: 224 [2560/50000 (6%)]\tLoss: 0.006297, Accuracy: 100.00\n",
      "Train Epoch: 224 [5120/50000 (11%)]\tLoss: 0.002755, Accuracy: 100.00\n",
      "Train Epoch: 224 [7680/50000 (17%)]\tLoss: 0.004495, Accuracy: 100.00\n",
      "Train Epoch: 224 [10240/50000 (23%)]\tLoss: 0.008925, Accuracy: 99.61\n",
      "Train Epoch: 224 [12800/50000 (28%)]\tLoss: 0.003259, Accuracy: 100.00\n",
      "Train Epoch: 224 [15360/50000 (34%)]\tLoss: 0.003697, Accuracy: 99.80\n",
      "Train Epoch: 224 [17920/50000 (40%)]\tLoss: 0.003862, Accuracy: 100.00\n",
      "Train Epoch: 224 [20480/50000 (45%)]\tLoss: 0.003481, Accuracy: 100.00\n",
      "Train Epoch: 224 [23040/50000 (51%)]\tLoss: 0.004149, Accuracy: 100.00\n",
      "Train Epoch: 224 [25600/50000 (57%)]\tLoss: 0.002415, Accuracy: 100.00\n",
      "Train Epoch: 224 [28160/50000 (62%)]\tLoss: 0.002136, Accuracy: 100.00\n",
      "Train Epoch: 224 [30720/50000 (68%)]\tLoss: 0.003226, Accuracy: 100.00\n",
      "Train Epoch: 224 [33280/50000 (74%)]\tLoss: 0.003720, Accuracy: 100.00\n",
      "Train Epoch: 224 [35840/50000 (80%)]\tLoss: 0.002106, Accuracy: 100.00\n",
      "Train Epoch: 224 [38400/50000 (85%)]\tLoss: 0.001448, Accuracy: 100.00\n",
      "Train Epoch: 224 [40960/50000 (91%)]\tLoss: 0.001819, Accuracy: 100.00\n",
      "Train Epoch: 224 [43520/50000 (97%)]\tLoss: 0.008514, Accuracy: 99.80\n",
      "\n",
      "Validation set: Average loss: 0.3749, Accuracy: 4601/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[36.86083126068115 s]\n",
      "\n",
      "Test set: Average loss: 0.3803, Accuracy: 9205/10000 (92.05%)\n",
      "\n",
      "Train Epoch: 225 [0/50000 (0%)]\tLoss: 0.001626, Accuracy: 100.00\n",
      "Train Epoch: 225 [2560/50000 (6%)]\tLoss: 0.004594, Accuracy: 100.00\n",
      "Train Epoch: 225 [5120/50000 (11%)]\tLoss: 0.012116, Accuracy: 99.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 225 [7680/50000 (17%)]\tLoss: 0.005119, Accuracy: 99.80\n",
      "Train Epoch: 225 [10240/50000 (23%)]\tLoss: 0.002700, Accuracy: 99.80\n",
      "Train Epoch: 225 [12800/50000 (28%)]\tLoss: 0.001657, Accuracy: 100.00\n",
      "Train Epoch: 225 [15360/50000 (34%)]\tLoss: 0.006161, Accuracy: 99.80\n",
      "Train Epoch: 225 [17920/50000 (40%)]\tLoss: 0.001912, Accuracy: 100.00\n",
      "Train Epoch: 225 [20480/50000 (45%)]\tLoss: 0.004709, Accuracy: 99.80\n",
      "Train Epoch: 225 [23040/50000 (51%)]\tLoss: 0.002736, Accuracy: 100.00\n",
      "Train Epoch: 225 [25600/50000 (57%)]\tLoss: 0.003575, Accuracy: 100.00\n",
      "Train Epoch: 225 [28160/50000 (62%)]\tLoss: 0.003949, Accuracy: 100.00\n",
      "Train Epoch: 225 [30720/50000 (68%)]\tLoss: 0.005870, Accuracy: 99.80\n",
      "Train Epoch: 225 [33280/50000 (74%)]\tLoss: 0.006829, Accuracy: 99.80\n",
      "Train Epoch: 225 [35840/50000 (80%)]\tLoss: 0.002331, Accuracy: 100.00\n",
      "Train Epoch: 225 [38400/50000 (85%)]\tLoss: 0.002525, Accuracy: 100.00\n",
      "Train Epoch: 225 [40960/50000 (91%)]\tLoss: 0.003049, Accuracy: 100.00\n",
      "Train Epoch: 225 [43520/50000 (97%)]\tLoss: 0.003098, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3690, Accuracy: 4619/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[39.10783791542053 s]\n",
      "Train Epoch: 226 [0/50000 (0%)]\tLoss: 0.002894, Accuracy: 100.00\n",
      "Train Epoch: 226 [2560/50000 (6%)]\tLoss: 0.001938, Accuracy: 100.00\n",
      "Train Epoch: 226 [5120/50000 (11%)]\tLoss: 0.003783, Accuracy: 100.00\n",
      "Train Epoch: 226 [7680/50000 (17%)]\tLoss: 0.004335, Accuracy: 100.00\n",
      "Train Epoch: 226 [10240/50000 (23%)]\tLoss: 0.011173, Accuracy: 99.80\n",
      "Train Epoch: 226 [12800/50000 (28%)]\tLoss: 0.002152, Accuracy: 100.00\n",
      "Train Epoch: 226 [15360/50000 (34%)]\tLoss: 0.005289, Accuracy: 99.80\n",
      "Train Epoch: 226 [17920/50000 (40%)]\tLoss: 0.004129, Accuracy: 99.80\n",
      "Train Epoch: 226 [20480/50000 (45%)]\tLoss: 0.005494, Accuracy: 99.80\n",
      "Train Epoch: 226 [23040/50000 (51%)]\tLoss: 0.001724, Accuracy: 100.00\n",
      "Train Epoch: 226 [25600/50000 (57%)]\tLoss: 0.003875, Accuracy: 100.00\n",
      "Train Epoch: 226 [28160/50000 (62%)]\tLoss: 0.003279, Accuracy: 100.00\n",
      "Train Epoch: 226 [30720/50000 (68%)]\tLoss: 0.003156, Accuracy: 100.00\n",
      "Train Epoch: 226 [33280/50000 (74%)]\tLoss: 0.004217, Accuracy: 99.80\n",
      "Train Epoch: 226 [35840/50000 (80%)]\tLoss: 0.002851, Accuracy: 100.00\n",
      "Train Epoch: 226 [38400/50000 (85%)]\tLoss: 0.004179, Accuracy: 100.00\n",
      "Train Epoch: 226 [40960/50000 (91%)]\tLoss: 0.003624, Accuracy: 100.00\n",
      "Train Epoch: 226 [43520/50000 (97%)]\tLoss: 0.001859, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3633, Accuracy: 4614/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[35.66699433326721 s]\n",
      "\n",
      "Test set: Average loss: 0.3890, Accuracy: 9183/10000 (91.83%)\n",
      "\n",
      "Train Epoch: 227 [0/50000 (0%)]\tLoss: 0.001593, Accuracy: 100.00\n",
      "Train Epoch: 227 [2560/50000 (6%)]\tLoss: 0.005305, Accuracy: 99.80\n",
      "Train Epoch: 227 [5120/50000 (11%)]\tLoss: 0.004254, Accuracy: 99.80\n",
      "Train Epoch: 227 [7680/50000 (17%)]\tLoss: 0.002102, Accuracy: 100.00\n",
      "Train Epoch: 227 [10240/50000 (23%)]\tLoss: 0.005503, Accuracy: 99.80\n",
      "Train Epoch: 227 [12800/50000 (28%)]\tLoss: 0.005030, Accuracy: 100.00\n",
      "Train Epoch: 227 [15360/50000 (34%)]\tLoss: 0.003013, Accuracy: 99.80\n",
      "Train Epoch: 227 [17920/50000 (40%)]\tLoss: 0.004263, Accuracy: 100.00\n",
      "Train Epoch: 227 [20480/50000 (45%)]\tLoss: 0.001857, Accuracy: 100.00\n",
      "Train Epoch: 227 [23040/50000 (51%)]\tLoss: 0.004128, Accuracy: 100.00\n",
      "Train Epoch: 227 [25600/50000 (57%)]\tLoss: 0.014965, Accuracy: 99.61\n",
      "Train Epoch: 227 [28160/50000 (62%)]\tLoss: 0.001896, Accuracy: 100.00\n",
      "Train Epoch: 227 [30720/50000 (68%)]\tLoss: 0.006027, Accuracy: 99.80\n",
      "Train Epoch: 227 [33280/50000 (74%)]\tLoss: 0.002815, Accuracy: 100.00\n",
      "Train Epoch: 227 [35840/50000 (80%)]\tLoss: 0.014434, Accuracy: 99.80\n",
      "Train Epoch: 227 [38400/50000 (85%)]\tLoss: 0.004175, Accuracy: 100.00\n",
      "Train Epoch: 227 [40960/50000 (91%)]\tLoss: 0.003528, Accuracy: 100.00\n",
      "Train Epoch: 227 [43520/50000 (97%)]\tLoss: 0.003990, Accuracy: 99.80\n",
      "\n",
      "Validation set: Average loss: 0.3619, Accuracy: 4625/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[38.84267044067383 s]\n",
      "Train Epoch: 228 [0/50000 (0%)]\tLoss: 0.002841, Accuracy: 100.00\n",
      "Train Epoch: 228 [2560/50000 (6%)]\tLoss: 0.003556, Accuracy: 100.00\n",
      "Train Epoch: 228 [5120/50000 (11%)]\tLoss: 0.002469, Accuracy: 100.00\n",
      "Train Epoch: 228 [7680/50000 (17%)]\tLoss: 0.002604, Accuracy: 100.00\n",
      "Train Epoch: 228 [10240/50000 (23%)]\tLoss: 0.002118, Accuracy: 100.00\n",
      "Train Epoch: 228 [12800/50000 (28%)]\tLoss: 0.003569, Accuracy: 100.00\n",
      "Train Epoch: 228 [15360/50000 (34%)]\tLoss: 0.002485, Accuracy: 100.00\n",
      "Train Epoch: 228 [17920/50000 (40%)]\tLoss: 0.003183, Accuracy: 100.00\n",
      "Train Epoch: 228 [20480/50000 (45%)]\tLoss: 0.009832, Accuracy: 99.80\n",
      "Train Epoch: 228 [23040/50000 (51%)]\tLoss: 0.005853, Accuracy: 99.80\n",
      "Train Epoch: 228 [25600/50000 (57%)]\tLoss: 0.002922, Accuracy: 100.00\n",
      "Train Epoch: 228 [28160/50000 (62%)]\tLoss: 0.005286, Accuracy: 99.80\n",
      "Train Epoch: 228 [30720/50000 (68%)]\tLoss: 0.009551, Accuracy: 99.41\n",
      "Train Epoch: 228 [33280/50000 (74%)]\tLoss: 0.003022, Accuracy: 99.80\n",
      "Train Epoch: 228 [35840/50000 (80%)]\tLoss: 0.006575, Accuracy: 99.80\n",
      "Train Epoch: 228 [38400/50000 (85%)]\tLoss: 0.002049, Accuracy: 100.00\n",
      "Train Epoch: 228 [40960/50000 (91%)]\tLoss: 0.006251, Accuracy: 99.61\n",
      "Train Epoch: 228 [43520/50000 (97%)]\tLoss: 0.003447, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3682, Accuracy: 4604/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[35.759750843048096 s]\n",
      "\n",
      "Test set: Average loss: 0.3945, Accuracy: 9190/10000 (91.90%)\n",
      "\n",
      "Train Epoch: 229 [0/50000 (0%)]\tLoss: 0.004963, Accuracy: 99.61\n",
      "Train Epoch: 229 [2560/50000 (6%)]\tLoss: 0.003540, Accuracy: 100.00\n",
      "Train Epoch: 229 [5120/50000 (11%)]\tLoss: 0.003241, Accuracy: 100.00\n",
      "Train Epoch: 229 [7680/50000 (17%)]\tLoss: 0.003495, Accuracy: 99.80\n",
      "Train Epoch: 229 [10240/50000 (23%)]\tLoss: 0.004751, Accuracy: 100.00\n",
      "Train Epoch: 229 [12800/50000 (28%)]\tLoss: 0.002516, Accuracy: 100.00\n",
      "Train Epoch: 229 [15360/50000 (34%)]\tLoss: 0.003724, Accuracy: 100.00\n",
      "Train Epoch: 229 [17920/50000 (40%)]\tLoss: 0.004728, Accuracy: 99.80\n",
      "Train Epoch: 229 [20480/50000 (45%)]\tLoss: 0.003354, Accuracy: 100.00\n",
      "Train Epoch: 229 [23040/50000 (51%)]\tLoss: 0.004993, Accuracy: 99.80\n",
      "Train Epoch: 229 [25600/50000 (57%)]\tLoss: 0.002801, Accuracy: 100.00\n",
      "Train Epoch: 229 [28160/50000 (62%)]\tLoss: 0.002723, Accuracy: 100.00\n",
      "Train Epoch: 229 [30720/50000 (68%)]\tLoss: 0.005763, Accuracy: 99.80\n",
      "Train Epoch: 229 [33280/50000 (74%)]\tLoss: 0.010454, Accuracy: 99.80\n",
      "Train Epoch: 229 [35840/50000 (80%)]\tLoss: 0.007987, Accuracy: 99.80\n",
      "Train Epoch: 229 [38400/50000 (85%)]\tLoss: 0.005524, Accuracy: 99.80\n",
      "Train Epoch: 229 [40960/50000 (91%)]\tLoss: 0.003132, Accuracy: 100.00\n",
      "Train Epoch: 229 [43520/50000 (97%)]\tLoss: 0.004001, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3723, Accuracy: 4612/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[39.21221303939819 s]\n",
      "Train Epoch: 230 [0/50000 (0%)]\tLoss: 0.003006, Accuracy: 100.00\n",
      "Train Epoch: 230 [2560/50000 (6%)]\tLoss: 0.002123, Accuracy: 100.00\n",
      "Train Epoch: 230 [5120/50000 (11%)]\tLoss: 0.005042, Accuracy: 99.80\n",
      "Train Epoch: 230 [7680/50000 (17%)]\tLoss: 0.001931, Accuracy: 100.00\n",
      "Train Epoch: 230 [10240/50000 (23%)]\tLoss: 0.002626, Accuracy: 100.00\n",
      "Train Epoch: 230 [12800/50000 (28%)]\tLoss: 0.004151, Accuracy: 99.80\n",
      "Train Epoch: 230 [15360/50000 (34%)]\tLoss: 0.003872, Accuracy: 100.00\n",
      "Train Epoch: 230 [17920/50000 (40%)]\tLoss: 0.003505, Accuracy: 100.00\n",
      "Train Epoch: 230 [20480/50000 (45%)]\tLoss: 0.005313, Accuracy: 99.80\n",
      "Train Epoch: 230 [23040/50000 (51%)]\tLoss: 0.001640, Accuracy: 100.00\n",
      "Train Epoch: 230 [25600/50000 (57%)]\tLoss: 0.010482, Accuracy: 99.61\n",
      "Train Epoch: 230 [28160/50000 (62%)]\tLoss: 0.003947, Accuracy: 100.00\n",
      "Train Epoch: 230 [30720/50000 (68%)]\tLoss: 0.006720, Accuracy: 99.61\n",
      "Train Epoch: 230 [33280/50000 (74%)]\tLoss: 0.003078, Accuracy: 100.00\n",
      "Train Epoch: 230 [35840/50000 (80%)]\tLoss: 0.001880, Accuracy: 100.00\n",
      "Train Epoch: 230 [38400/50000 (85%)]\tLoss: 0.002157, Accuracy: 100.00\n",
      "Train Epoch: 230 [40960/50000 (91%)]\tLoss: 0.002822, Accuracy: 100.00\n",
      "Train Epoch: 230 [43520/50000 (97%)]\tLoss: 0.003826, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3687, Accuracy: 4610/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[36.096460580825806 s]\n",
      "\n",
      "Test set: Average loss: 0.3913, Accuracy: 9188/10000 (91.88%)\n",
      "\n",
      "Train Epoch: 231 [0/50000 (0%)]\tLoss: 0.002075, Accuracy: 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 231 [2560/50000 (6%)]\tLoss: 0.001643, Accuracy: 100.00\n",
      "Train Epoch: 231 [5120/50000 (11%)]\tLoss: 0.004874, Accuracy: 100.00\n",
      "Train Epoch: 231 [7680/50000 (17%)]\tLoss: 0.007060, Accuracy: 99.80\n",
      "Train Epoch: 231 [10240/50000 (23%)]\tLoss: 0.001928, Accuracy: 100.00\n",
      "Train Epoch: 231 [12800/50000 (28%)]\tLoss: 0.001797, Accuracy: 100.00\n",
      "Train Epoch: 231 [15360/50000 (34%)]\tLoss: 0.003063, Accuracy: 100.00\n",
      "Train Epoch: 231 [17920/50000 (40%)]\tLoss: 0.002519, Accuracy: 100.00\n",
      "Train Epoch: 231 [20480/50000 (45%)]\tLoss: 0.010595, Accuracy: 99.80\n",
      "Train Epoch: 231 [23040/50000 (51%)]\tLoss: 0.006791, Accuracy: 99.80\n",
      "Train Epoch: 231 [25600/50000 (57%)]\tLoss: 0.007134, Accuracy: 99.80\n",
      "Train Epoch: 231 [28160/50000 (62%)]\tLoss: 0.002295, Accuracy: 100.00\n",
      "Train Epoch: 231 [30720/50000 (68%)]\tLoss: 0.001353, Accuracy: 100.00\n",
      "Train Epoch: 231 [33280/50000 (74%)]\tLoss: 0.002055, Accuracy: 100.00\n",
      "Train Epoch: 231 [35840/50000 (80%)]\tLoss: 0.003185, Accuracy: 100.00\n",
      "Train Epoch: 231 [38400/50000 (85%)]\tLoss: 0.002689, Accuracy: 100.00\n",
      "Train Epoch: 231 [40960/50000 (91%)]\tLoss: 0.003605, Accuracy: 100.00\n",
      "Train Epoch: 231 [43520/50000 (97%)]\tLoss: 0.001524, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3761, Accuracy: 4614/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[39.68823742866516 s]\n",
      "Train Epoch: 232 [0/50000 (0%)]\tLoss: 0.001714, Accuracy: 100.00\n",
      "Train Epoch: 232 [2560/50000 (6%)]\tLoss: 0.002435, Accuracy: 100.00\n",
      "Train Epoch: 232 [5120/50000 (11%)]\tLoss: 0.002374, Accuracy: 100.00\n",
      "Train Epoch: 232 [7680/50000 (17%)]\tLoss: 0.002408, Accuracy: 100.00\n",
      "Train Epoch: 232 [10240/50000 (23%)]\tLoss: 0.003749, Accuracy: 100.00\n",
      "Train Epoch: 232 [12800/50000 (28%)]\tLoss: 0.004594, Accuracy: 99.80\n",
      "Train Epoch: 232 [15360/50000 (34%)]\tLoss: 0.003346, Accuracy: 100.00\n",
      "Train Epoch: 232 [17920/50000 (40%)]\tLoss: 0.001534, Accuracy: 100.00\n",
      "Train Epoch: 232 [20480/50000 (45%)]\tLoss: 0.009696, Accuracy: 99.61\n",
      "Train Epoch: 232 [23040/50000 (51%)]\tLoss: 0.002939, Accuracy: 100.00\n",
      "Train Epoch: 232 [25600/50000 (57%)]\tLoss: 0.008809, Accuracy: 99.80\n",
      "Train Epoch: 232 [28160/50000 (62%)]\tLoss: 0.008342, Accuracy: 99.80\n",
      "Train Epoch: 232 [30720/50000 (68%)]\tLoss: 0.003071, Accuracy: 100.00\n",
      "Train Epoch: 232 [33280/50000 (74%)]\tLoss: 0.009790, Accuracy: 99.80\n",
      "Train Epoch: 232 [35840/50000 (80%)]\tLoss: 0.002779, Accuracy: 100.00\n",
      "Train Epoch: 232 [38400/50000 (85%)]\tLoss: 0.003681, Accuracy: 100.00\n",
      "Train Epoch: 232 [40960/50000 (91%)]\tLoss: 0.002211, Accuracy: 100.00\n",
      "Train Epoch: 232 [43520/50000 (97%)]\tLoss: 0.003311, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3662, Accuracy: 4617/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[36.06865859031677 s]\n",
      "\n",
      "Test set: Average loss: 0.3867, Accuracy: 9198/10000 (91.98%)\n",
      "\n",
      "Train Epoch: 233 [0/50000 (0%)]\tLoss: 0.003459, Accuracy: 99.80\n",
      "Train Epoch: 233 [2560/50000 (6%)]\tLoss: 0.002828, Accuracy: 99.80\n",
      "Train Epoch: 233 [5120/50000 (11%)]\tLoss: 0.001493, Accuracy: 100.00\n",
      "Train Epoch: 233 [7680/50000 (17%)]\tLoss: 0.003826, Accuracy: 100.00\n",
      "Train Epoch: 233 [10240/50000 (23%)]\tLoss: 0.002483, Accuracy: 100.00\n",
      "Train Epoch: 233 [12800/50000 (28%)]\tLoss: 0.006772, Accuracy: 99.80\n",
      "Train Epoch: 233 [15360/50000 (34%)]\tLoss: 0.006747, Accuracy: 99.80\n",
      "Train Epoch: 233 [17920/50000 (40%)]\tLoss: 0.006229, Accuracy: 100.00\n",
      "Train Epoch: 233 [20480/50000 (45%)]\tLoss: 0.002634, Accuracy: 100.00\n",
      "Train Epoch: 233 [23040/50000 (51%)]\tLoss: 0.003281, Accuracy: 100.00\n",
      "Train Epoch: 233 [25600/50000 (57%)]\tLoss: 0.006998, Accuracy: 99.80\n",
      "Train Epoch: 233 [28160/50000 (62%)]\tLoss: 0.003605, Accuracy: 100.00\n",
      "Train Epoch: 233 [30720/50000 (68%)]\tLoss: 0.011279, Accuracy: 99.80\n",
      "Train Epoch: 233 [33280/50000 (74%)]\tLoss: 0.002765, Accuracy: 100.00\n",
      "Train Epoch: 233 [35840/50000 (80%)]\tLoss: 0.001786, Accuracy: 100.00\n",
      "Train Epoch: 233 [38400/50000 (85%)]\tLoss: 0.002973, Accuracy: 100.00\n",
      "Train Epoch: 233 [40960/50000 (91%)]\tLoss: 0.001283, Accuracy: 100.00\n",
      "Train Epoch: 233 [43520/50000 (97%)]\tLoss: 0.001364, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3784, Accuracy: 4612/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[40.941386222839355 s]\n",
      "Train Epoch: 234 [0/50000 (0%)]\tLoss: 0.001325, Accuracy: 100.00\n",
      "Train Epoch: 234 [2560/50000 (6%)]\tLoss: 0.002055, Accuracy: 100.00\n",
      "Train Epoch: 234 [5120/50000 (11%)]\tLoss: 0.001563, Accuracy: 100.00\n",
      "Train Epoch: 234 [7680/50000 (17%)]\tLoss: 0.002419, Accuracy: 100.00\n",
      "Train Epoch: 234 [10240/50000 (23%)]\tLoss: 0.003160, Accuracy: 100.00\n",
      "Train Epoch: 234 [12800/50000 (28%)]\tLoss: 0.006899, Accuracy: 99.80\n",
      "Train Epoch: 234 [15360/50000 (34%)]\tLoss: 0.006009, Accuracy: 99.80\n",
      "Train Epoch: 234 [17920/50000 (40%)]\tLoss: 0.005224, Accuracy: 99.80\n",
      "Train Epoch: 234 [20480/50000 (45%)]\tLoss: 0.005341, Accuracy: 99.80\n",
      "Train Epoch: 234 [23040/50000 (51%)]\tLoss: 0.002165, Accuracy: 100.00\n",
      "Train Epoch: 234 [25600/50000 (57%)]\tLoss: 0.004597, Accuracy: 99.80\n",
      "Train Epoch: 234 [28160/50000 (62%)]\tLoss: 0.001822, Accuracy: 100.00\n",
      "Train Epoch: 234 [30720/50000 (68%)]\tLoss: 0.002090, Accuracy: 100.00\n",
      "Train Epoch: 234 [33280/50000 (74%)]\tLoss: 0.010730, Accuracy: 99.80\n",
      "Train Epoch: 234 [35840/50000 (80%)]\tLoss: 0.002003, Accuracy: 100.00\n",
      "Train Epoch: 234 [38400/50000 (85%)]\tLoss: 0.003703, Accuracy: 100.00\n",
      "Train Epoch: 234 [40960/50000 (91%)]\tLoss: 0.006796, Accuracy: 99.80\n",
      "Train Epoch: 234 [43520/50000 (97%)]\tLoss: 0.002730, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3619, Accuracy: 4619/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[35.62975740432739 s]\n",
      "\n",
      "Test set: Average loss: 0.3867, Accuracy: 9209/10000 (92.09%)\n",
      "\n",
      "Train Epoch: 235 [0/50000 (0%)]\tLoss: 0.002492, Accuracy: 100.00\n",
      "Train Epoch: 235 [2560/50000 (6%)]\tLoss: 0.003088, Accuracy: 99.80\n",
      "Train Epoch: 235 [5120/50000 (11%)]\tLoss: 0.002655, Accuracy: 100.00\n",
      "Train Epoch: 235 [7680/50000 (17%)]\tLoss: 0.009412, Accuracy: 99.61\n",
      "Train Epoch: 235 [10240/50000 (23%)]\tLoss: 0.006384, Accuracy: 99.80\n",
      "Train Epoch: 235 [12800/50000 (28%)]\tLoss: 0.006954, Accuracy: 99.61\n",
      "Train Epoch: 235 [15360/50000 (34%)]\tLoss: 0.002884, Accuracy: 100.00\n",
      "Train Epoch: 235 [17920/50000 (40%)]\tLoss: 0.002158, Accuracy: 100.00\n",
      "Train Epoch: 235 [20480/50000 (45%)]\tLoss: 0.004591, Accuracy: 100.00\n",
      "Train Epoch: 235 [23040/50000 (51%)]\tLoss: 0.003163, Accuracy: 100.00\n",
      "Train Epoch: 235 [25600/50000 (57%)]\tLoss: 0.004625, Accuracy: 100.00\n",
      "Train Epoch: 235 [28160/50000 (62%)]\tLoss: 0.006747, Accuracy: 99.80\n",
      "Train Epoch: 235 [30720/50000 (68%)]\tLoss: 0.004353, Accuracy: 100.00\n",
      "Train Epoch: 235 [33280/50000 (74%)]\tLoss: 0.003972, Accuracy: 100.00\n",
      "Train Epoch: 235 [35840/50000 (80%)]\tLoss: 0.008054, Accuracy: 99.80\n",
      "Train Epoch: 235 [38400/50000 (85%)]\tLoss: 0.002439, Accuracy: 100.00\n",
      "Train Epoch: 235 [40960/50000 (91%)]\tLoss: 0.005407, Accuracy: 99.80\n",
      "Train Epoch: 235 [43520/50000 (97%)]\tLoss: 0.001863, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3657, Accuracy: 4602/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[38.885684967041016 s]\n",
      "Train Epoch: 236 [0/50000 (0%)]\tLoss: 0.002902, Accuracy: 100.00\n",
      "Train Epoch: 236 [2560/50000 (6%)]\tLoss: 0.003890, Accuracy: 99.80\n",
      "Train Epoch: 236 [5120/50000 (11%)]\tLoss: 0.011055, Accuracy: 99.80\n",
      "Train Epoch: 236 [7680/50000 (17%)]\tLoss: 0.003777, Accuracy: 99.80\n",
      "Train Epoch: 236 [10240/50000 (23%)]\tLoss: 0.002375, Accuracy: 100.00\n",
      "Train Epoch: 236 [12800/50000 (28%)]\tLoss: 0.012232, Accuracy: 99.80\n",
      "Train Epoch: 236 [15360/50000 (34%)]\tLoss: 0.001999, Accuracy: 100.00\n",
      "Train Epoch: 236 [17920/50000 (40%)]\tLoss: 0.002416, Accuracy: 100.00\n",
      "Train Epoch: 236 [20480/50000 (45%)]\tLoss: 0.004468, Accuracy: 100.00\n",
      "Train Epoch: 236 [23040/50000 (51%)]\tLoss: 0.006187, Accuracy: 99.80\n",
      "Train Epoch: 236 [25600/50000 (57%)]\tLoss: 0.003531, Accuracy: 100.00\n",
      "Train Epoch: 236 [28160/50000 (62%)]\tLoss: 0.002941, Accuracy: 100.00\n",
      "Train Epoch: 236 [30720/50000 (68%)]\tLoss: 0.004681, Accuracy: 100.00\n",
      "Train Epoch: 236 [33280/50000 (74%)]\tLoss: 0.007549, Accuracy: 99.80\n",
      "Train Epoch: 236 [35840/50000 (80%)]\tLoss: 0.006052, Accuracy: 99.80\n",
      "Train Epoch: 236 [38400/50000 (85%)]\tLoss: 0.003282, Accuracy: 100.00\n",
      "Train Epoch: 236 [40960/50000 (91%)]\tLoss: 0.004593, Accuracy: 99.80\n",
      "Train Epoch: 236 [43520/50000 (97%)]\tLoss: 0.002307, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3735, Accuracy: 4602/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[35.5808961391449 s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3929, Accuracy: 9190/10000 (91.90%)\n",
      "\n",
      "Train Epoch: 237 [0/50000 (0%)]\tLoss: 0.006710, Accuracy: 99.80\n",
      "Train Epoch: 237 [2560/50000 (6%)]\tLoss: 0.006691, Accuracy: 99.80\n",
      "Train Epoch: 237 [5120/50000 (11%)]\tLoss: 0.003327, Accuracy: 100.00\n",
      "Train Epoch: 237 [7680/50000 (17%)]\tLoss: 0.002720, Accuracy: 100.00\n",
      "Train Epoch: 237 [10240/50000 (23%)]\tLoss: 0.001595, Accuracy: 100.00\n",
      "Train Epoch: 237 [12800/50000 (28%)]\tLoss: 0.002852, Accuracy: 100.00\n",
      "Train Epoch: 237 [15360/50000 (34%)]\tLoss: 0.006716, Accuracy: 99.80\n",
      "Train Epoch: 237 [17920/50000 (40%)]\tLoss: 0.002769, Accuracy: 100.00\n",
      "Train Epoch: 237 [20480/50000 (45%)]\tLoss: 0.009644, Accuracy: 99.80\n",
      "Train Epoch: 237 [23040/50000 (51%)]\tLoss: 0.003914, Accuracy: 100.00\n",
      "Train Epoch: 237 [25600/50000 (57%)]\tLoss: 0.010034, Accuracy: 99.80\n",
      "Train Epoch: 237 [28160/50000 (62%)]\tLoss: 0.005435, Accuracy: 99.80\n",
      "Train Epoch: 237 [30720/50000 (68%)]\tLoss: 0.003544, Accuracy: 100.00\n",
      "Train Epoch: 237 [33280/50000 (74%)]\tLoss: 0.002463, Accuracy: 100.00\n",
      "Train Epoch: 237 [35840/50000 (80%)]\tLoss: 0.005627, Accuracy: 100.00\n",
      "Train Epoch: 237 [38400/50000 (85%)]\tLoss: 0.001610, Accuracy: 100.00\n",
      "Train Epoch: 237 [40960/50000 (91%)]\tLoss: 0.004614, Accuracy: 100.00\n",
      "Train Epoch: 237 [43520/50000 (97%)]\tLoss: 0.001443, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3862, Accuracy: 4588/5000 (91.00%)\n",
      "\n",
      "the time of this epoch:[39.68836164474487 s]\n",
      "Train Epoch: 238 [0/50000 (0%)]\tLoss: 0.001942, Accuracy: 100.00\n",
      "Train Epoch: 238 [2560/50000 (6%)]\tLoss: 0.001528, Accuracy: 100.00\n",
      "Train Epoch: 238 [5120/50000 (11%)]\tLoss: 0.002223, Accuracy: 100.00\n",
      "Train Epoch: 238 [7680/50000 (17%)]\tLoss: 0.002360, Accuracy: 100.00\n",
      "Train Epoch: 238 [10240/50000 (23%)]\tLoss: 0.002192, Accuracy: 100.00\n",
      "Train Epoch: 238 [12800/50000 (28%)]\tLoss: 0.002521, Accuracy: 100.00\n",
      "Train Epoch: 238 [15360/50000 (34%)]\tLoss: 0.007396, Accuracy: 99.80\n",
      "Train Epoch: 238 [17920/50000 (40%)]\tLoss: 0.006273, Accuracy: 99.80\n",
      "Train Epoch: 238 [20480/50000 (45%)]\tLoss: 0.001937, Accuracy: 100.00\n",
      "Train Epoch: 238 [23040/50000 (51%)]\tLoss: 0.003237, Accuracy: 100.00\n",
      "Train Epoch: 238 [25600/50000 (57%)]\tLoss: 0.004261, Accuracy: 100.00\n",
      "Train Epoch: 238 [28160/50000 (62%)]\tLoss: 0.003894, Accuracy: 100.00\n",
      "Train Epoch: 238 [30720/50000 (68%)]\tLoss: 0.004758, Accuracy: 99.80\n",
      "Train Epoch: 238 [33280/50000 (74%)]\tLoss: 0.004775, Accuracy: 99.80\n",
      "Train Epoch: 238 [35840/50000 (80%)]\tLoss: 0.002264, Accuracy: 100.00\n",
      "Train Epoch: 238 [38400/50000 (85%)]\tLoss: 0.007114, Accuracy: 99.80\n",
      "Train Epoch: 238 [40960/50000 (91%)]\tLoss: 0.001664, Accuracy: 100.00\n",
      "Train Epoch: 238 [43520/50000 (97%)]\tLoss: 0.004249, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3610, Accuracy: 4617/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[35.95624566078186 s]\n",
      "\n",
      "Test set: Average loss: 0.3845, Accuracy: 9198/10000 (91.98%)\n",
      "\n",
      "Train Epoch: 239 [0/50000 (0%)]\tLoss: 0.008524, Accuracy: 99.61\n",
      "Train Epoch: 239 [2560/50000 (6%)]\tLoss: 0.002504, Accuracy: 100.00\n",
      "Train Epoch: 239 [5120/50000 (11%)]\tLoss: 0.002424, Accuracy: 100.00\n",
      "Train Epoch: 239 [7680/50000 (17%)]\tLoss: 0.002591, Accuracy: 100.00\n",
      "Train Epoch: 239 [10240/50000 (23%)]\tLoss: 0.004609, Accuracy: 100.00\n",
      "Train Epoch: 239 [12800/50000 (28%)]\tLoss: 0.002941, Accuracy: 100.00\n",
      "Train Epoch: 239 [15360/50000 (34%)]\tLoss: 0.006508, Accuracy: 99.80\n",
      "Train Epoch: 239 [17920/50000 (40%)]\tLoss: 0.008261, Accuracy: 99.80\n",
      "Train Epoch: 239 [20480/50000 (45%)]\tLoss: 0.002789, Accuracy: 100.00\n",
      "Train Epoch: 239 [23040/50000 (51%)]\tLoss: 0.001852, Accuracy: 100.00\n",
      "Train Epoch: 239 [25600/50000 (57%)]\tLoss: 0.003476, Accuracy: 100.00\n",
      "Train Epoch: 239 [28160/50000 (62%)]\tLoss: 0.006478, Accuracy: 99.80\n",
      "Train Epoch: 239 [30720/50000 (68%)]\tLoss: 0.004766, Accuracy: 99.80\n",
      "Train Epoch: 239 [33280/50000 (74%)]\tLoss: 0.001462, Accuracy: 100.00\n",
      "Train Epoch: 239 [35840/50000 (80%)]\tLoss: 0.002556, Accuracy: 100.00\n",
      "Train Epoch: 239 [38400/50000 (85%)]\tLoss: 0.005063, Accuracy: 99.80\n",
      "Train Epoch: 239 [40960/50000 (91%)]\tLoss: 0.003129, Accuracy: 100.00\n",
      "Train Epoch: 239 [43520/50000 (97%)]\tLoss: 0.001475, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3667, Accuracy: 4613/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[39.44468402862549 s]\n",
      "Train Epoch: 240 [0/50000 (0%)]\tLoss: 0.002450, Accuracy: 100.00\n",
      "Train Epoch: 240 [2560/50000 (6%)]\tLoss: 0.007669, Accuracy: 99.80\n",
      "Train Epoch: 240 [5120/50000 (11%)]\tLoss: 0.020777, Accuracy: 99.41\n",
      "Train Epoch: 240 [7680/50000 (17%)]\tLoss: 0.009961, Accuracy: 99.80\n",
      "Train Epoch: 240 [10240/50000 (23%)]\tLoss: 0.002823, Accuracy: 100.00\n",
      "Train Epoch: 240 [12800/50000 (28%)]\tLoss: 0.002111, Accuracy: 100.00\n",
      "Train Epoch: 240 [15360/50000 (34%)]\tLoss: 0.002141, Accuracy: 100.00\n",
      "Train Epoch: 240 [17920/50000 (40%)]\tLoss: 0.007263, Accuracy: 99.61\n",
      "Train Epoch: 240 [20480/50000 (45%)]\tLoss: 0.004273, Accuracy: 99.80\n",
      "Train Epoch: 240 [23040/50000 (51%)]\tLoss: 0.008818, Accuracy: 99.80\n",
      "Train Epoch: 240 [25600/50000 (57%)]\tLoss: 0.010825, Accuracy: 99.41\n",
      "Train Epoch: 240 [28160/50000 (62%)]\tLoss: 0.019061, Accuracy: 99.41\n",
      "Train Epoch: 240 [30720/50000 (68%)]\tLoss: 0.002398, Accuracy: 100.00\n",
      "Train Epoch: 240 [33280/50000 (74%)]\tLoss: 0.005316, Accuracy: 99.80\n",
      "Train Epoch: 240 [35840/50000 (80%)]\tLoss: 0.015995, Accuracy: 99.61\n",
      "Train Epoch: 240 [38400/50000 (85%)]\tLoss: 0.004055, Accuracy: 99.80\n",
      "Train Epoch: 240 [40960/50000 (91%)]\tLoss: 0.004635, Accuracy: 99.80\n",
      "Train Epoch: 240 [43520/50000 (97%)]\tLoss: 0.008948, Accuracy: 99.80\n",
      "\n",
      "Validation set: Average loss: 0.3676, Accuracy: 4610/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[35.939372539520264 s]\n",
      "\n",
      "Test set: Average loss: 0.3895, Accuracy: 9197/10000 (91.97%)\n",
      "\n",
      "Train Epoch: 241 [0/50000 (0%)]\tLoss: 0.001897, Accuracy: 100.00\n",
      "Train Epoch: 241 [2560/50000 (6%)]\tLoss: 0.006353, Accuracy: 99.80\n",
      "Train Epoch: 241 [5120/50000 (11%)]\tLoss: 0.008487, Accuracy: 99.80\n",
      "Train Epoch: 241 [7680/50000 (17%)]\tLoss: 0.001660, Accuracy: 100.00\n",
      "Train Epoch: 241 [10240/50000 (23%)]\tLoss: 0.001645, Accuracy: 100.00\n",
      "Train Epoch: 241 [12800/50000 (28%)]\tLoss: 0.003796, Accuracy: 100.00\n",
      "Train Epoch: 241 [15360/50000 (34%)]\tLoss: 0.002562, Accuracy: 100.00\n",
      "Train Epoch: 241 [17920/50000 (40%)]\tLoss: 0.002184, Accuracy: 100.00\n",
      "Train Epoch: 241 [20480/50000 (45%)]\tLoss: 0.004874, Accuracy: 100.00\n",
      "Train Epoch: 241 [23040/50000 (51%)]\tLoss: 0.002569, Accuracy: 100.00\n",
      "Train Epoch: 241 [25600/50000 (57%)]\tLoss: 0.003923, Accuracy: 99.80\n",
      "Train Epoch: 241 [28160/50000 (62%)]\tLoss: 0.004259, Accuracy: 100.00\n",
      "Train Epoch: 241 [30720/50000 (68%)]\tLoss: 0.005060, Accuracy: 99.80\n",
      "Train Epoch: 241 [33280/50000 (74%)]\tLoss: 0.001692, Accuracy: 100.00\n",
      "Train Epoch: 241 [35840/50000 (80%)]\tLoss: 0.006147, Accuracy: 99.80\n",
      "Train Epoch: 241 [38400/50000 (85%)]\tLoss: 0.002936, Accuracy: 100.00\n",
      "Train Epoch: 241 [40960/50000 (91%)]\tLoss: 0.001520, Accuracy: 100.00\n",
      "Train Epoch: 241 [43520/50000 (97%)]\tLoss: 0.005412, Accuracy: 99.80\n",
      "\n",
      "Validation set: Average loss: 0.3622, Accuracy: 4617/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[39.652605295181274 s]\n",
      "Train Epoch: 242 [0/50000 (0%)]\tLoss: 0.005304, Accuracy: 99.80\n",
      "Train Epoch: 242 [2560/50000 (6%)]\tLoss: 0.001789, Accuracy: 100.00\n",
      "Train Epoch: 242 [5120/50000 (11%)]\tLoss: 0.001410, Accuracy: 100.00\n",
      "Train Epoch: 242 [7680/50000 (17%)]\tLoss: 0.010965, Accuracy: 99.80\n",
      "Train Epoch: 242 [10240/50000 (23%)]\tLoss: 0.001965, Accuracy: 100.00\n",
      "Train Epoch: 242 [12800/50000 (28%)]\tLoss: 0.002220, Accuracy: 100.00\n",
      "Train Epoch: 242 [15360/50000 (34%)]\tLoss: 0.008353, Accuracy: 99.80\n",
      "Train Epoch: 242 [17920/50000 (40%)]\tLoss: 0.003109, Accuracy: 100.00\n",
      "Train Epoch: 242 [20480/50000 (45%)]\tLoss: 0.004803, Accuracy: 99.80\n",
      "Train Epoch: 242 [23040/50000 (51%)]\tLoss: 0.004937, Accuracy: 99.80\n",
      "Train Epoch: 242 [25600/50000 (57%)]\tLoss: 0.003946, Accuracy: 99.80\n",
      "Train Epoch: 242 [28160/50000 (62%)]\tLoss: 0.003819, Accuracy: 100.00\n",
      "Train Epoch: 242 [30720/50000 (68%)]\tLoss: 0.003052, Accuracy: 100.00\n",
      "Train Epoch: 242 [33280/50000 (74%)]\tLoss: 0.005363, Accuracy: 99.80\n",
      "Train Epoch: 242 [35840/50000 (80%)]\tLoss: 0.007471, Accuracy: 99.80\n",
      "Train Epoch: 242 [38400/50000 (85%)]\tLoss: 0.008114, Accuracy: 99.61\n",
      "Train Epoch: 242 [40960/50000 (91%)]\tLoss: 0.003199, Accuracy: 100.00\n",
      "Train Epoch: 242 [43520/50000 (97%)]\tLoss: 0.006184, Accuracy: 100.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.3761, Accuracy: 4606/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[36.04136323928833 s]\n",
      "\n",
      "Test set: Average loss: 0.3849, Accuracy: 9211/10000 (92.11%)\n",
      "\n",
      "Train Epoch: 243 [0/50000 (0%)]\tLoss: 0.001135, Accuracy: 100.00\n",
      "Train Epoch: 243 [2560/50000 (6%)]\tLoss: 0.013339, Accuracy: 99.61\n",
      "Train Epoch: 243 [5120/50000 (11%)]\tLoss: 0.003659, Accuracy: 100.00\n",
      "Train Epoch: 243 [7680/50000 (17%)]\tLoss: 0.002362, Accuracy: 100.00\n",
      "Train Epoch: 243 [10240/50000 (23%)]\tLoss: 0.002584, Accuracy: 100.00\n",
      "Train Epoch: 243 [12800/50000 (28%)]\tLoss: 0.006639, Accuracy: 99.80\n",
      "Train Epoch: 243 [15360/50000 (34%)]\tLoss: 0.002348, Accuracy: 100.00\n",
      "Train Epoch: 243 [17920/50000 (40%)]\tLoss: 0.003094, Accuracy: 99.80\n",
      "Train Epoch: 243 [20480/50000 (45%)]\tLoss: 0.003462, Accuracy: 100.00\n",
      "Train Epoch: 243 [23040/50000 (51%)]\tLoss: 0.006215, Accuracy: 99.80\n",
      "Train Epoch: 243 [25600/50000 (57%)]\tLoss: 0.002001, Accuracy: 100.00\n",
      "Train Epoch: 243 [28160/50000 (62%)]\tLoss: 0.002628, Accuracy: 100.00\n",
      "Train Epoch: 243 [30720/50000 (68%)]\tLoss: 0.003050, Accuracy: 100.00\n",
      "Train Epoch: 243 [33280/50000 (74%)]\tLoss: 0.004197, Accuracy: 100.00\n",
      "Train Epoch: 243 [35840/50000 (80%)]\tLoss: 0.002578, Accuracy: 100.00\n",
      "Train Epoch: 243 [38400/50000 (85%)]\tLoss: 0.003952, Accuracy: 99.80\n",
      "Train Epoch: 243 [40960/50000 (91%)]\tLoss: 0.007887, Accuracy: 99.80\n",
      "Train Epoch: 243 [43520/50000 (97%)]\tLoss: 0.011400, Accuracy: 99.61\n",
      "\n",
      "Validation set: Average loss: 0.3712, Accuracy: 4612/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[39.45242404937744 s]\n",
      "Train Epoch: 244 [0/50000 (0%)]\tLoss: 0.002067, Accuracy: 100.00\n",
      "Train Epoch: 244 [2560/50000 (6%)]\tLoss: 0.003169, Accuracy: 100.00\n",
      "Train Epoch: 244 [5120/50000 (11%)]\tLoss: 0.002857, Accuracy: 100.00\n",
      "Train Epoch: 244 [7680/50000 (17%)]\tLoss: 0.006763, Accuracy: 99.80\n",
      "Train Epoch: 244 [10240/50000 (23%)]\tLoss: 0.012019, Accuracy: 99.41\n",
      "Train Epoch: 244 [12800/50000 (28%)]\tLoss: 0.008081, Accuracy: 99.80\n",
      "Train Epoch: 244 [15360/50000 (34%)]\tLoss: 0.007006, Accuracy: 99.80\n",
      "Train Epoch: 244 [17920/50000 (40%)]\tLoss: 0.002623, Accuracy: 100.00\n",
      "Train Epoch: 244 [20480/50000 (45%)]\tLoss: 0.002315, Accuracy: 100.00\n",
      "Train Epoch: 244 [23040/50000 (51%)]\tLoss: 0.003256, Accuracy: 100.00\n",
      "Train Epoch: 244 [25600/50000 (57%)]\tLoss: 0.008098, Accuracy: 99.80\n",
      "Train Epoch: 244 [28160/50000 (62%)]\tLoss: 0.004136, Accuracy: 100.00\n",
      "Train Epoch: 244 [30720/50000 (68%)]\tLoss: 0.009744, Accuracy: 99.80\n",
      "Train Epoch: 244 [33280/50000 (74%)]\tLoss: 0.002070, Accuracy: 100.00\n",
      "Train Epoch: 244 [35840/50000 (80%)]\tLoss: 0.004124, Accuracy: 99.80\n",
      "Train Epoch: 244 [38400/50000 (85%)]\tLoss: 0.003843, Accuracy: 100.00\n",
      "Train Epoch: 244 [40960/50000 (91%)]\tLoss: 0.003444, Accuracy: 100.00\n",
      "Train Epoch: 244 [43520/50000 (97%)]\tLoss: 0.008372, Accuracy: 99.80\n",
      "\n",
      "Validation set: Average loss: 0.3675, Accuracy: 4616/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[35.89189791679382 s]\n",
      "\n",
      "Test set: Average loss: 0.3779, Accuracy: 9212/10000 (92.12%)\n",
      "\n",
      "Train Epoch: 245 [0/50000 (0%)]\tLoss: 0.004405, Accuracy: 100.00\n",
      "Train Epoch: 245 [2560/50000 (6%)]\tLoss: 0.005643, Accuracy: 99.80\n",
      "Train Epoch: 245 [5120/50000 (11%)]\tLoss: 0.001608, Accuracy: 100.00\n",
      "Train Epoch: 245 [7680/50000 (17%)]\tLoss: 0.002518, Accuracy: 100.00\n",
      "Train Epoch: 245 [10240/50000 (23%)]\tLoss: 0.010226, Accuracy: 99.61\n",
      "Train Epoch: 245 [12800/50000 (28%)]\tLoss: 0.002497, Accuracy: 100.00\n",
      "Train Epoch: 245 [15360/50000 (34%)]\tLoss: 0.001744, Accuracy: 100.00\n",
      "Train Epoch: 245 [17920/50000 (40%)]\tLoss: 0.008122, Accuracy: 99.80\n",
      "Train Epoch: 245 [20480/50000 (45%)]\tLoss: 0.003760, Accuracy: 100.00\n",
      "Train Epoch: 245 [23040/50000 (51%)]\tLoss: 0.002374, Accuracy: 100.00\n",
      "Train Epoch: 245 [25600/50000 (57%)]\tLoss: 0.001518, Accuracy: 100.00\n",
      "Train Epoch: 245 [28160/50000 (62%)]\tLoss: 0.004026, Accuracy: 100.00\n",
      "Train Epoch: 245 [30720/50000 (68%)]\tLoss: 0.008143, Accuracy: 99.80\n",
      "Train Epoch: 245 [33280/50000 (74%)]\tLoss: 0.003694, Accuracy: 100.00\n",
      "Train Epoch: 245 [35840/50000 (80%)]\tLoss: 0.011855, Accuracy: 99.80\n",
      "Train Epoch: 245 [38400/50000 (85%)]\tLoss: 0.004702, Accuracy: 99.80\n",
      "Train Epoch: 245 [40960/50000 (91%)]\tLoss: 0.004257, Accuracy: 100.00\n",
      "Train Epoch: 245 [43520/50000 (97%)]\tLoss: 0.001943, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3738, Accuracy: 4613/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[39.28332757949829 s]\n",
      "Train Epoch: 246 [0/50000 (0%)]\tLoss: 0.002313, Accuracy: 100.00\n",
      "Train Epoch: 246 [2560/50000 (6%)]\tLoss: 0.002639, Accuracy: 100.00\n",
      "Train Epoch: 246 [5120/50000 (11%)]\tLoss: 0.003208, Accuracy: 100.00\n",
      "Train Epoch: 246 [7680/50000 (17%)]\tLoss: 0.013132, Accuracy: 99.80\n",
      "Train Epoch: 246 [10240/50000 (23%)]\tLoss: 0.003230, Accuracy: 100.00\n",
      "Train Epoch: 246 [12800/50000 (28%)]\tLoss: 0.000961, Accuracy: 100.00\n",
      "Train Epoch: 246 [15360/50000 (34%)]\tLoss: 0.002357, Accuracy: 100.00\n",
      "Train Epoch: 246 [17920/50000 (40%)]\tLoss: 0.003687, Accuracy: 99.80\n",
      "Train Epoch: 246 [20480/50000 (45%)]\tLoss: 0.004321, Accuracy: 99.80\n",
      "Train Epoch: 246 [23040/50000 (51%)]\tLoss: 0.001866, Accuracy: 100.00\n",
      "Train Epoch: 246 [25600/50000 (57%)]\tLoss: 0.004284, Accuracy: 99.80\n",
      "Train Epoch: 246 [28160/50000 (62%)]\tLoss: 0.004051, Accuracy: 100.00\n",
      "Train Epoch: 246 [30720/50000 (68%)]\tLoss: 0.014944, Accuracy: 99.41\n",
      "Train Epoch: 246 [33280/50000 (74%)]\tLoss: 0.003413, Accuracy: 100.00\n",
      "Train Epoch: 246 [35840/50000 (80%)]\tLoss: 0.002000, Accuracy: 100.00\n",
      "Train Epoch: 246 [38400/50000 (85%)]\tLoss: 0.001767, Accuracy: 100.00\n",
      "Train Epoch: 246 [40960/50000 (91%)]\tLoss: 0.002951, Accuracy: 100.00\n",
      "Train Epoch: 246 [43520/50000 (97%)]\tLoss: 0.004982, Accuracy: 99.80\n",
      "\n",
      "Validation set: Average loss: 0.3711, Accuracy: 4609/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[36.3037109375 s]\n",
      "\n",
      "Test set: Average loss: 0.3963, Accuracy: 9196/10000 (91.96%)\n",
      "\n",
      "Train Epoch: 247 [0/50000 (0%)]\tLoss: 0.003007, Accuracy: 100.00\n",
      "Train Epoch: 247 [2560/50000 (6%)]\tLoss: 0.002355, Accuracy: 100.00\n",
      "Train Epoch: 247 [5120/50000 (11%)]\tLoss: 0.005455, Accuracy: 99.80\n",
      "Train Epoch: 247 [7680/50000 (17%)]\tLoss: 0.002465, Accuracy: 100.00\n",
      "Train Epoch: 247 [10240/50000 (23%)]\tLoss: 0.002704, Accuracy: 100.00\n",
      "Train Epoch: 247 [12800/50000 (28%)]\tLoss: 0.004096, Accuracy: 100.00\n",
      "Train Epoch: 247 [15360/50000 (34%)]\tLoss: 0.001981, Accuracy: 100.00\n",
      "Train Epoch: 247 [17920/50000 (40%)]\tLoss: 0.001588, Accuracy: 100.00\n",
      "Train Epoch: 247 [20480/50000 (45%)]\tLoss: 0.004673, Accuracy: 100.00\n",
      "Train Epoch: 247 [23040/50000 (51%)]\tLoss: 0.003997, Accuracy: 100.00\n",
      "Train Epoch: 247 [25600/50000 (57%)]\tLoss: 0.002984, Accuracy: 100.00\n",
      "Train Epoch: 247 [28160/50000 (62%)]\tLoss: 0.002707, Accuracy: 100.00\n",
      "Train Epoch: 247 [30720/50000 (68%)]\tLoss: 0.001745, Accuracy: 100.00\n",
      "Train Epoch: 247 [33280/50000 (74%)]\tLoss: 0.001704, Accuracy: 100.00\n",
      "Train Epoch: 247 [35840/50000 (80%)]\tLoss: 0.010544, Accuracy: 99.80\n",
      "Train Epoch: 247 [38400/50000 (85%)]\tLoss: 0.002010, Accuracy: 100.00\n",
      "Train Epoch: 247 [40960/50000 (91%)]\tLoss: 0.004663, Accuracy: 100.00\n",
      "Train Epoch: 247 [43520/50000 (97%)]\tLoss: 0.005293, Accuracy: 99.80\n",
      "\n",
      "Validation set: Average loss: 0.3728, Accuracy: 4611/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[39.344990730285645 s]\n",
      "Train Epoch: 248 [0/50000 (0%)]\tLoss: 0.003105, Accuracy: 100.00\n",
      "Train Epoch: 248 [2560/50000 (6%)]\tLoss: 0.003353, Accuracy: 100.00\n",
      "Train Epoch: 248 [5120/50000 (11%)]\tLoss: 0.006796, Accuracy: 99.80\n",
      "Train Epoch: 248 [7680/50000 (17%)]\tLoss: 0.002222, Accuracy: 100.00\n",
      "Train Epoch: 248 [10240/50000 (23%)]\tLoss: 0.014713, Accuracy: 99.61\n",
      "Train Epoch: 248 [12800/50000 (28%)]\tLoss: 0.002912, Accuracy: 100.00\n",
      "Train Epoch: 248 [15360/50000 (34%)]\tLoss: 0.003730, Accuracy: 100.00\n",
      "Train Epoch: 248 [17920/50000 (40%)]\tLoss: 0.001183, Accuracy: 100.00\n",
      "Train Epoch: 248 [20480/50000 (45%)]\tLoss: 0.002229, Accuracy: 100.00\n",
      "Train Epoch: 248 [23040/50000 (51%)]\tLoss: 0.002476, Accuracy: 100.00\n",
      "Train Epoch: 248 [25600/50000 (57%)]\tLoss: 0.003706, Accuracy: 100.00\n",
      "Train Epoch: 248 [28160/50000 (62%)]\tLoss: 0.004538, Accuracy: 100.00\n",
      "Train Epoch: 248 [30720/50000 (68%)]\tLoss: 0.003994, Accuracy: 100.00\n",
      "Train Epoch: 248 [33280/50000 (74%)]\tLoss: 0.007513, Accuracy: 99.80\n",
      "Train Epoch: 248 [35840/50000 (80%)]\tLoss: 0.009387, Accuracy: 99.61\n",
      "Train Epoch: 248 [38400/50000 (85%)]\tLoss: 0.005677, Accuracy: 99.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 248 [40960/50000 (91%)]\tLoss: 0.002805, Accuracy: 100.00\n",
      "Train Epoch: 248 [43520/50000 (97%)]\tLoss: 0.003480, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3650, Accuracy: 4617/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[35.94659876823425 s]\n",
      "\n",
      "Test set: Average loss: 0.3907, Accuracy: 9193/10000 (91.93%)\n",
      "\n",
      "Train Epoch: 249 [0/50000 (0%)]\tLoss: 0.006565, Accuracy: 99.80\n",
      "Train Epoch: 249 [2560/50000 (6%)]\tLoss: 0.001817, Accuracy: 100.00\n",
      "Train Epoch: 249 [5120/50000 (11%)]\tLoss: 0.008137, Accuracy: 99.61\n",
      "Train Epoch: 249 [7680/50000 (17%)]\tLoss: 0.005168, Accuracy: 100.00\n",
      "Train Epoch: 249 [10240/50000 (23%)]\tLoss: 0.005722, Accuracy: 99.80\n",
      "Train Epoch: 249 [12800/50000 (28%)]\tLoss: 0.002275, Accuracy: 100.00\n",
      "Train Epoch: 249 [15360/50000 (34%)]\tLoss: 0.005633, Accuracy: 100.00\n",
      "Train Epoch: 249 [17920/50000 (40%)]\tLoss: 0.007291, Accuracy: 99.80\n",
      "Train Epoch: 249 [20480/50000 (45%)]\tLoss: 0.002038, Accuracy: 100.00\n",
      "Train Epoch: 249 [23040/50000 (51%)]\tLoss: 0.002422, Accuracy: 100.00\n",
      "Train Epoch: 249 [25600/50000 (57%)]\tLoss: 0.003977, Accuracy: 100.00\n",
      "Train Epoch: 249 [28160/50000 (62%)]\tLoss: 0.002846, Accuracy: 100.00\n",
      "Train Epoch: 249 [30720/50000 (68%)]\tLoss: 0.001721, Accuracy: 100.00\n",
      "Train Epoch: 249 [33280/50000 (74%)]\tLoss: 0.003643, Accuracy: 100.00\n",
      "Train Epoch: 249 [35840/50000 (80%)]\tLoss: 0.001506, Accuracy: 100.00\n",
      "Train Epoch: 249 [38400/50000 (85%)]\tLoss: 0.004656, Accuracy: 99.80\n",
      "Train Epoch: 249 [40960/50000 (91%)]\tLoss: 0.003141, Accuracy: 100.00\n",
      "Train Epoch: 249 [43520/50000 (97%)]\tLoss: 0.001580, Accuracy: 100.00\n",
      "\n",
      "Validation set: Average loss: 0.3632, Accuracy: 4626/5000 (92.00%)\n",
      "\n",
      "the time of this epoch:[39.443925619125366 s]\n",
      "\n",
      "Test set: Average loss: 0.3952, Accuracy: 9204/10000 (92.04%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fantastic logger for tensorboard and pytorch, \n",
    "# run tensorboard by opening a new terminal and run \"tensorboard --logdir runs\"\n",
    "# open tensorboard at http://localhost:6006/\n",
    "from tensorboardX import SummaryWriter\n",
    "best_loss = None\n",
    "best_acc = None\n",
    "\n",
    "import time \n",
    "SINCE=time.time()\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    train(epoch)\n",
    "    \n",
    "    loss, accuracy = validate(epoch)\n",
    "    best_loss, best_acc = save_best(loss, accuracy, best_loss, best_acc)\n",
    "    \n",
    "    NOW=time.time() \n",
    "    DURINGS=NOW-SINCE\n",
    "    SINCE=NOW\n",
    "    print(\"the time of this epoch:[{} s]\".format(DURINGS))\n",
    "    \n",
    "    if epoch>=10 and (epoch-10)%2==0:\n",
    "        test(epoch)\n",
    "    \n",
    "# writer = SummaryWriter() \n",
    "# writer.export_scalars_to_json(\"./all_scalars.json\")\n",
    "\n",
    "# writer.close()\n",
    "\n",
    "#---------------------------- Test ------------------------------\n",
    "test(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6902, Accuracy: 8877/10000 (88.77%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一次 scale 位于[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](http://op4a94iq8.bkt.clouddn.com/18-7-14/70206949.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x9BnCF17x72RAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhLQQijshhLQQijshhLQQijshhLSQ/w9isHt8TVxEXQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 查看训练过程的信息\n",
    "import  matplotlib.pyplot as plt\n",
    "\n",
    "def parse(in_file,flag):\n",
    "    num=-1\n",
    "    ys=list()\n",
    "    xs=list()\n",
    "    losses=list()\n",
    "    with open(in_file,\"r\") as reader:\n",
    "        for aLine in reader:\n",
    "            #print(aLine)\n",
    "\n",
    "            res=[e for e in aLine.strip('\\n').split(\" \")]\n",
    "            if res[0]==\"Train\" and flag==\"Train\":\n",
    "                num=num+1\n",
    "                ys.append(float(res[-1]))\n",
    "                xs.append(int(num))\n",
    "                losses.append(float(res[-3].split(',')[0]))\n",
    "            if res[0]==\"Validation\" and flag==\"Validation\":\n",
    "                num=num+1\n",
    "                xs.append(int(num))\n",
    "                tmp=[float(e) for e in res[-2].split('/')]\n",
    "                ys.append(100*float(tmp[0]/tmp[1]))\n",
    "                losses.append(float(res[-4].split(',')[0]))\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot(xs,ys,'ro')\n",
    "\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.plot(xs, losses, 'ro')\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    in_file=\"D://INFO.txt\"\n",
    "    # 显示训练阶段的正确率和Loss信息\n",
    "    parse(in_file,\"Train\") # \"Validation\"\n",
    "    # 显示验证阶段的正确率和Loss信息\n",
    "    #parse(in_file,\"Validation\") # \"Validation\"\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naRBY0BmGYRqE/w/U/zxNDJVCvAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngFDcCSGkAaG4E0JIA0JxJ4SQBuT/AHC9SchdaANwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDuAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wPtS+GMghk59AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 查看训练过程的信息\n",
    "import  matplotlib.pyplot as plt\n",
    "\n",
    "def parse(in_file,flag):\n",
    "    num=-1\n",
    "    ys=list()\n",
    "    xs=list()\n",
    "    losses=list()\n",
    "    with open(in_file,\"r\") as reader:\n",
    "        for aLine in reader:\n",
    "            #print(aLine)\n",
    "\n",
    "            res=[e for e in aLine.strip('\\n').split(\" \")]\n",
    "            if res[0]==\"Train\" and flag==\"Train\":\n",
    "                num=num+1\n",
    "                ys.append(float(res[-1]))\n",
    "                xs.append(int(num))\n",
    "                losses.append(float(res[-3].split(',')[0]))\n",
    "            if res[0]==\"Validation\" and flag==\"Validation\":\n",
    "                num=num+1\n",
    "                xs.append(int(num))\n",
    "                tmp=[float(e) for e in res[-2].split('/')]\n",
    "                ys.append(100*float(tmp[0]/tmp[1]))\n",
    "                losses.append(float(res[-4].split(',')[0]))\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot(xs,ys,'r-')\n",
    "\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.plot(xs, losses, 'r-')\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    in_file=\"D://INFO.txt\"\n",
    "    # 显示训练阶段的正确率和Loss信息\n",
    "    parse(in_file,\"Train\") # \"Validation\"\n",
    "    # 显示验证阶段的正确率和Loss信息\n",
    "    parse(in_file,\"Validation\") # \"Validation\"\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
